
struct pyopencv_AKAZE_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_AKAZE_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".AKAZE",
    sizeof(pyopencv_AKAZE_t),
};

static void pyopencv_AKAZE_dealloc(PyObject* self)
{
    ((pyopencv_AKAZE_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::AKAZE>& r)
{
    pyopencv_AKAZE_t *m = PyObject_NEW(pyopencv_AKAZE_t, &pyopencv_AKAZE_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::AKAZE>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_AKAZE_Type))
    {
        failmsg("Expected cv::AKAZE for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_AKAZE_t*)src)->v.dynamicCast<cv::AKAZE>();
    return true;
}


struct pyopencv_AffineTransformer_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_AffineTransformer_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".AffineTransformer",
    sizeof(pyopencv_AffineTransformer_t),
};

static void pyopencv_AffineTransformer_dealloc(PyObject* self)
{
    ((pyopencv_AffineTransformer_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::AffineTransformer>& r)
{
    pyopencv_AffineTransformer_t *m = PyObject_NEW(pyopencv_AffineTransformer_t, &pyopencv_AffineTransformer_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::AffineTransformer>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_AffineTransformer_Type))
    {
        failmsg("Expected cv::AffineTransformer for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_AffineTransformer_t*)src)->v.dynamicCast<cv::AffineTransformer>();
    return true;
}


struct pyopencv_AgastFeatureDetector_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_AgastFeatureDetector_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".AgastFeatureDetector",
    sizeof(pyopencv_AgastFeatureDetector_t),
};

static void pyopencv_AgastFeatureDetector_dealloc(PyObject* self)
{
    ((pyopencv_AgastFeatureDetector_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::AgastFeatureDetector>& r)
{
    pyopencv_AgastFeatureDetector_t *m = PyObject_NEW(pyopencv_AgastFeatureDetector_t, &pyopencv_AgastFeatureDetector_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::AgastFeatureDetector>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_AgastFeatureDetector_Type))
    {
        failmsg("Expected cv::AgastFeatureDetector for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_AgastFeatureDetector_t*)src)->v.dynamicCast<cv::AgastFeatureDetector>();
    return true;
}


struct pyopencv_Algorithm_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_Algorithm_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".Algorithm",
    sizeof(pyopencv_Algorithm_t),
};

static void pyopencv_Algorithm_dealloc(PyObject* self)
{
    ((pyopencv_Algorithm_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::Algorithm>& r)
{
    pyopencv_Algorithm_t *m = PyObject_NEW(pyopencv_Algorithm_t, &pyopencv_Algorithm_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::Algorithm>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_Algorithm_Type))
    {
        failmsg("Expected cv::Algorithm for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_Algorithm_t*)src)->v.dynamicCast<cv::Algorithm>();
    return true;
}


struct pyopencv_AlignExposures_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_AlignExposures_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".AlignExposures",
    sizeof(pyopencv_AlignExposures_t),
};

static void pyopencv_AlignExposures_dealloc(PyObject* self)
{
    ((pyopencv_AlignExposures_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::AlignExposures>& r)
{
    pyopencv_AlignExposures_t *m = PyObject_NEW(pyopencv_AlignExposures_t, &pyopencv_AlignExposures_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::AlignExposures>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_AlignExposures_Type))
    {
        failmsg("Expected cv::AlignExposures for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_AlignExposures_t*)src)->v.dynamicCast<cv::AlignExposures>();
    return true;
}


struct pyopencv_AlignMTB_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_AlignMTB_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".AlignMTB",
    sizeof(pyopencv_AlignMTB_t),
};

static void pyopencv_AlignMTB_dealloc(PyObject* self)
{
    ((pyopencv_AlignMTB_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::AlignMTB>& r)
{
    pyopencv_AlignMTB_t *m = PyObject_NEW(pyopencv_AlignMTB_t, &pyopencv_AlignMTB_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::AlignMTB>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_AlignMTB_Type))
    {
        failmsg("Expected cv::AlignMTB for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_AlignMTB_t*)src)->v.dynamicCast<cv::AlignMTB>();
    return true;
}


struct pyopencv_BFMatcher_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_BFMatcher_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".BFMatcher",
    sizeof(pyopencv_BFMatcher_t),
};

static void pyopencv_BFMatcher_dealloc(PyObject* self)
{
    ((pyopencv_BFMatcher_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::BFMatcher>& r)
{
    pyopencv_BFMatcher_t *m = PyObject_NEW(pyopencv_BFMatcher_t, &pyopencv_BFMatcher_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::BFMatcher>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_BFMatcher_Type))
    {
        failmsg("Expected cv::BFMatcher for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_BFMatcher_t*)src)->v.dynamicCast<cv::BFMatcher>();
    return true;
}


struct pyopencv_BOWImgDescriptorExtractor_t
{
    PyObject_HEAD
    Ptr<cv::BOWImgDescriptorExtractor> v;
};

static PyTypeObject pyopencv_BOWImgDescriptorExtractor_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".BOWImgDescriptorExtractor",
    sizeof(pyopencv_BOWImgDescriptorExtractor_t),
};

static void pyopencv_BOWImgDescriptorExtractor_dealloc(PyObject* self)
{
    ((pyopencv_BOWImgDescriptorExtractor_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::BOWImgDescriptorExtractor>& r)
{
    pyopencv_BOWImgDescriptorExtractor_t *m = PyObject_NEW(pyopencv_BOWImgDescriptorExtractor_t, &pyopencv_BOWImgDescriptorExtractor_Type);
    new (&(m->v)) Ptr<cv::BOWImgDescriptorExtractor>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::BOWImgDescriptorExtractor>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_BOWImgDescriptorExtractor_Type))
    {
        failmsg("Expected cv::BOWImgDescriptorExtractor for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_BOWImgDescriptorExtractor_t*)src)->v.dynamicCast<cv::BOWImgDescriptorExtractor>();
    return true;
}


struct pyopencv_BOWKMeansTrainer_t
{
    PyObject_HEAD
    Ptr<cv::BOWKMeansTrainer> v;
};

static PyTypeObject pyopencv_BOWKMeansTrainer_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".BOWKMeansTrainer",
    sizeof(pyopencv_BOWKMeansTrainer_t),
};

static void pyopencv_BOWKMeansTrainer_dealloc(PyObject* self)
{
    ((pyopencv_BOWKMeansTrainer_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::BOWKMeansTrainer>& r)
{
    pyopencv_BOWKMeansTrainer_t *m = PyObject_NEW(pyopencv_BOWKMeansTrainer_t, &pyopencv_BOWKMeansTrainer_Type);
    new (&(m->v)) Ptr<cv::BOWKMeansTrainer>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::BOWKMeansTrainer>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_BOWKMeansTrainer_Type))
    {
        failmsg("Expected cv::BOWKMeansTrainer for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_BOWKMeansTrainer_t*)src)->v.dynamicCast<cv::BOWKMeansTrainer>();
    return true;
}


struct pyopencv_BOWTrainer_t
{
    PyObject_HEAD
    Ptr<cv::BOWTrainer> v;
};

static PyTypeObject pyopencv_BOWTrainer_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".BOWTrainer",
    sizeof(pyopencv_BOWTrainer_t),
};

static void pyopencv_BOWTrainer_dealloc(PyObject* self)
{
    ((pyopencv_BOWTrainer_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::BOWTrainer>& r)
{
    pyopencv_BOWTrainer_t *m = PyObject_NEW(pyopencv_BOWTrainer_t, &pyopencv_BOWTrainer_Type);
    new (&(m->v)) Ptr<cv::BOWTrainer>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::BOWTrainer>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_BOWTrainer_Type))
    {
        failmsg("Expected cv::BOWTrainer for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_BOWTrainer_t*)src)->v.dynamicCast<cv::BOWTrainer>();
    return true;
}


struct pyopencv_BRISK_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_BRISK_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".BRISK",
    sizeof(pyopencv_BRISK_t),
};

static void pyopencv_BRISK_dealloc(PyObject* self)
{
    ((pyopencv_BRISK_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::BRISK>& r)
{
    pyopencv_BRISK_t *m = PyObject_NEW(pyopencv_BRISK_t, &pyopencv_BRISK_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::BRISK>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_BRISK_Type))
    {
        failmsg("Expected cv::BRISK for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_BRISK_t*)src)->v.dynamicCast<cv::BRISK>();
    return true;
}


struct pyopencv_BackgroundSubtractor_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_BackgroundSubtractor_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".BackgroundSubtractor",
    sizeof(pyopencv_BackgroundSubtractor_t),
};

static void pyopencv_BackgroundSubtractor_dealloc(PyObject* self)
{
    ((pyopencv_BackgroundSubtractor_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::BackgroundSubtractor>& r)
{
    pyopencv_BackgroundSubtractor_t *m = PyObject_NEW(pyopencv_BackgroundSubtractor_t, &pyopencv_BackgroundSubtractor_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::BackgroundSubtractor>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_BackgroundSubtractor_Type))
    {
        failmsg("Expected cv::BackgroundSubtractor for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_BackgroundSubtractor_t*)src)->v.dynamicCast<cv::BackgroundSubtractor>();
    return true;
}


struct pyopencv_BackgroundSubtractorKNN_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_BackgroundSubtractorKNN_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".BackgroundSubtractorKNN",
    sizeof(pyopencv_BackgroundSubtractorKNN_t),
};

static void pyopencv_BackgroundSubtractorKNN_dealloc(PyObject* self)
{
    ((pyopencv_BackgroundSubtractorKNN_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::BackgroundSubtractorKNN>& r)
{
    pyopencv_BackgroundSubtractorKNN_t *m = PyObject_NEW(pyopencv_BackgroundSubtractorKNN_t, &pyopencv_BackgroundSubtractorKNN_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::BackgroundSubtractorKNN>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_BackgroundSubtractorKNN_Type))
    {
        failmsg("Expected cv::BackgroundSubtractorKNN for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_BackgroundSubtractorKNN_t*)src)->v.dynamicCast<cv::BackgroundSubtractorKNN>();
    return true;
}


struct pyopencv_BackgroundSubtractorMOG2_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_BackgroundSubtractorMOG2_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".BackgroundSubtractorMOG2",
    sizeof(pyopencv_BackgroundSubtractorMOG2_t),
};

static void pyopencv_BackgroundSubtractorMOG2_dealloc(PyObject* self)
{
    ((pyopencv_BackgroundSubtractorMOG2_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::BackgroundSubtractorMOG2>& r)
{
    pyopencv_BackgroundSubtractorMOG2_t *m = PyObject_NEW(pyopencv_BackgroundSubtractorMOG2_t, &pyopencv_BackgroundSubtractorMOG2_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::BackgroundSubtractorMOG2>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_BackgroundSubtractorMOG2_Type))
    {
        failmsg("Expected cv::BackgroundSubtractorMOG2 for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_BackgroundSubtractorMOG2_t*)src)->v.dynamicCast<cv::BackgroundSubtractorMOG2>();
    return true;
}


struct pyopencv_BaseCascadeClassifier_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_BaseCascadeClassifier_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".BaseCascadeClassifier",
    sizeof(pyopencv_BaseCascadeClassifier_t),
};

static void pyopencv_BaseCascadeClassifier_dealloc(PyObject* self)
{
    ((pyopencv_BaseCascadeClassifier_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::BaseCascadeClassifier>& r)
{
    pyopencv_BaseCascadeClassifier_t *m = PyObject_NEW(pyopencv_BaseCascadeClassifier_t, &pyopencv_BaseCascadeClassifier_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::BaseCascadeClassifier>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_BaseCascadeClassifier_Type))
    {
        failmsg("Expected cv::BaseCascadeClassifier for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_BaseCascadeClassifier_t*)src)->v.dynamicCast<cv::BaseCascadeClassifier>();
    return true;
}


struct pyopencv_CLAHE_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_CLAHE_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".CLAHE",
    sizeof(pyopencv_CLAHE_t),
};

static void pyopencv_CLAHE_dealloc(PyObject* self)
{
    ((pyopencv_CLAHE_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::CLAHE>& r)
{
    pyopencv_CLAHE_t *m = PyObject_NEW(pyopencv_CLAHE_t, &pyopencv_CLAHE_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::CLAHE>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_CLAHE_Type))
    {
        failmsg("Expected cv::CLAHE for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_CLAHE_t*)src)->v.dynamicCast<cv::CLAHE>();
    return true;
}


struct pyopencv_CalibrateCRF_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_CalibrateCRF_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".CalibrateCRF",
    sizeof(pyopencv_CalibrateCRF_t),
};

static void pyopencv_CalibrateCRF_dealloc(PyObject* self)
{
    ((pyopencv_CalibrateCRF_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::CalibrateCRF>& r)
{
    pyopencv_CalibrateCRF_t *m = PyObject_NEW(pyopencv_CalibrateCRF_t, &pyopencv_CalibrateCRF_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::CalibrateCRF>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_CalibrateCRF_Type))
    {
        failmsg("Expected cv::CalibrateCRF for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_CalibrateCRF_t*)src)->v.dynamicCast<cv::CalibrateCRF>();
    return true;
}


struct pyopencv_CalibrateDebevec_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_CalibrateDebevec_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".CalibrateDebevec",
    sizeof(pyopencv_CalibrateDebevec_t),
};

static void pyopencv_CalibrateDebevec_dealloc(PyObject* self)
{
    ((pyopencv_CalibrateDebevec_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::CalibrateDebevec>& r)
{
    pyopencv_CalibrateDebevec_t *m = PyObject_NEW(pyopencv_CalibrateDebevec_t, &pyopencv_CalibrateDebevec_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::CalibrateDebevec>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_CalibrateDebevec_Type))
    {
        failmsg("Expected cv::CalibrateDebevec for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_CalibrateDebevec_t*)src)->v.dynamicCast<cv::CalibrateDebevec>();
    return true;
}


struct pyopencv_CalibrateRobertson_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_CalibrateRobertson_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".CalibrateRobertson",
    sizeof(pyopencv_CalibrateRobertson_t),
};

static void pyopencv_CalibrateRobertson_dealloc(PyObject* self)
{
    ((pyopencv_CalibrateRobertson_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::CalibrateRobertson>& r)
{
    pyopencv_CalibrateRobertson_t *m = PyObject_NEW(pyopencv_CalibrateRobertson_t, &pyopencv_CalibrateRobertson_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::CalibrateRobertson>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_CalibrateRobertson_Type))
    {
        failmsg("Expected cv::CalibrateRobertson for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_CalibrateRobertson_t*)src)->v.dynamicCast<cv::CalibrateRobertson>();
    return true;
}


struct pyopencv_CascadeClassifier_t
{
    PyObject_HEAD
    Ptr<cv::CascadeClassifier> v;
};

static PyTypeObject pyopencv_CascadeClassifier_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".CascadeClassifier",
    sizeof(pyopencv_CascadeClassifier_t),
};

static void pyopencv_CascadeClassifier_dealloc(PyObject* self)
{
    ((pyopencv_CascadeClassifier_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::CascadeClassifier>& r)
{
    pyopencv_CascadeClassifier_t *m = PyObject_NEW(pyopencv_CascadeClassifier_t, &pyopencv_CascadeClassifier_Type);
    new (&(m->v)) Ptr<cv::CascadeClassifier>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::CascadeClassifier>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_CascadeClassifier_Type))
    {
        failmsg("Expected cv::CascadeClassifier for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_CascadeClassifier_t*)src)->v.dynamicCast<cv::CascadeClassifier>();
    return true;
}


struct pyopencv_ChiHistogramCostExtractor_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_ChiHistogramCostExtractor_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".ChiHistogramCostExtractor",
    sizeof(pyopencv_ChiHistogramCostExtractor_t),
};

static void pyopencv_ChiHistogramCostExtractor_dealloc(PyObject* self)
{
    ((pyopencv_ChiHistogramCostExtractor_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::ChiHistogramCostExtractor>& r)
{
    pyopencv_ChiHistogramCostExtractor_t *m = PyObject_NEW(pyopencv_ChiHistogramCostExtractor_t, &pyopencv_ChiHistogramCostExtractor_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::ChiHistogramCostExtractor>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_ChiHistogramCostExtractor_Type))
    {
        failmsg("Expected cv::ChiHistogramCostExtractor for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_ChiHistogramCostExtractor_t*)src)->v.dynamicCast<cv::ChiHistogramCostExtractor>();
    return true;
}


struct pyopencv_DMatch_t
{
    PyObject_HEAD
    cv::DMatch v;
};

static PyTypeObject pyopencv_DMatch_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".DMatch",
    sizeof(pyopencv_DMatch_t),
};

static void pyopencv_DMatch_dealloc(PyObject* self)
{
    ((pyopencv_DMatch_t*)self)->v.cv::DMatch::~DMatch();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const cv::DMatch& r)
{
    pyopencv_DMatch_t *m = PyObject_NEW(pyopencv_DMatch_t, &pyopencv_DMatch_Type);
    new (&m->v) cv::DMatch(r); //Copy constructor
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, cv::DMatch& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_DMatch_Type))
    {
        failmsg("Expected cv::DMatch for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_DMatch_t*)src)->v;
    return true;
}

struct pyopencv_DenseOpticalFlow_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_DenseOpticalFlow_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".DenseOpticalFlow",
    sizeof(pyopencv_DenseOpticalFlow_t),
};

static void pyopencv_DenseOpticalFlow_dealloc(PyObject* self)
{
    ((pyopencv_DenseOpticalFlow_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::DenseOpticalFlow>& r)
{
    pyopencv_DenseOpticalFlow_t *m = PyObject_NEW(pyopencv_DenseOpticalFlow_t, &pyopencv_DenseOpticalFlow_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::DenseOpticalFlow>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_DenseOpticalFlow_Type))
    {
        failmsg("Expected cv::DenseOpticalFlow for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_DenseOpticalFlow_t*)src)->v.dynamicCast<cv::DenseOpticalFlow>();
    return true;
}


struct pyopencv_DescriptorMatcher_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_DescriptorMatcher_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".DescriptorMatcher",
    sizeof(pyopencv_DescriptorMatcher_t),
};

static void pyopencv_DescriptorMatcher_dealloc(PyObject* self)
{
    ((pyopencv_DescriptorMatcher_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::DescriptorMatcher>& r)
{
    pyopencv_DescriptorMatcher_t *m = PyObject_NEW(pyopencv_DescriptorMatcher_t, &pyopencv_DescriptorMatcher_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::DescriptorMatcher>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_DescriptorMatcher_Type))
    {
        failmsg("Expected cv::DescriptorMatcher for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_DescriptorMatcher_t*)src)->v.dynamicCast<cv::DescriptorMatcher>();
    return true;
}


struct pyopencv_DualTVL1OpticalFlow_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_DualTVL1OpticalFlow_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".DualTVL1OpticalFlow",
    sizeof(pyopencv_DualTVL1OpticalFlow_t),
};

static void pyopencv_DualTVL1OpticalFlow_dealloc(PyObject* self)
{
    ((pyopencv_DualTVL1OpticalFlow_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::DualTVL1OpticalFlow>& r)
{
    pyopencv_DualTVL1OpticalFlow_t *m = PyObject_NEW(pyopencv_DualTVL1OpticalFlow_t, &pyopencv_DualTVL1OpticalFlow_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::DualTVL1OpticalFlow>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_DualTVL1OpticalFlow_Type))
    {
        failmsg("Expected cv::DualTVL1OpticalFlow for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_DualTVL1OpticalFlow_t*)src)->v.dynamicCast<cv::DualTVL1OpticalFlow>();
    return true;
}


struct pyopencv_EMDHistogramCostExtractor_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_EMDHistogramCostExtractor_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".EMDHistogramCostExtractor",
    sizeof(pyopencv_EMDHistogramCostExtractor_t),
};

static void pyopencv_EMDHistogramCostExtractor_dealloc(PyObject* self)
{
    ((pyopencv_EMDHistogramCostExtractor_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::EMDHistogramCostExtractor>& r)
{
    pyopencv_EMDHistogramCostExtractor_t *m = PyObject_NEW(pyopencv_EMDHistogramCostExtractor_t, &pyopencv_EMDHistogramCostExtractor_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::EMDHistogramCostExtractor>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_EMDHistogramCostExtractor_Type))
    {
        failmsg("Expected cv::EMDHistogramCostExtractor for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_EMDHistogramCostExtractor_t*)src)->v.dynamicCast<cv::EMDHistogramCostExtractor>();
    return true;
}


struct pyopencv_EMDL1HistogramCostExtractor_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_EMDL1HistogramCostExtractor_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".EMDL1HistogramCostExtractor",
    sizeof(pyopencv_EMDL1HistogramCostExtractor_t),
};

static void pyopencv_EMDL1HistogramCostExtractor_dealloc(PyObject* self)
{
    ((pyopencv_EMDL1HistogramCostExtractor_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::EMDL1HistogramCostExtractor>& r)
{
    pyopencv_EMDL1HistogramCostExtractor_t *m = PyObject_NEW(pyopencv_EMDL1HistogramCostExtractor_t, &pyopencv_EMDL1HistogramCostExtractor_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::EMDL1HistogramCostExtractor>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_EMDL1HistogramCostExtractor_Type))
    {
        failmsg("Expected cv::EMDL1HistogramCostExtractor for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_EMDL1HistogramCostExtractor_t*)src)->v.dynamicCast<cv::EMDL1HistogramCostExtractor>();
    return true;
}


struct pyopencv_FarnebackOpticalFlow_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_FarnebackOpticalFlow_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".FarnebackOpticalFlow",
    sizeof(pyopencv_FarnebackOpticalFlow_t),
};

static void pyopencv_FarnebackOpticalFlow_dealloc(PyObject* self)
{
    ((pyopencv_FarnebackOpticalFlow_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::FarnebackOpticalFlow>& r)
{
    pyopencv_FarnebackOpticalFlow_t *m = PyObject_NEW(pyopencv_FarnebackOpticalFlow_t, &pyopencv_FarnebackOpticalFlow_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::FarnebackOpticalFlow>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_FarnebackOpticalFlow_Type))
    {
        failmsg("Expected cv::FarnebackOpticalFlow for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_FarnebackOpticalFlow_t*)src)->v.dynamicCast<cv::FarnebackOpticalFlow>();
    return true;
}


struct pyopencv_FastFeatureDetector_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_FastFeatureDetector_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".FastFeatureDetector",
    sizeof(pyopencv_FastFeatureDetector_t),
};

static void pyopencv_FastFeatureDetector_dealloc(PyObject* self)
{
    ((pyopencv_FastFeatureDetector_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::FastFeatureDetector>& r)
{
    pyopencv_FastFeatureDetector_t *m = PyObject_NEW(pyopencv_FastFeatureDetector_t, &pyopencv_FastFeatureDetector_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::FastFeatureDetector>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_FastFeatureDetector_Type))
    {
        failmsg("Expected cv::FastFeatureDetector for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_FastFeatureDetector_t*)src)->v.dynamicCast<cv::FastFeatureDetector>();
    return true;
}


struct pyopencv_Feature2D_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_Feature2D_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".Feature2D",
    sizeof(pyopencv_Feature2D_t),
};

static void pyopencv_Feature2D_dealloc(PyObject* self)
{
    ((pyopencv_Feature2D_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::Feature2D>& r)
{
    pyopencv_Feature2D_t *m = PyObject_NEW(pyopencv_Feature2D_t, &pyopencv_Feature2D_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::Feature2D>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_Feature2D_Type))
    {
        failmsg("Expected cv::Feature2D for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_Feature2D_t*)src)->v.dynamicCast<cv::Feature2D>();
    return true;
}


struct pyopencv_FileNode_t
{
    PyObject_HEAD
    cv::FileNode v;
};

static PyTypeObject pyopencv_FileNode_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".FileNode",
    sizeof(pyopencv_FileNode_t),
};

static void pyopencv_FileNode_dealloc(PyObject* self)
{
    ((pyopencv_FileNode_t*)self)->v.cv::FileNode::~FileNode();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const cv::FileNode& r)
{
    pyopencv_FileNode_t *m = PyObject_NEW(pyopencv_FileNode_t, &pyopencv_FileNode_Type);
    new (&m->v) cv::FileNode(r); //Copy constructor
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, cv::FileNode& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_FileNode_Type))
    {
        failmsg("Expected cv::FileNode for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_FileNode_t*)src)->v;
    return true;
}

struct pyopencv_FileStorage_t
{
    PyObject_HEAD
    Ptr<cv::FileStorage> v;
};

static PyTypeObject pyopencv_FileStorage_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".FileStorage",
    sizeof(pyopencv_FileStorage_t),
};

static void pyopencv_FileStorage_dealloc(PyObject* self)
{
    ((pyopencv_FileStorage_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::FileStorage>& r)
{
    pyopencv_FileStorage_t *m = PyObject_NEW(pyopencv_FileStorage_t, &pyopencv_FileStorage_Type);
    new (&(m->v)) Ptr<cv::FileStorage>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::FileStorage>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_FileStorage_Type))
    {
        failmsg("Expected cv::FileStorage for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_FileStorage_t*)src)->v.dynamicCast<cv::FileStorage>();
    return true;
}


struct pyopencv_FlannBasedMatcher_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_FlannBasedMatcher_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".FlannBasedMatcher",
    sizeof(pyopencv_FlannBasedMatcher_t),
};

static void pyopencv_FlannBasedMatcher_dealloc(PyObject* self)
{
    ((pyopencv_FlannBasedMatcher_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::FlannBasedMatcher>& r)
{
    pyopencv_FlannBasedMatcher_t *m = PyObject_NEW(pyopencv_FlannBasedMatcher_t, &pyopencv_FlannBasedMatcher_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::FlannBasedMatcher>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_FlannBasedMatcher_Type))
    {
        failmsg("Expected cv::FlannBasedMatcher for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_FlannBasedMatcher_t*)src)->v.dynamicCast<cv::FlannBasedMatcher>();
    return true;
}


struct pyopencv_GFTTDetector_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_GFTTDetector_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".GFTTDetector",
    sizeof(pyopencv_GFTTDetector_t),
};

static void pyopencv_GFTTDetector_dealloc(PyObject* self)
{
    ((pyopencv_GFTTDetector_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::GFTTDetector>& r)
{
    pyopencv_GFTTDetector_t *m = PyObject_NEW(pyopencv_GFTTDetector_t, &pyopencv_GFTTDetector_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::GFTTDetector>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_GFTTDetector_Type))
    {
        failmsg("Expected cv::GFTTDetector for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_GFTTDetector_t*)src)->v.dynamicCast<cv::GFTTDetector>();
    return true;
}


struct pyopencv_HOGDescriptor_t
{
    PyObject_HEAD
    Ptr<cv::HOGDescriptor> v;
};

static PyTypeObject pyopencv_HOGDescriptor_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".HOGDescriptor",
    sizeof(pyopencv_HOGDescriptor_t),
};

static void pyopencv_HOGDescriptor_dealloc(PyObject* self)
{
    ((pyopencv_HOGDescriptor_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::HOGDescriptor>& r)
{
    pyopencv_HOGDescriptor_t *m = PyObject_NEW(pyopencv_HOGDescriptor_t, &pyopencv_HOGDescriptor_Type);
    new (&(m->v)) Ptr<cv::HOGDescriptor>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::HOGDescriptor>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_HOGDescriptor_Type))
    {
        failmsg("Expected cv::HOGDescriptor for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_HOGDescriptor_t*)src)->v.dynamicCast<cv::HOGDescriptor>();
    return true;
}


struct pyopencv_HausdorffDistanceExtractor_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_HausdorffDistanceExtractor_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".HausdorffDistanceExtractor",
    sizeof(pyopencv_HausdorffDistanceExtractor_t),
};

static void pyopencv_HausdorffDistanceExtractor_dealloc(PyObject* self)
{
    ((pyopencv_HausdorffDistanceExtractor_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::HausdorffDistanceExtractor>& r)
{
    pyopencv_HausdorffDistanceExtractor_t *m = PyObject_NEW(pyopencv_HausdorffDistanceExtractor_t, &pyopencv_HausdorffDistanceExtractor_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::HausdorffDistanceExtractor>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_HausdorffDistanceExtractor_Type))
    {
        failmsg("Expected cv::HausdorffDistanceExtractor for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_HausdorffDistanceExtractor_t*)src)->v.dynamicCast<cv::HausdorffDistanceExtractor>();
    return true;
}


struct pyopencv_HistogramCostExtractor_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_HistogramCostExtractor_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".HistogramCostExtractor",
    sizeof(pyopencv_HistogramCostExtractor_t),
};

static void pyopencv_HistogramCostExtractor_dealloc(PyObject* self)
{
    ((pyopencv_HistogramCostExtractor_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::HistogramCostExtractor>& r)
{
    pyopencv_HistogramCostExtractor_t *m = PyObject_NEW(pyopencv_HistogramCostExtractor_t, &pyopencv_HistogramCostExtractor_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::HistogramCostExtractor>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_HistogramCostExtractor_Type))
    {
        failmsg("Expected cv::HistogramCostExtractor for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_HistogramCostExtractor_t*)src)->v.dynamicCast<cv::HistogramCostExtractor>();
    return true;
}


struct pyopencv_KAZE_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_KAZE_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".KAZE",
    sizeof(pyopencv_KAZE_t),
};

static void pyopencv_KAZE_dealloc(PyObject* self)
{
    ((pyopencv_KAZE_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::KAZE>& r)
{
    pyopencv_KAZE_t *m = PyObject_NEW(pyopencv_KAZE_t, &pyopencv_KAZE_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::KAZE>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_KAZE_Type))
    {
        failmsg("Expected cv::KAZE for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_KAZE_t*)src)->v.dynamicCast<cv::KAZE>();
    return true;
}


struct pyopencv_KalmanFilter_t
{
    PyObject_HEAD
    Ptr<cv::KalmanFilter> v;
};

static PyTypeObject pyopencv_KalmanFilter_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".KalmanFilter",
    sizeof(pyopencv_KalmanFilter_t),
};

static void pyopencv_KalmanFilter_dealloc(PyObject* self)
{
    ((pyopencv_KalmanFilter_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::KalmanFilter>& r)
{
    pyopencv_KalmanFilter_t *m = PyObject_NEW(pyopencv_KalmanFilter_t, &pyopencv_KalmanFilter_Type);
    new (&(m->v)) Ptr<cv::KalmanFilter>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::KalmanFilter>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_KalmanFilter_Type))
    {
        failmsg("Expected cv::KalmanFilter for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_KalmanFilter_t*)src)->v.dynamicCast<cv::KalmanFilter>();
    return true;
}


struct pyopencv_KeyPoint_t
{
    PyObject_HEAD
    cv::KeyPoint v;
};

static PyTypeObject pyopencv_KeyPoint_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".KeyPoint",
    sizeof(pyopencv_KeyPoint_t),
};

static void pyopencv_KeyPoint_dealloc(PyObject* self)
{
    ((pyopencv_KeyPoint_t*)self)->v.cv::KeyPoint::~KeyPoint();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const cv::KeyPoint& r)
{
    pyopencv_KeyPoint_t *m = PyObject_NEW(pyopencv_KeyPoint_t, &pyopencv_KeyPoint_Type);
    new (&m->v) cv::KeyPoint(r); //Copy constructor
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, cv::KeyPoint& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_KeyPoint_Type))
    {
        failmsg("Expected cv::KeyPoint for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_KeyPoint_t*)src)->v;
    return true;
}

struct pyopencv_LineSegmentDetector_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_LineSegmentDetector_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".LineSegmentDetector",
    sizeof(pyopencv_LineSegmentDetector_t),
};

static void pyopencv_LineSegmentDetector_dealloc(PyObject* self)
{
    ((pyopencv_LineSegmentDetector_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::LineSegmentDetector>& r)
{
    pyopencv_LineSegmentDetector_t *m = PyObject_NEW(pyopencv_LineSegmentDetector_t, &pyopencv_LineSegmentDetector_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::LineSegmentDetector>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_LineSegmentDetector_Type))
    {
        failmsg("Expected cv::LineSegmentDetector for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_LineSegmentDetector_t*)src)->v.dynamicCast<cv::LineSegmentDetector>();
    return true;
}


struct pyopencv_MSER_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_MSER_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".MSER",
    sizeof(pyopencv_MSER_t),
};

static void pyopencv_MSER_dealloc(PyObject* self)
{
    ((pyopencv_MSER_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::MSER>& r)
{
    pyopencv_MSER_t *m = PyObject_NEW(pyopencv_MSER_t, &pyopencv_MSER_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::MSER>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_MSER_Type))
    {
        failmsg("Expected cv::MSER for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_MSER_t*)src)->v.dynamicCast<cv::MSER>();
    return true;
}


struct pyopencv_MergeDebevec_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_MergeDebevec_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".MergeDebevec",
    sizeof(pyopencv_MergeDebevec_t),
};

static void pyopencv_MergeDebevec_dealloc(PyObject* self)
{
    ((pyopencv_MergeDebevec_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::MergeDebevec>& r)
{
    pyopencv_MergeDebevec_t *m = PyObject_NEW(pyopencv_MergeDebevec_t, &pyopencv_MergeDebevec_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::MergeDebevec>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_MergeDebevec_Type))
    {
        failmsg("Expected cv::MergeDebevec for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_MergeDebevec_t*)src)->v.dynamicCast<cv::MergeDebevec>();
    return true;
}


struct pyopencv_MergeExposures_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_MergeExposures_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".MergeExposures",
    sizeof(pyopencv_MergeExposures_t),
};

static void pyopencv_MergeExposures_dealloc(PyObject* self)
{
    ((pyopencv_MergeExposures_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::MergeExposures>& r)
{
    pyopencv_MergeExposures_t *m = PyObject_NEW(pyopencv_MergeExposures_t, &pyopencv_MergeExposures_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::MergeExposures>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_MergeExposures_Type))
    {
        failmsg("Expected cv::MergeExposures for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_MergeExposures_t*)src)->v.dynamicCast<cv::MergeExposures>();
    return true;
}


struct pyopencv_MergeMertens_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_MergeMertens_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".MergeMertens",
    sizeof(pyopencv_MergeMertens_t),
};

static void pyopencv_MergeMertens_dealloc(PyObject* self)
{
    ((pyopencv_MergeMertens_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::MergeMertens>& r)
{
    pyopencv_MergeMertens_t *m = PyObject_NEW(pyopencv_MergeMertens_t, &pyopencv_MergeMertens_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::MergeMertens>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_MergeMertens_Type))
    {
        failmsg("Expected cv::MergeMertens for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_MergeMertens_t*)src)->v.dynamicCast<cv::MergeMertens>();
    return true;
}


struct pyopencv_MergeRobertson_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_MergeRobertson_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".MergeRobertson",
    sizeof(pyopencv_MergeRobertson_t),
};

static void pyopencv_MergeRobertson_dealloc(PyObject* self)
{
    ((pyopencv_MergeRobertson_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::MergeRobertson>& r)
{
    pyopencv_MergeRobertson_t *m = PyObject_NEW(pyopencv_MergeRobertson_t, &pyopencv_MergeRobertson_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::MergeRobertson>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_MergeRobertson_Type))
    {
        failmsg("Expected cv::MergeRobertson for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_MergeRobertson_t*)src)->v.dynamicCast<cv::MergeRobertson>();
    return true;
}


template<> bool pyopencv_to(PyObject* src, cv::Moments& dst, const char* name);

struct pyopencv_MultiTracker_t
{
    PyObject_HEAD
    Ptr<cv::MultiTracker> v;
};

static PyTypeObject pyopencv_MultiTracker_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".MultiTracker",
    sizeof(pyopencv_MultiTracker_t),
};

static void pyopencv_MultiTracker_dealloc(PyObject* self)
{
    ((pyopencv_MultiTracker_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::MultiTracker>& r)
{
    pyopencv_MultiTracker_t *m = PyObject_NEW(pyopencv_MultiTracker_t, &pyopencv_MultiTracker_Type);
    new (&(m->v)) Ptr<cv::MultiTracker>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::MultiTracker>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_MultiTracker_Type))
    {
        failmsg("Expected cv::MultiTracker for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_MultiTracker_t*)src)->v.dynamicCast<cv::MultiTracker>();
    return true;
}


struct pyopencv_NormHistogramCostExtractor_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_NormHistogramCostExtractor_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".NormHistogramCostExtractor",
    sizeof(pyopencv_NormHistogramCostExtractor_t),
};

static void pyopencv_NormHistogramCostExtractor_dealloc(PyObject* self)
{
    ((pyopencv_NormHistogramCostExtractor_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::NormHistogramCostExtractor>& r)
{
    pyopencv_NormHistogramCostExtractor_t *m = PyObject_NEW(pyopencv_NormHistogramCostExtractor_t, &pyopencv_NormHistogramCostExtractor_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::NormHistogramCostExtractor>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_NormHistogramCostExtractor_Type))
    {
        failmsg("Expected cv::NormHistogramCostExtractor for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_NormHistogramCostExtractor_t*)src)->v.dynamicCast<cv::NormHistogramCostExtractor>();
    return true;
}


struct pyopencv_ORB_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_ORB_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".ORB",
    sizeof(pyopencv_ORB_t),
};

static void pyopencv_ORB_dealloc(PyObject* self)
{
    ((pyopencv_ORB_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::ORB>& r)
{
    pyopencv_ORB_t *m = PyObject_NEW(pyopencv_ORB_t, &pyopencv_ORB_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::ORB>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_ORB_Type))
    {
        failmsg("Expected cv::ORB for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_ORB_t*)src)->v.dynamicCast<cv::ORB>();
    return true;
}


struct pyopencv_ShapeContextDistanceExtractor_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_ShapeContextDistanceExtractor_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".ShapeContextDistanceExtractor",
    sizeof(pyopencv_ShapeContextDistanceExtractor_t),
};

static void pyopencv_ShapeContextDistanceExtractor_dealloc(PyObject* self)
{
    ((pyopencv_ShapeContextDistanceExtractor_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::ShapeContextDistanceExtractor>& r)
{
    pyopencv_ShapeContextDistanceExtractor_t *m = PyObject_NEW(pyopencv_ShapeContextDistanceExtractor_t, &pyopencv_ShapeContextDistanceExtractor_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::ShapeContextDistanceExtractor>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_ShapeContextDistanceExtractor_Type))
    {
        failmsg("Expected cv::ShapeContextDistanceExtractor for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_ShapeContextDistanceExtractor_t*)src)->v.dynamicCast<cv::ShapeContextDistanceExtractor>();
    return true;
}


struct pyopencv_ShapeDistanceExtractor_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_ShapeDistanceExtractor_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".ShapeDistanceExtractor",
    sizeof(pyopencv_ShapeDistanceExtractor_t),
};

static void pyopencv_ShapeDistanceExtractor_dealloc(PyObject* self)
{
    ((pyopencv_ShapeDistanceExtractor_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::ShapeDistanceExtractor>& r)
{
    pyopencv_ShapeDistanceExtractor_t *m = PyObject_NEW(pyopencv_ShapeDistanceExtractor_t, &pyopencv_ShapeDistanceExtractor_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::ShapeDistanceExtractor>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_ShapeDistanceExtractor_Type))
    {
        failmsg("Expected cv::ShapeDistanceExtractor for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_ShapeDistanceExtractor_t*)src)->v.dynamicCast<cv::ShapeDistanceExtractor>();
    return true;
}


struct pyopencv_ShapeTransformer_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_ShapeTransformer_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".ShapeTransformer",
    sizeof(pyopencv_ShapeTransformer_t),
};

static void pyopencv_ShapeTransformer_dealloc(PyObject* self)
{
    ((pyopencv_ShapeTransformer_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::ShapeTransformer>& r)
{
    pyopencv_ShapeTransformer_t *m = PyObject_NEW(pyopencv_ShapeTransformer_t, &pyopencv_ShapeTransformer_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::ShapeTransformer>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_ShapeTransformer_Type))
    {
        failmsg("Expected cv::ShapeTransformer for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_ShapeTransformer_t*)src)->v.dynamicCast<cv::ShapeTransformer>();
    return true;
}


struct pyopencv_SimpleBlobDetector_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_SimpleBlobDetector_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".SimpleBlobDetector",
    sizeof(pyopencv_SimpleBlobDetector_t),
};

static void pyopencv_SimpleBlobDetector_dealloc(PyObject* self)
{
    ((pyopencv_SimpleBlobDetector_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::SimpleBlobDetector>& r)
{
    pyopencv_SimpleBlobDetector_t *m = PyObject_NEW(pyopencv_SimpleBlobDetector_t, &pyopencv_SimpleBlobDetector_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::SimpleBlobDetector>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_SimpleBlobDetector_Type))
    {
        failmsg("Expected cv::SimpleBlobDetector for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_SimpleBlobDetector_t*)src)->v.dynamicCast<cv::SimpleBlobDetector>();
    return true;
}


struct pyopencv_SimpleBlobDetector_Params_t
{
    PyObject_HEAD
    cv::SimpleBlobDetector::Params v;
};

static PyTypeObject pyopencv_SimpleBlobDetector_Params_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".SimpleBlobDetector_Params",
    sizeof(pyopencv_SimpleBlobDetector_Params_t),
};

static void pyopencv_SimpleBlobDetector_Params_dealloc(PyObject* self)
{
    ((pyopencv_SimpleBlobDetector_Params_t*)self)->v.cv::SimpleBlobDetector::Params::~Params();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const cv::SimpleBlobDetector::Params& r)
{
    pyopencv_SimpleBlobDetector_Params_t *m = PyObject_NEW(pyopencv_SimpleBlobDetector_Params_t, &pyopencv_SimpleBlobDetector_Params_Type);
    new (&m->v) cv::SimpleBlobDetector::Params(r); //Copy constructor
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, cv::SimpleBlobDetector::Params& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_SimpleBlobDetector_Params_Type))
    {
        failmsg("Expected cv::SimpleBlobDetector::Params for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_SimpleBlobDetector_Params_t*)src)->v;
    return true;
}

struct pyopencv_SparseOpticalFlow_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_SparseOpticalFlow_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".SparseOpticalFlow",
    sizeof(pyopencv_SparseOpticalFlow_t),
};

static void pyopencv_SparseOpticalFlow_dealloc(PyObject* self)
{
    ((pyopencv_SparseOpticalFlow_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::SparseOpticalFlow>& r)
{
    pyopencv_SparseOpticalFlow_t *m = PyObject_NEW(pyopencv_SparseOpticalFlow_t, &pyopencv_SparseOpticalFlow_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::SparseOpticalFlow>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_SparseOpticalFlow_Type))
    {
        failmsg("Expected cv::SparseOpticalFlow for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_SparseOpticalFlow_t*)src)->v.dynamicCast<cv::SparseOpticalFlow>();
    return true;
}


struct pyopencv_SparsePyrLKOpticalFlow_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_SparsePyrLKOpticalFlow_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".SparsePyrLKOpticalFlow",
    sizeof(pyopencv_SparsePyrLKOpticalFlow_t),
};

static void pyopencv_SparsePyrLKOpticalFlow_dealloc(PyObject* self)
{
    ((pyopencv_SparsePyrLKOpticalFlow_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::SparsePyrLKOpticalFlow>& r)
{
    pyopencv_SparsePyrLKOpticalFlow_t *m = PyObject_NEW(pyopencv_SparsePyrLKOpticalFlow_t, &pyopencv_SparsePyrLKOpticalFlow_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::SparsePyrLKOpticalFlow>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_SparsePyrLKOpticalFlow_Type))
    {
        failmsg("Expected cv::SparsePyrLKOpticalFlow for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_SparsePyrLKOpticalFlow_t*)src)->v.dynamicCast<cv::SparsePyrLKOpticalFlow>();
    return true;
}


struct pyopencv_StereoBM_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_StereoBM_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".StereoBM",
    sizeof(pyopencv_StereoBM_t),
};

static void pyopencv_StereoBM_dealloc(PyObject* self)
{
    ((pyopencv_StereoBM_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::StereoBM>& r)
{
    pyopencv_StereoBM_t *m = PyObject_NEW(pyopencv_StereoBM_t, &pyopencv_StereoBM_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::StereoBM>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_StereoBM_Type))
    {
        failmsg("Expected cv::StereoBM for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_StereoBM_t*)src)->v.dynamicCast<cv::StereoBM>();
    return true;
}


struct pyopencv_StereoMatcher_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_StereoMatcher_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".StereoMatcher",
    sizeof(pyopencv_StereoMatcher_t),
};

static void pyopencv_StereoMatcher_dealloc(PyObject* self)
{
    ((pyopencv_StereoMatcher_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::StereoMatcher>& r)
{
    pyopencv_StereoMatcher_t *m = PyObject_NEW(pyopencv_StereoMatcher_t, &pyopencv_StereoMatcher_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::StereoMatcher>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_StereoMatcher_Type))
    {
        failmsg("Expected cv::StereoMatcher for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_StereoMatcher_t*)src)->v.dynamicCast<cv::StereoMatcher>();
    return true;
}


struct pyopencv_StereoSGBM_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_StereoSGBM_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".StereoSGBM",
    sizeof(pyopencv_StereoSGBM_t),
};

static void pyopencv_StereoSGBM_dealloc(PyObject* self)
{
    ((pyopencv_StereoSGBM_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::StereoSGBM>& r)
{
    pyopencv_StereoSGBM_t *m = PyObject_NEW(pyopencv_StereoSGBM_t, &pyopencv_StereoSGBM_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::StereoSGBM>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_StereoSGBM_Type))
    {
        failmsg("Expected cv::StereoSGBM for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_StereoSGBM_t*)src)->v.dynamicCast<cv::StereoSGBM>();
    return true;
}


struct pyopencv_Stitcher_t
{
    PyObject_HEAD
    Ptr<cv::Stitcher> v;
};

static PyTypeObject pyopencv_Stitcher_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".Stitcher",
    sizeof(pyopencv_Stitcher_t),
};

static void pyopencv_Stitcher_dealloc(PyObject* self)
{
    ((pyopencv_Stitcher_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::Stitcher>& r)
{
    pyopencv_Stitcher_t *m = PyObject_NEW(pyopencv_Stitcher_t, &pyopencv_Stitcher_Type);
    new (&(m->v)) Ptr<cv::Stitcher>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::Stitcher>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_Stitcher_Type))
    {
        failmsg("Expected cv::Stitcher for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_Stitcher_t*)src)->v.dynamicCast<cv::Stitcher>();
    return true;
}


struct pyopencv_Subdiv2D_t
{
    PyObject_HEAD
    Ptr<cv::Subdiv2D> v;
};

static PyTypeObject pyopencv_Subdiv2D_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".Subdiv2D",
    sizeof(pyopencv_Subdiv2D_t),
};

static void pyopencv_Subdiv2D_dealloc(PyObject* self)
{
    ((pyopencv_Subdiv2D_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::Subdiv2D>& r)
{
    pyopencv_Subdiv2D_t *m = PyObject_NEW(pyopencv_Subdiv2D_t, &pyopencv_Subdiv2D_Type);
    new (&(m->v)) Ptr<cv::Subdiv2D>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::Subdiv2D>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_Subdiv2D_Type))
    {
        failmsg("Expected cv::Subdiv2D for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_Subdiv2D_t*)src)->v.dynamicCast<cv::Subdiv2D>();
    return true;
}


struct pyopencv_ThinPlateSplineShapeTransformer_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_ThinPlateSplineShapeTransformer_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".ThinPlateSplineShapeTransformer",
    sizeof(pyopencv_ThinPlateSplineShapeTransformer_t),
};

static void pyopencv_ThinPlateSplineShapeTransformer_dealloc(PyObject* self)
{
    ((pyopencv_ThinPlateSplineShapeTransformer_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::ThinPlateSplineShapeTransformer>& r)
{
    pyopencv_ThinPlateSplineShapeTransformer_t *m = PyObject_NEW(pyopencv_ThinPlateSplineShapeTransformer_t, &pyopencv_ThinPlateSplineShapeTransformer_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::ThinPlateSplineShapeTransformer>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_ThinPlateSplineShapeTransformer_Type))
    {
        failmsg("Expected cv::ThinPlateSplineShapeTransformer for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_ThinPlateSplineShapeTransformer_t*)src)->v.dynamicCast<cv::ThinPlateSplineShapeTransformer>();
    return true;
}


struct pyopencv_TickMeter_t
{
    PyObject_HEAD
    Ptr<cv::TickMeter> v;
};

static PyTypeObject pyopencv_TickMeter_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".TickMeter",
    sizeof(pyopencv_TickMeter_t),
};

static void pyopencv_TickMeter_dealloc(PyObject* self)
{
    ((pyopencv_TickMeter_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::TickMeter>& r)
{
    pyopencv_TickMeter_t *m = PyObject_NEW(pyopencv_TickMeter_t, &pyopencv_TickMeter_Type);
    new (&(m->v)) Ptr<cv::TickMeter>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::TickMeter>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_TickMeter_Type))
    {
        failmsg("Expected cv::TickMeter for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_TickMeter_t*)src)->v.dynamicCast<cv::TickMeter>();
    return true;
}


struct pyopencv_Tonemap_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_Tonemap_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".Tonemap",
    sizeof(pyopencv_Tonemap_t),
};

static void pyopencv_Tonemap_dealloc(PyObject* self)
{
    ((pyopencv_Tonemap_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::Tonemap>& r)
{
    pyopencv_Tonemap_t *m = PyObject_NEW(pyopencv_Tonemap_t, &pyopencv_Tonemap_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::Tonemap>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_Tonemap_Type))
    {
        failmsg("Expected cv::Tonemap for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_Tonemap_t*)src)->v.dynamicCast<cv::Tonemap>();
    return true;
}


struct pyopencv_TonemapDrago_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_TonemapDrago_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".TonemapDrago",
    sizeof(pyopencv_TonemapDrago_t),
};

static void pyopencv_TonemapDrago_dealloc(PyObject* self)
{
    ((pyopencv_TonemapDrago_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::TonemapDrago>& r)
{
    pyopencv_TonemapDrago_t *m = PyObject_NEW(pyopencv_TonemapDrago_t, &pyopencv_TonemapDrago_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::TonemapDrago>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_TonemapDrago_Type))
    {
        failmsg("Expected cv::TonemapDrago for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_TonemapDrago_t*)src)->v.dynamicCast<cv::TonemapDrago>();
    return true;
}


struct pyopencv_TonemapDurand_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_TonemapDurand_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".TonemapDurand",
    sizeof(pyopencv_TonemapDurand_t),
};

static void pyopencv_TonemapDurand_dealloc(PyObject* self)
{
    ((pyopencv_TonemapDurand_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::TonemapDurand>& r)
{
    pyopencv_TonemapDurand_t *m = PyObject_NEW(pyopencv_TonemapDurand_t, &pyopencv_TonemapDurand_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::TonemapDurand>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_TonemapDurand_Type))
    {
        failmsg("Expected cv::TonemapDurand for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_TonemapDurand_t*)src)->v.dynamicCast<cv::TonemapDurand>();
    return true;
}


struct pyopencv_TonemapMantiuk_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_TonemapMantiuk_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".TonemapMantiuk",
    sizeof(pyopencv_TonemapMantiuk_t),
};

static void pyopencv_TonemapMantiuk_dealloc(PyObject* self)
{
    ((pyopencv_TonemapMantiuk_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::TonemapMantiuk>& r)
{
    pyopencv_TonemapMantiuk_t *m = PyObject_NEW(pyopencv_TonemapMantiuk_t, &pyopencv_TonemapMantiuk_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::TonemapMantiuk>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_TonemapMantiuk_Type))
    {
        failmsg("Expected cv::TonemapMantiuk for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_TonemapMantiuk_t*)src)->v.dynamicCast<cv::TonemapMantiuk>();
    return true;
}


struct pyopencv_TonemapReinhard_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_TonemapReinhard_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".TonemapReinhard",
    sizeof(pyopencv_TonemapReinhard_t),
};

static void pyopencv_TonemapReinhard_dealloc(PyObject* self)
{
    ((pyopencv_TonemapReinhard_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::TonemapReinhard>& r)
{
    pyopencv_TonemapReinhard_t *m = PyObject_NEW(pyopencv_TonemapReinhard_t, &pyopencv_TonemapReinhard_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::TonemapReinhard>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_TonemapReinhard_Type))
    {
        failmsg("Expected cv::TonemapReinhard for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_TonemapReinhard_t*)src)->v.dynamicCast<cv::TonemapReinhard>();
    return true;
}


struct pyopencv_Tracker_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_Tracker_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".Tracker",
    sizeof(pyopencv_Tracker_t),
};

static void pyopencv_Tracker_dealloc(PyObject* self)
{
    ((pyopencv_Tracker_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::Tracker>& r)
{
    pyopencv_Tracker_t *m = PyObject_NEW(pyopencv_Tracker_t, &pyopencv_Tracker_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::Tracker>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_Tracker_Type))
    {
        failmsg("Expected cv::Tracker for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_Tracker_t*)src)->v.dynamicCast<cv::Tracker>();
    return true;
}


struct pyopencv_VideoCapture_t
{
    PyObject_HEAD
    Ptr<cv::VideoCapture> v;
};

static PyTypeObject pyopencv_VideoCapture_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".VideoCapture",
    sizeof(pyopencv_VideoCapture_t),
};

static void pyopencv_VideoCapture_dealloc(PyObject* self)
{
    ((pyopencv_VideoCapture_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::VideoCapture>& r)
{
    pyopencv_VideoCapture_t *m = PyObject_NEW(pyopencv_VideoCapture_t, &pyopencv_VideoCapture_Type);
    new (&(m->v)) Ptr<cv::VideoCapture>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::VideoCapture>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_VideoCapture_Type))
    {
        failmsg("Expected cv::VideoCapture for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_VideoCapture_t*)src)->v.dynamicCast<cv::VideoCapture>();
    return true;
}


struct pyopencv_VideoWriter_t
{
    PyObject_HEAD
    Ptr<cv::VideoWriter> v;
};

static PyTypeObject pyopencv_VideoWriter_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".VideoWriter",
    sizeof(pyopencv_VideoWriter_t),
};

static void pyopencv_VideoWriter_dealloc(PyObject* self)
{
    ((pyopencv_VideoWriter_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::VideoWriter>& r)
{
    pyopencv_VideoWriter_t *m = PyObject_NEW(pyopencv_VideoWriter_t, &pyopencv_VideoWriter_Type);
    new (&(m->v)) Ptr<cv::VideoWriter>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::VideoWriter>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_VideoWriter_Type))
    {
        failmsg("Expected cv::VideoWriter for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_VideoWriter_t*)src)->v.dynamicCast<cv::VideoWriter>();
    return true;
}


struct pyopencv_aruco_Board_t
{
    PyObject_HEAD
    Ptr<cv::aruco::Board> v;
};

static PyTypeObject pyopencv_aruco_Board_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".aruco_Board",
    sizeof(pyopencv_aruco_Board_t),
};

static void pyopencv_aruco_Board_dealloc(PyObject* self)
{
    ((pyopencv_aruco_Board_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::aruco::Board>& r)
{
    pyopencv_aruco_Board_t *m = PyObject_NEW(pyopencv_aruco_Board_t, &pyopencv_aruco_Board_Type);
    new (&(m->v)) Ptr<cv::aruco::Board>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::aruco::Board>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_aruco_Board_Type))
    {
        failmsg("Expected cv::aruco::Board for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_aruco_Board_t*)src)->v.dynamicCast<cv::aruco::Board>();
    return true;
}


struct pyopencv_aruco_CharucoBoard_t
{
    PyObject_HEAD
    Ptr<cv::aruco::CharucoBoard> v;
};

static PyTypeObject pyopencv_aruco_CharucoBoard_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".aruco_CharucoBoard",
    sizeof(pyopencv_aruco_CharucoBoard_t),
};

static void pyopencv_aruco_CharucoBoard_dealloc(PyObject* self)
{
    ((pyopencv_aruco_CharucoBoard_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::aruco::CharucoBoard>& r)
{
    pyopencv_aruco_CharucoBoard_t *m = PyObject_NEW(pyopencv_aruco_CharucoBoard_t, &pyopencv_aruco_CharucoBoard_Type);
    new (&(m->v)) Ptr<cv::aruco::CharucoBoard>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::aruco::CharucoBoard>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_aruco_CharucoBoard_Type))
    {
        failmsg("Expected cv::aruco::CharucoBoard for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_aruco_CharucoBoard_t*)src)->v.dynamicCast<cv::aruco::CharucoBoard>();
    return true;
}


struct pyopencv_aruco_DetectorParameters_t
{
    PyObject_HEAD
    Ptr<cv::aruco::DetectorParameters> v;
};

static PyTypeObject pyopencv_aruco_DetectorParameters_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".aruco_DetectorParameters",
    sizeof(pyopencv_aruco_DetectorParameters_t),
};

static void pyopencv_aruco_DetectorParameters_dealloc(PyObject* self)
{
    ((pyopencv_aruco_DetectorParameters_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::aruco::DetectorParameters>& r)
{
    pyopencv_aruco_DetectorParameters_t *m = PyObject_NEW(pyopencv_aruco_DetectorParameters_t, &pyopencv_aruco_DetectorParameters_Type);
    new (&(m->v)) Ptr<cv::aruco::DetectorParameters>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::aruco::DetectorParameters>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_aruco_DetectorParameters_Type))
    {
        failmsg("Expected cv::aruco::DetectorParameters for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_aruco_DetectorParameters_t*)src)->v.dynamicCast<cv::aruco::DetectorParameters>();
    return true;
}


struct pyopencv_aruco_Dictionary_t
{
    PyObject_HEAD
    Ptr<cv::aruco::Dictionary> v;
};

static PyTypeObject pyopencv_aruco_Dictionary_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".aruco_Dictionary",
    sizeof(pyopencv_aruco_Dictionary_t),
};

static void pyopencv_aruco_Dictionary_dealloc(PyObject* self)
{
    ((pyopencv_aruco_Dictionary_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::aruco::Dictionary>& r)
{
    pyopencv_aruco_Dictionary_t *m = PyObject_NEW(pyopencv_aruco_Dictionary_t, &pyopencv_aruco_Dictionary_Type);
    new (&(m->v)) Ptr<cv::aruco::Dictionary>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::aruco::Dictionary>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_aruco_Dictionary_Type))
    {
        failmsg("Expected cv::aruco::Dictionary for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_aruco_Dictionary_t*)src)->v.dynamicCast<cv::aruco::Dictionary>();
    return true;
}


struct pyopencv_aruco_GridBoard_t
{
    PyObject_HEAD
    Ptr<cv::aruco::GridBoard> v;
};

static PyTypeObject pyopencv_aruco_GridBoard_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".aruco_GridBoard",
    sizeof(pyopencv_aruco_GridBoard_t),
};

static void pyopencv_aruco_GridBoard_dealloc(PyObject* self)
{
    ((pyopencv_aruco_GridBoard_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::aruco::GridBoard>& r)
{
    pyopencv_aruco_GridBoard_t *m = PyObject_NEW(pyopencv_aruco_GridBoard_t, &pyopencv_aruco_GridBoard_Type);
    new (&(m->v)) Ptr<cv::aruco::GridBoard>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::aruco::GridBoard>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_aruco_GridBoard_Type))
    {
        failmsg("Expected cv::aruco::GridBoard for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_aruco_GridBoard_t*)src)->v.dynamicCast<cv::aruco::GridBoard>();
    return true;
}


struct pyopencv_bgsegm_BackgroundSubtractorGMG_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_bgsegm_BackgroundSubtractorGMG_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".bgsegm_BackgroundSubtractorGMG",
    sizeof(pyopencv_bgsegm_BackgroundSubtractorGMG_t),
};

static void pyopencv_bgsegm_BackgroundSubtractorGMG_dealloc(PyObject* self)
{
    ((pyopencv_bgsegm_BackgroundSubtractorGMG_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::bgsegm::BackgroundSubtractorGMG>& r)
{
    pyopencv_bgsegm_BackgroundSubtractorGMG_t *m = PyObject_NEW(pyopencv_bgsegm_BackgroundSubtractorGMG_t, &pyopencv_bgsegm_BackgroundSubtractorGMG_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::bgsegm::BackgroundSubtractorGMG>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_bgsegm_BackgroundSubtractorGMG_Type))
    {
        failmsg("Expected cv::bgsegm::BackgroundSubtractorGMG for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_bgsegm_BackgroundSubtractorGMG_t*)src)->v.dynamicCast<cv::bgsegm::BackgroundSubtractorGMG>();
    return true;
}


struct pyopencv_bgsegm_BackgroundSubtractorMOG_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_bgsegm_BackgroundSubtractorMOG_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".bgsegm_BackgroundSubtractorMOG",
    sizeof(pyopencv_bgsegm_BackgroundSubtractorMOG_t),
};

static void pyopencv_bgsegm_BackgroundSubtractorMOG_dealloc(PyObject* self)
{
    ((pyopencv_bgsegm_BackgroundSubtractorMOG_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::bgsegm::BackgroundSubtractorMOG>& r)
{
    pyopencv_bgsegm_BackgroundSubtractorMOG_t *m = PyObject_NEW(pyopencv_bgsegm_BackgroundSubtractorMOG_t, &pyopencv_bgsegm_BackgroundSubtractorMOG_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::bgsegm::BackgroundSubtractorMOG>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_bgsegm_BackgroundSubtractorMOG_Type))
    {
        failmsg("Expected cv::bgsegm::BackgroundSubtractorMOG for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_bgsegm_BackgroundSubtractorMOG_t*)src)->v.dynamicCast<cv::bgsegm::BackgroundSubtractorMOG>();
    return true;
}


struct pyopencv_bioinspired_Retina_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_bioinspired_Retina_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".bioinspired_Retina",
    sizeof(pyopencv_bioinspired_Retina_t),
};

static void pyopencv_bioinspired_Retina_dealloc(PyObject* self)
{
    ((pyopencv_bioinspired_Retina_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::bioinspired::Retina>& r)
{
    pyopencv_bioinspired_Retina_t *m = PyObject_NEW(pyopencv_bioinspired_Retina_t, &pyopencv_bioinspired_Retina_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::bioinspired::Retina>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_bioinspired_Retina_Type))
    {
        failmsg("Expected cv::bioinspired::Retina for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_bioinspired_Retina_t*)src)->v.dynamicCast<cv::bioinspired::Retina>();
    return true;
}


struct pyopencv_bioinspired_RetinaFastToneMapping_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_bioinspired_RetinaFastToneMapping_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".bioinspired_RetinaFastToneMapping",
    sizeof(pyopencv_bioinspired_RetinaFastToneMapping_t),
};

static void pyopencv_bioinspired_RetinaFastToneMapping_dealloc(PyObject* self)
{
    ((pyopencv_bioinspired_RetinaFastToneMapping_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::bioinspired::RetinaFastToneMapping>& r)
{
    pyopencv_bioinspired_RetinaFastToneMapping_t *m = PyObject_NEW(pyopencv_bioinspired_RetinaFastToneMapping_t, &pyopencv_bioinspired_RetinaFastToneMapping_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::bioinspired::RetinaFastToneMapping>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_bioinspired_RetinaFastToneMapping_Type))
    {
        failmsg("Expected cv::bioinspired::RetinaFastToneMapping for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_bioinspired_RetinaFastToneMapping_t*)src)->v.dynamicCast<cv::bioinspired::RetinaFastToneMapping>();
    return true;
}


struct pyopencv_bioinspired_TransientAreasSegmentationModule_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_bioinspired_TransientAreasSegmentationModule_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".bioinspired_TransientAreasSegmentationModule",
    sizeof(pyopencv_bioinspired_TransientAreasSegmentationModule_t),
};

static void pyopencv_bioinspired_TransientAreasSegmentationModule_dealloc(PyObject* self)
{
    ((pyopencv_bioinspired_TransientAreasSegmentationModule_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::bioinspired::TransientAreasSegmentationModule>& r)
{
    pyopencv_bioinspired_TransientAreasSegmentationModule_t *m = PyObject_NEW(pyopencv_bioinspired_TransientAreasSegmentationModule_t, &pyopencv_bioinspired_TransientAreasSegmentationModule_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::bioinspired::TransientAreasSegmentationModule>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_bioinspired_TransientAreasSegmentationModule_Type))
    {
        failmsg("Expected cv::bioinspired::TransientAreasSegmentationModule for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_bioinspired_TransientAreasSegmentationModule_t*)src)->v.dynamicCast<cv::bioinspired::TransientAreasSegmentationModule>();
    return true;
}


struct pyopencv_dnn_AbsLayer_t
{
    PyObject_HEAD
    Ptr<cv::dnn::AbsLayer> v;
};

static PyTypeObject pyopencv_dnn_AbsLayer_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".dnn_AbsLayer",
    sizeof(pyopencv_dnn_AbsLayer_t),
};

static void pyopencv_dnn_AbsLayer_dealloc(PyObject* self)
{
    ((pyopencv_dnn_AbsLayer_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::dnn::AbsLayer>& r)
{
    pyopencv_dnn_AbsLayer_t *m = PyObject_NEW(pyopencv_dnn_AbsLayer_t, &pyopencv_dnn_AbsLayer_Type);
    new (&(m->v)) Ptr<cv::dnn::AbsLayer>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::dnn::AbsLayer>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_dnn_AbsLayer_Type))
    {
        failmsg("Expected cv::dnn::AbsLayer for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_dnn_AbsLayer_t*)src)->v.dynamicCast<cv::dnn::AbsLayer>();
    return true;
}


struct pyopencv_dnn_BNLLLayer_t
{
    PyObject_HEAD
    Ptr<cv::dnn::BNLLLayer> v;
};

static PyTypeObject pyopencv_dnn_BNLLLayer_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".dnn_BNLLLayer",
    sizeof(pyopencv_dnn_BNLLLayer_t),
};

static void pyopencv_dnn_BNLLLayer_dealloc(PyObject* self)
{
    ((pyopencv_dnn_BNLLLayer_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::dnn::BNLLLayer>& r)
{
    pyopencv_dnn_BNLLLayer_t *m = PyObject_NEW(pyopencv_dnn_BNLLLayer_t, &pyopencv_dnn_BNLLLayer_Type);
    new (&(m->v)) Ptr<cv::dnn::BNLLLayer>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::dnn::BNLLLayer>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_dnn_BNLLLayer_Type))
    {
        failmsg("Expected cv::dnn::BNLLLayer for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_dnn_BNLLLayer_t*)src)->v.dynamicCast<cv::dnn::BNLLLayer>();
    return true;
}


struct pyopencv_dnn_BaseConvolutionLayer_t
{
    PyObject_HEAD
    Ptr<cv::dnn::BaseConvolutionLayer> v;
};

static PyTypeObject pyopencv_dnn_BaseConvolutionLayer_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".dnn_BaseConvolutionLayer",
    sizeof(pyopencv_dnn_BaseConvolutionLayer_t),
};

static void pyopencv_dnn_BaseConvolutionLayer_dealloc(PyObject* self)
{
    ((pyopencv_dnn_BaseConvolutionLayer_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::dnn::BaseConvolutionLayer>& r)
{
    pyopencv_dnn_BaseConvolutionLayer_t *m = PyObject_NEW(pyopencv_dnn_BaseConvolutionLayer_t, &pyopencv_dnn_BaseConvolutionLayer_Type);
    new (&(m->v)) Ptr<cv::dnn::BaseConvolutionLayer>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::dnn::BaseConvolutionLayer>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_dnn_BaseConvolutionLayer_Type))
    {
        failmsg("Expected cv::dnn::BaseConvolutionLayer for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_dnn_BaseConvolutionLayer_t*)src)->v.dynamicCast<cv::dnn::BaseConvolutionLayer>();
    return true;
}


struct pyopencv_dnn_BatchNormLayer_t
{
    PyObject_HEAD
    Ptr<cv::dnn::BatchNormLayer> v;
};

static PyTypeObject pyopencv_dnn_BatchNormLayer_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".dnn_BatchNormLayer",
    sizeof(pyopencv_dnn_BatchNormLayer_t),
};

static void pyopencv_dnn_BatchNormLayer_dealloc(PyObject* self)
{
    ((pyopencv_dnn_BatchNormLayer_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::dnn::BatchNormLayer>& r)
{
    pyopencv_dnn_BatchNormLayer_t *m = PyObject_NEW(pyopencv_dnn_BatchNormLayer_t, &pyopencv_dnn_BatchNormLayer_Type);
    new (&(m->v)) Ptr<cv::dnn::BatchNormLayer>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::dnn::BatchNormLayer>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_dnn_BatchNormLayer_Type))
    {
        failmsg("Expected cv::dnn::BatchNormLayer for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_dnn_BatchNormLayer_t*)src)->v.dynamicCast<cv::dnn::BatchNormLayer>();
    return true;
}


struct pyopencv_dnn_Blob_t
{
    PyObject_HEAD
    Ptr<cv::dnn::Blob> v;
};

static PyTypeObject pyopencv_dnn_Blob_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".dnn_Blob",
    sizeof(pyopencv_dnn_Blob_t),
};

static void pyopencv_dnn_Blob_dealloc(PyObject* self)
{
    ((pyopencv_dnn_Blob_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::dnn::Blob>& r)
{
    pyopencv_dnn_Blob_t *m = PyObject_NEW(pyopencv_dnn_Blob_t, &pyopencv_dnn_Blob_Type);
    new (&(m->v)) Ptr<cv::dnn::Blob>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::dnn::Blob>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_dnn_Blob_Type))
    {
        failmsg("Expected cv::dnn::Blob for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_dnn_Blob_t*)src)->v.dynamicCast<cv::dnn::Blob>();
    return true;
}


struct pyopencv_dnn_BlobShape_t
{
    PyObject_HEAD
    Ptr<cv::dnn::BlobShape> v;
};

static PyTypeObject pyopencv_dnn_BlobShape_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".dnn_BlobShape",
    sizeof(pyopencv_dnn_BlobShape_t),
};

static void pyopencv_dnn_BlobShape_dealloc(PyObject* self)
{
    ((pyopencv_dnn_BlobShape_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::dnn::BlobShape>& r)
{
    pyopencv_dnn_BlobShape_t *m = PyObject_NEW(pyopencv_dnn_BlobShape_t, &pyopencv_dnn_BlobShape_Type);
    new (&(m->v)) Ptr<cv::dnn::BlobShape>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::dnn::BlobShape>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_dnn_BlobShape_Type))
    {
        failmsg("Expected cv::dnn::BlobShape for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_dnn_BlobShape_t*)src)->v.dynamicCast<cv::dnn::BlobShape>();
    return true;
}


struct pyopencv_dnn_ChannelsPReLULayer_t
{
    PyObject_HEAD
    Ptr<cv::dnn::ChannelsPReLULayer> v;
};

static PyTypeObject pyopencv_dnn_ChannelsPReLULayer_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".dnn_ChannelsPReLULayer",
    sizeof(pyopencv_dnn_ChannelsPReLULayer_t),
};

static void pyopencv_dnn_ChannelsPReLULayer_dealloc(PyObject* self)
{
    ((pyopencv_dnn_ChannelsPReLULayer_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::dnn::ChannelsPReLULayer>& r)
{
    pyopencv_dnn_ChannelsPReLULayer_t *m = PyObject_NEW(pyopencv_dnn_ChannelsPReLULayer_t, &pyopencv_dnn_ChannelsPReLULayer_Type);
    new (&(m->v)) Ptr<cv::dnn::ChannelsPReLULayer>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::dnn::ChannelsPReLULayer>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_dnn_ChannelsPReLULayer_Type))
    {
        failmsg("Expected cv::dnn::ChannelsPReLULayer for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_dnn_ChannelsPReLULayer_t*)src)->v.dynamicCast<cv::dnn::ChannelsPReLULayer>();
    return true;
}


struct pyopencv_dnn_ConcatLayer_t
{
    PyObject_HEAD
    Ptr<cv::dnn::ConcatLayer> v;
};

static PyTypeObject pyopencv_dnn_ConcatLayer_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".dnn_ConcatLayer",
    sizeof(pyopencv_dnn_ConcatLayer_t),
};

static void pyopencv_dnn_ConcatLayer_dealloc(PyObject* self)
{
    ((pyopencv_dnn_ConcatLayer_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::dnn::ConcatLayer>& r)
{
    pyopencv_dnn_ConcatLayer_t *m = PyObject_NEW(pyopencv_dnn_ConcatLayer_t, &pyopencv_dnn_ConcatLayer_Type);
    new (&(m->v)) Ptr<cv::dnn::ConcatLayer>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::dnn::ConcatLayer>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_dnn_ConcatLayer_Type))
    {
        failmsg("Expected cv::dnn::ConcatLayer for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_dnn_ConcatLayer_t*)src)->v.dynamicCast<cv::dnn::ConcatLayer>();
    return true;
}


struct pyopencv_dnn_ConvolutionLayer_t
{
    PyObject_HEAD
    Ptr<cv::dnn::ConvolutionLayer> v;
};

static PyTypeObject pyopencv_dnn_ConvolutionLayer_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".dnn_ConvolutionLayer",
    sizeof(pyopencv_dnn_ConvolutionLayer_t),
};

static void pyopencv_dnn_ConvolutionLayer_dealloc(PyObject* self)
{
    ((pyopencv_dnn_ConvolutionLayer_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::dnn::ConvolutionLayer>& r)
{
    pyopencv_dnn_ConvolutionLayer_t *m = PyObject_NEW(pyopencv_dnn_ConvolutionLayer_t, &pyopencv_dnn_ConvolutionLayer_Type);
    new (&(m->v)) Ptr<cv::dnn::ConvolutionLayer>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::dnn::ConvolutionLayer>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_dnn_ConvolutionLayer_Type))
    {
        failmsg("Expected cv::dnn::ConvolutionLayer for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_dnn_ConvolutionLayer_t*)src)->v.dynamicCast<cv::dnn::ConvolutionLayer>();
    return true;
}


struct pyopencv_dnn_CropLayer_t
{
    PyObject_HEAD
    Ptr<cv::dnn::CropLayer> v;
};

static PyTypeObject pyopencv_dnn_CropLayer_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".dnn_CropLayer",
    sizeof(pyopencv_dnn_CropLayer_t),
};

static void pyopencv_dnn_CropLayer_dealloc(PyObject* self)
{
    ((pyopencv_dnn_CropLayer_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::dnn::CropLayer>& r)
{
    pyopencv_dnn_CropLayer_t *m = PyObject_NEW(pyopencv_dnn_CropLayer_t, &pyopencv_dnn_CropLayer_Type);
    new (&(m->v)) Ptr<cv::dnn::CropLayer>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::dnn::CropLayer>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_dnn_CropLayer_Type))
    {
        failmsg("Expected cv::dnn::CropLayer for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_dnn_CropLayer_t*)src)->v.dynamicCast<cv::dnn::CropLayer>();
    return true;
}


struct pyopencv_dnn_DeconvolutionLayer_t
{
    PyObject_HEAD
    Ptr<cv::dnn::DeconvolutionLayer> v;
};

static PyTypeObject pyopencv_dnn_DeconvolutionLayer_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".dnn_DeconvolutionLayer",
    sizeof(pyopencv_dnn_DeconvolutionLayer_t),
};

static void pyopencv_dnn_DeconvolutionLayer_dealloc(PyObject* self)
{
    ((pyopencv_dnn_DeconvolutionLayer_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::dnn::DeconvolutionLayer>& r)
{
    pyopencv_dnn_DeconvolutionLayer_t *m = PyObject_NEW(pyopencv_dnn_DeconvolutionLayer_t, &pyopencv_dnn_DeconvolutionLayer_Type);
    new (&(m->v)) Ptr<cv::dnn::DeconvolutionLayer>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::dnn::DeconvolutionLayer>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_dnn_DeconvolutionLayer_Type))
    {
        failmsg("Expected cv::dnn::DeconvolutionLayer for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_dnn_DeconvolutionLayer_t*)src)->v.dynamicCast<cv::dnn::DeconvolutionLayer>();
    return true;
}


struct pyopencv_dnn_EltwiseLayer_t
{
    PyObject_HEAD
    Ptr<cv::dnn::EltwiseLayer> v;
};

static PyTypeObject pyopencv_dnn_EltwiseLayer_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".dnn_EltwiseLayer",
    sizeof(pyopencv_dnn_EltwiseLayer_t),
};

static void pyopencv_dnn_EltwiseLayer_dealloc(PyObject* self)
{
    ((pyopencv_dnn_EltwiseLayer_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::dnn::EltwiseLayer>& r)
{
    pyopencv_dnn_EltwiseLayer_t *m = PyObject_NEW(pyopencv_dnn_EltwiseLayer_t, &pyopencv_dnn_EltwiseLayer_Type);
    new (&(m->v)) Ptr<cv::dnn::EltwiseLayer>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::dnn::EltwiseLayer>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_dnn_EltwiseLayer_Type))
    {
        failmsg("Expected cv::dnn::EltwiseLayer for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_dnn_EltwiseLayer_t*)src)->v.dynamicCast<cv::dnn::EltwiseLayer>();
    return true;
}


struct pyopencv_dnn_Importer_t
{
    PyObject_HEAD
    Ptr<cv::dnn::Importer> v;
};

static PyTypeObject pyopencv_dnn_Importer_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".dnn_Importer",
    sizeof(pyopencv_dnn_Importer_t),
};

static void pyopencv_dnn_Importer_dealloc(PyObject* self)
{
    ((pyopencv_dnn_Importer_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::dnn::Importer>& r)
{
    pyopencv_dnn_Importer_t *m = PyObject_NEW(pyopencv_dnn_Importer_t, &pyopencv_dnn_Importer_Type);
    new (&(m->v)) Ptr<cv::dnn::Importer>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::dnn::Importer>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_dnn_Importer_Type))
    {
        failmsg("Expected cv::dnn::Importer for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_dnn_Importer_t*)src)->v.dynamicCast<cv::dnn::Importer>();
    return true;
}


struct pyopencv_dnn_InnerProductLayer_t
{
    PyObject_HEAD
    Ptr<cv::dnn::InnerProductLayer> v;
};

static PyTypeObject pyopencv_dnn_InnerProductLayer_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".dnn_InnerProductLayer",
    sizeof(pyopencv_dnn_InnerProductLayer_t),
};

static void pyopencv_dnn_InnerProductLayer_dealloc(PyObject* self)
{
    ((pyopencv_dnn_InnerProductLayer_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::dnn::InnerProductLayer>& r)
{
    pyopencv_dnn_InnerProductLayer_t *m = PyObject_NEW(pyopencv_dnn_InnerProductLayer_t, &pyopencv_dnn_InnerProductLayer_Type);
    new (&(m->v)) Ptr<cv::dnn::InnerProductLayer>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::dnn::InnerProductLayer>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_dnn_InnerProductLayer_Type))
    {
        failmsg("Expected cv::dnn::InnerProductLayer for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_dnn_InnerProductLayer_t*)src)->v.dynamicCast<cv::dnn::InnerProductLayer>();
    return true;
}


struct pyopencv_dnn_LRNLayer_t
{
    PyObject_HEAD
    Ptr<cv::dnn::LRNLayer> v;
};

static PyTypeObject pyopencv_dnn_LRNLayer_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".dnn_LRNLayer",
    sizeof(pyopencv_dnn_LRNLayer_t),
};

static void pyopencv_dnn_LRNLayer_dealloc(PyObject* self)
{
    ((pyopencv_dnn_LRNLayer_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::dnn::LRNLayer>& r)
{
    pyopencv_dnn_LRNLayer_t *m = PyObject_NEW(pyopencv_dnn_LRNLayer_t, &pyopencv_dnn_LRNLayer_Type);
    new (&(m->v)) Ptr<cv::dnn::LRNLayer>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::dnn::LRNLayer>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_dnn_LRNLayer_Type))
    {
        failmsg("Expected cv::dnn::LRNLayer for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_dnn_LRNLayer_t*)src)->v.dynamicCast<cv::dnn::LRNLayer>();
    return true;
}


struct pyopencv_dnn_LSTMLayer_t
{
    PyObject_HEAD
    Ptr<cv::dnn::LSTMLayer> v;
};

static PyTypeObject pyopencv_dnn_LSTMLayer_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".dnn_LSTMLayer",
    sizeof(pyopencv_dnn_LSTMLayer_t),
};

static void pyopencv_dnn_LSTMLayer_dealloc(PyObject* self)
{
    ((pyopencv_dnn_LSTMLayer_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::dnn::LSTMLayer>& r)
{
    pyopencv_dnn_LSTMLayer_t *m = PyObject_NEW(pyopencv_dnn_LSTMLayer_t, &pyopencv_dnn_LSTMLayer_Type);
    new (&(m->v)) Ptr<cv::dnn::LSTMLayer>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::dnn::LSTMLayer>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_dnn_LSTMLayer_Type))
    {
        failmsg("Expected cv::dnn::LSTMLayer for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_dnn_LSTMLayer_t*)src)->v.dynamicCast<cv::dnn::LSTMLayer>();
    return true;
}


struct pyopencv_dnn_Layer_t
{
    PyObject_HEAD
    Ptr<cv::dnn::Layer> v;
};

static PyTypeObject pyopencv_dnn_Layer_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".dnn_Layer",
    sizeof(pyopencv_dnn_Layer_t),
};

static void pyopencv_dnn_Layer_dealloc(PyObject* self)
{
    ((pyopencv_dnn_Layer_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::dnn::Layer>& r)
{
    pyopencv_dnn_Layer_t *m = PyObject_NEW(pyopencv_dnn_Layer_t, &pyopencv_dnn_Layer_Type);
    new (&(m->v)) Ptr<cv::dnn::Layer>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::dnn::Layer>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_dnn_Layer_Type))
    {
        failmsg("Expected cv::dnn::Layer for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_dnn_Layer_t*)src)->v.dynamicCast<cv::dnn::Layer>();
    return true;
}


struct pyopencv_dnn_MVNLayer_t
{
    PyObject_HEAD
    Ptr<cv::dnn::MVNLayer> v;
};

static PyTypeObject pyopencv_dnn_MVNLayer_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".dnn_MVNLayer",
    sizeof(pyopencv_dnn_MVNLayer_t),
};

static void pyopencv_dnn_MVNLayer_dealloc(PyObject* self)
{
    ((pyopencv_dnn_MVNLayer_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::dnn::MVNLayer>& r)
{
    pyopencv_dnn_MVNLayer_t *m = PyObject_NEW(pyopencv_dnn_MVNLayer_t, &pyopencv_dnn_MVNLayer_Type);
    new (&(m->v)) Ptr<cv::dnn::MVNLayer>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::dnn::MVNLayer>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_dnn_MVNLayer_Type))
    {
        failmsg("Expected cv::dnn::MVNLayer for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_dnn_MVNLayer_t*)src)->v.dynamicCast<cv::dnn::MVNLayer>();
    return true;
}


struct pyopencv_dnn_MaxUnpoolLayer_t
{
    PyObject_HEAD
    Ptr<cv::dnn::MaxUnpoolLayer> v;
};

static PyTypeObject pyopencv_dnn_MaxUnpoolLayer_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".dnn_MaxUnpoolLayer",
    sizeof(pyopencv_dnn_MaxUnpoolLayer_t),
};

static void pyopencv_dnn_MaxUnpoolLayer_dealloc(PyObject* self)
{
    ((pyopencv_dnn_MaxUnpoolLayer_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::dnn::MaxUnpoolLayer>& r)
{
    pyopencv_dnn_MaxUnpoolLayer_t *m = PyObject_NEW(pyopencv_dnn_MaxUnpoolLayer_t, &pyopencv_dnn_MaxUnpoolLayer_Type);
    new (&(m->v)) Ptr<cv::dnn::MaxUnpoolLayer>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::dnn::MaxUnpoolLayer>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_dnn_MaxUnpoolLayer_Type))
    {
        failmsg("Expected cv::dnn::MaxUnpoolLayer for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_dnn_MaxUnpoolLayer_t*)src)->v.dynamicCast<cv::dnn::MaxUnpoolLayer>();
    return true;
}


struct pyopencv_dnn_Net_t
{
    PyObject_HEAD
    cv::dnn::Net v;
};

static PyTypeObject pyopencv_dnn_Net_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".dnn_Net",
    sizeof(pyopencv_dnn_Net_t),
};

static void pyopencv_dnn_Net_dealloc(PyObject* self)
{
    ((pyopencv_dnn_Net_t*)self)->v.cv::dnn::Net::~Net();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const cv::dnn::Net& r)
{
    pyopencv_dnn_Net_t *m = PyObject_NEW(pyopencv_dnn_Net_t, &pyopencv_dnn_Net_Type);
    new (&m->v) cv::dnn::Net(r); //Copy constructor
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, cv::dnn::Net& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_dnn_Net_Type))
    {
        failmsg("Expected cv::dnn::Net for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_dnn_Net_t*)src)->v;
    return true;
}

struct pyopencv_dnn_PoolingLayer_t
{
    PyObject_HEAD
    Ptr<cv::dnn::PoolingLayer> v;
};

static PyTypeObject pyopencv_dnn_PoolingLayer_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".dnn_PoolingLayer",
    sizeof(pyopencv_dnn_PoolingLayer_t),
};

static void pyopencv_dnn_PoolingLayer_dealloc(PyObject* self)
{
    ((pyopencv_dnn_PoolingLayer_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::dnn::PoolingLayer>& r)
{
    pyopencv_dnn_PoolingLayer_t *m = PyObject_NEW(pyopencv_dnn_PoolingLayer_t, &pyopencv_dnn_PoolingLayer_Type);
    new (&(m->v)) Ptr<cv::dnn::PoolingLayer>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::dnn::PoolingLayer>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_dnn_PoolingLayer_Type))
    {
        failmsg("Expected cv::dnn::PoolingLayer for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_dnn_PoolingLayer_t*)src)->v.dynamicCast<cv::dnn::PoolingLayer>();
    return true;
}


struct pyopencv_dnn_PowerLayer_t
{
    PyObject_HEAD
    Ptr<cv::dnn::PowerLayer> v;
};

static PyTypeObject pyopencv_dnn_PowerLayer_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".dnn_PowerLayer",
    sizeof(pyopencv_dnn_PowerLayer_t),
};

static void pyopencv_dnn_PowerLayer_dealloc(PyObject* self)
{
    ((pyopencv_dnn_PowerLayer_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::dnn::PowerLayer>& r)
{
    pyopencv_dnn_PowerLayer_t *m = PyObject_NEW(pyopencv_dnn_PowerLayer_t, &pyopencv_dnn_PowerLayer_Type);
    new (&(m->v)) Ptr<cv::dnn::PowerLayer>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::dnn::PowerLayer>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_dnn_PowerLayer_Type))
    {
        failmsg("Expected cv::dnn::PowerLayer for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_dnn_PowerLayer_t*)src)->v.dynamicCast<cv::dnn::PowerLayer>();
    return true;
}


struct pyopencv_dnn_RNNLayer_t
{
    PyObject_HEAD
    Ptr<cv::dnn::RNNLayer> v;
};

static PyTypeObject pyopencv_dnn_RNNLayer_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".dnn_RNNLayer",
    sizeof(pyopencv_dnn_RNNLayer_t),
};

static void pyopencv_dnn_RNNLayer_dealloc(PyObject* self)
{
    ((pyopencv_dnn_RNNLayer_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::dnn::RNNLayer>& r)
{
    pyopencv_dnn_RNNLayer_t *m = PyObject_NEW(pyopencv_dnn_RNNLayer_t, &pyopencv_dnn_RNNLayer_Type);
    new (&(m->v)) Ptr<cv::dnn::RNNLayer>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::dnn::RNNLayer>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_dnn_RNNLayer_Type))
    {
        failmsg("Expected cv::dnn::RNNLayer for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_dnn_RNNLayer_t*)src)->v.dynamicCast<cv::dnn::RNNLayer>();
    return true;
}


struct pyopencv_dnn_ReLULayer_t
{
    PyObject_HEAD
    Ptr<cv::dnn::ReLULayer> v;
};

static PyTypeObject pyopencv_dnn_ReLULayer_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".dnn_ReLULayer",
    sizeof(pyopencv_dnn_ReLULayer_t),
};

static void pyopencv_dnn_ReLULayer_dealloc(PyObject* self)
{
    ((pyopencv_dnn_ReLULayer_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::dnn::ReLULayer>& r)
{
    pyopencv_dnn_ReLULayer_t *m = PyObject_NEW(pyopencv_dnn_ReLULayer_t, &pyopencv_dnn_ReLULayer_Type);
    new (&(m->v)) Ptr<cv::dnn::ReLULayer>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::dnn::ReLULayer>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_dnn_ReLULayer_Type))
    {
        failmsg("Expected cv::dnn::ReLULayer for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_dnn_ReLULayer_t*)src)->v.dynamicCast<cv::dnn::ReLULayer>();
    return true;
}


struct pyopencv_dnn_ReshapeLayer_t
{
    PyObject_HEAD
    Ptr<cv::dnn::ReshapeLayer> v;
};

static PyTypeObject pyopencv_dnn_ReshapeLayer_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".dnn_ReshapeLayer",
    sizeof(pyopencv_dnn_ReshapeLayer_t),
};

static void pyopencv_dnn_ReshapeLayer_dealloc(PyObject* self)
{
    ((pyopencv_dnn_ReshapeLayer_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::dnn::ReshapeLayer>& r)
{
    pyopencv_dnn_ReshapeLayer_t *m = PyObject_NEW(pyopencv_dnn_ReshapeLayer_t, &pyopencv_dnn_ReshapeLayer_Type);
    new (&(m->v)) Ptr<cv::dnn::ReshapeLayer>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::dnn::ReshapeLayer>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_dnn_ReshapeLayer_Type))
    {
        failmsg("Expected cv::dnn::ReshapeLayer for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_dnn_ReshapeLayer_t*)src)->v.dynamicCast<cv::dnn::ReshapeLayer>();
    return true;
}


struct pyopencv_dnn_ScaleLayer_t
{
    PyObject_HEAD
    Ptr<cv::dnn::ScaleLayer> v;
};

static PyTypeObject pyopencv_dnn_ScaleLayer_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".dnn_ScaleLayer",
    sizeof(pyopencv_dnn_ScaleLayer_t),
};

static void pyopencv_dnn_ScaleLayer_dealloc(PyObject* self)
{
    ((pyopencv_dnn_ScaleLayer_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::dnn::ScaleLayer>& r)
{
    pyopencv_dnn_ScaleLayer_t *m = PyObject_NEW(pyopencv_dnn_ScaleLayer_t, &pyopencv_dnn_ScaleLayer_Type);
    new (&(m->v)) Ptr<cv::dnn::ScaleLayer>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::dnn::ScaleLayer>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_dnn_ScaleLayer_Type))
    {
        failmsg("Expected cv::dnn::ScaleLayer for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_dnn_ScaleLayer_t*)src)->v.dynamicCast<cv::dnn::ScaleLayer>();
    return true;
}


struct pyopencv_dnn_SigmoidLayer_t
{
    PyObject_HEAD
    Ptr<cv::dnn::SigmoidLayer> v;
};

static PyTypeObject pyopencv_dnn_SigmoidLayer_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".dnn_SigmoidLayer",
    sizeof(pyopencv_dnn_SigmoidLayer_t),
};

static void pyopencv_dnn_SigmoidLayer_dealloc(PyObject* self)
{
    ((pyopencv_dnn_SigmoidLayer_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::dnn::SigmoidLayer>& r)
{
    pyopencv_dnn_SigmoidLayer_t *m = PyObject_NEW(pyopencv_dnn_SigmoidLayer_t, &pyopencv_dnn_SigmoidLayer_Type);
    new (&(m->v)) Ptr<cv::dnn::SigmoidLayer>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::dnn::SigmoidLayer>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_dnn_SigmoidLayer_Type))
    {
        failmsg("Expected cv::dnn::SigmoidLayer for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_dnn_SigmoidLayer_t*)src)->v.dynamicCast<cv::dnn::SigmoidLayer>();
    return true;
}


struct pyopencv_dnn_SliceLayer_t
{
    PyObject_HEAD
    Ptr<cv::dnn::SliceLayer> v;
};

static PyTypeObject pyopencv_dnn_SliceLayer_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".dnn_SliceLayer",
    sizeof(pyopencv_dnn_SliceLayer_t),
};

static void pyopencv_dnn_SliceLayer_dealloc(PyObject* self)
{
    ((pyopencv_dnn_SliceLayer_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::dnn::SliceLayer>& r)
{
    pyopencv_dnn_SliceLayer_t *m = PyObject_NEW(pyopencv_dnn_SliceLayer_t, &pyopencv_dnn_SliceLayer_Type);
    new (&(m->v)) Ptr<cv::dnn::SliceLayer>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::dnn::SliceLayer>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_dnn_SliceLayer_Type))
    {
        failmsg("Expected cv::dnn::SliceLayer for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_dnn_SliceLayer_t*)src)->v.dynamicCast<cv::dnn::SliceLayer>();
    return true;
}


struct pyopencv_dnn_SoftmaxLayer_t
{
    PyObject_HEAD
    Ptr<cv::dnn::SoftmaxLayer> v;
};

static PyTypeObject pyopencv_dnn_SoftmaxLayer_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".dnn_SoftmaxLayer",
    sizeof(pyopencv_dnn_SoftmaxLayer_t),
};

static void pyopencv_dnn_SoftmaxLayer_dealloc(PyObject* self)
{
    ((pyopencv_dnn_SoftmaxLayer_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::dnn::SoftmaxLayer>& r)
{
    pyopencv_dnn_SoftmaxLayer_t *m = PyObject_NEW(pyopencv_dnn_SoftmaxLayer_t, &pyopencv_dnn_SoftmaxLayer_Type);
    new (&(m->v)) Ptr<cv::dnn::SoftmaxLayer>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::dnn::SoftmaxLayer>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_dnn_SoftmaxLayer_Type))
    {
        failmsg("Expected cv::dnn::SoftmaxLayer for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_dnn_SoftmaxLayer_t*)src)->v.dynamicCast<cv::dnn::SoftmaxLayer>();
    return true;
}


struct pyopencv_dnn_SplitLayer_t
{
    PyObject_HEAD
    Ptr<cv::dnn::SplitLayer> v;
};

static PyTypeObject pyopencv_dnn_SplitLayer_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".dnn_SplitLayer",
    sizeof(pyopencv_dnn_SplitLayer_t),
};

static void pyopencv_dnn_SplitLayer_dealloc(PyObject* self)
{
    ((pyopencv_dnn_SplitLayer_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::dnn::SplitLayer>& r)
{
    pyopencv_dnn_SplitLayer_t *m = PyObject_NEW(pyopencv_dnn_SplitLayer_t, &pyopencv_dnn_SplitLayer_Type);
    new (&(m->v)) Ptr<cv::dnn::SplitLayer>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::dnn::SplitLayer>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_dnn_SplitLayer_Type))
    {
        failmsg("Expected cv::dnn::SplitLayer for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_dnn_SplitLayer_t*)src)->v.dynamicCast<cv::dnn::SplitLayer>();
    return true;
}


struct pyopencv_dnn_TanHLayer_t
{
    PyObject_HEAD
    Ptr<cv::dnn::TanHLayer> v;
};

static PyTypeObject pyopencv_dnn_TanHLayer_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".dnn_TanHLayer",
    sizeof(pyopencv_dnn_TanHLayer_t),
};

static void pyopencv_dnn_TanHLayer_dealloc(PyObject* self)
{
    ((pyopencv_dnn_TanHLayer_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::dnn::TanHLayer>& r)
{
    pyopencv_dnn_TanHLayer_t *m = PyObject_NEW(pyopencv_dnn_TanHLayer_t, &pyopencv_dnn_TanHLayer_Type);
    new (&(m->v)) Ptr<cv::dnn::TanHLayer>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::dnn::TanHLayer>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_dnn_TanHLayer_Type))
    {
        failmsg("Expected cv::dnn::TanHLayer for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_dnn_TanHLayer_t*)src)->v.dynamicCast<cv::dnn::TanHLayer>();
    return true;
}


struct pyopencv_dpm_DPMDetector_t
{
    PyObject_HEAD
    Ptr<cv::dpm::DPMDetector> v;
};

static PyTypeObject pyopencv_dpm_DPMDetector_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".dpm_DPMDetector",
    sizeof(pyopencv_dpm_DPMDetector_t),
};

static void pyopencv_dpm_DPMDetector_dealloc(PyObject* self)
{
    ((pyopencv_dpm_DPMDetector_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::dpm::DPMDetector>& r)
{
    pyopencv_dpm_DPMDetector_t *m = PyObject_NEW(pyopencv_dpm_DPMDetector_t, &pyopencv_dpm_DPMDetector_Type);
    new (&(m->v)) Ptr<cv::dpm::DPMDetector>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::dpm::DPMDetector>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_dpm_DPMDetector_Type))
    {
        failmsg("Expected cv::dpm::DPMDetector for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_dpm_DPMDetector_t*)src)->v.dynamicCast<cv::dpm::DPMDetector>();
    return true;
}


struct pyopencv_dpm_DPMDetector_ObjectDetection_t
{
    PyObject_HEAD
    Ptr<cv::dpm::DPMDetector::ObjectDetection> v;
};

static PyTypeObject pyopencv_dpm_DPMDetector_ObjectDetection_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".dpm_DPMDetector_ObjectDetection",
    sizeof(pyopencv_dpm_DPMDetector_ObjectDetection_t),
};

static void pyopencv_dpm_DPMDetector_ObjectDetection_dealloc(PyObject* self)
{
    ((pyopencv_dpm_DPMDetector_ObjectDetection_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::dpm::DPMDetector::ObjectDetection>& r)
{
    pyopencv_dpm_DPMDetector_ObjectDetection_t *m = PyObject_NEW(pyopencv_dpm_DPMDetector_ObjectDetection_t, &pyopencv_dpm_DPMDetector_ObjectDetection_Type);
    new (&(m->v)) Ptr<cv::dpm::DPMDetector::ObjectDetection>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::dpm::DPMDetector::ObjectDetection>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_dpm_DPMDetector_ObjectDetection_Type))
    {
        failmsg("Expected cv::dpm::DPMDetector::ObjectDetection for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_dpm_DPMDetector_ObjectDetection_t*)src)->v.dynamicCast<cv::dpm::DPMDetector::ObjectDetection>();
    return true;
}


struct pyopencv_face_BIF_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_face_BIF_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".face_BIF",
    sizeof(pyopencv_face_BIF_t),
};

static void pyopencv_face_BIF_dealloc(PyObject* self)
{
    ((pyopencv_face_BIF_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::face::BIF>& r)
{
    pyopencv_face_BIF_t *m = PyObject_NEW(pyopencv_face_BIF_t, &pyopencv_face_BIF_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::face::BIF>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_face_BIF_Type))
    {
        failmsg("Expected cv::face::BIF for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_face_BIF_t*)src)->v.dynamicCast<cv::face::BIF>();
    return true;
}


struct pyopencv_face_BasicFaceRecognizer_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_face_BasicFaceRecognizer_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".face_BasicFaceRecognizer",
    sizeof(pyopencv_face_BasicFaceRecognizer_t),
};

static void pyopencv_face_BasicFaceRecognizer_dealloc(PyObject* self)
{
    ((pyopencv_face_BasicFaceRecognizer_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::face::BasicFaceRecognizer>& r)
{
    pyopencv_face_BasicFaceRecognizer_t *m = PyObject_NEW(pyopencv_face_BasicFaceRecognizer_t, &pyopencv_face_BasicFaceRecognizer_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::face::BasicFaceRecognizer>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_face_BasicFaceRecognizer_Type))
    {
        failmsg("Expected cv::face::BasicFaceRecognizer for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_face_BasicFaceRecognizer_t*)src)->v.dynamicCast<cv::face::BasicFaceRecognizer>();
    return true;
}


struct pyopencv_face_FaceRecognizer_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_face_FaceRecognizer_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".face_FaceRecognizer",
    sizeof(pyopencv_face_FaceRecognizer_t),
};

static void pyopencv_face_FaceRecognizer_dealloc(PyObject* self)
{
    ((pyopencv_face_FaceRecognizer_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::face::FaceRecognizer>& r)
{
    pyopencv_face_FaceRecognizer_t *m = PyObject_NEW(pyopencv_face_FaceRecognizer_t, &pyopencv_face_FaceRecognizer_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::face::FaceRecognizer>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_face_FaceRecognizer_Type))
    {
        failmsg("Expected cv::face::FaceRecognizer for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_face_FaceRecognizer_t*)src)->v.dynamicCast<cv::face::FaceRecognizer>();
    return true;
}


struct pyopencv_face_LBPHFaceRecognizer_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_face_LBPHFaceRecognizer_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".face_LBPHFaceRecognizer",
    sizeof(pyopencv_face_LBPHFaceRecognizer_t),
};

static void pyopencv_face_LBPHFaceRecognizer_dealloc(PyObject* self)
{
    ((pyopencv_face_LBPHFaceRecognizer_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::face::LBPHFaceRecognizer>& r)
{
    pyopencv_face_LBPHFaceRecognizer_t *m = PyObject_NEW(pyopencv_face_LBPHFaceRecognizer_t, &pyopencv_face_LBPHFaceRecognizer_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::face::LBPHFaceRecognizer>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_face_LBPHFaceRecognizer_Type))
    {
        failmsg("Expected cv::face::LBPHFaceRecognizer for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_face_LBPHFaceRecognizer_t*)src)->v.dynamicCast<cv::face::LBPHFaceRecognizer>();
    return true;
}


struct pyopencv_face_PredictCollector_t
{
    PyObject_HEAD
    Ptr<cv::face::PredictCollector> v;
};

static PyTypeObject pyopencv_face_PredictCollector_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".face_PredictCollector",
    sizeof(pyopencv_face_PredictCollector_t),
};

static void pyopencv_face_PredictCollector_dealloc(PyObject* self)
{
    ((pyopencv_face_PredictCollector_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::face::PredictCollector>& r)
{
    pyopencv_face_PredictCollector_t *m = PyObject_NEW(pyopencv_face_PredictCollector_t, &pyopencv_face_PredictCollector_Type);
    new (&(m->v)) Ptr<cv::face::PredictCollector>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::face::PredictCollector>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_face_PredictCollector_Type))
    {
        failmsg("Expected cv::face::PredictCollector for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_face_PredictCollector_t*)src)->v.dynamicCast<cv::face::PredictCollector>();
    return true;
}


struct pyopencv_face_StandardCollector_t
{
    PyObject_HEAD
    Ptr<cv::face::StandardCollector> v;
};

static PyTypeObject pyopencv_face_StandardCollector_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".face_StandardCollector",
    sizeof(pyopencv_face_StandardCollector_t),
};

static void pyopencv_face_StandardCollector_dealloc(PyObject* self)
{
    ((pyopencv_face_StandardCollector_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::face::StandardCollector>& r)
{
    pyopencv_face_StandardCollector_t *m = PyObject_NEW(pyopencv_face_StandardCollector_t, &pyopencv_face_StandardCollector_Type);
    new (&(m->v)) Ptr<cv::face::StandardCollector>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::face::StandardCollector>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_face_StandardCollector_Type))
    {
        failmsg("Expected cv::face::StandardCollector for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_face_StandardCollector_t*)src)->v.dynamicCast<cv::face::StandardCollector>();
    return true;
}


struct pyopencv_flann_Index_t
{
    PyObject_HEAD
    Ptr<cv::flann::Index> v;
};

static PyTypeObject pyopencv_flann_Index_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".flann_Index",
    sizeof(pyopencv_flann_Index_t),
};

static void pyopencv_flann_Index_dealloc(PyObject* self)
{
    ((pyopencv_flann_Index_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::flann::Index>& r)
{
    pyopencv_flann_Index_t *m = PyObject_NEW(pyopencv_flann_Index_t, &pyopencv_flann_Index_Type);
    new (&(m->v)) Ptr<cv::flann::Index>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::flann::Index>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_flann_Index_Type))
    {
        failmsg("Expected cv::flann::Index for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_flann_Index_t*)src)->v.dynamicCast<cv::flann::Index>();
    return true;
}


struct pyopencv_ml_ANN_MLP_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_ml_ANN_MLP_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".ml_ANN_MLP",
    sizeof(pyopencv_ml_ANN_MLP_t),
};

static void pyopencv_ml_ANN_MLP_dealloc(PyObject* self)
{
    ((pyopencv_ml_ANN_MLP_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::ml::ANN_MLP>& r)
{
    pyopencv_ml_ANN_MLP_t *m = PyObject_NEW(pyopencv_ml_ANN_MLP_t, &pyopencv_ml_ANN_MLP_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::ml::ANN_MLP>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_ml_ANN_MLP_Type))
    {
        failmsg("Expected cv::ml::ANN_MLP for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_ml_ANN_MLP_t*)src)->v.dynamicCast<cv::ml::ANN_MLP>();
    return true;
}


struct pyopencv_ml_Boost_t
{
    PyObject_HEAD
    Ptr<cv::ml::Boost> v;
};

static PyTypeObject pyopencv_ml_Boost_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".ml_Boost",
    sizeof(pyopencv_ml_Boost_t),
};

static void pyopencv_ml_Boost_dealloc(PyObject* self)
{
    ((pyopencv_ml_Boost_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::ml::Boost>& r)
{
    pyopencv_ml_Boost_t *m = PyObject_NEW(pyopencv_ml_Boost_t, &pyopencv_ml_Boost_Type);
    new (&(m->v)) Ptr<cv::ml::Boost>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::ml::Boost>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_ml_Boost_Type))
    {
        failmsg("Expected cv::ml::Boost for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_ml_Boost_t*)src)->v.dynamicCast<cv::ml::Boost>();
    return true;
}


struct pyopencv_ml_DTrees_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_ml_DTrees_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".ml_DTrees",
    sizeof(pyopencv_ml_DTrees_t),
};

static void pyopencv_ml_DTrees_dealloc(PyObject* self)
{
    ((pyopencv_ml_DTrees_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::ml::DTrees>& r)
{
    pyopencv_ml_DTrees_t *m = PyObject_NEW(pyopencv_ml_DTrees_t, &pyopencv_ml_DTrees_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::ml::DTrees>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_ml_DTrees_Type))
    {
        failmsg("Expected cv::ml::DTrees for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_ml_DTrees_t*)src)->v.dynamicCast<cv::ml::DTrees>();
    return true;
}


struct pyopencv_ml_EM_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_ml_EM_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".ml_EM",
    sizeof(pyopencv_ml_EM_t),
};

static void pyopencv_ml_EM_dealloc(PyObject* self)
{
    ((pyopencv_ml_EM_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::ml::EM>& r)
{
    pyopencv_ml_EM_t *m = PyObject_NEW(pyopencv_ml_EM_t, &pyopencv_ml_EM_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::ml::EM>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_ml_EM_Type))
    {
        failmsg("Expected cv::ml::EM for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_ml_EM_t*)src)->v.dynamicCast<cv::ml::EM>();
    return true;
}


struct pyopencv_ml_KNearest_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_ml_KNearest_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".ml_KNearest",
    sizeof(pyopencv_ml_KNearest_t),
};

static void pyopencv_ml_KNearest_dealloc(PyObject* self)
{
    ((pyopencv_ml_KNearest_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::ml::KNearest>& r)
{
    pyopencv_ml_KNearest_t *m = PyObject_NEW(pyopencv_ml_KNearest_t, &pyopencv_ml_KNearest_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::ml::KNearest>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_ml_KNearest_Type))
    {
        failmsg("Expected cv::ml::KNearest for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_ml_KNearest_t*)src)->v.dynamicCast<cv::ml::KNearest>();
    return true;
}


struct pyopencv_ml_LogisticRegression_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_ml_LogisticRegression_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".ml_LogisticRegression",
    sizeof(pyopencv_ml_LogisticRegression_t),
};

static void pyopencv_ml_LogisticRegression_dealloc(PyObject* self)
{
    ((pyopencv_ml_LogisticRegression_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::ml::LogisticRegression>& r)
{
    pyopencv_ml_LogisticRegression_t *m = PyObject_NEW(pyopencv_ml_LogisticRegression_t, &pyopencv_ml_LogisticRegression_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::ml::LogisticRegression>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_ml_LogisticRegression_Type))
    {
        failmsg("Expected cv::ml::LogisticRegression for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_ml_LogisticRegression_t*)src)->v.dynamicCast<cv::ml::LogisticRegression>();
    return true;
}


struct pyopencv_ml_NormalBayesClassifier_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_ml_NormalBayesClassifier_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".ml_NormalBayesClassifier",
    sizeof(pyopencv_ml_NormalBayesClassifier_t),
};

static void pyopencv_ml_NormalBayesClassifier_dealloc(PyObject* self)
{
    ((pyopencv_ml_NormalBayesClassifier_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::ml::NormalBayesClassifier>& r)
{
    pyopencv_ml_NormalBayesClassifier_t *m = PyObject_NEW(pyopencv_ml_NormalBayesClassifier_t, &pyopencv_ml_NormalBayesClassifier_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::ml::NormalBayesClassifier>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_ml_NormalBayesClassifier_Type))
    {
        failmsg("Expected cv::ml::NormalBayesClassifier for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_ml_NormalBayesClassifier_t*)src)->v.dynamicCast<cv::ml::NormalBayesClassifier>();
    return true;
}


struct pyopencv_ml_RTrees_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_ml_RTrees_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".ml_RTrees",
    sizeof(pyopencv_ml_RTrees_t),
};

static void pyopencv_ml_RTrees_dealloc(PyObject* self)
{
    ((pyopencv_ml_RTrees_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::ml::RTrees>& r)
{
    pyopencv_ml_RTrees_t *m = PyObject_NEW(pyopencv_ml_RTrees_t, &pyopencv_ml_RTrees_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::ml::RTrees>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_ml_RTrees_Type))
    {
        failmsg("Expected cv::ml::RTrees for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_ml_RTrees_t*)src)->v.dynamicCast<cv::ml::RTrees>();
    return true;
}


struct pyopencv_ml_SVM_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_ml_SVM_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".ml_SVM",
    sizeof(pyopencv_ml_SVM_t),
};

static void pyopencv_ml_SVM_dealloc(PyObject* self)
{
    ((pyopencv_ml_SVM_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::ml::SVM>& r)
{
    pyopencv_ml_SVM_t *m = PyObject_NEW(pyopencv_ml_SVM_t, &pyopencv_ml_SVM_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::ml::SVM>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_ml_SVM_Type))
    {
        failmsg("Expected cv::ml::SVM for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_ml_SVM_t*)src)->v.dynamicCast<cv::ml::SVM>();
    return true;
}


struct pyopencv_ml_SVMSGD_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_ml_SVMSGD_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".ml_SVMSGD",
    sizeof(pyopencv_ml_SVMSGD_t),
};

static void pyopencv_ml_SVMSGD_dealloc(PyObject* self)
{
    ((pyopencv_ml_SVMSGD_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::ml::SVMSGD>& r)
{
    pyopencv_ml_SVMSGD_t *m = PyObject_NEW(pyopencv_ml_SVMSGD_t, &pyopencv_ml_SVMSGD_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::ml::SVMSGD>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_ml_SVMSGD_Type))
    {
        failmsg("Expected cv::ml::SVMSGD for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_ml_SVMSGD_t*)src)->v.dynamicCast<cv::ml::SVMSGD>();
    return true;
}


struct pyopencv_ml_StatModel_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_ml_StatModel_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".ml_StatModel",
    sizeof(pyopencv_ml_StatModel_t),
};

static void pyopencv_ml_StatModel_dealloc(PyObject* self)
{
    ((pyopencv_ml_StatModel_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::ml::StatModel>& r)
{
    pyopencv_ml_StatModel_t *m = PyObject_NEW(pyopencv_ml_StatModel_t, &pyopencv_ml_StatModel_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::ml::StatModel>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_ml_StatModel_Type))
    {
        failmsg("Expected cv::ml::StatModel for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_ml_StatModel_t*)src)->v.dynamicCast<cv::ml::StatModel>();
    return true;
}


struct pyopencv_ml_TrainData_t
{
    PyObject_HEAD
    Ptr<cv::ml::TrainData> v;
};

static PyTypeObject pyopencv_ml_TrainData_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".ml_TrainData",
    sizeof(pyopencv_ml_TrainData_t),
};

static void pyopencv_ml_TrainData_dealloc(PyObject* self)
{
    ((pyopencv_ml_TrainData_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::ml::TrainData>& r)
{
    pyopencv_ml_TrainData_t *m = PyObject_NEW(pyopencv_ml_TrainData_t, &pyopencv_ml_TrainData_Type);
    new (&(m->v)) Ptr<cv::ml::TrainData>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::ml::TrainData>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_ml_TrainData_Type))
    {
        failmsg("Expected cv::ml::TrainData for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_ml_TrainData_t*)src)->v.dynamicCast<cv::ml::TrainData>();
    return true;
}


struct pyopencv_optflow_DISOpticalFlow_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_optflow_DISOpticalFlow_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".optflow_DISOpticalFlow",
    sizeof(pyopencv_optflow_DISOpticalFlow_t),
};

static void pyopencv_optflow_DISOpticalFlow_dealloc(PyObject* self)
{
    ((pyopencv_optflow_DISOpticalFlow_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::optflow::DISOpticalFlow>& r)
{
    pyopencv_optflow_DISOpticalFlow_t *m = PyObject_NEW(pyopencv_optflow_DISOpticalFlow_t, &pyopencv_optflow_DISOpticalFlow_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::optflow::DISOpticalFlow>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_optflow_DISOpticalFlow_Type))
    {
        failmsg("Expected cv::optflow::DISOpticalFlow for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_optflow_DISOpticalFlow_t*)src)->v.dynamicCast<cv::optflow::DISOpticalFlow>();
    return true;
}


struct pyopencv_optflow_GPCDetails_t
{
    PyObject_HEAD
    Ptr<cv::optflow::GPCDetails> v;
};

static PyTypeObject pyopencv_optflow_GPCDetails_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".optflow_GPCDetails",
    sizeof(pyopencv_optflow_GPCDetails_t),
};

static void pyopencv_optflow_GPCDetails_dealloc(PyObject* self)
{
    ((pyopencv_optflow_GPCDetails_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::optflow::GPCDetails>& r)
{
    pyopencv_optflow_GPCDetails_t *m = PyObject_NEW(pyopencv_optflow_GPCDetails_t, &pyopencv_optflow_GPCDetails_Type);
    new (&(m->v)) Ptr<cv::optflow::GPCDetails>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::optflow::GPCDetails>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_optflow_GPCDetails_Type))
    {
        failmsg("Expected cv::optflow::GPCDetails for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_optflow_GPCDetails_t*)src)->v.dynamicCast<cv::optflow::GPCDetails>();
    return true;
}


struct pyopencv_optflow_GPCPatchDescriptor_t
{
    PyObject_HEAD
    Ptr<cv::optflow::GPCPatchDescriptor> v;
};

static PyTypeObject pyopencv_optflow_GPCPatchDescriptor_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".optflow_GPCPatchDescriptor",
    sizeof(pyopencv_optflow_GPCPatchDescriptor_t),
};

static void pyopencv_optflow_GPCPatchDescriptor_dealloc(PyObject* self)
{
    ((pyopencv_optflow_GPCPatchDescriptor_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::optflow::GPCPatchDescriptor>& r)
{
    pyopencv_optflow_GPCPatchDescriptor_t *m = PyObject_NEW(pyopencv_optflow_GPCPatchDescriptor_t, &pyopencv_optflow_GPCPatchDescriptor_Type);
    new (&(m->v)) Ptr<cv::optflow::GPCPatchDescriptor>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::optflow::GPCPatchDescriptor>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_optflow_GPCPatchDescriptor_Type))
    {
        failmsg("Expected cv::optflow::GPCPatchDescriptor for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_optflow_GPCPatchDescriptor_t*)src)->v.dynamicCast<cv::optflow::GPCPatchDescriptor>();
    return true;
}


struct pyopencv_optflow_GPCPatchSample_t
{
    PyObject_HEAD
    Ptr<cv::optflow::GPCPatchSample> v;
};

static PyTypeObject pyopencv_optflow_GPCPatchSample_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".optflow_GPCPatchSample",
    sizeof(pyopencv_optflow_GPCPatchSample_t),
};

static void pyopencv_optflow_GPCPatchSample_dealloc(PyObject* self)
{
    ((pyopencv_optflow_GPCPatchSample_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::optflow::GPCPatchSample>& r)
{
    pyopencv_optflow_GPCPatchSample_t *m = PyObject_NEW(pyopencv_optflow_GPCPatchSample_t, &pyopencv_optflow_GPCPatchSample_Type);
    new (&(m->v)) Ptr<cv::optflow::GPCPatchSample>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::optflow::GPCPatchSample>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_optflow_GPCPatchSample_Type))
    {
        failmsg("Expected cv::optflow::GPCPatchSample for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_optflow_GPCPatchSample_t*)src)->v.dynamicCast<cv::optflow::GPCPatchSample>();
    return true;
}


struct pyopencv_optflow_GPCTrainingSamples_t
{
    PyObject_HEAD
    Ptr<cv::optflow::GPCTrainingSamples> v;
};

static PyTypeObject pyopencv_optflow_GPCTrainingSamples_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".optflow_GPCTrainingSamples",
    sizeof(pyopencv_optflow_GPCTrainingSamples_t),
};

static void pyopencv_optflow_GPCTrainingSamples_dealloc(PyObject* self)
{
    ((pyopencv_optflow_GPCTrainingSamples_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::optflow::GPCTrainingSamples>& r)
{
    pyopencv_optflow_GPCTrainingSamples_t *m = PyObject_NEW(pyopencv_optflow_GPCTrainingSamples_t, &pyopencv_optflow_GPCTrainingSamples_Type);
    new (&(m->v)) Ptr<cv::optflow::GPCTrainingSamples>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::optflow::GPCTrainingSamples>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_optflow_GPCTrainingSamples_Type))
    {
        failmsg("Expected cv::optflow::GPCTrainingSamples for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_optflow_GPCTrainingSamples_t*)src)->v.dynamicCast<cv::optflow::GPCTrainingSamples>();
    return true;
}


struct pyopencv_optflow_GPCTree_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_optflow_GPCTree_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".optflow_GPCTree",
    sizeof(pyopencv_optflow_GPCTree_t),
};

static void pyopencv_optflow_GPCTree_dealloc(PyObject* self)
{
    ((pyopencv_optflow_GPCTree_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::optflow::GPCTree>& r)
{
    pyopencv_optflow_GPCTree_t *m = PyObject_NEW(pyopencv_optflow_GPCTree_t, &pyopencv_optflow_GPCTree_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::optflow::GPCTree>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_optflow_GPCTree_Type))
    {
        failmsg("Expected cv::optflow::GPCTree for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_optflow_GPCTree_t*)src)->v.dynamicCast<cv::optflow::GPCTree>();
    return true;
}


struct pyopencv_optflow_OpticalFlowPCAFlow_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_optflow_OpticalFlowPCAFlow_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".optflow_OpticalFlowPCAFlow",
    sizeof(pyopencv_optflow_OpticalFlowPCAFlow_t),
};

static void pyopencv_optflow_OpticalFlowPCAFlow_dealloc(PyObject* self)
{
    ((pyopencv_optflow_OpticalFlowPCAFlow_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::optflow::OpticalFlowPCAFlow>& r)
{
    pyopencv_optflow_OpticalFlowPCAFlow_t *m = PyObject_NEW(pyopencv_optflow_OpticalFlowPCAFlow_t, &pyopencv_optflow_OpticalFlowPCAFlow_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::optflow::OpticalFlowPCAFlow>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_optflow_OpticalFlowPCAFlow_Type))
    {
        failmsg("Expected cv::optflow::OpticalFlowPCAFlow for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_optflow_OpticalFlowPCAFlow_t*)src)->v.dynamicCast<cv::optflow::OpticalFlowPCAFlow>();
    return true;
}


struct pyopencv_optflow_PCAPrior_t
{
    PyObject_HEAD
    Ptr<cv::optflow::PCAPrior> v;
};

static PyTypeObject pyopencv_optflow_PCAPrior_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".optflow_PCAPrior",
    sizeof(pyopencv_optflow_PCAPrior_t),
};

static void pyopencv_optflow_PCAPrior_dealloc(PyObject* self)
{
    ((pyopencv_optflow_PCAPrior_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::optflow::PCAPrior>& r)
{
    pyopencv_optflow_PCAPrior_t *m = PyObject_NEW(pyopencv_optflow_PCAPrior_t, &pyopencv_optflow_PCAPrior_Type);
    new (&(m->v)) Ptr<cv::optflow::PCAPrior>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::optflow::PCAPrior>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_optflow_PCAPrior_Type))
    {
        failmsg("Expected cv::optflow::PCAPrior for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_optflow_PCAPrior_t*)src)->v.dynamicCast<cv::optflow::PCAPrior>();
    return true;
}


struct pyopencv_optflow_VariationalRefinement_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_optflow_VariationalRefinement_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".optflow_VariationalRefinement",
    sizeof(pyopencv_optflow_VariationalRefinement_t),
};

static void pyopencv_optflow_VariationalRefinement_dealloc(PyObject* self)
{
    ((pyopencv_optflow_VariationalRefinement_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::optflow::VariationalRefinement>& r)
{
    pyopencv_optflow_VariationalRefinement_t *m = PyObject_NEW(pyopencv_optflow_VariationalRefinement_t, &pyopencv_optflow_VariationalRefinement_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::optflow::VariationalRefinement>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_optflow_VariationalRefinement_Type))
    {
        failmsg("Expected cv::optflow::VariationalRefinement for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_optflow_VariationalRefinement_t*)src)->v.dynamicCast<cv::optflow::VariationalRefinement>();
    return true;
}


struct pyopencv_phase_unwrapping_HistogramPhaseUnwrapping_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_phase_unwrapping_HistogramPhaseUnwrapping_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".phase_unwrapping_HistogramPhaseUnwrapping",
    sizeof(pyopencv_phase_unwrapping_HistogramPhaseUnwrapping_t),
};

static void pyopencv_phase_unwrapping_HistogramPhaseUnwrapping_dealloc(PyObject* self)
{
    ((pyopencv_phase_unwrapping_HistogramPhaseUnwrapping_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::phase_unwrapping::HistogramPhaseUnwrapping>& r)
{
    pyopencv_phase_unwrapping_HistogramPhaseUnwrapping_t *m = PyObject_NEW(pyopencv_phase_unwrapping_HistogramPhaseUnwrapping_t, &pyopencv_phase_unwrapping_HistogramPhaseUnwrapping_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::phase_unwrapping::HistogramPhaseUnwrapping>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_phase_unwrapping_HistogramPhaseUnwrapping_Type))
    {
        failmsg("Expected cv::phase_unwrapping::HistogramPhaseUnwrapping for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_phase_unwrapping_HistogramPhaseUnwrapping_t*)src)->v.dynamicCast<cv::phase_unwrapping::HistogramPhaseUnwrapping>();
    return true;
}


struct pyopencv_phase_unwrapping_PhaseUnwrapping_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_phase_unwrapping_PhaseUnwrapping_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".phase_unwrapping_PhaseUnwrapping",
    sizeof(pyopencv_phase_unwrapping_PhaseUnwrapping_t),
};

static void pyopencv_phase_unwrapping_PhaseUnwrapping_dealloc(PyObject* self)
{
    ((pyopencv_phase_unwrapping_PhaseUnwrapping_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::phase_unwrapping::PhaseUnwrapping>& r)
{
    pyopencv_phase_unwrapping_PhaseUnwrapping_t *m = PyObject_NEW(pyopencv_phase_unwrapping_PhaseUnwrapping_t, &pyopencv_phase_unwrapping_PhaseUnwrapping_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::phase_unwrapping::PhaseUnwrapping>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_phase_unwrapping_PhaseUnwrapping_Type))
    {
        failmsg("Expected cv::phase_unwrapping::PhaseUnwrapping for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_phase_unwrapping_PhaseUnwrapping_t*)src)->v.dynamicCast<cv::phase_unwrapping::PhaseUnwrapping>();
    return true;
}


struct pyopencv_plot_Plot2d_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_plot_Plot2d_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".plot_Plot2d",
    sizeof(pyopencv_plot_Plot2d_t),
};

static void pyopencv_plot_Plot2d_dealloc(PyObject* self)
{
    ((pyopencv_plot_Plot2d_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::plot::Plot2d>& r)
{
    pyopencv_plot_Plot2d_t *m = PyObject_NEW(pyopencv_plot_Plot2d_t, &pyopencv_plot_Plot2d_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::plot::Plot2d>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_plot_Plot2d_Type))
    {
        failmsg("Expected cv::plot::Plot2d for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_plot_Plot2d_t*)src)->v.dynamicCast<cv::plot::Plot2d>();
    return true;
}


struct pyopencv_ppf_match_3d_ICP_t
{
    PyObject_HEAD
    Ptr<cv::ppf_match_3d::ICP> v;
};

static PyTypeObject pyopencv_ppf_match_3d_ICP_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".ppf_match_3d_ICP",
    sizeof(pyopencv_ppf_match_3d_ICP_t),
};

static void pyopencv_ppf_match_3d_ICP_dealloc(PyObject* self)
{
    ((pyopencv_ppf_match_3d_ICP_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::ppf_match_3d::ICP>& r)
{
    pyopencv_ppf_match_3d_ICP_t *m = PyObject_NEW(pyopencv_ppf_match_3d_ICP_t, &pyopencv_ppf_match_3d_ICP_Type);
    new (&(m->v)) Ptr<cv::ppf_match_3d::ICP>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::ppf_match_3d::ICP>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_ppf_match_3d_ICP_Type))
    {
        failmsg("Expected cv::ppf_match_3d::ICP for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_ppf_match_3d_ICP_t*)src)->v.dynamicCast<cv::ppf_match_3d::ICP>();
    return true;
}


struct pyopencv_reg_Map_t
{
    PyObject_HEAD
    Ptr<cv::reg::Map> v;
};

static PyTypeObject pyopencv_reg_Map_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".reg_Map",
    sizeof(pyopencv_reg_Map_t),
};

static void pyopencv_reg_Map_dealloc(PyObject* self)
{
    ((pyopencv_reg_Map_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::reg::Map>& r)
{
    pyopencv_reg_Map_t *m = PyObject_NEW(pyopencv_reg_Map_t, &pyopencv_reg_Map_Type);
    new (&(m->v)) Ptr<cv::reg::Map>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::reg::Map>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_reg_Map_Type))
    {
        failmsg("Expected cv::reg::Map for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_reg_Map_t*)src)->v.dynamicCast<cv::reg::Map>();
    return true;
}


struct pyopencv_reg_MapAffine_t
{
    PyObject_HEAD
    Ptr<cv::reg::MapAffine> v;
};

static PyTypeObject pyopencv_reg_MapAffine_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".reg_MapAffine",
    sizeof(pyopencv_reg_MapAffine_t),
};

static void pyopencv_reg_MapAffine_dealloc(PyObject* self)
{
    ((pyopencv_reg_MapAffine_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::reg::MapAffine>& r)
{
    pyopencv_reg_MapAffine_t *m = PyObject_NEW(pyopencv_reg_MapAffine_t, &pyopencv_reg_MapAffine_Type);
    new (&(m->v)) Ptr<cv::reg::MapAffine>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::reg::MapAffine>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_reg_MapAffine_Type))
    {
        failmsg("Expected cv::reg::MapAffine for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_reg_MapAffine_t*)src)->v.dynamicCast<cv::reg::MapAffine>();
    return true;
}


struct pyopencv_reg_MapProjec_t
{
    PyObject_HEAD
    Ptr<cv::reg::MapProjec> v;
};

static PyTypeObject pyopencv_reg_MapProjec_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".reg_MapProjec",
    sizeof(pyopencv_reg_MapProjec_t),
};

static void pyopencv_reg_MapProjec_dealloc(PyObject* self)
{
    ((pyopencv_reg_MapProjec_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::reg::MapProjec>& r)
{
    pyopencv_reg_MapProjec_t *m = PyObject_NEW(pyopencv_reg_MapProjec_t, &pyopencv_reg_MapProjec_Type);
    new (&(m->v)) Ptr<cv::reg::MapProjec>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::reg::MapProjec>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_reg_MapProjec_Type))
    {
        failmsg("Expected cv::reg::MapProjec for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_reg_MapProjec_t*)src)->v.dynamicCast<cv::reg::MapProjec>();
    return true;
}


struct pyopencv_reg_MapShift_t
{
    PyObject_HEAD
    Ptr<cv::reg::MapShift> v;
};

static PyTypeObject pyopencv_reg_MapShift_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".reg_MapShift",
    sizeof(pyopencv_reg_MapShift_t),
};

static void pyopencv_reg_MapShift_dealloc(PyObject* self)
{
    ((pyopencv_reg_MapShift_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::reg::MapShift>& r)
{
    pyopencv_reg_MapShift_t *m = PyObject_NEW(pyopencv_reg_MapShift_t, &pyopencv_reg_MapShift_Type);
    new (&(m->v)) Ptr<cv::reg::MapShift>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::reg::MapShift>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_reg_MapShift_Type))
    {
        failmsg("Expected cv::reg::MapShift for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_reg_MapShift_t*)src)->v.dynamicCast<cv::reg::MapShift>();
    return true;
}


struct pyopencv_reg_MapTypeCaster_t
{
    PyObject_HEAD
    Ptr<cv::reg::MapTypeCaster> v;
};

static PyTypeObject pyopencv_reg_MapTypeCaster_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".reg_MapTypeCaster",
    sizeof(pyopencv_reg_MapTypeCaster_t),
};

static void pyopencv_reg_MapTypeCaster_dealloc(PyObject* self)
{
    ((pyopencv_reg_MapTypeCaster_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::reg::MapTypeCaster>& r)
{
    pyopencv_reg_MapTypeCaster_t *m = PyObject_NEW(pyopencv_reg_MapTypeCaster_t, &pyopencv_reg_MapTypeCaster_Type);
    new (&(m->v)) Ptr<cv::reg::MapTypeCaster>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::reg::MapTypeCaster>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_reg_MapTypeCaster_Type))
    {
        failmsg("Expected cv::reg::MapTypeCaster for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_reg_MapTypeCaster_t*)src)->v.dynamicCast<cv::reg::MapTypeCaster>();
    return true;
}


struct pyopencv_reg_Mapper_t
{
    PyObject_HEAD
    Ptr<cv::reg::Mapper> v;
};

static PyTypeObject pyopencv_reg_Mapper_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".reg_Mapper",
    sizeof(pyopencv_reg_Mapper_t),
};

static void pyopencv_reg_Mapper_dealloc(PyObject* self)
{
    ((pyopencv_reg_Mapper_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::reg::Mapper>& r)
{
    pyopencv_reg_Mapper_t *m = PyObject_NEW(pyopencv_reg_Mapper_t, &pyopencv_reg_Mapper_Type);
    new (&(m->v)) Ptr<cv::reg::Mapper>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::reg::Mapper>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_reg_Mapper_Type))
    {
        failmsg("Expected cv::reg::Mapper for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_reg_Mapper_t*)src)->v.dynamicCast<cv::reg::Mapper>();
    return true;
}


struct pyopencv_reg_MapperGradAffine_t
{
    PyObject_HEAD
    Ptr<cv::reg::MapperGradAffine> v;
};

static PyTypeObject pyopencv_reg_MapperGradAffine_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".reg_MapperGradAffine",
    sizeof(pyopencv_reg_MapperGradAffine_t),
};

static void pyopencv_reg_MapperGradAffine_dealloc(PyObject* self)
{
    ((pyopencv_reg_MapperGradAffine_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::reg::MapperGradAffine>& r)
{
    pyopencv_reg_MapperGradAffine_t *m = PyObject_NEW(pyopencv_reg_MapperGradAffine_t, &pyopencv_reg_MapperGradAffine_Type);
    new (&(m->v)) Ptr<cv::reg::MapperGradAffine>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::reg::MapperGradAffine>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_reg_MapperGradAffine_Type))
    {
        failmsg("Expected cv::reg::MapperGradAffine for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_reg_MapperGradAffine_t*)src)->v.dynamicCast<cv::reg::MapperGradAffine>();
    return true;
}


struct pyopencv_reg_MapperGradEuclid_t
{
    PyObject_HEAD
    Ptr<cv::reg::MapperGradEuclid> v;
};

static PyTypeObject pyopencv_reg_MapperGradEuclid_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".reg_MapperGradEuclid",
    sizeof(pyopencv_reg_MapperGradEuclid_t),
};

static void pyopencv_reg_MapperGradEuclid_dealloc(PyObject* self)
{
    ((pyopencv_reg_MapperGradEuclid_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::reg::MapperGradEuclid>& r)
{
    pyopencv_reg_MapperGradEuclid_t *m = PyObject_NEW(pyopencv_reg_MapperGradEuclid_t, &pyopencv_reg_MapperGradEuclid_Type);
    new (&(m->v)) Ptr<cv::reg::MapperGradEuclid>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::reg::MapperGradEuclid>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_reg_MapperGradEuclid_Type))
    {
        failmsg("Expected cv::reg::MapperGradEuclid for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_reg_MapperGradEuclid_t*)src)->v.dynamicCast<cv::reg::MapperGradEuclid>();
    return true;
}


struct pyopencv_reg_MapperGradProj_t
{
    PyObject_HEAD
    Ptr<cv::reg::MapperGradProj> v;
};

static PyTypeObject pyopencv_reg_MapperGradProj_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".reg_MapperGradProj",
    sizeof(pyopencv_reg_MapperGradProj_t),
};

static void pyopencv_reg_MapperGradProj_dealloc(PyObject* self)
{
    ((pyopencv_reg_MapperGradProj_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::reg::MapperGradProj>& r)
{
    pyopencv_reg_MapperGradProj_t *m = PyObject_NEW(pyopencv_reg_MapperGradProj_t, &pyopencv_reg_MapperGradProj_Type);
    new (&(m->v)) Ptr<cv::reg::MapperGradProj>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::reg::MapperGradProj>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_reg_MapperGradProj_Type))
    {
        failmsg("Expected cv::reg::MapperGradProj for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_reg_MapperGradProj_t*)src)->v.dynamicCast<cv::reg::MapperGradProj>();
    return true;
}


struct pyopencv_reg_MapperGradShift_t
{
    PyObject_HEAD
    Ptr<cv::reg::MapperGradShift> v;
};

static PyTypeObject pyopencv_reg_MapperGradShift_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".reg_MapperGradShift",
    sizeof(pyopencv_reg_MapperGradShift_t),
};

static void pyopencv_reg_MapperGradShift_dealloc(PyObject* self)
{
    ((pyopencv_reg_MapperGradShift_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::reg::MapperGradShift>& r)
{
    pyopencv_reg_MapperGradShift_t *m = PyObject_NEW(pyopencv_reg_MapperGradShift_t, &pyopencv_reg_MapperGradShift_Type);
    new (&(m->v)) Ptr<cv::reg::MapperGradShift>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::reg::MapperGradShift>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_reg_MapperGradShift_Type))
    {
        failmsg("Expected cv::reg::MapperGradShift for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_reg_MapperGradShift_t*)src)->v.dynamicCast<cv::reg::MapperGradShift>();
    return true;
}


struct pyopencv_reg_MapperGradSimilar_t
{
    PyObject_HEAD
    Ptr<cv::reg::MapperGradSimilar> v;
};

static PyTypeObject pyopencv_reg_MapperGradSimilar_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".reg_MapperGradSimilar",
    sizeof(pyopencv_reg_MapperGradSimilar_t),
};

static void pyopencv_reg_MapperGradSimilar_dealloc(PyObject* self)
{
    ((pyopencv_reg_MapperGradSimilar_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::reg::MapperGradSimilar>& r)
{
    pyopencv_reg_MapperGradSimilar_t *m = PyObject_NEW(pyopencv_reg_MapperGradSimilar_t, &pyopencv_reg_MapperGradSimilar_Type);
    new (&(m->v)) Ptr<cv::reg::MapperGradSimilar>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::reg::MapperGradSimilar>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_reg_MapperGradSimilar_Type))
    {
        failmsg("Expected cv::reg::MapperGradSimilar for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_reg_MapperGradSimilar_t*)src)->v.dynamicCast<cv::reg::MapperGradSimilar>();
    return true;
}


struct pyopencv_reg_MapperPyramid_t
{
    PyObject_HEAD
    Ptr<cv::reg::MapperPyramid> v;
};

static PyTypeObject pyopencv_reg_MapperPyramid_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".reg_MapperPyramid",
    sizeof(pyopencv_reg_MapperPyramid_t),
};

static void pyopencv_reg_MapperPyramid_dealloc(PyObject* self)
{
    ((pyopencv_reg_MapperPyramid_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::reg::MapperPyramid>& r)
{
    pyopencv_reg_MapperPyramid_t *m = PyObject_NEW(pyopencv_reg_MapperPyramid_t, &pyopencv_reg_MapperPyramid_Type);
    new (&(m->v)) Ptr<cv::reg::MapperPyramid>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::reg::MapperPyramid>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_reg_MapperPyramid_Type))
    {
        failmsg("Expected cv::reg::MapperPyramid for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_reg_MapperPyramid_t*)src)->v.dynamicCast<cv::reg::MapperPyramid>();
    return true;
}


struct pyopencv_saliency_MotionSaliency_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_saliency_MotionSaliency_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".saliency_MotionSaliency",
    sizeof(pyopencv_saliency_MotionSaliency_t),
};

static void pyopencv_saliency_MotionSaliency_dealloc(PyObject* self)
{
    ((pyopencv_saliency_MotionSaliency_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::saliency::MotionSaliency>& r)
{
    pyopencv_saliency_MotionSaliency_t *m = PyObject_NEW(pyopencv_saliency_MotionSaliency_t, &pyopencv_saliency_MotionSaliency_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::saliency::MotionSaliency>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_saliency_MotionSaliency_Type))
    {
        failmsg("Expected cv::saliency::MotionSaliency for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_saliency_MotionSaliency_t*)src)->v.dynamicCast<cv::saliency::MotionSaliency>();
    return true;
}


struct pyopencv_saliency_MotionSaliencyBinWangApr2014_t
{
    PyObject_HEAD
    Ptr<cv::saliency::MotionSaliencyBinWangApr2014> v;
};

static PyTypeObject pyopencv_saliency_MotionSaliencyBinWangApr2014_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".saliency_MotionSaliencyBinWangApr2014",
    sizeof(pyopencv_saliency_MotionSaliencyBinWangApr2014_t),
};

static void pyopencv_saliency_MotionSaliencyBinWangApr2014_dealloc(PyObject* self)
{
    ((pyopencv_saliency_MotionSaliencyBinWangApr2014_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::saliency::MotionSaliencyBinWangApr2014>& r)
{
    pyopencv_saliency_MotionSaliencyBinWangApr2014_t *m = PyObject_NEW(pyopencv_saliency_MotionSaliencyBinWangApr2014_t, &pyopencv_saliency_MotionSaliencyBinWangApr2014_Type);
    new (&(m->v)) Ptr<cv::saliency::MotionSaliencyBinWangApr2014>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::saliency::MotionSaliencyBinWangApr2014>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_saliency_MotionSaliencyBinWangApr2014_Type))
    {
        failmsg("Expected cv::saliency::MotionSaliencyBinWangApr2014 for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_saliency_MotionSaliencyBinWangApr2014_t*)src)->v.dynamicCast<cv::saliency::MotionSaliencyBinWangApr2014>();
    return true;
}


struct pyopencv_saliency_Objectness_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_saliency_Objectness_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".saliency_Objectness",
    sizeof(pyopencv_saliency_Objectness_t),
};

static void pyopencv_saliency_Objectness_dealloc(PyObject* self)
{
    ((pyopencv_saliency_Objectness_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::saliency::Objectness>& r)
{
    pyopencv_saliency_Objectness_t *m = PyObject_NEW(pyopencv_saliency_Objectness_t, &pyopencv_saliency_Objectness_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::saliency::Objectness>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_saliency_Objectness_Type))
    {
        failmsg("Expected cv::saliency::Objectness for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_saliency_Objectness_t*)src)->v.dynamicCast<cv::saliency::Objectness>();
    return true;
}


struct pyopencv_saliency_ObjectnessBING_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_saliency_ObjectnessBING_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".saliency_ObjectnessBING",
    sizeof(pyopencv_saliency_ObjectnessBING_t),
};

static void pyopencv_saliency_ObjectnessBING_dealloc(PyObject* self)
{
    ((pyopencv_saliency_ObjectnessBING_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::saliency::ObjectnessBING>& r)
{
    pyopencv_saliency_ObjectnessBING_t *m = PyObject_NEW(pyopencv_saliency_ObjectnessBING_t, &pyopencv_saliency_ObjectnessBING_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::saliency::ObjectnessBING>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_saliency_ObjectnessBING_Type))
    {
        failmsg("Expected cv::saliency::ObjectnessBING for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_saliency_ObjectnessBING_t*)src)->v.dynamicCast<cv::saliency::ObjectnessBING>();
    return true;
}


struct pyopencv_saliency_Saliency_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_saliency_Saliency_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".saliency_Saliency",
    sizeof(pyopencv_saliency_Saliency_t),
};

static void pyopencv_saliency_Saliency_dealloc(PyObject* self)
{
    ((pyopencv_saliency_Saliency_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::saliency::Saliency>& r)
{
    pyopencv_saliency_Saliency_t *m = PyObject_NEW(pyopencv_saliency_Saliency_t, &pyopencv_saliency_Saliency_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::saliency::Saliency>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_saliency_Saliency_Type))
    {
        failmsg("Expected cv::saliency::Saliency for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_saliency_Saliency_t*)src)->v.dynamicCast<cv::saliency::Saliency>();
    return true;
}


struct pyopencv_saliency_StaticSaliency_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_saliency_StaticSaliency_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".saliency_StaticSaliency",
    sizeof(pyopencv_saliency_StaticSaliency_t),
};

static void pyopencv_saliency_StaticSaliency_dealloc(PyObject* self)
{
    ((pyopencv_saliency_StaticSaliency_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::saliency::StaticSaliency>& r)
{
    pyopencv_saliency_StaticSaliency_t *m = PyObject_NEW(pyopencv_saliency_StaticSaliency_t, &pyopencv_saliency_StaticSaliency_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::saliency::StaticSaliency>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_saliency_StaticSaliency_Type))
    {
        failmsg("Expected cv::saliency::StaticSaliency for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_saliency_StaticSaliency_t*)src)->v.dynamicCast<cv::saliency::StaticSaliency>();
    return true;
}


struct pyopencv_saliency_StaticSaliencyFineGrained_t
{
    PyObject_HEAD
    Ptr<cv::saliency::StaticSaliencyFineGrained> v;
};

static PyTypeObject pyopencv_saliency_StaticSaliencyFineGrained_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".saliency_StaticSaliencyFineGrained",
    sizeof(pyopencv_saliency_StaticSaliencyFineGrained_t),
};

static void pyopencv_saliency_StaticSaliencyFineGrained_dealloc(PyObject* self)
{
    ((pyopencv_saliency_StaticSaliencyFineGrained_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::saliency::StaticSaliencyFineGrained>& r)
{
    pyopencv_saliency_StaticSaliencyFineGrained_t *m = PyObject_NEW(pyopencv_saliency_StaticSaliencyFineGrained_t, &pyopencv_saliency_StaticSaliencyFineGrained_Type);
    new (&(m->v)) Ptr<cv::saliency::StaticSaliencyFineGrained>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::saliency::StaticSaliencyFineGrained>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_saliency_StaticSaliencyFineGrained_Type))
    {
        failmsg("Expected cv::saliency::StaticSaliencyFineGrained for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_saliency_StaticSaliencyFineGrained_t*)src)->v.dynamicCast<cv::saliency::StaticSaliencyFineGrained>();
    return true;
}


struct pyopencv_saliency_StaticSaliencySpectralResidual_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_saliency_StaticSaliencySpectralResidual_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".saliency_StaticSaliencySpectralResidual",
    sizeof(pyopencv_saliency_StaticSaliencySpectralResidual_t),
};

static void pyopencv_saliency_StaticSaliencySpectralResidual_dealloc(PyObject* self)
{
    ((pyopencv_saliency_StaticSaliencySpectralResidual_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::saliency::StaticSaliencySpectralResidual>& r)
{
    pyopencv_saliency_StaticSaliencySpectralResidual_t *m = PyObject_NEW(pyopencv_saliency_StaticSaliencySpectralResidual_t, &pyopencv_saliency_StaticSaliencySpectralResidual_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::saliency::StaticSaliencySpectralResidual>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_saliency_StaticSaliencySpectralResidual_Type))
    {
        failmsg("Expected cv::saliency::StaticSaliencySpectralResidual for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_saliency_StaticSaliencySpectralResidual_t*)src)->v.dynamicCast<cv::saliency::StaticSaliencySpectralResidual>();
    return true;
}


struct pyopencv_structured_light_GrayCodePattern_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_structured_light_GrayCodePattern_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".structured_light_GrayCodePattern",
    sizeof(pyopencv_structured_light_GrayCodePattern_t),
};

static void pyopencv_structured_light_GrayCodePattern_dealloc(PyObject* self)
{
    ((pyopencv_structured_light_GrayCodePattern_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::structured_light::GrayCodePattern>& r)
{
    pyopencv_structured_light_GrayCodePattern_t *m = PyObject_NEW(pyopencv_structured_light_GrayCodePattern_t, &pyopencv_structured_light_GrayCodePattern_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::structured_light::GrayCodePattern>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_structured_light_GrayCodePattern_Type))
    {
        failmsg("Expected cv::structured_light::GrayCodePattern for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_structured_light_GrayCodePattern_t*)src)->v.dynamicCast<cv::structured_light::GrayCodePattern>();
    return true;
}


struct pyopencv_structured_light_SinusoidalPattern_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_structured_light_SinusoidalPattern_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".structured_light_SinusoidalPattern",
    sizeof(pyopencv_structured_light_SinusoidalPattern_t),
};

static void pyopencv_structured_light_SinusoidalPattern_dealloc(PyObject* self)
{
    ((pyopencv_structured_light_SinusoidalPattern_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::structured_light::SinusoidalPattern>& r)
{
    pyopencv_structured_light_SinusoidalPattern_t *m = PyObject_NEW(pyopencv_structured_light_SinusoidalPattern_t, &pyopencv_structured_light_SinusoidalPattern_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::structured_light::SinusoidalPattern>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_structured_light_SinusoidalPattern_Type))
    {
        failmsg("Expected cv::structured_light::SinusoidalPattern for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_structured_light_SinusoidalPattern_t*)src)->v.dynamicCast<cv::structured_light::SinusoidalPattern>();
    return true;
}


struct pyopencv_structured_light_StructuredLightPattern_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_structured_light_StructuredLightPattern_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".structured_light_StructuredLightPattern",
    sizeof(pyopencv_structured_light_StructuredLightPattern_t),
};

static void pyopencv_structured_light_StructuredLightPattern_dealloc(PyObject* self)
{
    ((pyopencv_structured_light_StructuredLightPattern_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::structured_light::StructuredLightPattern>& r)
{
    pyopencv_structured_light_StructuredLightPattern_t *m = PyObject_NEW(pyopencv_structured_light_StructuredLightPattern_t, &pyopencv_structured_light_StructuredLightPattern_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::structured_light::StructuredLightPattern>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_structured_light_StructuredLightPattern_Type))
    {
        failmsg("Expected cv::structured_light::StructuredLightPattern for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_structured_light_StructuredLightPattern_t*)src)->v.dynamicCast<cv::structured_light::StructuredLightPattern>();
    return true;
}


struct pyopencv_text_BaseOCR_t
{
    PyObject_HEAD
    Ptr<cv::text::BaseOCR> v;
};

static PyTypeObject pyopencv_text_BaseOCR_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".text_BaseOCR",
    sizeof(pyopencv_text_BaseOCR_t),
};

static void pyopencv_text_BaseOCR_dealloc(PyObject* self)
{
    ((pyopencv_text_BaseOCR_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::text::BaseOCR>& r)
{
    pyopencv_text_BaseOCR_t *m = PyObject_NEW(pyopencv_text_BaseOCR_t, &pyopencv_text_BaseOCR_Type);
    new (&(m->v)) Ptr<cv::text::BaseOCR>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::text::BaseOCR>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_text_BaseOCR_Type))
    {
        failmsg("Expected cv::text::BaseOCR for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_text_BaseOCR_t*)src)->v.dynamicCast<cv::text::BaseOCR>();
    return true;
}


struct pyopencv_text_ERFilter_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_text_ERFilter_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".text_ERFilter",
    sizeof(pyopencv_text_ERFilter_t),
};

static void pyopencv_text_ERFilter_dealloc(PyObject* self)
{
    ((pyopencv_text_ERFilter_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::text::ERFilter>& r)
{
    pyopencv_text_ERFilter_t *m = PyObject_NEW(pyopencv_text_ERFilter_t, &pyopencv_text_ERFilter_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::text::ERFilter>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_text_ERFilter_Type))
    {
        failmsg("Expected cv::text::ERFilter for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_text_ERFilter_t*)src)->v.dynamicCast<cv::text::ERFilter>();
    return true;
}


struct pyopencv_text_ERFilter_Callback_t
{
    PyObject_HEAD
    Ptr<cv::text::ERFilter::Callback> v;
};

static PyTypeObject pyopencv_text_ERFilter_Callback_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".text_ERFilter_Callback",
    sizeof(pyopencv_text_ERFilter_Callback_t),
};

static void pyopencv_text_ERFilter_Callback_dealloc(PyObject* self)
{
    ((pyopencv_text_ERFilter_Callback_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::text::ERFilter::Callback>& r)
{
    pyopencv_text_ERFilter_Callback_t *m = PyObject_NEW(pyopencv_text_ERFilter_Callback_t, &pyopencv_text_ERFilter_Callback_Type);
    new (&(m->v)) Ptr<cv::text::ERFilter::Callback>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::text::ERFilter::Callback>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_text_ERFilter_Callback_Type))
    {
        failmsg("Expected cv::text::ERFilter::Callback for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_text_ERFilter_Callback_t*)src)->v.dynamicCast<cv::text::ERFilter::Callback>();
    return true;
}


struct pyopencv_text_OCRBeamSearchDecoder_t
{
    PyObject_HEAD
    Ptr<cv::text::OCRBeamSearchDecoder> v;
};

static PyTypeObject pyopencv_text_OCRBeamSearchDecoder_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".text_OCRBeamSearchDecoder",
    sizeof(pyopencv_text_OCRBeamSearchDecoder_t),
};

static void pyopencv_text_OCRBeamSearchDecoder_dealloc(PyObject* self)
{
    ((pyopencv_text_OCRBeamSearchDecoder_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::text::OCRBeamSearchDecoder>& r)
{
    pyopencv_text_OCRBeamSearchDecoder_t *m = PyObject_NEW(pyopencv_text_OCRBeamSearchDecoder_t, &pyopencv_text_OCRBeamSearchDecoder_Type);
    new (&(m->v)) Ptr<cv::text::OCRBeamSearchDecoder>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::text::OCRBeamSearchDecoder>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_text_OCRBeamSearchDecoder_Type))
    {
        failmsg("Expected cv::text::OCRBeamSearchDecoder for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_text_OCRBeamSearchDecoder_t*)src)->v.dynamicCast<cv::text::OCRBeamSearchDecoder>();
    return true;
}


struct pyopencv_text_OCRBeamSearchDecoder_ClassifierCallback_t
{
    PyObject_HEAD
    Ptr<cv::text::OCRBeamSearchDecoder::ClassifierCallback> v;
};

static PyTypeObject pyopencv_text_OCRBeamSearchDecoder_ClassifierCallback_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".text_OCRBeamSearchDecoder_ClassifierCallback",
    sizeof(pyopencv_text_OCRBeamSearchDecoder_ClassifierCallback_t),
};

static void pyopencv_text_OCRBeamSearchDecoder_ClassifierCallback_dealloc(PyObject* self)
{
    ((pyopencv_text_OCRBeamSearchDecoder_ClassifierCallback_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::text::OCRBeamSearchDecoder::ClassifierCallback>& r)
{
    pyopencv_text_OCRBeamSearchDecoder_ClassifierCallback_t *m = PyObject_NEW(pyopencv_text_OCRBeamSearchDecoder_ClassifierCallback_t, &pyopencv_text_OCRBeamSearchDecoder_ClassifierCallback_Type);
    new (&(m->v)) Ptr<cv::text::OCRBeamSearchDecoder::ClassifierCallback>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::text::OCRBeamSearchDecoder::ClassifierCallback>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_text_OCRBeamSearchDecoder_ClassifierCallback_Type))
    {
        failmsg("Expected cv::text::OCRBeamSearchDecoder::ClassifierCallback for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_text_OCRBeamSearchDecoder_ClassifierCallback_t*)src)->v.dynamicCast<cv::text::OCRBeamSearchDecoder::ClassifierCallback>();
    return true;
}


struct pyopencv_text_OCRHMMDecoder_t
{
    PyObject_HEAD
    Ptr<cv::text::OCRHMMDecoder> v;
};

static PyTypeObject pyopencv_text_OCRHMMDecoder_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".text_OCRHMMDecoder",
    sizeof(pyopencv_text_OCRHMMDecoder_t),
};

static void pyopencv_text_OCRHMMDecoder_dealloc(PyObject* self)
{
    ((pyopencv_text_OCRHMMDecoder_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::text::OCRHMMDecoder>& r)
{
    pyopencv_text_OCRHMMDecoder_t *m = PyObject_NEW(pyopencv_text_OCRHMMDecoder_t, &pyopencv_text_OCRHMMDecoder_Type);
    new (&(m->v)) Ptr<cv::text::OCRHMMDecoder>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::text::OCRHMMDecoder>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_text_OCRHMMDecoder_Type))
    {
        failmsg("Expected cv::text::OCRHMMDecoder for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_text_OCRHMMDecoder_t*)src)->v.dynamicCast<cv::text::OCRHMMDecoder>();
    return true;
}


struct pyopencv_text_OCRHMMDecoder_ClassifierCallback_t
{
    PyObject_HEAD
    Ptr<cv::text::OCRHMMDecoder::ClassifierCallback> v;
};

static PyTypeObject pyopencv_text_OCRHMMDecoder_ClassifierCallback_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".text_OCRHMMDecoder_ClassifierCallback",
    sizeof(pyopencv_text_OCRHMMDecoder_ClassifierCallback_t),
};

static void pyopencv_text_OCRHMMDecoder_ClassifierCallback_dealloc(PyObject* self)
{
    ((pyopencv_text_OCRHMMDecoder_ClassifierCallback_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::text::OCRHMMDecoder::ClassifierCallback>& r)
{
    pyopencv_text_OCRHMMDecoder_ClassifierCallback_t *m = PyObject_NEW(pyopencv_text_OCRHMMDecoder_ClassifierCallback_t, &pyopencv_text_OCRHMMDecoder_ClassifierCallback_Type);
    new (&(m->v)) Ptr<cv::text::OCRHMMDecoder::ClassifierCallback>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::text::OCRHMMDecoder::ClassifierCallback>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_text_OCRHMMDecoder_ClassifierCallback_Type))
    {
        failmsg("Expected cv::text::OCRHMMDecoder::ClassifierCallback for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_text_OCRHMMDecoder_ClassifierCallback_t*)src)->v.dynamicCast<cv::text::OCRHMMDecoder::ClassifierCallback>();
    return true;
}


struct pyopencv_text_OCRTesseract_t
{
    PyObject_HEAD
    Ptr<cv::text::OCRTesseract> v;
};

static PyTypeObject pyopencv_text_OCRTesseract_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".text_OCRTesseract",
    sizeof(pyopencv_text_OCRTesseract_t),
};

static void pyopencv_text_OCRTesseract_dealloc(PyObject* self)
{
    ((pyopencv_text_OCRTesseract_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::text::OCRTesseract>& r)
{
    pyopencv_text_OCRTesseract_t *m = PyObject_NEW(pyopencv_text_OCRTesseract_t, &pyopencv_text_OCRTesseract_Type);
    new (&(m->v)) Ptr<cv::text::OCRTesseract>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::text::OCRTesseract>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_text_OCRTesseract_Type))
    {
        failmsg("Expected cv::text::OCRTesseract for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_text_OCRTesseract_t*)src)->v.dynamicCast<cv::text::OCRTesseract>();
    return true;
}


struct pyopencv_xfeatures2d_BoostDesc_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_xfeatures2d_BoostDesc_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".xfeatures2d_BoostDesc",
    sizeof(pyopencv_xfeatures2d_BoostDesc_t),
};

static void pyopencv_xfeatures2d_BoostDesc_dealloc(PyObject* self)
{
    ((pyopencv_xfeatures2d_BoostDesc_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::xfeatures2d::BoostDesc>& r)
{
    pyopencv_xfeatures2d_BoostDesc_t *m = PyObject_NEW(pyopencv_xfeatures2d_BoostDesc_t, &pyopencv_xfeatures2d_BoostDesc_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::xfeatures2d::BoostDesc>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_xfeatures2d_BoostDesc_Type))
    {
        failmsg("Expected cv::xfeatures2d::BoostDesc for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_xfeatures2d_BoostDesc_t*)src)->v.dynamicCast<cv::xfeatures2d::BoostDesc>();
    return true;
}


struct pyopencv_xfeatures2d_BriefDescriptorExtractor_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_xfeatures2d_BriefDescriptorExtractor_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".xfeatures2d_BriefDescriptorExtractor",
    sizeof(pyopencv_xfeatures2d_BriefDescriptorExtractor_t),
};

static void pyopencv_xfeatures2d_BriefDescriptorExtractor_dealloc(PyObject* self)
{
    ((pyopencv_xfeatures2d_BriefDescriptorExtractor_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::xfeatures2d::BriefDescriptorExtractor>& r)
{
    pyopencv_xfeatures2d_BriefDescriptorExtractor_t *m = PyObject_NEW(pyopencv_xfeatures2d_BriefDescriptorExtractor_t, &pyopencv_xfeatures2d_BriefDescriptorExtractor_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::xfeatures2d::BriefDescriptorExtractor>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_xfeatures2d_BriefDescriptorExtractor_Type))
    {
        failmsg("Expected cv::xfeatures2d::BriefDescriptorExtractor for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_xfeatures2d_BriefDescriptorExtractor_t*)src)->v.dynamicCast<cv::xfeatures2d::BriefDescriptorExtractor>();
    return true;
}


struct pyopencv_xfeatures2d_DAISY_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_xfeatures2d_DAISY_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".xfeatures2d_DAISY",
    sizeof(pyopencv_xfeatures2d_DAISY_t),
};

static void pyopencv_xfeatures2d_DAISY_dealloc(PyObject* self)
{
    ((pyopencv_xfeatures2d_DAISY_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::xfeatures2d::DAISY>& r)
{
    pyopencv_xfeatures2d_DAISY_t *m = PyObject_NEW(pyopencv_xfeatures2d_DAISY_t, &pyopencv_xfeatures2d_DAISY_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::xfeatures2d::DAISY>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_xfeatures2d_DAISY_Type))
    {
        failmsg("Expected cv::xfeatures2d::DAISY for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_xfeatures2d_DAISY_t*)src)->v.dynamicCast<cv::xfeatures2d::DAISY>();
    return true;
}


struct pyopencv_xfeatures2d_FREAK_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_xfeatures2d_FREAK_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".xfeatures2d_FREAK",
    sizeof(pyopencv_xfeatures2d_FREAK_t),
};

static void pyopencv_xfeatures2d_FREAK_dealloc(PyObject* self)
{
    ((pyopencv_xfeatures2d_FREAK_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::xfeatures2d::FREAK>& r)
{
    pyopencv_xfeatures2d_FREAK_t *m = PyObject_NEW(pyopencv_xfeatures2d_FREAK_t, &pyopencv_xfeatures2d_FREAK_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::xfeatures2d::FREAK>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_xfeatures2d_FREAK_Type))
    {
        failmsg("Expected cv::xfeatures2d::FREAK for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_xfeatures2d_FREAK_t*)src)->v.dynamicCast<cv::xfeatures2d::FREAK>();
    return true;
}


struct pyopencv_xfeatures2d_HarrisLaplaceFeatureDetector_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_xfeatures2d_HarrisLaplaceFeatureDetector_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".xfeatures2d_HarrisLaplaceFeatureDetector",
    sizeof(pyopencv_xfeatures2d_HarrisLaplaceFeatureDetector_t),
};

static void pyopencv_xfeatures2d_HarrisLaplaceFeatureDetector_dealloc(PyObject* self)
{
    ((pyopencv_xfeatures2d_HarrisLaplaceFeatureDetector_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::xfeatures2d::HarrisLaplaceFeatureDetector>& r)
{
    pyopencv_xfeatures2d_HarrisLaplaceFeatureDetector_t *m = PyObject_NEW(pyopencv_xfeatures2d_HarrisLaplaceFeatureDetector_t, &pyopencv_xfeatures2d_HarrisLaplaceFeatureDetector_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::xfeatures2d::HarrisLaplaceFeatureDetector>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_xfeatures2d_HarrisLaplaceFeatureDetector_Type))
    {
        failmsg("Expected cv::xfeatures2d::HarrisLaplaceFeatureDetector for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_xfeatures2d_HarrisLaplaceFeatureDetector_t*)src)->v.dynamicCast<cv::xfeatures2d::HarrisLaplaceFeatureDetector>();
    return true;
}


struct pyopencv_xfeatures2d_LATCH_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_xfeatures2d_LATCH_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".xfeatures2d_LATCH",
    sizeof(pyopencv_xfeatures2d_LATCH_t),
};

static void pyopencv_xfeatures2d_LATCH_dealloc(PyObject* self)
{
    ((pyopencv_xfeatures2d_LATCH_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::xfeatures2d::LATCH>& r)
{
    pyopencv_xfeatures2d_LATCH_t *m = PyObject_NEW(pyopencv_xfeatures2d_LATCH_t, &pyopencv_xfeatures2d_LATCH_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::xfeatures2d::LATCH>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_xfeatures2d_LATCH_Type))
    {
        failmsg("Expected cv::xfeatures2d::LATCH for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_xfeatures2d_LATCH_t*)src)->v.dynamicCast<cv::xfeatures2d::LATCH>();
    return true;
}


struct pyopencv_xfeatures2d_LUCID_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_xfeatures2d_LUCID_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".xfeatures2d_LUCID",
    sizeof(pyopencv_xfeatures2d_LUCID_t),
};

static void pyopencv_xfeatures2d_LUCID_dealloc(PyObject* self)
{
    ((pyopencv_xfeatures2d_LUCID_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::xfeatures2d::LUCID>& r)
{
    pyopencv_xfeatures2d_LUCID_t *m = PyObject_NEW(pyopencv_xfeatures2d_LUCID_t, &pyopencv_xfeatures2d_LUCID_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::xfeatures2d::LUCID>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_xfeatures2d_LUCID_Type))
    {
        failmsg("Expected cv::xfeatures2d::LUCID for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_xfeatures2d_LUCID_t*)src)->v.dynamicCast<cv::xfeatures2d::LUCID>();
    return true;
}


struct pyopencv_xfeatures2d_MSDDetector_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_xfeatures2d_MSDDetector_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".xfeatures2d_MSDDetector",
    sizeof(pyopencv_xfeatures2d_MSDDetector_t),
};

static void pyopencv_xfeatures2d_MSDDetector_dealloc(PyObject* self)
{
    ((pyopencv_xfeatures2d_MSDDetector_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::xfeatures2d::MSDDetector>& r)
{
    pyopencv_xfeatures2d_MSDDetector_t *m = PyObject_NEW(pyopencv_xfeatures2d_MSDDetector_t, &pyopencv_xfeatures2d_MSDDetector_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::xfeatures2d::MSDDetector>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_xfeatures2d_MSDDetector_Type))
    {
        failmsg("Expected cv::xfeatures2d::MSDDetector for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_xfeatures2d_MSDDetector_t*)src)->v.dynamicCast<cv::xfeatures2d::MSDDetector>();
    return true;
}


struct pyopencv_xfeatures2d_PCTSignatures_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_xfeatures2d_PCTSignatures_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".xfeatures2d_PCTSignatures",
    sizeof(pyopencv_xfeatures2d_PCTSignatures_t),
};

static void pyopencv_xfeatures2d_PCTSignatures_dealloc(PyObject* self)
{
    ((pyopencv_xfeatures2d_PCTSignatures_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::xfeatures2d::PCTSignatures>& r)
{
    pyopencv_xfeatures2d_PCTSignatures_t *m = PyObject_NEW(pyopencv_xfeatures2d_PCTSignatures_t, &pyopencv_xfeatures2d_PCTSignatures_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::xfeatures2d::PCTSignatures>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_xfeatures2d_PCTSignatures_Type))
    {
        failmsg("Expected cv::xfeatures2d::PCTSignatures for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_xfeatures2d_PCTSignatures_t*)src)->v.dynamicCast<cv::xfeatures2d::PCTSignatures>();
    return true;
}


struct pyopencv_xfeatures2d_PCTSignaturesSQFD_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_xfeatures2d_PCTSignaturesSQFD_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".xfeatures2d_PCTSignaturesSQFD",
    sizeof(pyopencv_xfeatures2d_PCTSignaturesSQFD_t),
};

static void pyopencv_xfeatures2d_PCTSignaturesSQFD_dealloc(PyObject* self)
{
    ((pyopencv_xfeatures2d_PCTSignaturesSQFD_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::xfeatures2d::PCTSignaturesSQFD>& r)
{
    pyopencv_xfeatures2d_PCTSignaturesSQFD_t *m = PyObject_NEW(pyopencv_xfeatures2d_PCTSignaturesSQFD_t, &pyopencv_xfeatures2d_PCTSignaturesSQFD_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::xfeatures2d::PCTSignaturesSQFD>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_xfeatures2d_PCTSignaturesSQFD_Type))
    {
        failmsg("Expected cv::xfeatures2d::PCTSignaturesSQFD for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_xfeatures2d_PCTSignaturesSQFD_t*)src)->v.dynamicCast<cv::xfeatures2d::PCTSignaturesSQFD>();
    return true;
}


struct pyopencv_xfeatures2d_SIFT_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_xfeatures2d_SIFT_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".xfeatures2d_SIFT",
    sizeof(pyopencv_xfeatures2d_SIFT_t),
};

static void pyopencv_xfeatures2d_SIFT_dealloc(PyObject* self)
{
    ((pyopencv_xfeatures2d_SIFT_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::xfeatures2d::SIFT>& r)
{
    pyopencv_xfeatures2d_SIFT_t *m = PyObject_NEW(pyopencv_xfeatures2d_SIFT_t, &pyopencv_xfeatures2d_SIFT_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::xfeatures2d::SIFT>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_xfeatures2d_SIFT_Type))
    {
        failmsg("Expected cv::xfeatures2d::SIFT for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_xfeatures2d_SIFT_t*)src)->v.dynamicCast<cv::xfeatures2d::SIFT>();
    return true;
}


struct pyopencv_xfeatures2d_SURF_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_xfeatures2d_SURF_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".xfeatures2d_SURF",
    sizeof(pyopencv_xfeatures2d_SURF_t),
};

static void pyopencv_xfeatures2d_SURF_dealloc(PyObject* self)
{
    ((pyopencv_xfeatures2d_SURF_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::xfeatures2d::SURF>& r)
{
    pyopencv_xfeatures2d_SURF_t *m = PyObject_NEW(pyopencv_xfeatures2d_SURF_t, &pyopencv_xfeatures2d_SURF_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::xfeatures2d::SURF>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_xfeatures2d_SURF_Type))
    {
        failmsg("Expected cv::xfeatures2d::SURF for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_xfeatures2d_SURF_t*)src)->v.dynamicCast<cv::xfeatures2d::SURF>();
    return true;
}


struct pyopencv_xfeatures2d_StarDetector_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_xfeatures2d_StarDetector_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".xfeatures2d_StarDetector",
    sizeof(pyopencv_xfeatures2d_StarDetector_t),
};

static void pyopencv_xfeatures2d_StarDetector_dealloc(PyObject* self)
{
    ((pyopencv_xfeatures2d_StarDetector_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::xfeatures2d::StarDetector>& r)
{
    pyopencv_xfeatures2d_StarDetector_t *m = PyObject_NEW(pyopencv_xfeatures2d_StarDetector_t, &pyopencv_xfeatures2d_StarDetector_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::xfeatures2d::StarDetector>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_xfeatures2d_StarDetector_Type))
    {
        failmsg("Expected cv::xfeatures2d::StarDetector for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_xfeatures2d_StarDetector_t*)src)->v.dynamicCast<cv::xfeatures2d::StarDetector>();
    return true;
}


struct pyopencv_xfeatures2d_VGG_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_xfeatures2d_VGG_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".xfeatures2d_VGG",
    sizeof(pyopencv_xfeatures2d_VGG_t),
};

static void pyopencv_xfeatures2d_VGG_dealloc(PyObject* self)
{
    ((pyopencv_xfeatures2d_VGG_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::xfeatures2d::VGG>& r)
{
    pyopencv_xfeatures2d_VGG_t *m = PyObject_NEW(pyopencv_xfeatures2d_VGG_t, &pyopencv_xfeatures2d_VGG_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::xfeatures2d::VGG>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_xfeatures2d_VGG_Type))
    {
        failmsg("Expected cv::xfeatures2d::VGG for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_xfeatures2d_VGG_t*)src)->v.dynamicCast<cv::xfeatures2d::VGG>();
    return true;
}


struct pyopencv_ximgproc_AdaptiveManifoldFilter_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_ximgproc_AdaptiveManifoldFilter_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".ximgproc_AdaptiveManifoldFilter",
    sizeof(pyopencv_ximgproc_AdaptiveManifoldFilter_t),
};

static void pyopencv_ximgproc_AdaptiveManifoldFilter_dealloc(PyObject* self)
{
    ((pyopencv_ximgproc_AdaptiveManifoldFilter_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::ximgproc::AdaptiveManifoldFilter>& r)
{
    pyopencv_ximgproc_AdaptiveManifoldFilter_t *m = PyObject_NEW(pyopencv_ximgproc_AdaptiveManifoldFilter_t, &pyopencv_ximgproc_AdaptiveManifoldFilter_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::ximgproc::AdaptiveManifoldFilter>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_ximgproc_AdaptiveManifoldFilter_Type))
    {
        failmsg("Expected cv::ximgproc::AdaptiveManifoldFilter for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_ximgproc_AdaptiveManifoldFilter_t*)src)->v.dynamicCast<cv::ximgproc::AdaptiveManifoldFilter>();
    return true;
}


struct pyopencv_ximgproc_DTFilter_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_ximgproc_DTFilter_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".ximgproc_DTFilter",
    sizeof(pyopencv_ximgproc_DTFilter_t),
};

static void pyopencv_ximgproc_DTFilter_dealloc(PyObject* self)
{
    ((pyopencv_ximgproc_DTFilter_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::ximgproc::DTFilter>& r)
{
    pyopencv_ximgproc_DTFilter_t *m = PyObject_NEW(pyopencv_ximgproc_DTFilter_t, &pyopencv_ximgproc_DTFilter_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::ximgproc::DTFilter>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_ximgproc_DTFilter_Type))
    {
        failmsg("Expected cv::ximgproc::DTFilter for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_ximgproc_DTFilter_t*)src)->v.dynamicCast<cv::ximgproc::DTFilter>();
    return true;
}


struct pyopencv_ximgproc_DisparityFilter_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_ximgproc_DisparityFilter_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".ximgproc_DisparityFilter",
    sizeof(pyopencv_ximgproc_DisparityFilter_t),
};

static void pyopencv_ximgproc_DisparityFilter_dealloc(PyObject* self)
{
    ((pyopencv_ximgproc_DisparityFilter_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::ximgproc::DisparityFilter>& r)
{
    pyopencv_ximgproc_DisparityFilter_t *m = PyObject_NEW(pyopencv_ximgproc_DisparityFilter_t, &pyopencv_ximgproc_DisparityFilter_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::ximgproc::DisparityFilter>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_ximgproc_DisparityFilter_Type))
    {
        failmsg("Expected cv::ximgproc::DisparityFilter for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_ximgproc_DisparityFilter_t*)src)->v.dynamicCast<cv::ximgproc::DisparityFilter>();
    return true;
}


struct pyopencv_ximgproc_DisparityWLSFilter_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_ximgproc_DisparityWLSFilter_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".ximgproc_DisparityWLSFilter",
    sizeof(pyopencv_ximgproc_DisparityWLSFilter_t),
};

static void pyopencv_ximgproc_DisparityWLSFilter_dealloc(PyObject* self)
{
    ((pyopencv_ximgproc_DisparityWLSFilter_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::ximgproc::DisparityWLSFilter>& r)
{
    pyopencv_ximgproc_DisparityWLSFilter_t *m = PyObject_NEW(pyopencv_ximgproc_DisparityWLSFilter_t, &pyopencv_ximgproc_DisparityWLSFilter_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::ximgproc::DisparityWLSFilter>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_ximgproc_DisparityWLSFilter_Type))
    {
        failmsg("Expected cv::ximgproc::DisparityWLSFilter for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_ximgproc_DisparityWLSFilter_t*)src)->v.dynamicCast<cv::ximgproc::DisparityWLSFilter>();
    return true;
}


struct pyopencv_ximgproc_EdgeAwareInterpolator_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_ximgproc_EdgeAwareInterpolator_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".ximgproc_EdgeAwareInterpolator",
    sizeof(pyopencv_ximgproc_EdgeAwareInterpolator_t),
};

static void pyopencv_ximgproc_EdgeAwareInterpolator_dealloc(PyObject* self)
{
    ((pyopencv_ximgproc_EdgeAwareInterpolator_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::ximgproc::EdgeAwareInterpolator>& r)
{
    pyopencv_ximgproc_EdgeAwareInterpolator_t *m = PyObject_NEW(pyopencv_ximgproc_EdgeAwareInterpolator_t, &pyopencv_ximgproc_EdgeAwareInterpolator_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::ximgproc::EdgeAwareInterpolator>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_ximgproc_EdgeAwareInterpolator_Type))
    {
        failmsg("Expected cv::ximgproc::EdgeAwareInterpolator for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_ximgproc_EdgeAwareInterpolator_t*)src)->v.dynamicCast<cv::ximgproc::EdgeAwareInterpolator>();
    return true;
}


struct pyopencv_ximgproc_FastGlobalSmootherFilter_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_ximgproc_FastGlobalSmootherFilter_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".ximgproc_FastGlobalSmootherFilter",
    sizeof(pyopencv_ximgproc_FastGlobalSmootherFilter_t),
};

static void pyopencv_ximgproc_FastGlobalSmootherFilter_dealloc(PyObject* self)
{
    ((pyopencv_ximgproc_FastGlobalSmootherFilter_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::ximgproc::FastGlobalSmootherFilter>& r)
{
    pyopencv_ximgproc_FastGlobalSmootherFilter_t *m = PyObject_NEW(pyopencv_ximgproc_FastGlobalSmootherFilter_t, &pyopencv_ximgproc_FastGlobalSmootherFilter_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::ximgproc::FastGlobalSmootherFilter>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_ximgproc_FastGlobalSmootherFilter_Type))
    {
        failmsg("Expected cv::ximgproc::FastGlobalSmootherFilter for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_ximgproc_FastGlobalSmootherFilter_t*)src)->v.dynamicCast<cv::ximgproc::FastGlobalSmootherFilter>();
    return true;
}


struct pyopencv_ximgproc_FastLineDetector_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_ximgproc_FastLineDetector_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".ximgproc_FastLineDetector",
    sizeof(pyopencv_ximgproc_FastLineDetector_t),
};

static void pyopencv_ximgproc_FastLineDetector_dealloc(PyObject* self)
{
    ((pyopencv_ximgproc_FastLineDetector_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::ximgproc::FastLineDetector>& r)
{
    pyopencv_ximgproc_FastLineDetector_t *m = PyObject_NEW(pyopencv_ximgproc_FastLineDetector_t, &pyopencv_ximgproc_FastLineDetector_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::ximgproc::FastLineDetector>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_ximgproc_FastLineDetector_Type))
    {
        failmsg("Expected cv::ximgproc::FastLineDetector for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_ximgproc_FastLineDetector_t*)src)->v.dynamicCast<cv::ximgproc::FastLineDetector>();
    return true;
}


struct pyopencv_ximgproc_GuidedFilter_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_ximgproc_GuidedFilter_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".ximgproc_GuidedFilter",
    sizeof(pyopencv_ximgproc_GuidedFilter_t),
};

static void pyopencv_ximgproc_GuidedFilter_dealloc(PyObject* self)
{
    ((pyopencv_ximgproc_GuidedFilter_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::ximgproc::GuidedFilter>& r)
{
    pyopencv_ximgproc_GuidedFilter_t *m = PyObject_NEW(pyopencv_ximgproc_GuidedFilter_t, &pyopencv_ximgproc_GuidedFilter_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::ximgproc::GuidedFilter>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_ximgproc_GuidedFilter_Type))
    {
        failmsg("Expected cv::ximgproc::GuidedFilter for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_ximgproc_GuidedFilter_t*)src)->v.dynamicCast<cv::ximgproc::GuidedFilter>();
    return true;
}


struct pyopencv_ximgproc_RFFeatureGetter_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_ximgproc_RFFeatureGetter_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".ximgproc_RFFeatureGetter",
    sizeof(pyopencv_ximgproc_RFFeatureGetter_t),
};

static void pyopencv_ximgproc_RFFeatureGetter_dealloc(PyObject* self)
{
    ((pyopencv_ximgproc_RFFeatureGetter_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::ximgproc::RFFeatureGetter>& r)
{
    pyopencv_ximgproc_RFFeatureGetter_t *m = PyObject_NEW(pyopencv_ximgproc_RFFeatureGetter_t, &pyopencv_ximgproc_RFFeatureGetter_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::ximgproc::RFFeatureGetter>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_ximgproc_RFFeatureGetter_Type))
    {
        failmsg("Expected cv::ximgproc::RFFeatureGetter for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_ximgproc_RFFeatureGetter_t*)src)->v.dynamicCast<cv::ximgproc::RFFeatureGetter>();
    return true;
}


struct pyopencv_ximgproc_SparseMatchInterpolator_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_ximgproc_SparseMatchInterpolator_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".ximgproc_SparseMatchInterpolator",
    sizeof(pyopencv_ximgproc_SparseMatchInterpolator_t),
};

static void pyopencv_ximgproc_SparseMatchInterpolator_dealloc(PyObject* self)
{
    ((pyopencv_ximgproc_SparseMatchInterpolator_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::ximgproc::SparseMatchInterpolator>& r)
{
    pyopencv_ximgproc_SparseMatchInterpolator_t *m = PyObject_NEW(pyopencv_ximgproc_SparseMatchInterpolator_t, &pyopencv_ximgproc_SparseMatchInterpolator_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::ximgproc::SparseMatchInterpolator>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_ximgproc_SparseMatchInterpolator_Type))
    {
        failmsg("Expected cv::ximgproc::SparseMatchInterpolator for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_ximgproc_SparseMatchInterpolator_t*)src)->v.dynamicCast<cv::ximgproc::SparseMatchInterpolator>();
    return true;
}


struct pyopencv_ximgproc_StructuredEdgeDetection_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_ximgproc_StructuredEdgeDetection_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".ximgproc_StructuredEdgeDetection",
    sizeof(pyopencv_ximgproc_StructuredEdgeDetection_t),
};

static void pyopencv_ximgproc_StructuredEdgeDetection_dealloc(PyObject* self)
{
    ((pyopencv_ximgproc_StructuredEdgeDetection_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::ximgproc::StructuredEdgeDetection>& r)
{
    pyopencv_ximgproc_StructuredEdgeDetection_t *m = PyObject_NEW(pyopencv_ximgproc_StructuredEdgeDetection_t, &pyopencv_ximgproc_StructuredEdgeDetection_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::ximgproc::StructuredEdgeDetection>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_ximgproc_StructuredEdgeDetection_Type))
    {
        failmsg("Expected cv::ximgproc::StructuredEdgeDetection for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_ximgproc_StructuredEdgeDetection_t*)src)->v.dynamicCast<cv::ximgproc::StructuredEdgeDetection>();
    return true;
}


struct pyopencv_ximgproc_SuperpixelLSC_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_ximgproc_SuperpixelLSC_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".ximgproc_SuperpixelLSC",
    sizeof(pyopencv_ximgproc_SuperpixelLSC_t),
};

static void pyopencv_ximgproc_SuperpixelLSC_dealloc(PyObject* self)
{
    ((pyopencv_ximgproc_SuperpixelLSC_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::ximgproc::SuperpixelLSC>& r)
{
    pyopencv_ximgproc_SuperpixelLSC_t *m = PyObject_NEW(pyopencv_ximgproc_SuperpixelLSC_t, &pyopencv_ximgproc_SuperpixelLSC_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::ximgproc::SuperpixelLSC>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_ximgproc_SuperpixelLSC_Type))
    {
        failmsg("Expected cv::ximgproc::SuperpixelLSC for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_ximgproc_SuperpixelLSC_t*)src)->v.dynamicCast<cv::ximgproc::SuperpixelLSC>();
    return true;
}


struct pyopencv_ximgproc_SuperpixelSEEDS_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_ximgproc_SuperpixelSEEDS_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".ximgproc_SuperpixelSEEDS",
    sizeof(pyopencv_ximgproc_SuperpixelSEEDS_t),
};

static void pyopencv_ximgproc_SuperpixelSEEDS_dealloc(PyObject* self)
{
    ((pyopencv_ximgproc_SuperpixelSEEDS_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::ximgproc::SuperpixelSEEDS>& r)
{
    pyopencv_ximgproc_SuperpixelSEEDS_t *m = PyObject_NEW(pyopencv_ximgproc_SuperpixelSEEDS_t, &pyopencv_ximgproc_SuperpixelSEEDS_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::ximgproc::SuperpixelSEEDS>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_ximgproc_SuperpixelSEEDS_Type))
    {
        failmsg("Expected cv::ximgproc::SuperpixelSEEDS for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_ximgproc_SuperpixelSEEDS_t*)src)->v.dynamicCast<cv::ximgproc::SuperpixelSEEDS>();
    return true;
}


struct pyopencv_ximgproc_SuperpixelSLIC_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_ximgproc_SuperpixelSLIC_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".ximgproc_SuperpixelSLIC",
    sizeof(pyopencv_ximgproc_SuperpixelSLIC_t),
};

static void pyopencv_ximgproc_SuperpixelSLIC_dealloc(PyObject* self)
{
    ((pyopencv_ximgproc_SuperpixelSLIC_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::ximgproc::SuperpixelSLIC>& r)
{
    pyopencv_ximgproc_SuperpixelSLIC_t *m = PyObject_NEW(pyopencv_ximgproc_SuperpixelSLIC_t, &pyopencv_ximgproc_SuperpixelSLIC_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::ximgproc::SuperpixelSLIC>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_ximgproc_SuperpixelSLIC_Type))
    {
        failmsg("Expected cv::ximgproc::SuperpixelSLIC for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_ximgproc_SuperpixelSLIC_t*)src)->v.dynamicCast<cv::ximgproc::SuperpixelSLIC>();
    return true;
}


struct pyopencv_ximgproc_segmentation_GraphSegmentation_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_ximgproc_segmentation_GraphSegmentation_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".ximgproc_segmentation_GraphSegmentation",
    sizeof(pyopencv_ximgproc_segmentation_GraphSegmentation_t),
};

static void pyopencv_ximgproc_segmentation_GraphSegmentation_dealloc(PyObject* self)
{
    ((pyopencv_ximgproc_segmentation_GraphSegmentation_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::ximgproc::segmentation::GraphSegmentation>& r)
{
    pyopencv_ximgproc_segmentation_GraphSegmentation_t *m = PyObject_NEW(pyopencv_ximgproc_segmentation_GraphSegmentation_t, &pyopencv_ximgproc_segmentation_GraphSegmentation_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::ximgproc::segmentation::GraphSegmentation>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_ximgproc_segmentation_GraphSegmentation_Type))
    {
        failmsg("Expected cv::ximgproc::segmentation::GraphSegmentation for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_ximgproc_segmentation_GraphSegmentation_t*)src)->v.dynamicCast<cv::ximgproc::segmentation::GraphSegmentation>();
    return true;
}


struct pyopencv_ximgproc_segmentation_SelectiveSearchSegmentation_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_ximgproc_segmentation_SelectiveSearchSegmentation_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".ximgproc_segmentation_SelectiveSearchSegmentation",
    sizeof(pyopencv_ximgproc_segmentation_SelectiveSearchSegmentation_t),
};

static void pyopencv_ximgproc_segmentation_SelectiveSearchSegmentation_dealloc(PyObject* self)
{
    ((pyopencv_ximgproc_segmentation_SelectiveSearchSegmentation_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::ximgproc::segmentation::SelectiveSearchSegmentation>& r)
{
    pyopencv_ximgproc_segmentation_SelectiveSearchSegmentation_t *m = PyObject_NEW(pyopencv_ximgproc_segmentation_SelectiveSearchSegmentation_t, &pyopencv_ximgproc_segmentation_SelectiveSearchSegmentation_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::ximgproc::segmentation::SelectiveSearchSegmentation>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_ximgproc_segmentation_SelectiveSearchSegmentation_Type))
    {
        failmsg("Expected cv::ximgproc::segmentation::SelectiveSearchSegmentation for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_ximgproc_segmentation_SelectiveSearchSegmentation_t*)src)->v.dynamicCast<cv::ximgproc::segmentation::SelectiveSearchSegmentation>();
    return true;
}


struct pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategy_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategy_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".ximgproc_segmentation_SelectiveSearchSegmentationStrategy",
    sizeof(pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategy_t),
};

static void pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategy_dealloc(PyObject* self)
{
    ((pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategy_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::ximgproc::segmentation::SelectiveSearchSegmentationStrategy>& r)
{
    pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategy_t *m = PyObject_NEW(pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategy_t, &pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategy_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::ximgproc::segmentation::SelectiveSearchSegmentationStrategy>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategy_Type))
    {
        failmsg("Expected cv::ximgproc::segmentation::SelectiveSearchSegmentationStrategy for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategy_t*)src)->v.dynamicCast<cv::ximgproc::segmentation::SelectiveSearchSegmentationStrategy>();
    return true;
}


struct pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyColor_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyColor_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".ximgproc_segmentation_SelectiveSearchSegmentationStrategyColor",
    sizeof(pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyColor_t),
};

static void pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyColor_dealloc(PyObject* self)
{
    ((pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyColor_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::ximgproc::segmentation::SelectiveSearchSegmentationStrategyColor>& r)
{
    pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyColor_t *m = PyObject_NEW(pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyColor_t, &pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyColor_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::ximgproc::segmentation::SelectiveSearchSegmentationStrategyColor>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyColor_Type))
    {
        failmsg("Expected cv::ximgproc::segmentation::SelectiveSearchSegmentationStrategyColor for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyColor_t*)src)->v.dynamicCast<cv::ximgproc::segmentation::SelectiveSearchSegmentationStrategyColor>();
    return true;
}


struct pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyFill_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyFill_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".ximgproc_segmentation_SelectiveSearchSegmentationStrategyFill",
    sizeof(pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyFill_t),
};

static void pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyFill_dealloc(PyObject* self)
{
    ((pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyFill_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::ximgproc::segmentation::SelectiveSearchSegmentationStrategyFill>& r)
{
    pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyFill_t *m = PyObject_NEW(pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyFill_t, &pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyFill_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::ximgproc::segmentation::SelectiveSearchSegmentationStrategyFill>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyFill_Type))
    {
        failmsg("Expected cv::ximgproc::segmentation::SelectiveSearchSegmentationStrategyFill for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyFill_t*)src)->v.dynamicCast<cv::ximgproc::segmentation::SelectiveSearchSegmentationStrategyFill>();
    return true;
}


struct pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyMultiple_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyMultiple_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".ximgproc_segmentation_SelectiveSearchSegmentationStrategyMultiple",
    sizeof(pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyMultiple_t),
};

static void pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyMultiple_dealloc(PyObject* self)
{
    ((pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyMultiple_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::ximgproc::segmentation::SelectiveSearchSegmentationStrategyMultiple>& r)
{
    pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyMultiple_t *m = PyObject_NEW(pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyMultiple_t, &pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyMultiple_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::ximgproc::segmentation::SelectiveSearchSegmentationStrategyMultiple>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyMultiple_Type))
    {
        failmsg("Expected cv::ximgproc::segmentation::SelectiveSearchSegmentationStrategyMultiple for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyMultiple_t*)src)->v.dynamicCast<cv::ximgproc::segmentation::SelectiveSearchSegmentationStrategyMultiple>();
    return true;
}


struct pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategySize_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategySize_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".ximgproc_segmentation_SelectiveSearchSegmentationStrategySize",
    sizeof(pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategySize_t),
};

static void pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategySize_dealloc(PyObject* self)
{
    ((pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategySize_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::ximgproc::segmentation::SelectiveSearchSegmentationStrategySize>& r)
{
    pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategySize_t *m = PyObject_NEW(pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategySize_t, &pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategySize_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::ximgproc::segmentation::SelectiveSearchSegmentationStrategySize>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategySize_Type))
    {
        failmsg("Expected cv::ximgproc::segmentation::SelectiveSearchSegmentationStrategySize for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategySize_t*)src)->v.dynamicCast<cv::ximgproc::segmentation::SelectiveSearchSegmentationStrategySize>();
    return true;
}


struct pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyTexture_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyTexture_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".ximgproc_segmentation_SelectiveSearchSegmentationStrategyTexture",
    sizeof(pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyTexture_t),
};

static void pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyTexture_dealloc(PyObject* self)
{
    ((pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyTexture_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::ximgproc::segmentation::SelectiveSearchSegmentationStrategyTexture>& r)
{
    pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyTexture_t *m = PyObject_NEW(pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyTexture_t, &pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyTexture_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::ximgproc::segmentation::SelectiveSearchSegmentationStrategyTexture>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyTexture_Type))
    {
        failmsg("Expected cv::ximgproc::segmentation::SelectiveSearchSegmentationStrategyTexture for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyTexture_t*)src)->v.dynamicCast<cv::ximgproc::segmentation::SelectiveSearchSegmentationStrategyTexture>();
    return true;
}


struct pyopencv_xphoto_GrayworldWB_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_xphoto_GrayworldWB_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".xphoto_GrayworldWB",
    sizeof(pyopencv_xphoto_GrayworldWB_t),
};

static void pyopencv_xphoto_GrayworldWB_dealloc(PyObject* self)
{
    ((pyopencv_xphoto_GrayworldWB_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::xphoto::GrayworldWB>& r)
{
    pyopencv_xphoto_GrayworldWB_t *m = PyObject_NEW(pyopencv_xphoto_GrayworldWB_t, &pyopencv_xphoto_GrayworldWB_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::xphoto::GrayworldWB>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_xphoto_GrayworldWB_Type))
    {
        failmsg("Expected cv::xphoto::GrayworldWB for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_xphoto_GrayworldWB_t*)src)->v.dynamicCast<cv::xphoto::GrayworldWB>();
    return true;
}


struct pyopencv_xphoto_LearningBasedWB_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_xphoto_LearningBasedWB_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".xphoto_LearningBasedWB",
    sizeof(pyopencv_xphoto_LearningBasedWB_t),
};

static void pyopencv_xphoto_LearningBasedWB_dealloc(PyObject* self)
{
    ((pyopencv_xphoto_LearningBasedWB_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::xphoto::LearningBasedWB>& r)
{
    pyopencv_xphoto_LearningBasedWB_t *m = PyObject_NEW(pyopencv_xphoto_LearningBasedWB_t, &pyopencv_xphoto_LearningBasedWB_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::xphoto::LearningBasedWB>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_xphoto_LearningBasedWB_Type))
    {
        failmsg("Expected cv::xphoto::LearningBasedWB for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_xphoto_LearningBasedWB_t*)src)->v.dynamicCast<cv::xphoto::LearningBasedWB>();
    return true;
}


struct pyopencv_xphoto_SimpleWB_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_xphoto_SimpleWB_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".xphoto_SimpleWB",
    sizeof(pyopencv_xphoto_SimpleWB_t),
};

static void pyopencv_xphoto_SimpleWB_dealloc(PyObject* self)
{
    ((pyopencv_xphoto_SimpleWB_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::xphoto::SimpleWB>& r)
{
    pyopencv_xphoto_SimpleWB_t *m = PyObject_NEW(pyopencv_xphoto_SimpleWB_t, &pyopencv_xphoto_SimpleWB_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::xphoto::SimpleWB>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_xphoto_SimpleWB_Type))
    {
        failmsg("Expected cv::xphoto::SimpleWB for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_xphoto_SimpleWB_t*)src)->v.dynamicCast<cv::xphoto::SimpleWB>();
    return true;
}


struct pyopencv_xphoto_WhiteBalancer_t
{
    PyObject_HEAD
    Ptr<cv::Algorithm> v;
};

static PyTypeObject pyopencv_xphoto_WhiteBalancer_Type =
{
    PyVarObject_HEAD_INIT(&PyType_Type, 0)
    MODULESTR".xphoto_WhiteBalancer",
    sizeof(pyopencv_xphoto_WhiteBalancer_t),
};

static void pyopencv_xphoto_WhiteBalancer_dealloc(PyObject* self)
{
    ((pyopencv_xphoto_WhiteBalancer_t*)self)->v.release();
    PyObject_Del(self);
}

template<> PyObject* pyopencv_from(const Ptr<cv::xphoto::WhiteBalancer>& r)
{
    pyopencv_xphoto_WhiteBalancer_t *m = PyObject_NEW(pyopencv_xphoto_WhiteBalancer_t, &pyopencv_xphoto_WhiteBalancer_Type);
    new (&(m->v)) Ptr<cv::Algorithm>(); // init Ptr with placement new
    m->v = r;
    return (PyObject*)m;
}

template<> bool pyopencv_to(PyObject* src, Ptr<cv::xphoto::WhiteBalancer>& dst, const char* name)
{
    if( src == NULL || src == Py_None )
        return true;
    if(!PyObject_TypeCheck(src, &pyopencv_xphoto_WhiteBalancer_Type))
    {
        failmsg("Expected cv::xphoto::WhiteBalancer for argument '%s'", name);
        return false;
    }
    dst = ((pyopencv_xphoto_WhiteBalancer_t*)src)->v.dynamicCast<cv::xphoto::WhiteBalancer>();
    return true;
}


static PyObject* pyopencv_Algorithm_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<Algorithm %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_Algorithm_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_Algorithm_clear(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_Algorithm_Type))
        return failmsgp("Incorrect type of self (must be 'Algorithm' or its derivative)");
    cv::Algorithm* _self_ = ((pyopencv_Algorithm_t*)self)->v.get();

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(_self_->clear());
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_Algorithm_getDefaultName(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_Algorithm_Type))
        return failmsgp("Incorrect type of self (must be 'Algorithm' or its derivative)");
    cv::Algorithm* _self_ = ((pyopencv_Algorithm_t*)self)->v.get();
    String retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getDefaultName());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_Algorithm_save(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_Algorithm_Type))
        return failmsgp("Incorrect type of self (must be 'Algorithm' or its derivative)");
    cv::Algorithm* _self_ = ((pyopencv_Algorithm_t*)self)->v.get();
    PyObject* pyobj_filename = NULL;
    String filename;

    const char* keywords[] = { "filename", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:Algorithm.save", (char**)keywords, &pyobj_filename) &&
        pyopencv_to(pyobj_filename, filename, ArgInfo("filename", 0)) )
    {
        ERRWRAP2(_self_->save(filename));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_Algorithm_methods[] =
{
    {"clear", (PyCFunction)pyopencv_cv_Algorithm_clear, METH_VARARGS | METH_KEYWORDS, "clear() -> None"},
    {"getDefaultName", (PyCFunction)pyopencv_cv_Algorithm_getDefaultName, METH_VARARGS | METH_KEYWORDS, "getDefaultName() -> retval"},
    {"save", (PyCFunction)pyopencv_cv_Algorithm_save, METH_VARARGS | METH_KEYWORDS, "save(filename) -> None"},

    {NULL,          NULL}
};

static void pyopencv_Algorithm_specials(void)
{
    pyopencv_Algorithm_Type.tp_base = NULL;
    pyopencv_Algorithm_Type.tp_dealloc = pyopencv_Algorithm_dealloc;
    pyopencv_Algorithm_Type.tp_repr = pyopencv_Algorithm_repr;
    pyopencv_Algorithm_Type.tp_getset = pyopencv_Algorithm_getseters;
    pyopencv_Algorithm_Type.tp_methods = pyopencv_Algorithm_methods;
}

static PyObject* pyopencv_FileStorage_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<FileStorage %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_FileStorage_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_FileStorage_getFirstTopLevelNode(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FileStorage_Type))
        return failmsgp("Incorrect type of self (must be 'FileStorage' or its derivative)");
    cv::FileStorage* _self_ = ((pyopencv_FileStorage_t*)self)->v.get();
    FileNode retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getFirstTopLevelNode());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_FileStorage_getNode(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FileStorage_Type))
        return failmsgp("Incorrect type of self (must be 'FileStorage' or its derivative)");
    cv::FileStorage* _self_ = ((pyopencv_FileStorage_t*)self)->v.get();
    char* nodename=(char*)"";
    FileNode retval;

    const char* keywords[] = { "nodename", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "s:FileStorage.getNode", (char**)keywords, &nodename) )
    {
        ERRWRAP2(retval = _self_->operator[](nodename));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_FileStorage_isOpened(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FileStorage_Type))
        return failmsgp("Incorrect type of self (must be 'FileStorage' or its derivative)");
    cv::FileStorage* _self_ = ((pyopencv_FileStorage_t*)self)->v.get();
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->isOpened());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_FileStorage_open(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FileStorage_Type))
        return failmsgp("Incorrect type of self (must be 'FileStorage' or its derivative)");
    cv::FileStorage* _self_ = ((pyopencv_FileStorage_t*)self)->v.get();
    PyObject* pyobj_filename = NULL;
    String filename;
    int flags=0;
    PyObject* pyobj_encoding = NULL;
    String encoding;
    bool retval;

    const char* keywords[] = { "filename", "flags", "encoding", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "Oi|O:FileStorage.open", (char**)keywords, &pyobj_filename, &flags, &pyobj_encoding) &&
        pyopencv_to(pyobj_filename, filename, ArgInfo("filename", 0)) &&
        pyopencv_to(pyobj_encoding, encoding, ArgInfo("encoding", 0)) )
    {
        ERRWRAP2(retval = _self_->open(filename, flags, encoding));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_FileStorage_release(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FileStorage_Type))
        return failmsgp("Incorrect type of self (must be 'FileStorage' or its derivative)");
    cv::FileStorage* _self_ = ((pyopencv_FileStorage_t*)self)->v.get();

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(_self_->release());
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_FileStorage_releaseAndGetString(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FileStorage_Type))
        return failmsgp("Incorrect type of self (must be 'FileStorage' or its derivative)");
    cv::FileStorage* _self_ = ((pyopencv_FileStorage_t*)self)->v.get();
    String retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->releaseAndGetString());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_FileStorage_root(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FileStorage_Type))
        return failmsgp("Incorrect type of self (must be 'FileStorage' or its derivative)");
    cv::FileStorage* _self_ = ((pyopencv_FileStorage_t*)self)->v.get();
    int streamidx=0;
    FileNode retval;

    const char* keywords[] = { "streamidx", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|i:FileStorage.root", (char**)keywords, &streamidx) )
    {
        ERRWRAP2(retval = _self_->root(streamidx));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_FileStorage_write(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FileStorage_Type))
        return failmsgp("Incorrect type of self (must be 'FileStorage' or its derivative)");
    cv::FileStorage* _self_ = ((pyopencv_FileStorage_t*)self)->v.get();
    {
    PyObject* pyobj_name = NULL;
    String name;
    double val=0;

    const char* keywords[] = { "name", "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "Od:FileStorage.write", (char**)keywords, &pyobj_name, &val) &&
        pyopencv_to(pyobj_name, name, ArgInfo("name", 0)) )
    {
        ERRWRAP2(_self_->write(name, val));
        Py_RETURN_NONE;
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_name = NULL;
    String name;
    PyObject* pyobj_val = NULL;
    String val;

    const char* keywords[] = { "name", "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO:FileStorage.write", (char**)keywords, &pyobj_name, &pyobj_val) &&
        pyopencv_to(pyobj_name, name, ArgInfo("name", 0)) &&
        pyopencv_to(pyobj_val, val, ArgInfo("val", 0)) )
    {
        ERRWRAP2(_self_->write(name, val));
        Py_RETURN_NONE;
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_name = NULL;
    String name;
    PyObject* pyobj_val = NULL;
    Mat val;

    const char* keywords[] = { "name", "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO:FileStorage.write", (char**)keywords, &pyobj_name, &pyobj_val) &&
        pyopencv_to(pyobj_name, name, ArgInfo("name", 0)) &&
        pyopencv_to(pyobj_val, val, ArgInfo("val", 0)) )
    {
        ERRWRAP2(_self_->write(name, val));
        Py_RETURN_NONE;
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_name = NULL;
    String name;
    PyObject* pyobj_val = NULL;
    UMat val;

    const char* keywords[] = { "name", "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO:FileStorage.write", (char**)keywords, &pyobj_name, &pyobj_val) &&
        pyopencv_to(pyobj_name, name, ArgInfo("name", 0)) &&
        pyopencv_to(pyobj_val, val, ArgInfo("val", 0)) )
    {
        ERRWRAP2(_self_->write(name, val));
        Py_RETURN_NONE;
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_FileStorage_writeComment(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FileStorage_Type))
        return failmsgp("Incorrect type of self (must be 'FileStorage' or its derivative)");
    cv::FileStorage* _self_ = ((pyopencv_FileStorage_t*)self)->v.get();
    PyObject* pyobj_comment = NULL;
    String comment;
    bool append=false;

    const char* keywords[] = { "comment", "append", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|b:FileStorage.writeComment", (char**)keywords, &pyobj_comment, &append) &&
        pyopencv_to(pyobj_comment, comment, ArgInfo("comment", 0)) )
    {
        ERRWRAP2(_self_->writeComment(comment, append));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_FileStorage_methods[] =
{
    {"getFirstTopLevelNode", (PyCFunction)pyopencv_cv_FileStorage_getFirstTopLevelNode, METH_VARARGS | METH_KEYWORDS, "getFirstTopLevelNode() -> retval"},
    {"getNode", (PyCFunction)pyopencv_cv_FileStorage_getNode, METH_VARARGS | METH_KEYWORDS, "getNode(nodename) -> retval"},
    {"isOpened", (PyCFunction)pyopencv_cv_FileStorage_isOpened, METH_VARARGS | METH_KEYWORDS, "isOpened() -> retval"},
    {"open", (PyCFunction)pyopencv_cv_FileStorage_open, METH_VARARGS | METH_KEYWORDS, "open(filename, flags[, encoding]) -> retval"},
    {"release", (PyCFunction)pyopencv_cv_FileStorage_release, METH_VARARGS | METH_KEYWORDS, "release() -> None"},
    {"releaseAndGetString", (PyCFunction)pyopencv_cv_FileStorage_releaseAndGetString, METH_VARARGS | METH_KEYWORDS, "releaseAndGetString() -> retval"},
    {"root", (PyCFunction)pyopencv_cv_FileStorage_root, METH_VARARGS | METH_KEYWORDS, "root([, streamidx]) -> retval"},
    {"write", (PyCFunction)pyopencv_cv_FileStorage_write, METH_VARARGS | METH_KEYWORDS, "write(name, val) -> None"},
    {"writeComment", (PyCFunction)pyopencv_cv_FileStorage_writeComment, METH_VARARGS | METH_KEYWORDS, "writeComment(comment[, append]) -> None"},

    {NULL,          NULL}
};

static void pyopencv_FileStorage_specials(void)
{
    pyopencv_FileStorage_Type.tp_base = NULL;
    pyopencv_FileStorage_Type.tp_dealloc = pyopencv_FileStorage_dealloc;
    pyopencv_FileStorage_Type.tp_repr = pyopencv_FileStorage_repr;
    pyopencv_FileStorage_Type.tp_getset = pyopencv_FileStorage_getseters;
    pyopencv_FileStorage_Type.tp_methods = pyopencv_FileStorage_methods;
}

static PyObject* pyopencv_FileNode_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<FileNode %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_FileNode_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_FileNode_at(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FileNode_Type))
        return failmsgp("Incorrect type of self (must be 'FileNode' or its derivative)");
    cv::FileNode* _self_ = &((pyopencv_FileNode_t*)self)->v;
    int i=0;
    FileNode retval;

    const char* keywords[] = { "i", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:FileNode.at", (char**)keywords, &i) )
    {
        ERRWRAP2(retval = _self_->operator[](i));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_FileNode_empty(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FileNode_Type))
        return failmsgp("Incorrect type of self (must be 'FileNode' or its derivative)");
    cv::FileNode* _self_ = &((pyopencv_FileNode_t*)self)->v;
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->empty());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_FileNode_getNode(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FileNode_Type))
        return failmsgp("Incorrect type of self (must be 'FileNode' or its derivative)");
    cv::FileNode* _self_ = &((pyopencv_FileNode_t*)self)->v;
    char* nodename=(char*)"";
    FileNode retval;

    const char* keywords[] = { "nodename", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "s:FileNode.getNode", (char**)keywords, &nodename) )
    {
        ERRWRAP2(retval = _self_->operator[](nodename));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_FileNode_isInt(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FileNode_Type))
        return failmsgp("Incorrect type of self (must be 'FileNode' or its derivative)");
    cv::FileNode* _self_ = &((pyopencv_FileNode_t*)self)->v;
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->isInt());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_FileNode_isMap(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FileNode_Type))
        return failmsgp("Incorrect type of self (must be 'FileNode' or its derivative)");
    cv::FileNode* _self_ = &((pyopencv_FileNode_t*)self)->v;
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->isMap());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_FileNode_isNamed(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FileNode_Type))
        return failmsgp("Incorrect type of self (must be 'FileNode' or its derivative)");
    cv::FileNode* _self_ = &((pyopencv_FileNode_t*)self)->v;
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->isNamed());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_FileNode_isNone(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FileNode_Type))
        return failmsgp("Incorrect type of self (must be 'FileNode' or its derivative)");
    cv::FileNode* _self_ = &((pyopencv_FileNode_t*)self)->v;
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->isNone());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_FileNode_isReal(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FileNode_Type))
        return failmsgp("Incorrect type of self (must be 'FileNode' or its derivative)");
    cv::FileNode* _self_ = &((pyopencv_FileNode_t*)self)->v;
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->isReal());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_FileNode_isSeq(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FileNode_Type))
        return failmsgp("Incorrect type of self (must be 'FileNode' or its derivative)");
    cv::FileNode* _self_ = &((pyopencv_FileNode_t*)self)->v;
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->isSeq());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_FileNode_isString(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FileNode_Type))
        return failmsgp("Incorrect type of self (must be 'FileNode' or its derivative)");
    cv::FileNode* _self_ = &((pyopencv_FileNode_t*)self)->v;
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->isString());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_FileNode_mat(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FileNode_Type))
        return failmsgp("Incorrect type of self (must be 'FileNode' or its derivative)");
    cv::FileNode* _self_ = &((pyopencv_FileNode_t*)self)->v;
    Mat retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->mat());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_FileNode_name(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FileNode_Type))
        return failmsgp("Incorrect type of self (must be 'FileNode' or its derivative)");
    cv::FileNode* _self_ = &((pyopencv_FileNode_t*)self)->v;
    String retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->name());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_FileNode_real(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FileNode_Type))
        return failmsgp("Incorrect type of self (must be 'FileNode' or its derivative)");
    cv::FileNode* _self_ = &((pyopencv_FileNode_t*)self)->v;
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->real());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_FileNode_size(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FileNode_Type))
        return failmsgp("Incorrect type of self (must be 'FileNode' or its derivative)");
    cv::FileNode* _self_ = &((pyopencv_FileNode_t*)self)->v;
    size_t retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->size());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_FileNode_string(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FileNode_Type))
        return failmsgp("Incorrect type of self (must be 'FileNode' or its derivative)");
    cv::FileNode* _self_ = &((pyopencv_FileNode_t*)self)->v;
    String retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->string());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_FileNode_type(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FileNode_Type))
        return failmsgp("Incorrect type of self (must be 'FileNode' or its derivative)");
    cv::FileNode* _self_ = &((pyopencv_FileNode_t*)self)->v;
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->type());
        return pyopencv_from(retval);
    }

    return NULL;
}



static PyMethodDef pyopencv_FileNode_methods[] =
{
    {"at", (PyCFunction)pyopencv_cv_FileNode_at, METH_VARARGS | METH_KEYWORDS, "at(i) -> retval"},
    {"empty", (PyCFunction)pyopencv_cv_FileNode_empty, METH_VARARGS | METH_KEYWORDS, "empty() -> retval"},
    {"getNode", (PyCFunction)pyopencv_cv_FileNode_getNode, METH_VARARGS | METH_KEYWORDS, "getNode(nodename) -> retval"},
    {"isInt", (PyCFunction)pyopencv_cv_FileNode_isInt, METH_VARARGS | METH_KEYWORDS, "isInt() -> retval"},
    {"isMap", (PyCFunction)pyopencv_cv_FileNode_isMap, METH_VARARGS | METH_KEYWORDS, "isMap() -> retval"},
    {"isNamed", (PyCFunction)pyopencv_cv_FileNode_isNamed, METH_VARARGS | METH_KEYWORDS, "isNamed() -> retval"},
    {"isNone", (PyCFunction)pyopencv_cv_FileNode_isNone, METH_VARARGS | METH_KEYWORDS, "isNone() -> retval"},
    {"isReal", (PyCFunction)pyopencv_cv_FileNode_isReal, METH_VARARGS | METH_KEYWORDS, "isReal() -> retval"},
    {"isSeq", (PyCFunction)pyopencv_cv_FileNode_isSeq, METH_VARARGS | METH_KEYWORDS, "isSeq() -> retval"},
    {"isString", (PyCFunction)pyopencv_cv_FileNode_isString, METH_VARARGS | METH_KEYWORDS, "isString() -> retval"},
    {"mat", (PyCFunction)pyopencv_cv_FileNode_mat, METH_VARARGS | METH_KEYWORDS, "mat() -> retval"},
    {"name", (PyCFunction)pyopencv_cv_FileNode_name, METH_VARARGS | METH_KEYWORDS, "name() -> retval"},
    {"real", (PyCFunction)pyopencv_cv_FileNode_real, METH_VARARGS | METH_KEYWORDS, "real() -> retval"},
    {"size", (PyCFunction)pyopencv_cv_FileNode_size, METH_VARARGS | METH_KEYWORDS, "size() -> retval"},
    {"string", (PyCFunction)pyopencv_cv_FileNode_string, METH_VARARGS | METH_KEYWORDS, "string() -> retval"},
    {"type", (PyCFunction)pyopencv_cv_FileNode_type, METH_VARARGS | METH_KEYWORDS, "type() -> retval"},

    {NULL,          NULL}
};

static void pyopencv_FileNode_specials(void)
{
    pyopencv_FileNode_Type.tp_base = NULL;
    pyopencv_FileNode_Type.tp_dealloc = pyopencv_FileNode_dealloc;
    pyopencv_FileNode_Type.tp_repr = pyopencv_FileNode_repr;
    pyopencv_FileNode_Type.tp_getset = pyopencv_FileNode_getseters;
    pyopencv_FileNode_Type.tp_methods = pyopencv_FileNode_methods;
}

static PyObject* pyopencv_KeyPoint_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<KeyPoint %p>", self);
    return PyString_FromString(str);
}


static PyObject* pyopencv_KeyPoint_get_angle(pyopencv_KeyPoint_t* p, void *closure)
{
    return pyopencv_from(p->v.angle);
}

static int pyopencv_KeyPoint_set_angle(pyopencv_KeyPoint_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the angle attribute");
        return -1;
    }
    return pyopencv_to(value, p->v.angle) ? 0 : -1;
}

static PyObject* pyopencv_KeyPoint_get_class_id(pyopencv_KeyPoint_t* p, void *closure)
{
    return pyopencv_from(p->v.class_id);
}

static int pyopencv_KeyPoint_set_class_id(pyopencv_KeyPoint_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the class_id attribute");
        return -1;
    }
    return pyopencv_to(value, p->v.class_id) ? 0 : -1;
}

static PyObject* pyopencv_KeyPoint_get_octave(pyopencv_KeyPoint_t* p, void *closure)
{
    return pyopencv_from(p->v.octave);
}

static int pyopencv_KeyPoint_set_octave(pyopencv_KeyPoint_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the octave attribute");
        return -1;
    }
    return pyopencv_to(value, p->v.octave) ? 0 : -1;
}

static PyObject* pyopencv_KeyPoint_get_pt(pyopencv_KeyPoint_t* p, void *closure)
{
    return pyopencv_from(p->v.pt);
}

static int pyopencv_KeyPoint_set_pt(pyopencv_KeyPoint_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the pt attribute");
        return -1;
    }
    return pyopencv_to(value, p->v.pt) ? 0 : -1;
}

static PyObject* pyopencv_KeyPoint_get_response(pyopencv_KeyPoint_t* p, void *closure)
{
    return pyopencv_from(p->v.response);
}

static int pyopencv_KeyPoint_set_response(pyopencv_KeyPoint_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the response attribute");
        return -1;
    }
    return pyopencv_to(value, p->v.response) ? 0 : -1;
}

static PyObject* pyopencv_KeyPoint_get_size(pyopencv_KeyPoint_t* p, void *closure)
{
    return pyopencv_from(p->v.size);
}

static int pyopencv_KeyPoint_set_size(pyopencv_KeyPoint_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the size attribute");
        return -1;
    }
    return pyopencv_to(value, p->v.size) ? 0 : -1;
}


static PyGetSetDef pyopencv_KeyPoint_getseters[] =
{
    {(char*)"angle", (getter)pyopencv_KeyPoint_get_angle, (setter)pyopencv_KeyPoint_set_angle, (char*)"angle", NULL},
    {(char*)"class_id", (getter)pyopencv_KeyPoint_get_class_id, (setter)pyopencv_KeyPoint_set_class_id, (char*)"class_id", NULL},
    {(char*)"octave", (getter)pyopencv_KeyPoint_get_octave, (setter)pyopencv_KeyPoint_set_octave, (char*)"octave", NULL},
    {(char*)"pt", (getter)pyopencv_KeyPoint_get_pt, (setter)pyopencv_KeyPoint_set_pt, (char*)"pt", NULL},
    {(char*)"response", (getter)pyopencv_KeyPoint_get_response, (setter)pyopencv_KeyPoint_set_response, (char*)"response", NULL},
    {(char*)"size", (getter)pyopencv_KeyPoint_get_size, (setter)pyopencv_KeyPoint_set_size, (char*)"size", NULL},
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_KeyPoint_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_KeyPoint_specials(void)
{
    pyopencv_KeyPoint_Type.tp_base = NULL;
    pyopencv_KeyPoint_Type.tp_dealloc = pyopencv_KeyPoint_dealloc;
    pyopencv_KeyPoint_Type.tp_repr = pyopencv_KeyPoint_repr;
    pyopencv_KeyPoint_Type.tp_getset = pyopencv_KeyPoint_getseters;
    pyopencv_KeyPoint_Type.tp_methods = pyopencv_KeyPoint_methods;
}

static PyObject* pyopencv_DMatch_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<DMatch %p>", self);
    return PyString_FromString(str);
}


static PyObject* pyopencv_DMatch_get_distance(pyopencv_DMatch_t* p, void *closure)
{
    return pyopencv_from(p->v.distance);
}

static int pyopencv_DMatch_set_distance(pyopencv_DMatch_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the distance attribute");
        return -1;
    }
    return pyopencv_to(value, p->v.distance) ? 0 : -1;
}

static PyObject* pyopencv_DMatch_get_imgIdx(pyopencv_DMatch_t* p, void *closure)
{
    return pyopencv_from(p->v.imgIdx);
}

static int pyopencv_DMatch_set_imgIdx(pyopencv_DMatch_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the imgIdx attribute");
        return -1;
    }
    return pyopencv_to(value, p->v.imgIdx) ? 0 : -1;
}

static PyObject* pyopencv_DMatch_get_queryIdx(pyopencv_DMatch_t* p, void *closure)
{
    return pyopencv_from(p->v.queryIdx);
}

static int pyopencv_DMatch_set_queryIdx(pyopencv_DMatch_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the queryIdx attribute");
        return -1;
    }
    return pyopencv_to(value, p->v.queryIdx) ? 0 : -1;
}

static PyObject* pyopencv_DMatch_get_trainIdx(pyopencv_DMatch_t* p, void *closure)
{
    return pyopencv_from(p->v.trainIdx);
}

static int pyopencv_DMatch_set_trainIdx(pyopencv_DMatch_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the trainIdx attribute");
        return -1;
    }
    return pyopencv_to(value, p->v.trainIdx) ? 0 : -1;
}


static PyGetSetDef pyopencv_DMatch_getseters[] =
{
    {(char*)"distance", (getter)pyopencv_DMatch_get_distance, (setter)pyopencv_DMatch_set_distance, (char*)"distance", NULL},
    {(char*)"imgIdx", (getter)pyopencv_DMatch_get_imgIdx, (setter)pyopencv_DMatch_set_imgIdx, (char*)"imgIdx", NULL},
    {(char*)"queryIdx", (getter)pyopencv_DMatch_get_queryIdx, (setter)pyopencv_DMatch_set_queryIdx, (char*)"queryIdx", NULL},
    {(char*)"trainIdx", (getter)pyopencv_DMatch_get_trainIdx, (setter)pyopencv_DMatch_set_trainIdx, (char*)"trainIdx", NULL},
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_DMatch_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_DMatch_specials(void)
{
    pyopencv_DMatch_Type.tp_base = NULL;
    pyopencv_DMatch_Type.tp_dealloc = pyopencv_DMatch_dealloc;
    pyopencv_DMatch_Type.tp_repr = pyopencv_DMatch_repr;
    pyopencv_DMatch_Type.tp_getset = pyopencv_DMatch_getseters;
    pyopencv_DMatch_Type.tp_methods = pyopencv_DMatch_methods;
}
static bool pyopencv_to(PyObject* src, cv::Moments& dst, const char* name)
{
    PyObject* tmp;
    bool ok;

    if( PyMapping_HasKeyString(src, (char*)"m00") )
    {
        tmp = PyMapping_GetItemString(src, (char*)"m00");
        ok = tmp && pyopencv_to(tmp, dst.m00);
        Py_DECREF(tmp);
        if(!ok) return false;
    }
    if( PyMapping_HasKeyString(src, (char*)"m10") )
    {
        tmp = PyMapping_GetItemString(src, (char*)"m10");
        ok = tmp && pyopencv_to(tmp, dst.m10);
        Py_DECREF(tmp);
        if(!ok) return false;
    }
    if( PyMapping_HasKeyString(src, (char*)"m01") )
    {
        tmp = PyMapping_GetItemString(src, (char*)"m01");
        ok = tmp && pyopencv_to(tmp, dst.m01);
        Py_DECREF(tmp);
        if(!ok) return false;
    }
    if( PyMapping_HasKeyString(src, (char*)"m20") )
    {
        tmp = PyMapping_GetItemString(src, (char*)"m20");
        ok = tmp && pyopencv_to(tmp, dst.m20);
        Py_DECREF(tmp);
        if(!ok) return false;
    }
    if( PyMapping_HasKeyString(src, (char*)"m11") )
    {
        tmp = PyMapping_GetItemString(src, (char*)"m11");
        ok = tmp && pyopencv_to(tmp, dst.m11);
        Py_DECREF(tmp);
        if(!ok) return false;
    }
    if( PyMapping_HasKeyString(src, (char*)"m02") )
    {
        tmp = PyMapping_GetItemString(src, (char*)"m02");
        ok = tmp && pyopencv_to(tmp, dst.m02);
        Py_DECREF(tmp);
        if(!ok) return false;
    }
    if( PyMapping_HasKeyString(src, (char*)"m30") )
    {
        tmp = PyMapping_GetItemString(src, (char*)"m30");
        ok = tmp && pyopencv_to(tmp, dst.m30);
        Py_DECREF(tmp);
        if(!ok) return false;
    }
    if( PyMapping_HasKeyString(src, (char*)"m21") )
    {
        tmp = PyMapping_GetItemString(src, (char*)"m21");
        ok = tmp && pyopencv_to(tmp, dst.m21);
        Py_DECREF(tmp);
        if(!ok) return false;
    }
    if( PyMapping_HasKeyString(src, (char*)"m12") )
    {
        tmp = PyMapping_GetItemString(src, (char*)"m12");
        ok = tmp && pyopencv_to(tmp, dst.m12);
        Py_DECREF(tmp);
        if(!ok) return false;
    }
    if( PyMapping_HasKeyString(src, (char*)"m03") )
    {
        tmp = PyMapping_GetItemString(src, (char*)"m03");
        ok = tmp && pyopencv_to(tmp, dst.m03);
        Py_DECREF(tmp);
        if(!ok) return false;
    }
    if( PyMapping_HasKeyString(src, (char*)"mu20") )
    {
        tmp = PyMapping_GetItemString(src, (char*)"mu20");
        ok = tmp && pyopencv_to(tmp, dst.mu20);
        Py_DECREF(tmp);
        if(!ok) return false;
    }
    if( PyMapping_HasKeyString(src, (char*)"mu11") )
    {
        tmp = PyMapping_GetItemString(src, (char*)"mu11");
        ok = tmp && pyopencv_to(tmp, dst.mu11);
        Py_DECREF(tmp);
        if(!ok) return false;
    }
    if( PyMapping_HasKeyString(src, (char*)"mu02") )
    {
        tmp = PyMapping_GetItemString(src, (char*)"mu02");
        ok = tmp && pyopencv_to(tmp, dst.mu02);
        Py_DECREF(tmp);
        if(!ok) return false;
    }
    if( PyMapping_HasKeyString(src, (char*)"mu30") )
    {
        tmp = PyMapping_GetItemString(src, (char*)"mu30");
        ok = tmp && pyopencv_to(tmp, dst.mu30);
        Py_DECREF(tmp);
        if(!ok) return false;
    }
    if( PyMapping_HasKeyString(src, (char*)"mu21") )
    {
        tmp = PyMapping_GetItemString(src, (char*)"mu21");
        ok = tmp && pyopencv_to(tmp, dst.mu21);
        Py_DECREF(tmp);
        if(!ok) return false;
    }
    if( PyMapping_HasKeyString(src, (char*)"mu12") )
    {
        tmp = PyMapping_GetItemString(src, (char*)"mu12");
        ok = tmp && pyopencv_to(tmp, dst.mu12);
        Py_DECREF(tmp);
        if(!ok) return false;
    }
    if( PyMapping_HasKeyString(src, (char*)"mu03") )
    {
        tmp = PyMapping_GetItemString(src, (char*)"mu03");
        ok = tmp && pyopencv_to(tmp, dst.mu03);
        Py_DECREF(tmp);
        if(!ok) return false;
    }
    if( PyMapping_HasKeyString(src, (char*)"nu20") )
    {
        tmp = PyMapping_GetItemString(src, (char*)"nu20");
        ok = tmp && pyopencv_to(tmp, dst.nu20);
        Py_DECREF(tmp);
        if(!ok) return false;
    }
    if( PyMapping_HasKeyString(src, (char*)"nu11") )
    {
        tmp = PyMapping_GetItemString(src, (char*)"nu11");
        ok = tmp && pyopencv_to(tmp, dst.nu11);
        Py_DECREF(tmp);
        if(!ok) return false;
    }
    if( PyMapping_HasKeyString(src, (char*)"nu02") )
    {
        tmp = PyMapping_GetItemString(src, (char*)"nu02");
        ok = tmp && pyopencv_to(tmp, dst.nu02);
        Py_DECREF(tmp);
        if(!ok) return false;
    }
    if( PyMapping_HasKeyString(src, (char*)"nu30") )
    {
        tmp = PyMapping_GetItemString(src, (char*)"nu30");
        ok = tmp && pyopencv_to(tmp, dst.nu30);
        Py_DECREF(tmp);
        if(!ok) return false;
    }
    if( PyMapping_HasKeyString(src, (char*)"nu21") )
    {
        tmp = PyMapping_GetItemString(src, (char*)"nu21");
        ok = tmp && pyopencv_to(tmp, dst.nu21);
        Py_DECREF(tmp);
        if(!ok) return false;
    }
    if( PyMapping_HasKeyString(src, (char*)"nu12") )
    {
        tmp = PyMapping_GetItemString(src, (char*)"nu12");
        ok = tmp && pyopencv_to(tmp, dst.nu12);
        Py_DECREF(tmp);
        if(!ok) return false;
    }
    if( PyMapping_HasKeyString(src, (char*)"nu03") )
    {
        tmp = PyMapping_GetItemString(src, (char*)"nu03");
        ok = tmp && pyopencv_to(tmp, dst.nu03);
        Py_DECREF(tmp);
        if(!ok) return false;
    }
    return true;
}

static PyObject* pyopencv_TickMeter_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<TickMeter %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_TickMeter_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_TickMeter_getCounter(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_TickMeter_Type))
        return failmsgp("Incorrect type of self (must be 'TickMeter' or its derivative)");
    cv::TickMeter* _self_ = ((pyopencv_TickMeter_t*)self)->v.get();
    int64 retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getCounter());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_TickMeter_getTimeMicro(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_TickMeter_Type))
        return failmsgp("Incorrect type of self (must be 'TickMeter' or its derivative)");
    cv::TickMeter* _self_ = ((pyopencv_TickMeter_t*)self)->v.get();
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getTimeMicro());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_TickMeter_getTimeMilli(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_TickMeter_Type))
        return failmsgp("Incorrect type of self (must be 'TickMeter' or its derivative)");
    cv::TickMeter* _self_ = ((pyopencv_TickMeter_t*)self)->v.get();
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getTimeMilli());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_TickMeter_getTimeSec(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_TickMeter_Type))
        return failmsgp("Incorrect type of self (must be 'TickMeter' or its derivative)");
    cv::TickMeter* _self_ = ((pyopencv_TickMeter_t*)self)->v.get();
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getTimeSec());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_TickMeter_getTimeTicks(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_TickMeter_Type))
        return failmsgp("Incorrect type of self (must be 'TickMeter' or its derivative)");
    cv::TickMeter* _self_ = ((pyopencv_TickMeter_t*)self)->v.get();
    int64 retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getTimeTicks());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_TickMeter_reset(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_TickMeter_Type))
        return failmsgp("Incorrect type of self (must be 'TickMeter' or its derivative)");
    cv::TickMeter* _self_ = ((pyopencv_TickMeter_t*)self)->v.get();

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(_self_->reset());
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_TickMeter_start(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_TickMeter_Type))
        return failmsgp("Incorrect type of self (must be 'TickMeter' or its derivative)");
    cv::TickMeter* _self_ = ((pyopencv_TickMeter_t*)self)->v.get();

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(_self_->start());
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_TickMeter_stop(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_TickMeter_Type))
        return failmsgp("Incorrect type of self (must be 'TickMeter' or its derivative)");
    cv::TickMeter* _self_ = ((pyopencv_TickMeter_t*)self)->v.get();

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(_self_->stop());
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_TickMeter_methods[] =
{
    {"getCounter", (PyCFunction)pyopencv_cv_TickMeter_getCounter, METH_VARARGS | METH_KEYWORDS, "getCounter() -> retval"},
    {"getTimeMicro", (PyCFunction)pyopencv_cv_TickMeter_getTimeMicro, METH_VARARGS | METH_KEYWORDS, "getTimeMicro() -> retval"},
    {"getTimeMilli", (PyCFunction)pyopencv_cv_TickMeter_getTimeMilli, METH_VARARGS | METH_KEYWORDS, "getTimeMilli() -> retval"},
    {"getTimeSec", (PyCFunction)pyopencv_cv_TickMeter_getTimeSec, METH_VARARGS | METH_KEYWORDS, "getTimeSec() -> retval"},
    {"getTimeTicks", (PyCFunction)pyopencv_cv_TickMeter_getTimeTicks, METH_VARARGS | METH_KEYWORDS, "getTimeTicks() -> retval"},
    {"reset", (PyCFunction)pyopencv_cv_TickMeter_reset, METH_VARARGS | METH_KEYWORDS, "reset() -> None"},
    {"start", (PyCFunction)pyopencv_cv_TickMeter_start, METH_VARARGS | METH_KEYWORDS, "start() -> None"},
    {"stop", (PyCFunction)pyopencv_cv_TickMeter_stop, METH_VARARGS | METH_KEYWORDS, "stop() -> None"},

    {NULL,          NULL}
};

static void pyopencv_TickMeter_specials(void)
{
    pyopencv_TickMeter_Type.tp_base = NULL;
    pyopencv_TickMeter_Type.tp_dealloc = pyopencv_TickMeter_dealloc;
    pyopencv_TickMeter_Type.tp_repr = pyopencv_TickMeter_repr;
    pyopencv_TickMeter_Type.tp_getset = pyopencv_TickMeter_getseters;
    pyopencv_TickMeter_Type.tp_methods = pyopencv_TickMeter_methods;
}

static PyObject* pyopencv_flann_Index_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<flann_Index %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_flann_Index_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_flann_flann_Index_build(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::flann;

    if(!PyObject_TypeCheck(self, &pyopencv_flann_Index_Type))
        return failmsgp("Incorrect type of self (must be 'flann_Index' or its derivative)");
    cv::flann::Index* _self_ = ((pyopencv_flann_Index_t*)self)->v.get();
    {
    PyObject* pyobj_features = NULL;
    Mat features;
    PyObject* pyobj_params = NULL;
    IndexParams params;
    PyObject* pyobj_distType = NULL;
    cvflann_flann_distance_t distType=cvflann::FLANN_DIST_L2;

    const char* keywords[] = { "features", "params", "distType", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|O:flann_Index.build", (char**)keywords, &pyobj_features, &pyobj_params, &pyobj_distType) &&
        pyopencv_to(pyobj_features, features, ArgInfo("features", 0)) &&
        pyopencv_to(pyobj_params, params, ArgInfo("params", 0)) &&
        pyopencv_to(pyobj_distType, distType, ArgInfo("distType", 0)) )
    {
        ERRWRAP2(_self_->build(features, params, distType));
        Py_RETURN_NONE;
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_features = NULL;
    UMat features;
    PyObject* pyobj_params = NULL;
    IndexParams params;
    PyObject* pyobj_distType = NULL;
    cvflann_flann_distance_t distType=cvflann::FLANN_DIST_L2;

    const char* keywords[] = { "features", "params", "distType", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|O:flann_Index.build", (char**)keywords, &pyobj_features, &pyobj_params, &pyobj_distType) &&
        pyopencv_to(pyobj_features, features, ArgInfo("features", 0)) &&
        pyopencv_to(pyobj_params, params, ArgInfo("params", 0)) &&
        pyopencv_to(pyobj_distType, distType, ArgInfo("distType", 0)) )
    {
        ERRWRAP2(_self_->build(features, params, distType));
        Py_RETURN_NONE;
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_flann_flann_Index_getAlgorithm(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::flann;

    if(!PyObject_TypeCheck(self, &pyopencv_flann_Index_Type))
        return failmsgp("Incorrect type of self (must be 'flann_Index' or its derivative)");
    cv::flann::Index* _self_ = ((pyopencv_flann_Index_t*)self)->v.get();
    cvflann::flann_algorithm_t retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getAlgorithm());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_flann_flann_Index_getDistance(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::flann;

    if(!PyObject_TypeCheck(self, &pyopencv_flann_Index_Type))
        return failmsgp("Incorrect type of self (must be 'flann_Index' or its derivative)");
    cv::flann::Index* _self_ = ((pyopencv_flann_Index_t*)self)->v.get();
    cvflann::flann_distance_t retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getDistance());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_flann_flann_Index_knnSearch(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::flann;

    if(!PyObject_TypeCheck(self, &pyopencv_flann_Index_Type))
        return failmsgp("Incorrect type of self (must be 'flann_Index' or its derivative)");
    cv::flann::Index* _self_ = ((pyopencv_flann_Index_t*)self)->v.get();
    {
    PyObject* pyobj_query = NULL;
    Mat query;
    PyObject* pyobj_indices = NULL;
    Mat indices;
    PyObject* pyobj_dists = NULL;
    Mat dists;
    int knn=0;
    PyObject* pyobj_params = NULL;
    SearchParams params;

    const char* keywords[] = { "query", "knn", "indices", "dists", "params", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "Oi|OOO:flann_Index.knnSearch", (char**)keywords, &pyobj_query, &knn, &pyobj_indices, &pyobj_dists, &pyobj_params) &&
        pyopencv_to(pyobj_query, query, ArgInfo("query", 0)) &&
        pyopencv_to(pyobj_indices, indices, ArgInfo("indices", 1)) &&
        pyopencv_to(pyobj_dists, dists, ArgInfo("dists", 1)) &&
        pyopencv_to(pyobj_params, params, ArgInfo("params", 0)) )
    {
        ERRWRAP2(_self_->knnSearch(query, indices, dists, knn, params));
        return Py_BuildValue("(NN)", pyopencv_from(indices), pyopencv_from(dists));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_query = NULL;
    UMat query;
    PyObject* pyobj_indices = NULL;
    UMat indices;
    PyObject* pyobj_dists = NULL;
    UMat dists;
    int knn=0;
    PyObject* pyobj_params = NULL;
    SearchParams params;

    const char* keywords[] = { "query", "knn", "indices", "dists", "params", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "Oi|OOO:flann_Index.knnSearch", (char**)keywords, &pyobj_query, &knn, &pyobj_indices, &pyobj_dists, &pyobj_params) &&
        pyopencv_to(pyobj_query, query, ArgInfo("query", 0)) &&
        pyopencv_to(pyobj_indices, indices, ArgInfo("indices", 1)) &&
        pyopencv_to(pyobj_dists, dists, ArgInfo("dists", 1)) &&
        pyopencv_to(pyobj_params, params, ArgInfo("params", 0)) )
    {
        ERRWRAP2(_self_->knnSearch(query, indices, dists, knn, params));
        return Py_BuildValue("(NN)", pyopencv_from(indices), pyopencv_from(dists));
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_flann_flann_Index_load(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::flann;

    if(!PyObject_TypeCheck(self, &pyopencv_flann_Index_Type))
        return failmsgp("Incorrect type of self (must be 'flann_Index' or its derivative)");
    cv::flann::Index* _self_ = ((pyopencv_flann_Index_t*)self)->v.get();
    {
    PyObject* pyobj_features = NULL;
    Mat features;
    PyObject* pyobj_filename = NULL;
    String filename;
    bool retval;

    const char* keywords[] = { "features", "filename", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO:flann_Index.load", (char**)keywords, &pyobj_features, &pyobj_filename) &&
        pyopencv_to(pyobj_features, features, ArgInfo("features", 0)) &&
        pyopencv_to(pyobj_filename, filename, ArgInfo("filename", 0)) )
    {
        ERRWRAP2(retval = _self_->load(features, filename));
        return pyopencv_from(retval);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_features = NULL;
    UMat features;
    PyObject* pyobj_filename = NULL;
    String filename;
    bool retval;

    const char* keywords[] = { "features", "filename", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO:flann_Index.load", (char**)keywords, &pyobj_features, &pyobj_filename) &&
        pyopencv_to(pyobj_features, features, ArgInfo("features", 0)) &&
        pyopencv_to(pyobj_filename, filename, ArgInfo("filename", 0)) )
    {
        ERRWRAP2(retval = _self_->load(features, filename));
        return pyopencv_from(retval);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_flann_flann_Index_radiusSearch(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::flann;

    if(!PyObject_TypeCheck(self, &pyopencv_flann_Index_Type))
        return failmsgp("Incorrect type of self (must be 'flann_Index' or its derivative)");
    cv::flann::Index* _self_ = ((pyopencv_flann_Index_t*)self)->v.get();
    {
    PyObject* pyobj_query = NULL;
    Mat query;
    PyObject* pyobj_indices = NULL;
    Mat indices;
    PyObject* pyobj_dists = NULL;
    Mat dists;
    double radius=0;
    int maxResults=0;
    PyObject* pyobj_params = NULL;
    SearchParams params;
    int retval;

    const char* keywords[] = { "query", "radius", "maxResults", "indices", "dists", "params", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "Odi|OOO:flann_Index.radiusSearch", (char**)keywords, &pyobj_query, &radius, &maxResults, &pyobj_indices, &pyobj_dists, &pyobj_params) &&
        pyopencv_to(pyobj_query, query, ArgInfo("query", 0)) &&
        pyopencv_to(pyobj_indices, indices, ArgInfo("indices", 1)) &&
        pyopencv_to(pyobj_dists, dists, ArgInfo("dists", 1)) &&
        pyopencv_to(pyobj_params, params, ArgInfo("params", 0)) )
    {
        ERRWRAP2(retval = _self_->radiusSearch(query, indices, dists, radius, maxResults, params));
        return Py_BuildValue("(NNN)", pyopencv_from(retval), pyopencv_from(indices), pyopencv_from(dists));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_query = NULL;
    UMat query;
    PyObject* pyobj_indices = NULL;
    UMat indices;
    PyObject* pyobj_dists = NULL;
    UMat dists;
    double radius=0;
    int maxResults=0;
    PyObject* pyobj_params = NULL;
    SearchParams params;
    int retval;

    const char* keywords[] = { "query", "radius", "maxResults", "indices", "dists", "params", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "Odi|OOO:flann_Index.radiusSearch", (char**)keywords, &pyobj_query, &radius, &maxResults, &pyobj_indices, &pyobj_dists, &pyobj_params) &&
        pyopencv_to(pyobj_query, query, ArgInfo("query", 0)) &&
        pyopencv_to(pyobj_indices, indices, ArgInfo("indices", 1)) &&
        pyopencv_to(pyobj_dists, dists, ArgInfo("dists", 1)) &&
        pyopencv_to(pyobj_params, params, ArgInfo("params", 0)) )
    {
        ERRWRAP2(retval = _self_->radiusSearch(query, indices, dists, radius, maxResults, params));
        return Py_BuildValue("(NNN)", pyopencv_from(retval), pyopencv_from(indices), pyopencv_from(dists));
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_flann_flann_Index_release(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::flann;

    if(!PyObject_TypeCheck(self, &pyopencv_flann_Index_Type))
        return failmsgp("Incorrect type of self (must be 'flann_Index' or its derivative)");
    cv::flann::Index* _self_ = ((pyopencv_flann_Index_t*)self)->v.get();

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(_self_->release());
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_flann_flann_Index_save(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::flann;

    if(!PyObject_TypeCheck(self, &pyopencv_flann_Index_Type))
        return failmsgp("Incorrect type of self (must be 'flann_Index' or its derivative)");
    cv::flann::Index* _self_ = ((pyopencv_flann_Index_t*)self)->v.get();
    PyObject* pyobj_filename = NULL;
    String filename;

    const char* keywords[] = { "filename", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:flann_Index.save", (char**)keywords, &pyobj_filename) &&
        pyopencv_to(pyobj_filename, filename, ArgInfo("filename", 0)) )
    {
        ERRWRAP2(_self_->save(filename));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_flann_Index_methods[] =
{
    {"build", (PyCFunction)pyopencv_cv_flann_flann_Index_build, METH_VARARGS | METH_KEYWORDS, "build(features, params[, distType]) -> None"},
    {"getAlgorithm", (PyCFunction)pyopencv_cv_flann_flann_Index_getAlgorithm, METH_VARARGS | METH_KEYWORDS, "getAlgorithm() -> retval"},
    {"getDistance", (PyCFunction)pyopencv_cv_flann_flann_Index_getDistance, METH_VARARGS | METH_KEYWORDS, "getDistance() -> retval"},
    {"knnSearch", (PyCFunction)pyopencv_cv_flann_flann_Index_knnSearch, METH_VARARGS | METH_KEYWORDS, "knnSearch(query, knn[, indices[, dists[, params]]]) -> indices, dists"},
    {"load", (PyCFunction)pyopencv_cv_flann_flann_Index_load, METH_VARARGS | METH_KEYWORDS, "load(features, filename) -> retval"},
    {"radiusSearch", (PyCFunction)pyopencv_cv_flann_flann_Index_radiusSearch, METH_VARARGS | METH_KEYWORDS, "radiusSearch(query, radius, maxResults[, indices[, dists[, params]]]) -> retval, indices, dists"},
    {"release", (PyCFunction)pyopencv_cv_flann_flann_Index_release, METH_VARARGS | METH_KEYWORDS, "release() -> None"},
    {"save", (PyCFunction)pyopencv_cv_flann_flann_Index_save, METH_VARARGS | METH_KEYWORDS, "save(filename) -> None"},

    {NULL,          NULL}
};

static void pyopencv_flann_Index_specials(void)
{
    pyopencv_flann_Index_Type.tp_base = NULL;
    pyopencv_flann_Index_Type.tp_dealloc = pyopencv_flann_Index_dealloc;
    pyopencv_flann_Index_Type.tp_repr = pyopencv_flann_Index_repr;
    pyopencv_flann_Index_Type.tp_getset = pyopencv_flann_Index_getseters;
    pyopencv_flann_Index_Type.tp_methods = pyopencv_flann_Index_methods;
}

static PyObject* pyopencv_CLAHE_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<CLAHE %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_CLAHE_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_CLAHE_apply(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_CLAHE_Type))
        return failmsgp("Incorrect type of self (must be 'CLAHE' or its derivative)");
    cv::CLAHE* _self_ = dynamic_cast<cv::CLAHE*>(((pyopencv_CLAHE_t*)self)->v.get());
    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;

    const char* keywords[] = { "src", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:CLAHE.apply", (char**)keywords, &pyobj_src, &pyobj_dst) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(_self_->apply(src, dst));
        return pyopencv_from(dst);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;

    const char* keywords[] = { "src", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:CLAHE.apply", (char**)keywords, &pyobj_src, &pyobj_dst) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(_self_->apply(src, dst));
        return pyopencv_from(dst);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_CLAHE_collectGarbage(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_CLAHE_Type))
        return failmsgp("Incorrect type of self (must be 'CLAHE' or its derivative)");
    cv::CLAHE* _self_ = dynamic_cast<cv::CLAHE*>(((pyopencv_CLAHE_t*)self)->v.get());

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(_self_->collectGarbage());
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_CLAHE_getClipLimit(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_CLAHE_Type))
        return failmsgp("Incorrect type of self (must be 'CLAHE' or its derivative)");
    cv::CLAHE* _self_ = dynamic_cast<cv::CLAHE*>(((pyopencv_CLAHE_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getClipLimit());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_CLAHE_getTilesGridSize(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_CLAHE_Type))
        return failmsgp("Incorrect type of self (must be 'CLAHE' or its derivative)");
    cv::CLAHE* _self_ = dynamic_cast<cv::CLAHE*>(((pyopencv_CLAHE_t*)self)->v.get());
    Size retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getTilesGridSize());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_CLAHE_setClipLimit(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_CLAHE_Type))
        return failmsgp("Incorrect type of self (must be 'CLAHE' or its derivative)");
    cv::CLAHE* _self_ = dynamic_cast<cv::CLAHE*>(((pyopencv_CLAHE_t*)self)->v.get());
    double clipLimit=0;

    const char* keywords[] = { "clipLimit", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:CLAHE.setClipLimit", (char**)keywords, &clipLimit) )
    {
        ERRWRAP2(_self_->setClipLimit(clipLimit));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_CLAHE_setTilesGridSize(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_CLAHE_Type))
        return failmsgp("Incorrect type of self (must be 'CLAHE' or its derivative)");
    cv::CLAHE* _self_ = dynamic_cast<cv::CLAHE*>(((pyopencv_CLAHE_t*)self)->v.get());
    PyObject* pyobj_tileGridSize = NULL;
    Size tileGridSize;

    const char* keywords[] = { "tileGridSize", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:CLAHE.setTilesGridSize", (char**)keywords, &pyobj_tileGridSize) &&
        pyopencv_to(pyobj_tileGridSize, tileGridSize, ArgInfo("tileGridSize", 0)) )
    {
        ERRWRAP2(_self_->setTilesGridSize(tileGridSize));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_CLAHE_methods[] =
{
    {"apply", (PyCFunction)pyopencv_cv_CLAHE_apply, METH_VARARGS | METH_KEYWORDS, "apply(src[, dst]) -> dst"},
    {"collectGarbage", (PyCFunction)pyopencv_cv_CLAHE_collectGarbage, METH_VARARGS | METH_KEYWORDS, "collectGarbage() -> None"},
    {"getClipLimit", (PyCFunction)pyopencv_cv_CLAHE_getClipLimit, METH_VARARGS | METH_KEYWORDS, "getClipLimit() -> retval"},
    {"getTilesGridSize", (PyCFunction)pyopencv_cv_CLAHE_getTilesGridSize, METH_VARARGS | METH_KEYWORDS, "getTilesGridSize() -> retval"},
    {"setClipLimit", (PyCFunction)pyopencv_cv_CLAHE_setClipLimit, METH_VARARGS | METH_KEYWORDS, "setClipLimit(clipLimit) -> None"},
    {"setTilesGridSize", (PyCFunction)pyopencv_cv_CLAHE_setTilesGridSize, METH_VARARGS | METH_KEYWORDS, "setTilesGridSize(tileGridSize) -> None"},

    {NULL,          NULL}
};

static void pyopencv_CLAHE_specials(void)
{
    pyopencv_CLAHE_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_CLAHE_Type.tp_dealloc = pyopencv_CLAHE_dealloc;
    pyopencv_CLAHE_Type.tp_repr = pyopencv_CLAHE_repr;
    pyopencv_CLAHE_Type.tp_getset = pyopencv_CLAHE_getseters;
    pyopencv_CLAHE_Type.tp_methods = pyopencv_CLAHE_methods;
}

static PyObject* pyopencv_Subdiv2D_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<Subdiv2D %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_Subdiv2D_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_Subdiv2D_edgeDst(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_Subdiv2D_Type))
        return failmsgp("Incorrect type of self (must be 'Subdiv2D' or its derivative)");
    cv::Subdiv2D* _self_ = ((pyopencv_Subdiv2D_t*)self)->v.get();
    int edge=0;
    Point2f dstpt;
    int retval;

    const char* keywords[] = { "edge", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:Subdiv2D.edgeDst", (char**)keywords, &edge) )
    {
        ERRWRAP2(retval = _self_->edgeDst(edge, &dstpt));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(dstpt));
    }

    return NULL;
}

static PyObject* pyopencv_cv_Subdiv2D_edgeOrg(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_Subdiv2D_Type))
        return failmsgp("Incorrect type of self (must be 'Subdiv2D' or its derivative)");
    cv::Subdiv2D* _self_ = ((pyopencv_Subdiv2D_t*)self)->v.get();
    int edge=0;
    Point2f orgpt;
    int retval;

    const char* keywords[] = { "edge", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:Subdiv2D.edgeOrg", (char**)keywords, &edge) )
    {
        ERRWRAP2(retval = _self_->edgeOrg(edge, &orgpt));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(orgpt));
    }

    return NULL;
}

static PyObject* pyopencv_cv_Subdiv2D_findNearest(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_Subdiv2D_Type))
        return failmsgp("Incorrect type of self (must be 'Subdiv2D' or its derivative)");
    cv::Subdiv2D* _self_ = ((pyopencv_Subdiv2D_t*)self)->v.get();
    PyObject* pyobj_pt = NULL;
    Point2f pt;
    Point2f nearestPt;
    int retval;

    const char* keywords[] = { "pt", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:Subdiv2D.findNearest", (char**)keywords, &pyobj_pt) &&
        pyopencv_to(pyobj_pt, pt, ArgInfo("pt", 0)) )
    {
        ERRWRAP2(retval = _self_->findNearest(pt, &nearestPt));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(nearestPt));
    }

    return NULL;
}

static PyObject* pyopencv_cv_Subdiv2D_getEdge(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_Subdiv2D_Type))
        return failmsgp("Incorrect type of self (must be 'Subdiv2D' or its derivative)");
    cv::Subdiv2D* _self_ = ((pyopencv_Subdiv2D_t*)self)->v.get();
    int edge=0;
    int nextEdgeType=0;
    int retval;

    const char* keywords[] = { "edge", "nextEdgeType", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "ii:Subdiv2D.getEdge", (char**)keywords, &edge, &nextEdgeType) )
    {
        ERRWRAP2(retval = _self_->getEdge(edge, nextEdgeType));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_Subdiv2D_getEdgeList(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_Subdiv2D_Type))
        return failmsgp("Incorrect type of self (must be 'Subdiv2D' or its derivative)");
    cv::Subdiv2D* _self_ = ((pyopencv_Subdiv2D_t*)self)->v.get();
    vector_Vec4f edgeList;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(_self_->getEdgeList(edgeList));
        return pyopencv_from(edgeList);
    }

    return NULL;
}

static PyObject* pyopencv_cv_Subdiv2D_getLeadingEdgeList(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_Subdiv2D_Type))
        return failmsgp("Incorrect type of self (must be 'Subdiv2D' or its derivative)");
    cv::Subdiv2D* _self_ = ((pyopencv_Subdiv2D_t*)self)->v.get();
    vector_int leadingEdgeList;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(_self_->getLeadingEdgeList(leadingEdgeList));
        return pyopencv_from(leadingEdgeList);
    }

    return NULL;
}

static PyObject* pyopencv_cv_Subdiv2D_getTriangleList(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_Subdiv2D_Type))
        return failmsgp("Incorrect type of self (must be 'Subdiv2D' or its derivative)");
    cv::Subdiv2D* _self_ = ((pyopencv_Subdiv2D_t*)self)->v.get();
    vector_Vec6f triangleList;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(_self_->getTriangleList(triangleList));
        return pyopencv_from(triangleList);
    }

    return NULL;
}

static PyObject* pyopencv_cv_Subdiv2D_getVertex(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_Subdiv2D_Type))
        return failmsgp("Incorrect type of self (must be 'Subdiv2D' or its derivative)");
    cv::Subdiv2D* _self_ = ((pyopencv_Subdiv2D_t*)self)->v.get();
    int vertex=0;
    int firstEdge;
    Point2f retval;

    const char* keywords[] = { "vertex", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:Subdiv2D.getVertex", (char**)keywords, &vertex) )
    {
        ERRWRAP2(retval = _self_->getVertex(vertex, &firstEdge));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(firstEdge));
    }

    return NULL;
}

static PyObject* pyopencv_cv_Subdiv2D_getVoronoiFacetList(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_Subdiv2D_Type))
        return failmsgp("Incorrect type of self (must be 'Subdiv2D' or its derivative)");
    cv::Subdiv2D* _self_ = ((pyopencv_Subdiv2D_t*)self)->v.get();
    PyObject* pyobj_idx = NULL;
    vector_int idx;
    vector_vector_Point2f facetList;
    vector_Point2f facetCenters;

    const char* keywords[] = { "idx", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:Subdiv2D.getVoronoiFacetList", (char**)keywords, &pyobj_idx) &&
        pyopencv_to(pyobj_idx, idx, ArgInfo("idx", 0)) )
    {
        ERRWRAP2(_self_->getVoronoiFacetList(idx, facetList, facetCenters));
        return Py_BuildValue("(NN)", pyopencv_from(facetList), pyopencv_from(facetCenters));
    }

    return NULL;
}

static PyObject* pyopencv_cv_Subdiv2D_initDelaunay(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_Subdiv2D_Type))
        return failmsgp("Incorrect type of self (must be 'Subdiv2D' or its derivative)");
    cv::Subdiv2D* _self_ = ((pyopencv_Subdiv2D_t*)self)->v.get();
    PyObject* pyobj_rect = NULL;
    Rect rect;

    const char* keywords[] = { "rect", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:Subdiv2D.initDelaunay", (char**)keywords, &pyobj_rect) &&
        pyopencv_to(pyobj_rect, rect, ArgInfo("rect", 0)) )
    {
        ERRWRAP2(_self_->initDelaunay(rect));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_Subdiv2D_insert(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_Subdiv2D_Type))
        return failmsgp("Incorrect type of self (must be 'Subdiv2D' or its derivative)");
    cv::Subdiv2D* _self_ = ((pyopencv_Subdiv2D_t*)self)->v.get();
    {
    PyObject* pyobj_pt = NULL;
    Point2f pt;
    int retval;

    const char* keywords[] = { "pt", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:Subdiv2D.insert", (char**)keywords, &pyobj_pt) &&
        pyopencv_to(pyobj_pt, pt, ArgInfo("pt", 0)) )
    {
        ERRWRAP2(retval = _self_->insert(pt));
        return pyopencv_from(retval);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_ptvec = NULL;
    vector_Point2f ptvec;

    const char* keywords[] = { "ptvec", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:Subdiv2D.insert", (char**)keywords, &pyobj_ptvec) &&
        pyopencv_to(pyobj_ptvec, ptvec, ArgInfo("ptvec", 0)) )
    {
        ERRWRAP2(_self_->insert(ptvec));
        Py_RETURN_NONE;
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_Subdiv2D_locate(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_Subdiv2D_Type))
        return failmsgp("Incorrect type of self (must be 'Subdiv2D' or its derivative)");
    cv::Subdiv2D* _self_ = ((pyopencv_Subdiv2D_t*)self)->v.get();
    PyObject* pyobj_pt = NULL;
    Point2f pt;
    int edge;
    int vertex;
    int retval;

    const char* keywords[] = { "pt", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:Subdiv2D.locate", (char**)keywords, &pyobj_pt) &&
        pyopencv_to(pyobj_pt, pt, ArgInfo("pt", 0)) )
    {
        ERRWRAP2(retval = _self_->locate(pt, edge, vertex));
        return Py_BuildValue("(NNN)", pyopencv_from(retval), pyopencv_from(edge), pyopencv_from(vertex));
    }

    return NULL;
}

static PyObject* pyopencv_cv_Subdiv2D_nextEdge(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_Subdiv2D_Type))
        return failmsgp("Incorrect type of self (must be 'Subdiv2D' or its derivative)");
    cv::Subdiv2D* _self_ = ((pyopencv_Subdiv2D_t*)self)->v.get();
    int edge=0;
    int retval;

    const char* keywords[] = { "edge", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:Subdiv2D.nextEdge", (char**)keywords, &edge) )
    {
        ERRWRAP2(retval = _self_->nextEdge(edge));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_Subdiv2D_rotateEdge(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_Subdiv2D_Type))
        return failmsgp("Incorrect type of self (must be 'Subdiv2D' or its derivative)");
    cv::Subdiv2D* _self_ = ((pyopencv_Subdiv2D_t*)self)->v.get();
    int edge=0;
    int rotate=0;
    int retval;

    const char* keywords[] = { "edge", "rotate", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "ii:Subdiv2D.rotateEdge", (char**)keywords, &edge, &rotate) )
    {
        ERRWRAP2(retval = _self_->rotateEdge(edge, rotate));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_Subdiv2D_symEdge(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_Subdiv2D_Type))
        return failmsgp("Incorrect type of self (must be 'Subdiv2D' or its derivative)");
    cv::Subdiv2D* _self_ = ((pyopencv_Subdiv2D_t*)self)->v.get();
    int edge=0;
    int retval;

    const char* keywords[] = { "edge", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:Subdiv2D.symEdge", (char**)keywords, &edge) )
    {
        ERRWRAP2(retval = _self_->symEdge(edge));
        return pyopencv_from(retval);
    }

    return NULL;
}



static PyMethodDef pyopencv_Subdiv2D_methods[] =
{
    {"edgeDst", (PyCFunction)pyopencv_cv_Subdiv2D_edgeDst, METH_VARARGS | METH_KEYWORDS, "edgeDst(edge) -> retval, dstpt"},
    {"edgeOrg", (PyCFunction)pyopencv_cv_Subdiv2D_edgeOrg, METH_VARARGS | METH_KEYWORDS, "edgeOrg(edge) -> retval, orgpt"},
    {"findNearest", (PyCFunction)pyopencv_cv_Subdiv2D_findNearest, METH_VARARGS | METH_KEYWORDS, "findNearest(pt) -> retval, nearestPt"},
    {"getEdge", (PyCFunction)pyopencv_cv_Subdiv2D_getEdge, METH_VARARGS | METH_KEYWORDS, "getEdge(edge, nextEdgeType) -> retval"},
    {"getEdgeList", (PyCFunction)pyopencv_cv_Subdiv2D_getEdgeList, METH_VARARGS | METH_KEYWORDS, "getEdgeList() -> edgeList"},
    {"getLeadingEdgeList", (PyCFunction)pyopencv_cv_Subdiv2D_getLeadingEdgeList, METH_VARARGS | METH_KEYWORDS, "getLeadingEdgeList() -> leadingEdgeList"},
    {"getTriangleList", (PyCFunction)pyopencv_cv_Subdiv2D_getTriangleList, METH_VARARGS | METH_KEYWORDS, "getTriangleList() -> triangleList"},
    {"getVertex", (PyCFunction)pyopencv_cv_Subdiv2D_getVertex, METH_VARARGS | METH_KEYWORDS, "getVertex(vertex) -> retval, firstEdge"},
    {"getVoronoiFacetList", (PyCFunction)pyopencv_cv_Subdiv2D_getVoronoiFacetList, METH_VARARGS | METH_KEYWORDS, "getVoronoiFacetList(idx) -> facetList, facetCenters"},
    {"initDelaunay", (PyCFunction)pyopencv_cv_Subdiv2D_initDelaunay, METH_VARARGS | METH_KEYWORDS, "initDelaunay(rect) -> None"},
    {"insert", (PyCFunction)pyopencv_cv_Subdiv2D_insert, METH_VARARGS | METH_KEYWORDS, "insert(pt) -> retval  or  insert(ptvec) -> None"},
    {"locate", (PyCFunction)pyopencv_cv_Subdiv2D_locate, METH_VARARGS | METH_KEYWORDS, "locate(pt) -> retval, edge, vertex"},
    {"nextEdge", (PyCFunction)pyopencv_cv_Subdiv2D_nextEdge, METH_VARARGS | METH_KEYWORDS, "nextEdge(edge) -> retval"},
    {"rotateEdge", (PyCFunction)pyopencv_cv_Subdiv2D_rotateEdge, METH_VARARGS | METH_KEYWORDS, "rotateEdge(edge, rotate) -> retval"},
    {"symEdge", (PyCFunction)pyopencv_cv_Subdiv2D_symEdge, METH_VARARGS | METH_KEYWORDS, "symEdge(edge) -> retval"},

    {NULL,          NULL}
};

static void pyopencv_Subdiv2D_specials(void)
{
    pyopencv_Subdiv2D_Type.tp_base = NULL;
    pyopencv_Subdiv2D_Type.tp_dealloc = pyopencv_Subdiv2D_dealloc;
    pyopencv_Subdiv2D_Type.tp_repr = pyopencv_Subdiv2D_repr;
    pyopencv_Subdiv2D_Type.tp_getset = pyopencv_Subdiv2D_getseters;
    pyopencv_Subdiv2D_Type.tp_methods = pyopencv_Subdiv2D_methods;
}

static PyObject* pyopencv_LineSegmentDetector_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<LineSegmentDetector %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_LineSegmentDetector_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_LineSegmentDetector_compareSegments(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_LineSegmentDetector_Type))
        return failmsgp("Incorrect type of self (must be 'LineSegmentDetector' or its derivative)");
    cv::LineSegmentDetector* _self_ = dynamic_cast<cv::LineSegmentDetector*>(((pyopencv_LineSegmentDetector_t*)self)->v.get());
    {
    PyObject* pyobj_size = NULL;
    Size size;
    PyObject* pyobj_lines1 = NULL;
    Mat lines1;
    PyObject* pyobj_lines2 = NULL;
    Mat lines2;
    PyObject* pyobj__image = NULL;
    Mat _image;
    int retval;

    const char* keywords[] = { "size", "lines1", "lines2", "_image", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OOO|O:LineSegmentDetector.compareSegments", (char**)keywords, &pyobj_size, &pyobj_lines1, &pyobj_lines2, &pyobj__image) &&
        pyopencv_to(pyobj_size, size, ArgInfo("size", 0)) &&
        pyopencv_to(pyobj_lines1, lines1, ArgInfo("lines1", 0)) &&
        pyopencv_to(pyobj_lines2, lines2, ArgInfo("lines2", 0)) &&
        pyopencv_to(pyobj__image, _image, ArgInfo("_image", 1)) )
    {
        ERRWRAP2(retval = _self_->compareSegments(size, lines1, lines2, _image));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(_image));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_size = NULL;
    Size size;
    PyObject* pyobj_lines1 = NULL;
    UMat lines1;
    PyObject* pyobj_lines2 = NULL;
    UMat lines2;
    PyObject* pyobj__image = NULL;
    UMat _image;
    int retval;

    const char* keywords[] = { "size", "lines1", "lines2", "_image", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OOO|O:LineSegmentDetector.compareSegments", (char**)keywords, &pyobj_size, &pyobj_lines1, &pyobj_lines2, &pyobj__image) &&
        pyopencv_to(pyobj_size, size, ArgInfo("size", 0)) &&
        pyopencv_to(pyobj_lines1, lines1, ArgInfo("lines1", 0)) &&
        pyopencv_to(pyobj_lines2, lines2, ArgInfo("lines2", 0)) &&
        pyopencv_to(pyobj__image, _image, ArgInfo("_image", 1)) )
    {
        ERRWRAP2(retval = _self_->compareSegments(size, lines1, lines2, _image));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(_image));
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_LineSegmentDetector_detect(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_LineSegmentDetector_Type))
        return failmsgp("Incorrect type of self (must be 'LineSegmentDetector' or its derivative)");
    cv::LineSegmentDetector* _self_ = dynamic_cast<cv::LineSegmentDetector*>(((pyopencv_LineSegmentDetector_t*)self)->v.get());
    {
    PyObject* pyobj__image = NULL;
    Mat _image;
    PyObject* pyobj__lines = NULL;
    Mat _lines;
    PyObject* pyobj_width = NULL;
    Mat width;
    PyObject* pyobj_prec = NULL;
    Mat prec;
    PyObject* pyobj_nfa = NULL;
    Mat nfa;

    const char* keywords[] = { "_image", "_lines", "width", "prec", "nfa", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|OOOO:LineSegmentDetector.detect", (char**)keywords, &pyobj__image, &pyobj__lines, &pyobj_width, &pyobj_prec, &pyobj_nfa) &&
        pyopencv_to(pyobj__image, _image, ArgInfo("_image", 0)) &&
        pyopencv_to(pyobj__lines, _lines, ArgInfo("_lines", 1)) &&
        pyopencv_to(pyobj_width, width, ArgInfo("width", 1)) &&
        pyopencv_to(pyobj_prec, prec, ArgInfo("prec", 1)) &&
        pyopencv_to(pyobj_nfa, nfa, ArgInfo("nfa", 1)) )
    {
        ERRWRAP2(_self_->detect(_image, _lines, width, prec, nfa));
        return Py_BuildValue("(NNNN)", pyopencv_from(_lines), pyopencv_from(width), pyopencv_from(prec), pyopencv_from(nfa));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj__image = NULL;
    UMat _image;
    PyObject* pyobj__lines = NULL;
    UMat _lines;
    PyObject* pyobj_width = NULL;
    UMat width;
    PyObject* pyobj_prec = NULL;
    UMat prec;
    PyObject* pyobj_nfa = NULL;
    UMat nfa;

    const char* keywords[] = { "_image", "_lines", "width", "prec", "nfa", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|OOOO:LineSegmentDetector.detect", (char**)keywords, &pyobj__image, &pyobj__lines, &pyobj_width, &pyobj_prec, &pyobj_nfa) &&
        pyopencv_to(pyobj__image, _image, ArgInfo("_image", 0)) &&
        pyopencv_to(pyobj__lines, _lines, ArgInfo("_lines", 1)) &&
        pyopencv_to(pyobj_width, width, ArgInfo("width", 1)) &&
        pyopencv_to(pyobj_prec, prec, ArgInfo("prec", 1)) &&
        pyopencv_to(pyobj_nfa, nfa, ArgInfo("nfa", 1)) )
    {
        ERRWRAP2(_self_->detect(_image, _lines, width, prec, nfa));
        return Py_BuildValue("(NNNN)", pyopencv_from(_lines), pyopencv_from(width), pyopencv_from(prec), pyopencv_from(nfa));
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_LineSegmentDetector_drawSegments(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_LineSegmentDetector_Type))
        return failmsgp("Incorrect type of self (must be 'LineSegmentDetector' or its derivative)");
    cv::LineSegmentDetector* _self_ = dynamic_cast<cv::LineSegmentDetector*>(((pyopencv_LineSegmentDetector_t*)self)->v.get());
    {
    PyObject* pyobj__image = NULL;
    Mat _image;
    PyObject* pyobj_lines = NULL;
    Mat lines;

    const char* keywords[] = { "_image", "lines", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO:LineSegmentDetector.drawSegments", (char**)keywords, &pyobj__image, &pyobj_lines) &&
        pyopencv_to(pyobj__image, _image, ArgInfo("_image", 1)) &&
        pyopencv_to(pyobj_lines, lines, ArgInfo("lines", 0)) )
    {
        ERRWRAP2(_self_->drawSegments(_image, lines));
        return pyopencv_from(_image);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj__image = NULL;
    UMat _image;
    PyObject* pyobj_lines = NULL;
    UMat lines;

    const char* keywords[] = { "_image", "lines", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO:LineSegmentDetector.drawSegments", (char**)keywords, &pyobj__image, &pyobj_lines) &&
        pyopencv_to(pyobj__image, _image, ArgInfo("_image", 1)) &&
        pyopencv_to(pyobj_lines, lines, ArgInfo("lines", 0)) )
    {
        ERRWRAP2(_self_->drawSegments(_image, lines));
        return pyopencv_from(_image);
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_LineSegmentDetector_methods[] =
{
    {"compareSegments", (PyCFunction)pyopencv_cv_LineSegmentDetector_compareSegments, METH_VARARGS | METH_KEYWORDS, "compareSegments(size, lines1, lines2[, _image]) -> retval, _image"},
    {"detect", (PyCFunction)pyopencv_cv_LineSegmentDetector_detect, METH_VARARGS | METH_KEYWORDS, "detect(_image[, _lines[, width[, prec[, nfa]]]]) -> _lines, width, prec, nfa"},
    {"drawSegments", (PyCFunction)pyopencv_cv_LineSegmentDetector_drawSegments, METH_VARARGS | METH_KEYWORDS, "drawSegments(_image, lines) -> _image"},

    {NULL,          NULL}
};

static void pyopencv_LineSegmentDetector_specials(void)
{
    pyopencv_LineSegmentDetector_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_LineSegmentDetector_Type.tp_dealloc = pyopencv_LineSegmentDetector_dealloc;
    pyopencv_LineSegmentDetector_Type.tp_repr = pyopencv_LineSegmentDetector_repr;
    pyopencv_LineSegmentDetector_Type.tp_getset = pyopencv_LineSegmentDetector_getseters;
    pyopencv_LineSegmentDetector_Type.tp_methods = pyopencv_LineSegmentDetector_methods;
}

static PyObject* pyopencv_ml_TrainData_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<ml_TrainData %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_ml_TrainData_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_ml_ml_TrainData_getCatCount(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_TrainData_Type))
        return failmsgp("Incorrect type of self (must be 'ml_TrainData' or its derivative)");
    cv::ml::TrainData* _self_ = ((pyopencv_ml_TrainData_t*)self)->v.get();
    int vi=0;
    int retval;

    const char* keywords[] = { "vi", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:ml_TrainData.getCatCount", (char**)keywords, &vi) )
    {
        ERRWRAP2(retval = _self_->getCatCount(vi));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_TrainData_getCatMap(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_TrainData_Type))
        return failmsgp("Incorrect type of self (must be 'ml_TrainData' or its derivative)");
    cv::ml::TrainData* _self_ = ((pyopencv_ml_TrainData_t*)self)->v.get();
    Mat retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getCatMap());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_TrainData_getCatOfs(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_TrainData_Type))
        return failmsgp("Incorrect type of self (must be 'ml_TrainData' or its derivative)");
    cv::ml::TrainData* _self_ = ((pyopencv_ml_TrainData_t*)self)->v.get();
    Mat retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getCatOfs());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_TrainData_getClassLabels(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_TrainData_Type))
        return failmsgp("Incorrect type of self (must be 'ml_TrainData' or its derivative)");
    cv::ml::TrainData* _self_ = ((pyopencv_ml_TrainData_t*)self)->v.get();
    Mat retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getClassLabels());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_TrainData_getDefaultSubstValues(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_TrainData_Type))
        return failmsgp("Incorrect type of self (must be 'ml_TrainData' or its derivative)");
    cv::ml::TrainData* _self_ = ((pyopencv_ml_TrainData_t*)self)->v.get();
    Mat retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getDefaultSubstValues());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_TrainData_getLayout(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_TrainData_Type))
        return failmsgp("Incorrect type of self (must be 'ml_TrainData' or its derivative)");
    cv::ml::TrainData* _self_ = ((pyopencv_ml_TrainData_t*)self)->v.get();
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getLayout());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_TrainData_getMissing(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_TrainData_Type))
        return failmsgp("Incorrect type of self (must be 'ml_TrainData' or its derivative)");
    cv::ml::TrainData* _self_ = ((pyopencv_ml_TrainData_t*)self)->v.get();
    Mat retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getMissing());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_TrainData_getNAllVars(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_TrainData_Type))
        return failmsgp("Incorrect type of self (must be 'ml_TrainData' or its derivative)");
    cv::ml::TrainData* _self_ = ((pyopencv_ml_TrainData_t*)self)->v.get();
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getNAllVars());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_TrainData_getNSamples(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_TrainData_Type))
        return failmsgp("Incorrect type of self (must be 'ml_TrainData' or its derivative)");
    cv::ml::TrainData* _self_ = ((pyopencv_ml_TrainData_t*)self)->v.get();
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getNSamples());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_TrainData_getNTestSamples(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_TrainData_Type))
        return failmsgp("Incorrect type of self (must be 'ml_TrainData' or its derivative)");
    cv::ml::TrainData* _self_ = ((pyopencv_ml_TrainData_t*)self)->v.get();
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getNTestSamples());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_TrainData_getNTrainSamples(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_TrainData_Type))
        return failmsgp("Incorrect type of self (must be 'ml_TrainData' or its derivative)");
    cv::ml::TrainData* _self_ = ((pyopencv_ml_TrainData_t*)self)->v.get();
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getNTrainSamples());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_TrainData_getNVars(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_TrainData_Type))
        return failmsgp("Incorrect type of self (must be 'ml_TrainData' or its derivative)");
    cv::ml::TrainData* _self_ = ((pyopencv_ml_TrainData_t*)self)->v.get();
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getNVars());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_TrainData_getNames(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_TrainData_Type))
        return failmsgp("Incorrect type of self (must be 'ml_TrainData' or its derivative)");
    cv::ml::TrainData* _self_ = ((pyopencv_ml_TrainData_t*)self)->v.get();
    PyObject* pyobj_names = NULL;
    vector_String names;

    const char* keywords[] = { "names", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:ml_TrainData.getNames", (char**)keywords, &pyobj_names) &&
        pyopencv_to(pyobj_names, names, ArgInfo("names", 0)) )
    {
        ERRWRAP2(_self_->getNames(names));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_TrainData_getNormCatResponses(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_TrainData_Type))
        return failmsgp("Incorrect type of self (must be 'ml_TrainData' or its derivative)");
    cv::ml::TrainData* _self_ = ((pyopencv_ml_TrainData_t*)self)->v.get();
    Mat retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getNormCatResponses());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_TrainData_getResponseType(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_TrainData_Type))
        return failmsgp("Incorrect type of self (must be 'ml_TrainData' or its derivative)");
    cv::ml::TrainData* _self_ = ((pyopencv_ml_TrainData_t*)self)->v.get();
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getResponseType());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_TrainData_getResponses(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_TrainData_Type))
        return failmsgp("Incorrect type of self (must be 'ml_TrainData' or its derivative)");
    cv::ml::TrainData* _self_ = ((pyopencv_ml_TrainData_t*)self)->v.get();
    Mat retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getResponses());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_TrainData_getSample(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_TrainData_Type))
        return failmsgp("Incorrect type of self (must be 'ml_TrainData' or its derivative)");
    cv::ml::TrainData* _self_ = ((pyopencv_ml_TrainData_t*)self)->v.get();
    {
    PyObject* pyobj_varIdx = NULL;
    Mat varIdx;
    int sidx=0;
    float buf=0.f;

    const char* keywords[] = { "varIdx", "sidx", "buf", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "Oif:ml_TrainData.getSample", (char**)keywords, &pyobj_varIdx, &sidx, &buf) &&
        pyopencv_to(pyobj_varIdx, varIdx, ArgInfo("varIdx", 0)) )
    {
        ERRWRAP2(_self_->getSample(varIdx, sidx, &buf));
        Py_RETURN_NONE;
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_varIdx = NULL;
    UMat varIdx;
    int sidx=0;
    float buf=0.f;

    const char* keywords[] = { "varIdx", "sidx", "buf", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "Oif:ml_TrainData.getSample", (char**)keywords, &pyobj_varIdx, &sidx, &buf) &&
        pyopencv_to(pyobj_varIdx, varIdx, ArgInfo("varIdx", 0)) )
    {
        ERRWRAP2(_self_->getSample(varIdx, sidx, &buf));
        Py_RETURN_NONE;
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_TrainData_getSampleWeights(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_TrainData_Type))
        return failmsgp("Incorrect type of self (must be 'ml_TrainData' or its derivative)");
    cv::ml::TrainData* _self_ = ((pyopencv_ml_TrainData_t*)self)->v.get();
    Mat retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getSampleWeights());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_TrainData_getSamples(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_TrainData_Type))
        return failmsgp("Incorrect type of self (must be 'ml_TrainData' or its derivative)");
    cv::ml::TrainData* _self_ = ((pyopencv_ml_TrainData_t*)self)->v.get();
    Mat retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getSamples());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_TrainData_getTestNormCatResponses(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_TrainData_Type))
        return failmsgp("Incorrect type of self (must be 'ml_TrainData' or its derivative)");
    cv::ml::TrainData* _self_ = ((pyopencv_ml_TrainData_t*)self)->v.get();
    Mat retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getTestNormCatResponses());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_TrainData_getTestResponses(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_TrainData_Type))
        return failmsgp("Incorrect type of self (must be 'ml_TrainData' or its derivative)");
    cv::ml::TrainData* _self_ = ((pyopencv_ml_TrainData_t*)self)->v.get();
    Mat retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getTestResponses());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_TrainData_getTestSampleIdx(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_TrainData_Type))
        return failmsgp("Incorrect type of self (must be 'ml_TrainData' or its derivative)");
    cv::ml::TrainData* _self_ = ((pyopencv_ml_TrainData_t*)self)->v.get();
    Mat retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getTestSampleIdx());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_TrainData_getTestSampleWeights(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_TrainData_Type))
        return failmsgp("Incorrect type of self (must be 'ml_TrainData' or its derivative)");
    cv::ml::TrainData* _self_ = ((pyopencv_ml_TrainData_t*)self)->v.get();
    Mat retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getTestSampleWeights());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_TrainData_getTestSamples(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_TrainData_Type))
        return failmsgp("Incorrect type of self (must be 'ml_TrainData' or its derivative)");
    cv::ml::TrainData* _self_ = ((pyopencv_ml_TrainData_t*)self)->v.get();
    Mat retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getTestSamples());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_TrainData_getTrainNormCatResponses(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_TrainData_Type))
        return failmsgp("Incorrect type of self (must be 'ml_TrainData' or its derivative)");
    cv::ml::TrainData* _self_ = ((pyopencv_ml_TrainData_t*)self)->v.get();
    Mat retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getTrainNormCatResponses());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_TrainData_getTrainResponses(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_TrainData_Type))
        return failmsgp("Incorrect type of self (must be 'ml_TrainData' or its derivative)");
    cv::ml::TrainData* _self_ = ((pyopencv_ml_TrainData_t*)self)->v.get();
    Mat retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getTrainResponses());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_TrainData_getTrainSampleIdx(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_TrainData_Type))
        return failmsgp("Incorrect type of self (must be 'ml_TrainData' or its derivative)");
    cv::ml::TrainData* _self_ = ((pyopencv_ml_TrainData_t*)self)->v.get();
    Mat retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getTrainSampleIdx());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_TrainData_getTrainSampleWeights(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_TrainData_Type))
        return failmsgp("Incorrect type of self (must be 'ml_TrainData' or its derivative)");
    cv::ml::TrainData* _self_ = ((pyopencv_ml_TrainData_t*)self)->v.get();
    Mat retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getTrainSampleWeights());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_TrainData_getTrainSamples(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_TrainData_Type))
        return failmsgp("Incorrect type of self (must be 'ml_TrainData' or its derivative)");
    cv::ml::TrainData* _self_ = ((pyopencv_ml_TrainData_t*)self)->v.get();
    int layout=ROW_SAMPLE;
    bool compressSamples=true;
    bool compressVars=true;
    Mat retval;

    const char* keywords[] = { "layout", "compressSamples", "compressVars", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|ibb:ml_TrainData.getTrainSamples", (char**)keywords, &layout, &compressSamples, &compressVars) )
    {
        ERRWRAP2(retval = _self_->getTrainSamples(layout, compressSamples, compressVars));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_TrainData_getValues(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_TrainData_Type))
        return failmsgp("Incorrect type of self (must be 'ml_TrainData' or its derivative)");
    cv::ml::TrainData* _self_ = ((pyopencv_ml_TrainData_t*)self)->v.get();
    {
    int vi=0;
    PyObject* pyobj_sidx = NULL;
    Mat sidx;
    float values=0.f;

    const char* keywords[] = { "vi", "sidx", "values", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "iOf:ml_TrainData.getValues", (char**)keywords, &vi, &pyobj_sidx, &values) &&
        pyopencv_to(pyobj_sidx, sidx, ArgInfo("sidx", 0)) )
    {
        ERRWRAP2(_self_->getValues(vi, sidx, &values));
        Py_RETURN_NONE;
    }
    }
    PyErr_Clear();

    {
    int vi=0;
    PyObject* pyobj_sidx = NULL;
    UMat sidx;
    float values=0.f;

    const char* keywords[] = { "vi", "sidx", "values", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "iOf:ml_TrainData.getValues", (char**)keywords, &vi, &pyobj_sidx, &values) &&
        pyopencv_to(pyobj_sidx, sidx, ArgInfo("sidx", 0)) )
    {
        ERRWRAP2(_self_->getValues(vi, sidx, &values));
        Py_RETURN_NONE;
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_TrainData_getVarIdx(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_TrainData_Type))
        return failmsgp("Incorrect type of self (must be 'ml_TrainData' or its derivative)");
    cv::ml::TrainData* _self_ = ((pyopencv_ml_TrainData_t*)self)->v.get();
    Mat retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getVarIdx());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_TrainData_getVarSymbolFlags(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_TrainData_Type))
        return failmsgp("Incorrect type of self (must be 'ml_TrainData' or its derivative)");
    cv::ml::TrainData* _self_ = ((pyopencv_ml_TrainData_t*)self)->v.get();
    Mat retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getVarSymbolFlags());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_TrainData_getVarType(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_TrainData_Type))
        return failmsgp("Incorrect type of self (must be 'ml_TrainData' or its derivative)");
    cv::ml::TrainData* _self_ = ((pyopencv_ml_TrainData_t*)self)->v.get();
    Mat retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getVarType());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_TrainData_setTrainTestSplit(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_TrainData_Type))
        return failmsgp("Incorrect type of self (must be 'ml_TrainData' or its derivative)");
    cv::ml::TrainData* _self_ = ((pyopencv_ml_TrainData_t*)self)->v.get();
    int count=0;
    bool shuffle=true;

    const char* keywords[] = { "count", "shuffle", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i|b:ml_TrainData.setTrainTestSplit", (char**)keywords, &count, &shuffle) )
    {
        ERRWRAP2(_self_->setTrainTestSplit(count, shuffle));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_TrainData_setTrainTestSplitRatio(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_TrainData_Type))
        return failmsgp("Incorrect type of self (must be 'ml_TrainData' or its derivative)");
    cv::ml::TrainData* _self_ = ((pyopencv_ml_TrainData_t*)self)->v.get();
    double ratio=0;
    bool shuffle=true;

    const char* keywords[] = { "ratio", "shuffle", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d|b:ml_TrainData.setTrainTestSplitRatio", (char**)keywords, &ratio, &shuffle) )
    {
        ERRWRAP2(_self_->setTrainTestSplitRatio(ratio, shuffle));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_TrainData_shuffleTrainTest(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_TrainData_Type))
        return failmsgp("Incorrect type of self (must be 'ml_TrainData' or its derivative)");
    cv::ml::TrainData* _self_ = ((pyopencv_ml_TrainData_t*)self)->v.get();

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(_self_->shuffleTrainTest());
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_ml_TrainData_methods[] =
{
    {"getCatCount", (PyCFunction)pyopencv_cv_ml_ml_TrainData_getCatCount, METH_VARARGS | METH_KEYWORDS, "getCatCount(vi) -> retval"},
    {"getCatMap", (PyCFunction)pyopencv_cv_ml_ml_TrainData_getCatMap, METH_VARARGS | METH_KEYWORDS, "getCatMap() -> retval"},
    {"getCatOfs", (PyCFunction)pyopencv_cv_ml_ml_TrainData_getCatOfs, METH_VARARGS | METH_KEYWORDS, "getCatOfs() -> retval"},
    {"getClassLabels", (PyCFunction)pyopencv_cv_ml_ml_TrainData_getClassLabels, METH_VARARGS | METH_KEYWORDS, "getClassLabels() -> retval"},
    {"getDefaultSubstValues", (PyCFunction)pyopencv_cv_ml_ml_TrainData_getDefaultSubstValues, METH_VARARGS | METH_KEYWORDS, "getDefaultSubstValues() -> retval"},
    {"getLayout", (PyCFunction)pyopencv_cv_ml_ml_TrainData_getLayout, METH_VARARGS | METH_KEYWORDS, "getLayout() -> retval"},
    {"getMissing", (PyCFunction)pyopencv_cv_ml_ml_TrainData_getMissing, METH_VARARGS | METH_KEYWORDS, "getMissing() -> retval"},
    {"getNAllVars", (PyCFunction)pyopencv_cv_ml_ml_TrainData_getNAllVars, METH_VARARGS | METH_KEYWORDS, "getNAllVars() -> retval"},
    {"getNSamples", (PyCFunction)pyopencv_cv_ml_ml_TrainData_getNSamples, METH_VARARGS | METH_KEYWORDS, "getNSamples() -> retval"},
    {"getNTestSamples", (PyCFunction)pyopencv_cv_ml_ml_TrainData_getNTestSamples, METH_VARARGS | METH_KEYWORDS, "getNTestSamples() -> retval"},
    {"getNTrainSamples", (PyCFunction)pyopencv_cv_ml_ml_TrainData_getNTrainSamples, METH_VARARGS | METH_KEYWORDS, "getNTrainSamples() -> retval"},
    {"getNVars", (PyCFunction)pyopencv_cv_ml_ml_TrainData_getNVars, METH_VARARGS | METH_KEYWORDS, "getNVars() -> retval"},
    {"getNames", (PyCFunction)pyopencv_cv_ml_ml_TrainData_getNames, METH_VARARGS | METH_KEYWORDS, "getNames(names) -> None"},
    {"getNormCatResponses", (PyCFunction)pyopencv_cv_ml_ml_TrainData_getNormCatResponses, METH_VARARGS | METH_KEYWORDS, "getNormCatResponses() -> retval"},
    {"getResponseType", (PyCFunction)pyopencv_cv_ml_ml_TrainData_getResponseType, METH_VARARGS | METH_KEYWORDS, "getResponseType() -> retval"},
    {"getResponses", (PyCFunction)pyopencv_cv_ml_ml_TrainData_getResponses, METH_VARARGS | METH_KEYWORDS, "getResponses() -> retval"},
    {"getSample", (PyCFunction)pyopencv_cv_ml_ml_TrainData_getSample, METH_VARARGS | METH_KEYWORDS, "getSample(varIdx, sidx, buf) -> None"},
    {"getSampleWeights", (PyCFunction)pyopencv_cv_ml_ml_TrainData_getSampleWeights, METH_VARARGS | METH_KEYWORDS, "getSampleWeights() -> retval"},
    {"getSamples", (PyCFunction)pyopencv_cv_ml_ml_TrainData_getSamples, METH_VARARGS | METH_KEYWORDS, "getSamples() -> retval"},
    {"getTestNormCatResponses", (PyCFunction)pyopencv_cv_ml_ml_TrainData_getTestNormCatResponses, METH_VARARGS | METH_KEYWORDS, "getTestNormCatResponses() -> retval"},
    {"getTestResponses", (PyCFunction)pyopencv_cv_ml_ml_TrainData_getTestResponses, METH_VARARGS | METH_KEYWORDS, "getTestResponses() -> retval"},
    {"getTestSampleIdx", (PyCFunction)pyopencv_cv_ml_ml_TrainData_getTestSampleIdx, METH_VARARGS | METH_KEYWORDS, "getTestSampleIdx() -> retval"},
    {"getTestSampleWeights", (PyCFunction)pyopencv_cv_ml_ml_TrainData_getTestSampleWeights, METH_VARARGS | METH_KEYWORDS, "getTestSampleWeights() -> retval"},
    {"getTestSamples", (PyCFunction)pyopencv_cv_ml_ml_TrainData_getTestSamples, METH_VARARGS | METH_KEYWORDS, "getTestSamples() -> retval"},
    {"getTrainNormCatResponses", (PyCFunction)pyopencv_cv_ml_ml_TrainData_getTrainNormCatResponses, METH_VARARGS | METH_KEYWORDS, "getTrainNormCatResponses() -> retval"},
    {"getTrainResponses", (PyCFunction)pyopencv_cv_ml_ml_TrainData_getTrainResponses, METH_VARARGS | METH_KEYWORDS, "getTrainResponses() -> retval"},
    {"getTrainSampleIdx", (PyCFunction)pyopencv_cv_ml_ml_TrainData_getTrainSampleIdx, METH_VARARGS | METH_KEYWORDS, "getTrainSampleIdx() -> retval"},
    {"getTrainSampleWeights", (PyCFunction)pyopencv_cv_ml_ml_TrainData_getTrainSampleWeights, METH_VARARGS | METH_KEYWORDS, "getTrainSampleWeights() -> retval"},
    {"getTrainSamples", (PyCFunction)pyopencv_cv_ml_ml_TrainData_getTrainSamples, METH_VARARGS | METH_KEYWORDS, "getTrainSamples([, layout[, compressSamples[, compressVars]]]) -> retval"},
    {"getValues", (PyCFunction)pyopencv_cv_ml_ml_TrainData_getValues, METH_VARARGS | METH_KEYWORDS, "getValues(vi, sidx, values) -> None"},
    {"getVarIdx", (PyCFunction)pyopencv_cv_ml_ml_TrainData_getVarIdx, METH_VARARGS | METH_KEYWORDS, "getVarIdx() -> retval"},
    {"getVarSymbolFlags", (PyCFunction)pyopencv_cv_ml_ml_TrainData_getVarSymbolFlags, METH_VARARGS | METH_KEYWORDS, "getVarSymbolFlags() -> retval"},
    {"getVarType", (PyCFunction)pyopencv_cv_ml_ml_TrainData_getVarType, METH_VARARGS | METH_KEYWORDS, "getVarType() -> retval"},
    {"setTrainTestSplit", (PyCFunction)pyopencv_cv_ml_ml_TrainData_setTrainTestSplit, METH_VARARGS | METH_KEYWORDS, "setTrainTestSplit(count[, shuffle]) -> None"},
    {"setTrainTestSplitRatio", (PyCFunction)pyopencv_cv_ml_ml_TrainData_setTrainTestSplitRatio, METH_VARARGS | METH_KEYWORDS, "setTrainTestSplitRatio(ratio[, shuffle]) -> None"},
    {"shuffleTrainTest", (PyCFunction)pyopencv_cv_ml_ml_TrainData_shuffleTrainTest, METH_VARARGS | METH_KEYWORDS, "shuffleTrainTest() -> None"},

    {NULL,          NULL}
};

static void pyopencv_ml_TrainData_specials(void)
{
    pyopencv_ml_TrainData_Type.tp_base = NULL;
    pyopencv_ml_TrainData_Type.tp_dealloc = pyopencv_ml_TrainData_dealloc;
    pyopencv_ml_TrainData_Type.tp_repr = pyopencv_ml_TrainData_repr;
    pyopencv_ml_TrainData_Type.tp_getset = pyopencv_ml_TrainData_getseters;
    pyopencv_ml_TrainData_Type.tp_methods = pyopencv_ml_TrainData_methods;
}

static PyObject* pyopencv_ml_StatModel_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<ml_StatModel %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_ml_StatModel_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_ml_ml_StatModel_calcError(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_StatModel_Type))
        return failmsgp("Incorrect type of self (must be 'ml_StatModel' or its derivative)");
    cv::ml::StatModel* _self_ = dynamic_cast<cv::ml::StatModel*>(((pyopencv_ml_StatModel_t*)self)->v.get());
    {
    PyObject* pyobj_data = NULL;
    Ptr<TrainData> data;
    bool test=0;
    PyObject* pyobj_resp = NULL;
    Mat resp;
    float retval;

    const char* keywords[] = { "data", "test", "resp", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "Ob|O:ml_StatModel.calcError", (char**)keywords, &pyobj_data, &test, &pyobj_resp) &&
        pyopencv_to(pyobj_data, data, ArgInfo("data", 0)) &&
        pyopencv_to(pyobj_resp, resp, ArgInfo("resp", 1)) )
    {
        ERRWRAP2(retval = _self_->calcError(data, test, resp));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(resp));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_data = NULL;
    Ptr<TrainData> data;
    bool test=0;
    PyObject* pyobj_resp = NULL;
    UMat resp;
    float retval;

    const char* keywords[] = { "data", "test", "resp", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "Ob|O:ml_StatModel.calcError", (char**)keywords, &pyobj_data, &test, &pyobj_resp) &&
        pyopencv_to(pyobj_data, data, ArgInfo("data", 0)) &&
        pyopencv_to(pyobj_resp, resp, ArgInfo("resp", 1)) )
    {
        ERRWRAP2(retval = _self_->calcError(data, test, resp));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(resp));
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_StatModel_empty(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_StatModel_Type))
        return failmsgp("Incorrect type of self (must be 'ml_StatModel' or its derivative)");
    cv::ml::StatModel* _self_ = dynamic_cast<cv::ml::StatModel*>(((pyopencv_ml_StatModel_t*)self)->v.get());
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->empty());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_StatModel_getVarCount(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_StatModel_Type))
        return failmsgp("Incorrect type of self (must be 'ml_StatModel' or its derivative)");
    cv::ml::StatModel* _self_ = dynamic_cast<cv::ml::StatModel*>(((pyopencv_ml_StatModel_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getVarCount());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_StatModel_isClassifier(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_StatModel_Type))
        return failmsgp("Incorrect type of self (must be 'ml_StatModel' or its derivative)");
    cv::ml::StatModel* _self_ = dynamic_cast<cv::ml::StatModel*>(((pyopencv_ml_StatModel_t*)self)->v.get());
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->isClassifier());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_StatModel_isTrained(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_StatModel_Type))
        return failmsgp("Incorrect type of self (must be 'ml_StatModel' or its derivative)");
    cv::ml::StatModel* _self_ = dynamic_cast<cv::ml::StatModel*>(((pyopencv_ml_StatModel_t*)self)->v.get());
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->isTrained());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_StatModel_predict(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_StatModel_Type))
        return failmsgp("Incorrect type of self (must be 'ml_StatModel' or its derivative)");
    cv::ml::StatModel* _self_ = dynamic_cast<cv::ml::StatModel*>(((pyopencv_ml_StatModel_t*)self)->v.get());
    {
    PyObject* pyobj_samples = NULL;
    Mat samples;
    PyObject* pyobj_results = NULL;
    Mat results;
    int flags=0;
    float retval;

    const char* keywords[] = { "samples", "results", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|Oi:ml_StatModel.predict", (char**)keywords, &pyobj_samples, &pyobj_results, &flags) &&
        pyopencv_to(pyobj_samples, samples, ArgInfo("samples", 0)) &&
        pyopencv_to(pyobj_results, results, ArgInfo("results", 1)) )
    {
        ERRWRAP2(retval = _self_->predict(samples, results, flags));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(results));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_samples = NULL;
    UMat samples;
    PyObject* pyobj_results = NULL;
    UMat results;
    int flags=0;
    float retval;

    const char* keywords[] = { "samples", "results", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|Oi:ml_StatModel.predict", (char**)keywords, &pyobj_samples, &pyobj_results, &flags) &&
        pyopencv_to(pyobj_samples, samples, ArgInfo("samples", 0)) &&
        pyopencv_to(pyobj_results, results, ArgInfo("results", 1)) )
    {
        ERRWRAP2(retval = _self_->predict(samples, results, flags));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(results));
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_StatModel_train(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_StatModel_Type))
        return failmsgp("Incorrect type of self (must be 'ml_StatModel' or its derivative)");
    cv::ml::StatModel* _self_ = dynamic_cast<cv::ml::StatModel*>(((pyopencv_ml_StatModel_t*)self)->v.get());
    {
    PyObject* pyobj_trainData = NULL;
    Ptr<TrainData> trainData;
    int flags=0;
    bool retval;

    const char* keywords[] = { "trainData", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|i:ml_StatModel.train", (char**)keywords, &pyobj_trainData, &flags) &&
        pyopencv_to(pyobj_trainData, trainData, ArgInfo("trainData", 0)) )
    {
        ERRWRAP2(retval = _self_->train(trainData, flags));
        return pyopencv_from(retval);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_samples = NULL;
    Mat samples;
    int layout=0;
    PyObject* pyobj_responses = NULL;
    Mat responses;
    bool retval;

    const char* keywords[] = { "samples", "layout", "responses", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OiO:ml_StatModel.train", (char**)keywords, &pyobj_samples, &layout, &pyobj_responses) &&
        pyopencv_to(pyobj_samples, samples, ArgInfo("samples", 0)) &&
        pyopencv_to(pyobj_responses, responses, ArgInfo("responses", 0)) )
    {
        ERRWRAP2(retval = _self_->train(samples, layout, responses));
        return pyopencv_from(retval);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_samples = NULL;
    UMat samples;
    int layout=0;
    PyObject* pyobj_responses = NULL;
    UMat responses;
    bool retval;

    const char* keywords[] = { "samples", "layout", "responses", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OiO:ml_StatModel.train", (char**)keywords, &pyobj_samples, &layout, &pyobj_responses) &&
        pyopencv_to(pyobj_samples, samples, ArgInfo("samples", 0)) &&
        pyopencv_to(pyobj_responses, responses, ArgInfo("responses", 0)) )
    {
        ERRWRAP2(retval = _self_->train(samples, layout, responses));
        return pyopencv_from(retval);
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_ml_StatModel_methods[] =
{
    {"calcError", (PyCFunction)pyopencv_cv_ml_ml_StatModel_calcError, METH_VARARGS | METH_KEYWORDS, "calcError(data, test[, resp]) -> retval, resp"},
    {"empty", (PyCFunction)pyopencv_cv_ml_ml_StatModel_empty, METH_VARARGS | METH_KEYWORDS, "empty() -> retval"},
    {"getVarCount", (PyCFunction)pyopencv_cv_ml_ml_StatModel_getVarCount, METH_VARARGS | METH_KEYWORDS, "getVarCount() -> retval"},
    {"isClassifier", (PyCFunction)pyopencv_cv_ml_ml_StatModel_isClassifier, METH_VARARGS | METH_KEYWORDS, "isClassifier() -> retval"},
    {"isTrained", (PyCFunction)pyopencv_cv_ml_ml_StatModel_isTrained, METH_VARARGS | METH_KEYWORDS, "isTrained() -> retval"},
    {"predict", (PyCFunction)pyopencv_cv_ml_ml_StatModel_predict, METH_VARARGS | METH_KEYWORDS, "predict(samples[, results[, flags]]) -> retval, results"},
    {"train", (PyCFunction)pyopencv_cv_ml_ml_StatModel_train, METH_VARARGS | METH_KEYWORDS, "train(trainData[, flags]) -> retval  or  train(samples, layout, responses) -> retval"},

    {NULL,          NULL}
};

static void pyopencv_ml_StatModel_specials(void)
{
    pyopencv_ml_StatModel_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_ml_StatModel_Type.tp_dealloc = pyopencv_ml_StatModel_dealloc;
    pyopencv_ml_StatModel_Type.tp_repr = pyopencv_ml_StatModel_repr;
    pyopencv_ml_StatModel_Type.tp_getset = pyopencv_ml_StatModel_getseters;
    pyopencv_ml_StatModel_Type.tp_methods = pyopencv_ml_StatModel_methods;
}

static PyObject* pyopencv_ml_NormalBayesClassifier_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<ml_NormalBayesClassifier %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_ml_NormalBayesClassifier_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_ml_ml_NormalBayesClassifier_predictProb(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_NormalBayesClassifier_Type))
        return failmsgp("Incorrect type of self (must be 'ml_NormalBayesClassifier' or its derivative)");
    cv::ml::NormalBayesClassifier* _self_ = dynamic_cast<cv::ml::NormalBayesClassifier*>(((pyopencv_ml_NormalBayesClassifier_t*)self)->v.get());
    {
    PyObject* pyobj_inputs = NULL;
    Mat inputs;
    PyObject* pyobj_outputs = NULL;
    Mat outputs;
    PyObject* pyobj_outputProbs = NULL;
    Mat outputProbs;
    int flags=0;
    float retval;

    const char* keywords[] = { "inputs", "outputs", "outputProbs", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|OOi:ml_NormalBayesClassifier.predictProb", (char**)keywords, &pyobj_inputs, &pyobj_outputs, &pyobj_outputProbs, &flags) &&
        pyopencv_to(pyobj_inputs, inputs, ArgInfo("inputs", 0)) &&
        pyopencv_to(pyobj_outputs, outputs, ArgInfo("outputs", 1)) &&
        pyopencv_to(pyobj_outputProbs, outputProbs, ArgInfo("outputProbs", 1)) )
    {
        ERRWRAP2(retval = _self_->predictProb(inputs, outputs, outputProbs, flags));
        return Py_BuildValue("(NNN)", pyopencv_from(retval), pyopencv_from(outputs), pyopencv_from(outputProbs));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_inputs = NULL;
    UMat inputs;
    PyObject* pyobj_outputs = NULL;
    UMat outputs;
    PyObject* pyobj_outputProbs = NULL;
    UMat outputProbs;
    int flags=0;
    float retval;

    const char* keywords[] = { "inputs", "outputs", "outputProbs", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|OOi:ml_NormalBayesClassifier.predictProb", (char**)keywords, &pyobj_inputs, &pyobj_outputs, &pyobj_outputProbs, &flags) &&
        pyopencv_to(pyobj_inputs, inputs, ArgInfo("inputs", 0)) &&
        pyopencv_to(pyobj_outputs, outputs, ArgInfo("outputs", 1)) &&
        pyopencv_to(pyobj_outputProbs, outputProbs, ArgInfo("outputProbs", 1)) )
    {
        ERRWRAP2(retval = _self_->predictProb(inputs, outputs, outputProbs, flags));
        return Py_BuildValue("(NNN)", pyopencv_from(retval), pyopencv_from(outputs), pyopencv_from(outputProbs));
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_ml_NormalBayesClassifier_methods[] =
{
    {"predictProb", (PyCFunction)pyopencv_cv_ml_ml_NormalBayesClassifier_predictProb, METH_VARARGS | METH_KEYWORDS, "predictProb(inputs[, outputs[, outputProbs[, flags]]]) -> retval, outputs, outputProbs"},

    {NULL,          NULL}
};

static void pyopencv_ml_NormalBayesClassifier_specials(void)
{
    pyopencv_ml_NormalBayesClassifier_Type.tp_base = &pyopencv_ml_StatModel_Type;
    pyopencv_ml_NormalBayesClassifier_Type.tp_dealloc = pyopencv_ml_NormalBayesClassifier_dealloc;
    pyopencv_ml_NormalBayesClassifier_Type.tp_repr = pyopencv_ml_NormalBayesClassifier_repr;
    pyopencv_ml_NormalBayesClassifier_Type.tp_getset = pyopencv_ml_NormalBayesClassifier_getseters;
    pyopencv_ml_NormalBayesClassifier_Type.tp_methods = pyopencv_ml_NormalBayesClassifier_methods;
}

static PyObject* pyopencv_ml_KNearest_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<ml_KNearest %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_ml_KNearest_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_ml_ml_KNearest_findNearest(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_KNearest_Type))
        return failmsgp("Incorrect type of self (must be 'ml_KNearest' or its derivative)");
    cv::ml::KNearest* _self_ = dynamic_cast<cv::ml::KNearest*>(((pyopencv_ml_KNearest_t*)self)->v.get());
    {
    PyObject* pyobj_samples = NULL;
    Mat samples;
    int k=0;
    PyObject* pyobj_results = NULL;
    Mat results;
    PyObject* pyobj_neighborResponses = NULL;
    Mat neighborResponses;
    PyObject* pyobj_dist = NULL;
    Mat dist;
    float retval;

    const char* keywords[] = { "samples", "k", "results", "neighborResponses", "dist", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "Oi|OOO:ml_KNearest.findNearest", (char**)keywords, &pyobj_samples, &k, &pyobj_results, &pyobj_neighborResponses, &pyobj_dist) &&
        pyopencv_to(pyobj_samples, samples, ArgInfo("samples", 0)) &&
        pyopencv_to(pyobj_results, results, ArgInfo("results", 1)) &&
        pyopencv_to(pyobj_neighborResponses, neighborResponses, ArgInfo("neighborResponses", 1)) &&
        pyopencv_to(pyobj_dist, dist, ArgInfo("dist", 1)) )
    {
        ERRWRAP2(retval = _self_->findNearest(samples, k, results, neighborResponses, dist));
        return Py_BuildValue("(NNNN)", pyopencv_from(retval), pyopencv_from(results), pyopencv_from(neighborResponses), pyopencv_from(dist));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_samples = NULL;
    UMat samples;
    int k=0;
    PyObject* pyobj_results = NULL;
    UMat results;
    PyObject* pyobj_neighborResponses = NULL;
    UMat neighborResponses;
    PyObject* pyobj_dist = NULL;
    UMat dist;
    float retval;

    const char* keywords[] = { "samples", "k", "results", "neighborResponses", "dist", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "Oi|OOO:ml_KNearest.findNearest", (char**)keywords, &pyobj_samples, &k, &pyobj_results, &pyobj_neighborResponses, &pyobj_dist) &&
        pyopencv_to(pyobj_samples, samples, ArgInfo("samples", 0)) &&
        pyopencv_to(pyobj_results, results, ArgInfo("results", 1)) &&
        pyopencv_to(pyobj_neighborResponses, neighborResponses, ArgInfo("neighborResponses", 1)) &&
        pyopencv_to(pyobj_dist, dist, ArgInfo("dist", 1)) )
    {
        ERRWRAP2(retval = _self_->findNearest(samples, k, results, neighborResponses, dist));
        return Py_BuildValue("(NNNN)", pyopencv_from(retval), pyopencv_from(results), pyopencv_from(neighborResponses), pyopencv_from(dist));
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_KNearest_getAlgorithmType(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_KNearest_Type))
        return failmsgp("Incorrect type of self (must be 'ml_KNearest' or its derivative)");
    cv::ml::KNearest* _self_ = dynamic_cast<cv::ml::KNearest*>(((pyopencv_ml_KNearest_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getAlgorithmType());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_KNearest_getDefaultK(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_KNearest_Type))
        return failmsgp("Incorrect type of self (must be 'ml_KNearest' or its derivative)");
    cv::ml::KNearest* _self_ = dynamic_cast<cv::ml::KNearest*>(((pyopencv_ml_KNearest_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getDefaultK());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_KNearest_getEmax(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_KNearest_Type))
        return failmsgp("Incorrect type of self (must be 'ml_KNearest' or its derivative)");
    cv::ml::KNearest* _self_ = dynamic_cast<cv::ml::KNearest*>(((pyopencv_ml_KNearest_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getEmax());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_KNearest_getIsClassifier(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_KNearest_Type))
        return failmsgp("Incorrect type of self (must be 'ml_KNearest' or its derivative)");
    cv::ml::KNearest* _self_ = dynamic_cast<cv::ml::KNearest*>(((pyopencv_ml_KNearest_t*)self)->v.get());
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getIsClassifier());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_KNearest_setAlgorithmType(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_KNearest_Type))
        return failmsgp("Incorrect type of self (must be 'ml_KNearest' or its derivative)");
    cv::ml::KNearest* _self_ = dynamic_cast<cv::ml::KNearest*>(((pyopencv_ml_KNearest_t*)self)->v.get());
    int val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:ml_KNearest.setAlgorithmType", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setAlgorithmType(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_KNearest_setDefaultK(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_KNearest_Type))
        return failmsgp("Incorrect type of self (must be 'ml_KNearest' or its derivative)");
    cv::ml::KNearest* _self_ = dynamic_cast<cv::ml::KNearest*>(((pyopencv_ml_KNearest_t*)self)->v.get());
    int val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:ml_KNearest.setDefaultK", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setDefaultK(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_KNearest_setEmax(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_KNearest_Type))
        return failmsgp("Incorrect type of self (must be 'ml_KNearest' or its derivative)");
    cv::ml::KNearest* _self_ = dynamic_cast<cv::ml::KNearest*>(((pyopencv_ml_KNearest_t*)self)->v.get());
    int val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:ml_KNearest.setEmax", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setEmax(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_KNearest_setIsClassifier(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_KNearest_Type))
        return failmsgp("Incorrect type of self (must be 'ml_KNearest' or its derivative)");
    cv::ml::KNearest* _self_ = dynamic_cast<cv::ml::KNearest*>(((pyopencv_ml_KNearest_t*)self)->v.get());
    bool val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "b:ml_KNearest.setIsClassifier", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setIsClassifier(val));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_ml_KNearest_methods[] =
{
    {"findNearest", (PyCFunction)pyopencv_cv_ml_ml_KNearest_findNearest, METH_VARARGS | METH_KEYWORDS, "findNearest(samples, k[, results[, neighborResponses[, dist]]]) -> retval, results, neighborResponses, dist"},
    {"getAlgorithmType", (PyCFunction)pyopencv_cv_ml_ml_KNearest_getAlgorithmType, METH_VARARGS | METH_KEYWORDS, "getAlgorithmType() -> retval"},
    {"getDefaultK", (PyCFunction)pyopencv_cv_ml_ml_KNearest_getDefaultK, METH_VARARGS | METH_KEYWORDS, "getDefaultK() -> retval"},
    {"getEmax", (PyCFunction)pyopencv_cv_ml_ml_KNearest_getEmax, METH_VARARGS | METH_KEYWORDS, "getEmax() -> retval"},
    {"getIsClassifier", (PyCFunction)pyopencv_cv_ml_ml_KNearest_getIsClassifier, METH_VARARGS | METH_KEYWORDS, "getIsClassifier() -> retval"},
    {"setAlgorithmType", (PyCFunction)pyopencv_cv_ml_ml_KNearest_setAlgorithmType, METH_VARARGS | METH_KEYWORDS, "setAlgorithmType(val) -> None"},
    {"setDefaultK", (PyCFunction)pyopencv_cv_ml_ml_KNearest_setDefaultK, METH_VARARGS | METH_KEYWORDS, "setDefaultK(val) -> None"},
    {"setEmax", (PyCFunction)pyopencv_cv_ml_ml_KNearest_setEmax, METH_VARARGS | METH_KEYWORDS, "setEmax(val) -> None"},
    {"setIsClassifier", (PyCFunction)pyopencv_cv_ml_ml_KNearest_setIsClassifier, METH_VARARGS | METH_KEYWORDS, "setIsClassifier(val) -> None"},

    {NULL,          NULL}
};

static void pyopencv_ml_KNearest_specials(void)
{
    pyopencv_ml_KNearest_Type.tp_base = &pyopencv_ml_StatModel_Type;
    pyopencv_ml_KNearest_Type.tp_dealloc = pyopencv_ml_KNearest_dealloc;
    pyopencv_ml_KNearest_Type.tp_repr = pyopencv_ml_KNearest_repr;
    pyopencv_ml_KNearest_Type.tp_getset = pyopencv_ml_KNearest_getseters;
    pyopencv_ml_KNearest_Type.tp_methods = pyopencv_ml_KNearest_methods;
}

static PyObject* pyopencv_ml_SVM_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<ml_SVM %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_ml_SVM_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_ml_ml_SVM_getC(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_SVM_Type))
        return failmsgp("Incorrect type of self (must be 'ml_SVM' or its derivative)");
    cv::ml::SVM* _self_ = dynamic_cast<cv::ml::SVM*>(((pyopencv_ml_SVM_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getC());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_SVM_getClassWeights(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_SVM_Type))
        return failmsgp("Incorrect type of self (must be 'ml_SVM' or its derivative)");
    cv::ml::SVM* _self_ = dynamic_cast<cv::ml::SVM*>(((pyopencv_ml_SVM_t*)self)->v.get());
    cv::Mat retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getClassWeights());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_SVM_getCoef0(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_SVM_Type))
        return failmsgp("Incorrect type of self (must be 'ml_SVM' or its derivative)");
    cv::ml::SVM* _self_ = dynamic_cast<cv::ml::SVM*>(((pyopencv_ml_SVM_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getCoef0());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_SVM_getDecisionFunction(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_SVM_Type))
        return failmsgp("Incorrect type of self (must be 'ml_SVM' or its derivative)");
    cv::ml::SVM* _self_ = dynamic_cast<cv::ml::SVM*>(((pyopencv_ml_SVM_t*)self)->v.get());
    {
    int i=0;
    PyObject* pyobj_alpha = NULL;
    Mat alpha;
    PyObject* pyobj_svidx = NULL;
    Mat svidx;
    double retval;

    const char* keywords[] = { "i", "alpha", "svidx", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i|OO:ml_SVM.getDecisionFunction", (char**)keywords, &i, &pyobj_alpha, &pyobj_svidx) &&
        pyopencv_to(pyobj_alpha, alpha, ArgInfo("alpha", 1)) &&
        pyopencv_to(pyobj_svidx, svidx, ArgInfo("svidx", 1)) )
    {
        ERRWRAP2(retval = _self_->getDecisionFunction(i, alpha, svidx));
        return Py_BuildValue("(NNN)", pyopencv_from(retval), pyopencv_from(alpha), pyopencv_from(svidx));
    }
    }
    PyErr_Clear();

    {
    int i=0;
    PyObject* pyobj_alpha = NULL;
    UMat alpha;
    PyObject* pyobj_svidx = NULL;
    UMat svidx;
    double retval;

    const char* keywords[] = { "i", "alpha", "svidx", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i|OO:ml_SVM.getDecisionFunction", (char**)keywords, &i, &pyobj_alpha, &pyobj_svidx) &&
        pyopencv_to(pyobj_alpha, alpha, ArgInfo("alpha", 1)) &&
        pyopencv_to(pyobj_svidx, svidx, ArgInfo("svidx", 1)) )
    {
        ERRWRAP2(retval = _self_->getDecisionFunction(i, alpha, svidx));
        return Py_BuildValue("(NNN)", pyopencv_from(retval), pyopencv_from(alpha), pyopencv_from(svidx));
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_SVM_getDegree(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_SVM_Type))
        return failmsgp("Incorrect type of self (must be 'ml_SVM' or its derivative)");
    cv::ml::SVM* _self_ = dynamic_cast<cv::ml::SVM*>(((pyopencv_ml_SVM_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getDegree());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_SVM_getGamma(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_SVM_Type))
        return failmsgp("Incorrect type of self (must be 'ml_SVM' or its derivative)");
    cv::ml::SVM* _self_ = dynamic_cast<cv::ml::SVM*>(((pyopencv_ml_SVM_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getGamma());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_SVM_getKernelType(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_SVM_Type))
        return failmsgp("Incorrect type of self (must be 'ml_SVM' or its derivative)");
    cv::ml::SVM* _self_ = dynamic_cast<cv::ml::SVM*>(((pyopencv_ml_SVM_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getKernelType());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_SVM_getNu(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_SVM_Type))
        return failmsgp("Incorrect type of self (must be 'ml_SVM' or its derivative)");
    cv::ml::SVM* _self_ = dynamic_cast<cv::ml::SVM*>(((pyopencv_ml_SVM_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getNu());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_SVM_getP(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_SVM_Type))
        return failmsgp("Incorrect type of self (must be 'ml_SVM' or its derivative)");
    cv::ml::SVM* _self_ = dynamic_cast<cv::ml::SVM*>(((pyopencv_ml_SVM_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getP());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_SVM_getSupportVectors(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_SVM_Type))
        return failmsgp("Incorrect type of self (must be 'ml_SVM' or its derivative)");
    cv::ml::SVM* _self_ = dynamic_cast<cv::ml::SVM*>(((pyopencv_ml_SVM_t*)self)->v.get());
    Mat retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getSupportVectors());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_SVM_getTermCriteria(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_SVM_Type))
        return failmsgp("Incorrect type of self (must be 'ml_SVM' or its derivative)");
    cv::ml::SVM* _self_ = dynamic_cast<cv::ml::SVM*>(((pyopencv_ml_SVM_t*)self)->v.get());
    cv::TermCriteria retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getTermCriteria());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_SVM_getType(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_SVM_Type))
        return failmsgp("Incorrect type of self (must be 'ml_SVM' or its derivative)");
    cv::ml::SVM* _self_ = dynamic_cast<cv::ml::SVM*>(((pyopencv_ml_SVM_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getType());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_SVM_getUncompressedSupportVectors(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_SVM_Type))
        return failmsgp("Incorrect type of self (must be 'ml_SVM' or its derivative)");
    cv::ml::SVM* _self_ = dynamic_cast<cv::ml::SVM*>(((pyopencv_ml_SVM_t*)self)->v.get());
    Mat retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getUncompressedSupportVectors());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_SVM_setC(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_SVM_Type))
        return failmsgp("Incorrect type of self (must be 'ml_SVM' or its derivative)");
    cv::ml::SVM* _self_ = dynamic_cast<cv::ml::SVM*>(((pyopencv_ml_SVM_t*)self)->v.get());
    double val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:ml_SVM.setC", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setC(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_SVM_setClassWeights(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_SVM_Type))
        return failmsgp("Incorrect type of self (must be 'ml_SVM' or its derivative)");
    cv::ml::SVM* _self_ = dynamic_cast<cv::ml::SVM*>(((pyopencv_ml_SVM_t*)self)->v.get());
    {
    PyObject* pyobj_val = NULL;
    Mat val;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:ml_SVM.setClassWeights", (char**)keywords, &pyobj_val) &&
        pyopencv_to(pyobj_val, val, ArgInfo("val", 0)) )
    {
        ERRWRAP2(_self_->setClassWeights(val));
        Py_RETURN_NONE;
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_val = NULL;
    Mat val;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:ml_SVM.setClassWeights", (char**)keywords, &pyobj_val) &&
        pyopencv_to(pyobj_val, val, ArgInfo("val", 0)) )
    {
        ERRWRAP2(_self_->setClassWeights(val));
        Py_RETURN_NONE;
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_SVM_setCoef0(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_SVM_Type))
        return failmsgp("Incorrect type of self (must be 'ml_SVM' or its derivative)");
    cv::ml::SVM* _self_ = dynamic_cast<cv::ml::SVM*>(((pyopencv_ml_SVM_t*)self)->v.get());
    double val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:ml_SVM.setCoef0", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setCoef0(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_SVM_setDegree(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_SVM_Type))
        return failmsgp("Incorrect type of self (must be 'ml_SVM' or its derivative)");
    cv::ml::SVM* _self_ = dynamic_cast<cv::ml::SVM*>(((pyopencv_ml_SVM_t*)self)->v.get());
    double val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:ml_SVM.setDegree", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setDegree(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_SVM_setGamma(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_SVM_Type))
        return failmsgp("Incorrect type of self (must be 'ml_SVM' or its derivative)");
    cv::ml::SVM* _self_ = dynamic_cast<cv::ml::SVM*>(((pyopencv_ml_SVM_t*)self)->v.get());
    double val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:ml_SVM.setGamma", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setGamma(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_SVM_setKernel(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_SVM_Type))
        return failmsgp("Incorrect type of self (must be 'ml_SVM' or its derivative)");
    cv::ml::SVM* _self_ = dynamic_cast<cv::ml::SVM*>(((pyopencv_ml_SVM_t*)self)->v.get());
    int kernelType=0;

    const char* keywords[] = { "kernelType", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:ml_SVM.setKernel", (char**)keywords, &kernelType) )
    {
        ERRWRAP2(_self_->setKernel(kernelType));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_SVM_setNu(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_SVM_Type))
        return failmsgp("Incorrect type of self (must be 'ml_SVM' or its derivative)");
    cv::ml::SVM* _self_ = dynamic_cast<cv::ml::SVM*>(((pyopencv_ml_SVM_t*)self)->v.get());
    double val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:ml_SVM.setNu", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setNu(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_SVM_setP(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_SVM_Type))
        return failmsgp("Incorrect type of self (must be 'ml_SVM' or its derivative)");
    cv::ml::SVM* _self_ = dynamic_cast<cv::ml::SVM*>(((pyopencv_ml_SVM_t*)self)->v.get());
    double val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:ml_SVM.setP", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setP(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_SVM_setTermCriteria(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_SVM_Type))
        return failmsgp("Incorrect type of self (must be 'ml_SVM' or its derivative)");
    cv::ml::SVM* _self_ = dynamic_cast<cv::ml::SVM*>(((pyopencv_ml_SVM_t*)self)->v.get());
    PyObject* pyobj_val = NULL;
    TermCriteria val;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:ml_SVM.setTermCriteria", (char**)keywords, &pyobj_val) &&
        pyopencv_to(pyobj_val, val, ArgInfo("val", 0)) )
    {
        ERRWRAP2(_self_->setTermCriteria(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_SVM_setType(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_SVM_Type))
        return failmsgp("Incorrect type of self (must be 'ml_SVM' or its derivative)");
    cv::ml::SVM* _self_ = dynamic_cast<cv::ml::SVM*>(((pyopencv_ml_SVM_t*)self)->v.get());
    int val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:ml_SVM.setType", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setType(val));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_ml_SVM_methods[] =
{
    {"getC", (PyCFunction)pyopencv_cv_ml_ml_SVM_getC, METH_VARARGS | METH_KEYWORDS, "getC() -> retval"},
    {"getClassWeights", (PyCFunction)pyopencv_cv_ml_ml_SVM_getClassWeights, METH_VARARGS | METH_KEYWORDS, "getClassWeights() -> retval"},
    {"getCoef0", (PyCFunction)pyopencv_cv_ml_ml_SVM_getCoef0, METH_VARARGS | METH_KEYWORDS, "getCoef0() -> retval"},
    {"getDecisionFunction", (PyCFunction)pyopencv_cv_ml_ml_SVM_getDecisionFunction, METH_VARARGS | METH_KEYWORDS, "getDecisionFunction(i[, alpha[, svidx]]) -> retval, alpha, svidx"},
    {"getDegree", (PyCFunction)pyopencv_cv_ml_ml_SVM_getDegree, METH_VARARGS | METH_KEYWORDS, "getDegree() -> retval"},
    {"getGamma", (PyCFunction)pyopencv_cv_ml_ml_SVM_getGamma, METH_VARARGS | METH_KEYWORDS, "getGamma() -> retval"},
    {"getKernelType", (PyCFunction)pyopencv_cv_ml_ml_SVM_getKernelType, METH_VARARGS | METH_KEYWORDS, "getKernelType() -> retval"},
    {"getNu", (PyCFunction)pyopencv_cv_ml_ml_SVM_getNu, METH_VARARGS | METH_KEYWORDS, "getNu() -> retval"},
    {"getP", (PyCFunction)pyopencv_cv_ml_ml_SVM_getP, METH_VARARGS | METH_KEYWORDS, "getP() -> retval"},
    {"getSupportVectors", (PyCFunction)pyopencv_cv_ml_ml_SVM_getSupportVectors, METH_VARARGS | METH_KEYWORDS, "getSupportVectors() -> retval"},
    {"getTermCriteria", (PyCFunction)pyopencv_cv_ml_ml_SVM_getTermCriteria, METH_VARARGS | METH_KEYWORDS, "getTermCriteria() -> retval"},
    {"getType", (PyCFunction)pyopencv_cv_ml_ml_SVM_getType, METH_VARARGS | METH_KEYWORDS, "getType() -> retval"},
    {"getUncompressedSupportVectors", (PyCFunction)pyopencv_cv_ml_ml_SVM_getUncompressedSupportVectors, METH_VARARGS | METH_KEYWORDS, "getUncompressedSupportVectors() -> retval"},
    {"setC", (PyCFunction)pyopencv_cv_ml_ml_SVM_setC, METH_VARARGS | METH_KEYWORDS, "setC(val) -> None"},
    {"setClassWeights", (PyCFunction)pyopencv_cv_ml_ml_SVM_setClassWeights, METH_VARARGS | METH_KEYWORDS, "setClassWeights(val) -> None"},
    {"setCoef0", (PyCFunction)pyopencv_cv_ml_ml_SVM_setCoef0, METH_VARARGS | METH_KEYWORDS, "setCoef0(val) -> None"},
    {"setDegree", (PyCFunction)pyopencv_cv_ml_ml_SVM_setDegree, METH_VARARGS | METH_KEYWORDS, "setDegree(val) -> None"},
    {"setGamma", (PyCFunction)pyopencv_cv_ml_ml_SVM_setGamma, METH_VARARGS | METH_KEYWORDS, "setGamma(val) -> None"},
    {"setKernel", (PyCFunction)pyopencv_cv_ml_ml_SVM_setKernel, METH_VARARGS | METH_KEYWORDS, "setKernel(kernelType) -> None"},
    {"setNu", (PyCFunction)pyopencv_cv_ml_ml_SVM_setNu, METH_VARARGS | METH_KEYWORDS, "setNu(val) -> None"},
    {"setP", (PyCFunction)pyopencv_cv_ml_ml_SVM_setP, METH_VARARGS | METH_KEYWORDS, "setP(val) -> None"},
    {"setTermCriteria", (PyCFunction)pyopencv_cv_ml_ml_SVM_setTermCriteria, METH_VARARGS | METH_KEYWORDS, "setTermCriteria(val) -> None"},
    {"setType", (PyCFunction)pyopencv_cv_ml_ml_SVM_setType, METH_VARARGS | METH_KEYWORDS, "setType(val) -> None"},

    {NULL,          NULL}
};

static void pyopencv_ml_SVM_specials(void)
{
    pyopencv_ml_SVM_Type.tp_base = &pyopencv_ml_StatModel_Type;
    pyopencv_ml_SVM_Type.tp_dealloc = pyopencv_ml_SVM_dealloc;
    pyopencv_ml_SVM_Type.tp_repr = pyopencv_ml_SVM_repr;
    pyopencv_ml_SVM_Type.tp_getset = pyopencv_ml_SVM_getseters;
    pyopencv_ml_SVM_Type.tp_methods = pyopencv_ml_SVM_methods;
}

static PyObject* pyopencv_ml_EM_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<ml_EM %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_ml_EM_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_ml_ml_EM_getClustersNumber(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_EM_Type))
        return failmsgp("Incorrect type of self (must be 'ml_EM' or its derivative)");
    cv::ml::EM* _self_ = dynamic_cast<cv::ml::EM*>(((pyopencv_ml_EM_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getClustersNumber());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_EM_getCovarianceMatrixType(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_EM_Type))
        return failmsgp("Incorrect type of self (must be 'ml_EM' or its derivative)");
    cv::ml::EM* _self_ = dynamic_cast<cv::ml::EM*>(((pyopencv_ml_EM_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getCovarianceMatrixType());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_EM_getCovs(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_EM_Type))
        return failmsgp("Incorrect type of self (must be 'ml_EM' or its derivative)");
    cv::ml::EM* _self_ = dynamic_cast<cv::ml::EM*>(((pyopencv_ml_EM_t*)self)->v.get());
    {
    PyObject* pyobj_covs = NULL;
    vector_Mat covs;

    const char* keywords[] = { "covs", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|O:ml_EM.getCovs", (char**)keywords, &pyobj_covs) &&
        pyopencv_to(pyobj_covs, covs, ArgInfo("covs", 1)) )
    {
        ERRWRAP2(_self_->getCovs(covs));
        return pyopencv_from(covs);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_covs = NULL;
    vector_Mat covs;

    const char* keywords[] = { "covs", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|O:ml_EM.getCovs", (char**)keywords, &pyobj_covs) &&
        pyopencv_to(pyobj_covs, covs, ArgInfo("covs", 1)) )
    {
        ERRWRAP2(_self_->getCovs(covs));
        return pyopencv_from(covs);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_EM_getMeans(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_EM_Type))
        return failmsgp("Incorrect type of self (must be 'ml_EM' or its derivative)");
    cv::ml::EM* _self_ = dynamic_cast<cv::ml::EM*>(((pyopencv_ml_EM_t*)self)->v.get());
    Mat retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getMeans());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_EM_getTermCriteria(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_EM_Type))
        return failmsgp("Incorrect type of self (must be 'ml_EM' or its derivative)");
    cv::ml::EM* _self_ = dynamic_cast<cv::ml::EM*>(((pyopencv_ml_EM_t*)self)->v.get());
    TermCriteria retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getTermCriteria());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_EM_getWeights(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_EM_Type))
        return failmsgp("Incorrect type of self (must be 'ml_EM' or its derivative)");
    cv::ml::EM* _self_ = dynamic_cast<cv::ml::EM*>(((pyopencv_ml_EM_t*)self)->v.get());
    Mat retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getWeights());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_EM_predict(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_EM_Type))
        return failmsgp("Incorrect type of self (must be 'ml_EM' or its derivative)");
    cv::ml::EM* _self_ = dynamic_cast<cv::ml::EM*>(((pyopencv_ml_EM_t*)self)->v.get());
    {
    PyObject* pyobj_samples = NULL;
    Mat samples;
    PyObject* pyobj_results = NULL;
    Mat results;
    int flags=0;
    float retval;

    const char* keywords[] = { "samples", "results", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|Oi:ml_EM.predict", (char**)keywords, &pyobj_samples, &pyobj_results, &flags) &&
        pyopencv_to(pyobj_samples, samples, ArgInfo("samples", 0)) &&
        pyopencv_to(pyobj_results, results, ArgInfo("results", 1)) )
    {
        ERRWRAP2(retval = _self_->predict(samples, results, flags));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(results));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_samples = NULL;
    UMat samples;
    PyObject* pyobj_results = NULL;
    UMat results;
    int flags=0;
    float retval;

    const char* keywords[] = { "samples", "results", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|Oi:ml_EM.predict", (char**)keywords, &pyobj_samples, &pyobj_results, &flags) &&
        pyopencv_to(pyobj_samples, samples, ArgInfo("samples", 0)) &&
        pyopencv_to(pyobj_results, results, ArgInfo("results", 1)) )
    {
        ERRWRAP2(retval = _self_->predict(samples, results, flags));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(results));
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_EM_predict2(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_EM_Type))
        return failmsgp("Incorrect type of self (must be 'ml_EM' or its derivative)");
    cv::ml::EM* _self_ = dynamic_cast<cv::ml::EM*>(((pyopencv_ml_EM_t*)self)->v.get());
    {
    PyObject* pyobj_sample = NULL;
    Mat sample;
    PyObject* pyobj_probs = NULL;
    Mat probs;
    Vec2d retval;

    const char* keywords[] = { "sample", "probs", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:ml_EM.predict2", (char**)keywords, &pyobj_sample, &pyobj_probs) &&
        pyopencv_to(pyobj_sample, sample, ArgInfo("sample", 0)) &&
        pyopencv_to(pyobj_probs, probs, ArgInfo("probs", 1)) )
    {
        ERRWRAP2(retval = _self_->predict2(sample, probs));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(probs));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_sample = NULL;
    UMat sample;
    PyObject* pyobj_probs = NULL;
    UMat probs;
    Vec2d retval;

    const char* keywords[] = { "sample", "probs", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:ml_EM.predict2", (char**)keywords, &pyobj_sample, &pyobj_probs) &&
        pyopencv_to(pyobj_sample, sample, ArgInfo("sample", 0)) &&
        pyopencv_to(pyobj_probs, probs, ArgInfo("probs", 1)) )
    {
        ERRWRAP2(retval = _self_->predict2(sample, probs));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(probs));
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_EM_setClustersNumber(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_EM_Type))
        return failmsgp("Incorrect type of self (must be 'ml_EM' or its derivative)");
    cv::ml::EM* _self_ = dynamic_cast<cv::ml::EM*>(((pyopencv_ml_EM_t*)self)->v.get());
    int val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:ml_EM.setClustersNumber", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setClustersNumber(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_EM_setCovarianceMatrixType(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_EM_Type))
        return failmsgp("Incorrect type of self (must be 'ml_EM' or its derivative)");
    cv::ml::EM* _self_ = dynamic_cast<cv::ml::EM*>(((pyopencv_ml_EM_t*)self)->v.get());
    int val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:ml_EM.setCovarianceMatrixType", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setCovarianceMatrixType(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_EM_setTermCriteria(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_EM_Type))
        return failmsgp("Incorrect type of self (must be 'ml_EM' or its derivative)");
    cv::ml::EM* _self_ = dynamic_cast<cv::ml::EM*>(((pyopencv_ml_EM_t*)self)->v.get());
    PyObject* pyobj_val = NULL;
    TermCriteria val;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:ml_EM.setTermCriteria", (char**)keywords, &pyobj_val) &&
        pyopencv_to(pyobj_val, val, ArgInfo("val", 0)) )
    {
        ERRWRAP2(_self_->setTermCriteria(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_EM_trainE(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_EM_Type))
        return failmsgp("Incorrect type of self (must be 'ml_EM' or its derivative)");
    cv::ml::EM* _self_ = dynamic_cast<cv::ml::EM*>(((pyopencv_ml_EM_t*)self)->v.get());
    {
    PyObject* pyobj_samples = NULL;
    Mat samples;
    PyObject* pyobj_means0 = NULL;
    Mat means0;
    PyObject* pyobj_covs0 = NULL;
    Mat covs0;
    PyObject* pyobj_weights0 = NULL;
    Mat weights0;
    PyObject* pyobj_logLikelihoods = NULL;
    Mat logLikelihoods;
    PyObject* pyobj_labels = NULL;
    Mat labels;
    PyObject* pyobj_probs = NULL;
    Mat probs;
    bool retval;

    const char* keywords[] = { "samples", "means0", "covs0", "weights0", "logLikelihoods", "labels", "probs", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|OOOOO:ml_EM.trainE", (char**)keywords, &pyobj_samples, &pyobj_means0, &pyobj_covs0, &pyobj_weights0, &pyobj_logLikelihoods, &pyobj_labels, &pyobj_probs) &&
        pyopencv_to(pyobj_samples, samples, ArgInfo("samples", 0)) &&
        pyopencv_to(pyobj_means0, means0, ArgInfo("means0", 0)) &&
        pyopencv_to(pyobj_covs0, covs0, ArgInfo("covs0", 0)) &&
        pyopencv_to(pyobj_weights0, weights0, ArgInfo("weights0", 0)) &&
        pyopencv_to(pyobj_logLikelihoods, logLikelihoods, ArgInfo("logLikelihoods", 1)) &&
        pyopencv_to(pyobj_labels, labels, ArgInfo("labels", 1)) &&
        pyopencv_to(pyobj_probs, probs, ArgInfo("probs", 1)) )
    {
        ERRWRAP2(retval = _self_->trainE(samples, means0, covs0, weights0, logLikelihoods, labels, probs));
        return Py_BuildValue("(NNNN)", pyopencv_from(retval), pyopencv_from(logLikelihoods), pyopencv_from(labels), pyopencv_from(probs));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_samples = NULL;
    UMat samples;
    PyObject* pyobj_means0 = NULL;
    UMat means0;
    PyObject* pyobj_covs0 = NULL;
    UMat covs0;
    PyObject* pyobj_weights0 = NULL;
    UMat weights0;
    PyObject* pyobj_logLikelihoods = NULL;
    UMat logLikelihoods;
    PyObject* pyobj_labels = NULL;
    UMat labels;
    PyObject* pyobj_probs = NULL;
    UMat probs;
    bool retval;

    const char* keywords[] = { "samples", "means0", "covs0", "weights0", "logLikelihoods", "labels", "probs", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|OOOOO:ml_EM.trainE", (char**)keywords, &pyobj_samples, &pyobj_means0, &pyobj_covs0, &pyobj_weights0, &pyobj_logLikelihoods, &pyobj_labels, &pyobj_probs) &&
        pyopencv_to(pyobj_samples, samples, ArgInfo("samples", 0)) &&
        pyopencv_to(pyobj_means0, means0, ArgInfo("means0", 0)) &&
        pyopencv_to(pyobj_covs0, covs0, ArgInfo("covs0", 0)) &&
        pyopencv_to(pyobj_weights0, weights0, ArgInfo("weights0", 0)) &&
        pyopencv_to(pyobj_logLikelihoods, logLikelihoods, ArgInfo("logLikelihoods", 1)) &&
        pyopencv_to(pyobj_labels, labels, ArgInfo("labels", 1)) &&
        pyopencv_to(pyobj_probs, probs, ArgInfo("probs", 1)) )
    {
        ERRWRAP2(retval = _self_->trainE(samples, means0, covs0, weights0, logLikelihoods, labels, probs));
        return Py_BuildValue("(NNNN)", pyopencv_from(retval), pyopencv_from(logLikelihoods), pyopencv_from(labels), pyopencv_from(probs));
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_EM_trainEM(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_EM_Type))
        return failmsgp("Incorrect type of self (must be 'ml_EM' or its derivative)");
    cv::ml::EM* _self_ = dynamic_cast<cv::ml::EM*>(((pyopencv_ml_EM_t*)self)->v.get());
    {
    PyObject* pyobj_samples = NULL;
    Mat samples;
    PyObject* pyobj_logLikelihoods = NULL;
    Mat logLikelihoods;
    PyObject* pyobj_labels = NULL;
    Mat labels;
    PyObject* pyobj_probs = NULL;
    Mat probs;
    bool retval;

    const char* keywords[] = { "samples", "logLikelihoods", "labels", "probs", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|OOO:ml_EM.trainEM", (char**)keywords, &pyobj_samples, &pyobj_logLikelihoods, &pyobj_labels, &pyobj_probs) &&
        pyopencv_to(pyobj_samples, samples, ArgInfo("samples", 0)) &&
        pyopencv_to(pyobj_logLikelihoods, logLikelihoods, ArgInfo("logLikelihoods", 1)) &&
        pyopencv_to(pyobj_labels, labels, ArgInfo("labels", 1)) &&
        pyopencv_to(pyobj_probs, probs, ArgInfo("probs", 1)) )
    {
        ERRWRAP2(retval = _self_->trainEM(samples, logLikelihoods, labels, probs));
        return Py_BuildValue("(NNNN)", pyopencv_from(retval), pyopencv_from(logLikelihoods), pyopencv_from(labels), pyopencv_from(probs));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_samples = NULL;
    UMat samples;
    PyObject* pyobj_logLikelihoods = NULL;
    UMat logLikelihoods;
    PyObject* pyobj_labels = NULL;
    UMat labels;
    PyObject* pyobj_probs = NULL;
    UMat probs;
    bool retval;

    const char* keywords[] = { "samples", "logLikelihoods", "labels", "probs", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|OOO:ml_EM.trainEM", (char**)keywords, &pyobj_samples, &pyobj_logLikelihoods, &pyobj_labels, &pyobj_probs) &&
        pyopencv_to(pyobj_samples, samples, ArgInfo("samples", 0)) &&
        pyopencv_to(pyobj_logLikelihoods, logLikelihoods, ArgInfo("logLikelihoods", 1)) &&
        pyopencv_to(pyobj_labels, labels, ArgInfo("labels", 1)) &&
        pyopencv_to(pyobj_probs, probs, ArgInfo("probs", 1)) )
    {
        ERRWRAP2(retval = _self_->trainEM(samples, logLikelihoods, labels, probs));
        return Py_BuildValue("(NNNN)", pyopencv_from(retval), pyopencv_from(logLikelihoods), pyopencv_from(labels), pyopencv_from(probs));
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_EM_trainM(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_EM_Type))
        return failmsgp("Incorrect type of self (must be 'ml_EM' or its derivative)");
    cv::ml::EM* _self_ = dynamic_cast<cv::ml::EM*>(((pyopencv_ml_EM_t*)self)->v.get());
    {
    PyObject* pyobj_samples = NULL;
    Mat samples;
    PyObject* pyobj_probs0 = NULL;
    Mat probs0;
    PyObject* pyobj_logLikelihoods = NULL;
    Mat logLikelihoods;
    PyObject* pyobj_labels = NULL;
    Mat labels;
    PyObject* pyobj_probs = NULL;
    Mat probs;
    bool retval;

    const char* keywords[] = { "samples", "probs0", "logLikelihoods", "labels", "probs", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|OOO:ml_EM.trainM", (char**)keywords, &pyobj_samples, &pyobj_probs0, &pyobj_logLikelihoods, &pyobj_labels, &pyobj_probs) &&
        pyopencv_to(pyobj_samples, samples, ArgInfo("samples", 0)) &&
        pyopencv_to(pyobj_probs0, probs0, ArgInfo("probs0", 0)) &&
        pyopencv_to(pyobj_logLikelihoods, logLikelihoods, ArgInfo("logLikelihoods", 1)) &&
        pyopencv_to(pyobj_labels, labels, ArgInfo("labels", 1)) &&
        pyopencv_to(pyobj_probs, probs, ArgInfo("probs", 1)) )
    {
        ERRWRAP2(retval = _self_->trainM(samples, probs0, logLikelihoods, labels, probs));
        return Py_BuildValue("(NNNN)", pyopencv_from(retval), pyopencv_from(logLikelihoods), pyopencv_from(labels), pyopencv_from(probs));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_samples = NULL;
    UMat samples;
    PyObject* pyobj_probs0 = NULL;
    UMat probs0;
    PyObject* pyobj_logLikelihoods = NULL;
    UMat logLikelihoods;
    PyObject* pyobj_labels = NULL;
    UMat labels;
    PyObject* pyobj_probs = NULL;
    UMat probs;
    bool retval;

    const char* keywords[] = { "samples", "probs0", "logLikelihoods", "labels", "probs", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|OOO:ml_EM.trainM", (char**)keywords, &pyobj_samples, &pyobj_probs0, &pyobj_logLikelihoods, &pyobj_labels, &pyobj_probs) &&
        pyopencv_to(pyobj_samples, samples, ArgInfo("samples", 0)) &&
        pyopencv_to(pyobj_probs0, probs0, ArgInfo("probs0", 0)) &&
        pyopencv_to(pyobj_logLikelihoods, logLikelihoods, ArgInfo("logLikelihoods", 1)) &&
        pyopencv_to(pyobj_labels, labels, ArgInfo("labels", 1)) &&
        pyopencv_to(pyobj_probs, probs, ArgInfo("probs", 1)) )
    {
        ERRWRAP2(retval = _self_->trainM(samples, probs0, logLikelihoods, labels, probs));
        return Py_BuildValue("(NNNN)", pyopencv_from(retval), pyopencv_from(logLikelihoods), pyopencv_from(labels), pyopencv_from(probs));
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_ml_EM_methods[] =
{
    {"getClustersNumber", (PyCFunction)pyopencv_cv_ml_ml_EM_getClustersNumber, METH_VARARGS | METH_KEYWORDS, "getClustersNumber() -> retval"},
    {"getCovarianceMatrixType", (PyCFunction)pyopencv_cv_ml_ml_EM_getCovarianceMatrixType, METH_VARARGS | METH_KEYWORDS, "getCovarianceMatrixType() -> retval"},
    {"getCovs", (PyCFunction)pyopencv_cv_ml_ml_EM_getCovs, METH_VARARGS | METH_KEYWORDS, "getCovs([, covs]) -> covs"},
    {"getMeans", (PyCFunction)pyopencv_cv_ml_ml_EM_getMeans, METH_VARARGS | METH_KEYWORDS, "getMeans() -> retval"},
    {"getTermCriteria", (PyCFunction)pyopencv_cv_ml_ml_EM_getTermCriteria, METH_VARARGS | METH_KEYWORDS, "getTermCriteria() -> retval"},
    {"getWeights", (PyCFunction)pyopencv_cv_ml_ml_EM_getWeights, METH_VARARGS | METH_KEYWORDS, "getWeights() -> retval"},
    {"predict", (PyCFunction)pyopencv_cv_ml_ml_EM_predict, METH_VARARGS | METH_KEYWORDS, "predict(samples[, results[, flags]]) -> retval, results"},
    {"predict2", (PyCFunction)pyopencv_cv_ml_ml_EM_predict2, METH_VARARGS | METH_KEYWORDS, "predict2(sample[, probs]) -> retval, probs"},
    {"setClustersNumber", (PyCFunction)pyopencv_cv_ml_ml_EM_setClustersNumber, METH_VARARGS | METH_KEYWORDS, "setClustersNumber(val) -> None"},
    {"setCovarianceMatrixType", (PyCFunction)pyopencv_cv_ml_ml_EM_setCovarianceMatrixType, METH_VARARGS | METH_KEYWORDS, "setCovarianceMatrixType(val) -> None"},
    {"setTermCriteria", (PyCFunction)pyopencv_cv_ml_ml_EM_setTermCriteria, METH_VARARGS | METH_KEYWORDS, "setTermCriteria(val) -> None"},
    {"trainE", (PyCFunction)pyopencv_cv_ml_ml_EM_trainE, METH_VARARGS | METH_KEYWORDS, "trainE(samples, means0[, covs0[, weights0[, logLikelihoods[, labels[, probs]]]]]) -> retval, logLikelihoods, labels, probs"},
    {"trainEM", (PyCFunction)pyopencv_cv_ml_ml_EM_trainEM, METH_VARARGS | METH_KEYWORDS, "trainEM(samples[, logLikelihoods[, labels[, probs]]]) -> retval, logLikelihoods, labels, probs"},
    {"trainM", (PyCFunction)pyopencv_cv_ml_ml_EM_trainM, METH_VARARGS | METH_KEYWORDS, "trainM(samples, probs0[, logLikelihoods[, labels[, probs]]]) -> retval, logLikelihoods, labels, probs"},

    {NULL,          NULL}
};

static void pyopencv_ml_EM_specials(void)
{
    pyopencv_ml_EM_Type.tp_base = &pyopencv_ml_StatModel_Type;
    pyopencv_ml_EM_Type.tp_dealloc = pyopencv_ml_EM_dealloc;
    pyopencv_ml_EM_Type.tp_repr = pyopencv_ml_EM_repr;
    pyopencv_ml_EM_Type.tp_getset = pyopencv_ml_EM_getseters;
    pyopencv_ml_EM_Type.tp_methods = pyopencv_ml_EM_methods;
}

static PyObject* pyopencv_ml_DTrees_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<ml_DTrees %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_ml_DTrees_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_ml_ml_DTrees_getCVFolds(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_DTrees_Type))
        return failmsgp("Incorrect type of self (must be 'ml_DTrees' or its derivative)");
    cv::ml::DTrees* _self_ = dynamic_cast<cv::ml::DTrees*>(((pyopencv_ml_DTrees_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getCVFolds());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_DTrees_getMaxCategories(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_DTrees_Type))
        return failmsgp("Incorrect type of self (must be 'ml_DTrees' or its derivative)");
    cv::ml::DTrees* _self_ = dynamic_cast<cv::ml::DTrees*>(((pyopencv_ml_DTrees_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getMaxCategories());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_DTrees_getMaxDepth(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_DTrees_Type))
        return failmsgp("Incorrect type of self (must be 'ml_DTrees' or its derivative)");
    cv::ml::DTrees* _self_ = dynamic_cast<cv::ml::DTrees*>(((pyopencv_ml_DTrees_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getMaxDepth());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_DTrees_getMinSampleCount(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_DTrees_Type))
        return failmsgp("Incorrect type of self (must be 'ml_DTrees' or its derivative)");
    cv::ml::DTrees* _self_ = dynamic_cast<cv::ml::DTrees*>(((pyopencv_ml_DTrees_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getMinSampleCount());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_DTrees_getPriors(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_DTrees_Type))
        return failmsgp("Incorrect type of self (must be 'ml_DTrees' or its derivative)");
    cv::ml::DTrees* _self_ = dynamic_cast<cv::ml::DTrees*>(((pyopencv_ml_DTrees_t*)self)->v.get());
    cv::Mat retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getPriors());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_DTrees_getRegressionAccuracy(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_DTrees_Type))
        return failmsgp("Incorrect type of self (must be 'ml_DTrees' or its derivative)");
    cv::ml::DTrees* _self_ = dynamic_cast<cv::ml::DTrees*>(((pyopencv_ml_DTrees_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getRegressionAccuracy());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_DTrees_getTruncatePrunedTree(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_DTrees_Type))
        return failmsgp("Incorrect type of self (must be 'ml_DTrees' or its derivative)");
    cv::ml::DTrees* _self_ = dynamic_cast<cv::ml::DTrees*>(((pyopencv_ml_DTrees_t*)self)->v.get());
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getTruncatePrunedTree());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_DTrees_getUse1SERule(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_DTrees_Type))
        return failmsgp("Incorrect type of self (must be 'ml_DTrees' or its derivative)");
    cv::ml::DTrees* _self_ = dynamic_cast<cv::ml::DTrees*>(((pyopencv_ml_DTrees_t*)self)->v.get());
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getUse1SERule());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_DTrees_getUseSurrogates(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_DTrees_Type))
        return failmsgp("Incorrect type of self (must be 'ml_DTrees' or its derivative)");
    cv::ml::DTrees* _self_ = dynamic_cast<cv::ml::DTrees*>(((pyopencv_ml_DTrees_t*)self)->v.get());
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getUseSurrogates());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_DTrees_setCVFolds(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_DTrees_Type))
        return failmsgp("Incorrect type of self (must be 'ml_DTrees' or its derivative)");
    cv::ml::DTrees* _self_ = dynamic_cast<cv::ml::DTrees*>(((pyopencv_ml_DTrees_t*)self)->v.get());
    int val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:ml_DTrees.setCVFolds", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setCVFolds(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_DTrees_setMaxCategories(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_DTrees_Type))
        return failmsgp("Incorrect type of self (must be 'ml_DTrees' or its derivative)");
    cv::ml::DTrees* _self_ = dynamic_cast<cv::ml::DTrees*>(((pyopencv_ml_DTrees_t*)self)->v.get());
    int val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:ml_DTrees.setMaxCategories", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setMaxCategories(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_DTrees_setMaxDepth(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_DTrees_Type))
        return failmsgp("Incorrect type of self (must be 'ml_DTrees' or its derivative)");
    cv::ml::DTrees* _self_ = dynamic_cast<cv::ml::DTrees*>(((pyopencv_ml_DTrees_t*)self)->v.get());
    int val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:ml_DTrees.setMaxDepth", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setMaxDepth(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_DTrees_setMinSampleCount(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_DTrees_Type))
        return failmsgp("Incorrect type of self (must be 'ml_DTrees' or its derivative)");
    cv::ml::DTrees* _self_ = dynamic_cast<cv::ml::DTrees*>(((pyopencv_ml_DTrees_t*)self)->v.get());
    int val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:ml_DTrees.setMinSampleCount", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setMinSampleCount(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_DTrees_setPriors(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_DTrees_Type))
        return failmsgp("Incorrect type of self (must be 'ml_DTrees' or its derivative)");
    cv::ml::DTrees* _self_ = dynamic_cast<cv::ml::DTrees*>(((pyopencv_ml_DTrees_t*)self)->v.get());
    {
    PyObject* pyobj_val = NULL;
    Mat val;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:ml_DTrees.setPriors", (char**)keywords, &pyobj_val) &&
        pyopencv_to(pyobj_val, val, ArgInfo("val", 0)) )
    {
        ERRWRAP2(_self_->setPriors(val));
        Py_RETURN_NONE;
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_val = NULL;
    Mat val;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:ml_DTrees.setPriors", (char**)keywords, &pyobj_val) &&
        pyopencv_to(pyobj_val, val, ArgInfo("val", 0)) )
    {
        ERRWRAP2(_self_->setPriors(val));
        Py_RETURN_NONE;
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_DTrees_setRegressionAccuracy(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_DTrees_Type))
        return failmsgp("Incorrect type of self (must be 'ml_DTrees' or its derivative)");
    cv::ml::DTrees* _self_ = dynamic_cast<cv::ml::DTrees*>(((pyopencv_ml_DTrees_t*)self)->v.get());
    float val=0.f;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:ml_DTrees.setRegressionAccuracy", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setRegressionAccuracy(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_DTrees_setTruncatePrunedTree(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_DTrees_Type))
        return failmsgp("Incorrect type of self (must be 'ml_DTrees' or its derivative)");
    cv::ml::DTrees* _self_ = dynamic_cast<cv::ml::DTrees*>(((pyopencv_ml_DTrees_t*)self)->v.get());
    bool val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "b:ml_DTrees.setTruncatePrunedTree", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setTruncatePrunedTree(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_DTrees_setUse1SERule(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_DTrees_Type))
        return failmsgp("Incorrect type of self (must be 'ml_DTrees' or its derivative)");
    cv::ml::DTrees* _self_ = dynamic_cast<cv::ml::DTrees*>(((pyopencv_ml_DTrees_t*)self)->v.get());
    bool val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "b:ml_DTrees.setUse1SERule", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setUse1SERule(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_DTrees_setUseSurrogates(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_DTrees_Type))
        return failmsgp("Incorrect type of self (must be 'ml_DTrees' or its derivative)");
    cv::ml::DTrees* _self_ = dynamic_cast<cv::ml::DTrees*>(((pyopencv_ml_DTrees_t*)self)->v.get());
    bool val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "b:ml_DTrees.setUseSurrogates", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setUseSurrogates(val));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_ml_DTrees_methods[] =
{
    {"getCVFolds", (PyCFunction)pyopencv_cv_ml_ml_DTrees_getCVFolds, METH_VARARGS | METH_KEYWORDS, "getCVFolds() -> retval"},
    {"getMaxCategories", (PyCFunction)pyopencv_cv_ml_ml_DTrees_getMaxCategories, METH_VARARGS | METH_KEYWORDS, "getMaxCategories() -> retval"},
    {"getMaxDepth", (PyCFunction)pyopencv_cv_ml_ml_DTrees_getMaxDepth, METH_VARARGS | METH_KEYWORDS, "getMaxDepth() -> retval"},
    {"getMinSampleCount", (PyCFunction)pyopencv_cv_ml_ml_DTrees_getMinSampleCount, METH_VARARGS | METH_KEYWORDS, "getMinSampleCount() -> retval"},
    {"getPriors", (PyCFunction)pyopencv_cv_ml_ml_DTrees_getPriors, METH_VARARGS | METH_KEYWORDS, "getPriors() -> retval"},
    {"getRegressionAccuracy", (PyCFunction)pyopencv_cv_ml_ml_DTrees_getRegressionAccuracy, METH_VARARGS | METH_KEYWORDS, "getRegressionAccuracy() -> retval"},
    {"getTruncatePrunedTree", (PyCFunction)pyopencv_cv_ml_ml_DTrees_getTruncatePrunedTree, METH_VARARGS | METH_KEYWORDS, "getTruncatePrunedTree() -> retval"},
    {"getUse1SERule", (PyCFunction)pyopencv_cv_ml_ml_DTrees_getUse1SERule, METH_VARARGS | METH_KEYWORDS, "getUse1SERule() -> retval"},
    {"getUseSurrogates", (PyCFunction)pyopencv_cv_ml_ml_DTrees_getUseSurrogates, METH_VARARGS | METH_KEYWORDS, "getUseSurrogates() -> retval"},
    {"setCVFolds", (PyCFunction)pyopencv_cv_ml_ml_DTrees_setCVFolds, METH_VARARGS | METH_KEYWORDS, "setCVFolds(val) -> None"},
    {"setMaxCategories", (PyCFunction)pyopencv_cv_ml_ml_DTrees_setMaxCategories, METH_VARARGS | METH_KEYWORDS, "setMaxCategories(val) -> None"},
    {"setMaxDepth", (PyCFunction)pyopencv_cv_ml_ml_DTrees_setMaxDepth, METH_VARARGS | METH_KEYWORDS, "setMaxDepth(val) -> None"},
    {"setMinSampleCount", (PyCFunction)pyopencv_cv_ml_ml_DTrees_setMinSampleCount, METH_VARARGS | METH_KEYWORDS, "setMinSampleCount(val) -> None"},
    {"setPriors", (PyCFunction)pyopencv_cv_ml_ml_DTrees_setPriors, METH_VARARGS | METH_KEYWORDS, "setPriors(val) -> None"},
    {"setRegressionAccuracy", (PyCFunction)pyopencv_cv_ml_ml_DTrees_setRegressionAccuracy, METH_VARARGS | METH_KEYWORDS, "setRegressionAccuracy(val) -> None"},
    {"setTruncatePrunedTree", (PyCFunction)pyopencv_cv_ml_ml_DTrees_setTruncatePrunedTree, METH_VARARGS | METH_KEYWORDS, "setTruncatePrunedTree(val) -> None"},
    {"setUse1SERule", (PyCFunction)pyopencv_cv_ml_ml_DTrees_setUse1SERule, METH_VARARGS | METH_KEYWORDS, "setUse1SERule(val) -> None"},
    {"setUseSurrogates", (PyCFunction)pyopencv_cv_ml_ml_DTrees_setUseSurrogates, METH_VARARGS | METH_KEYWORDS, "setUseSurrogates(val) -> None"},

    {NULL,          NULL}
};

static void pyopencv_ml_DTrees_specials(void)
{
    pyopencv_ml_DTrees_Type.tp_base = &pyopencv_ml_StatModel_Type;
    pyopencv_ml_DTrees_Type.tp_dealloc = pyopencv_ml_DTrees_dealloc;
    pyopencv_ml_DTrees_Type.tp_repr = pyopencv_ml_DTrees_repr;
    pyopencv_ml_DTrees_Type.tp_getset = pyopencv_ml_DTrees_getseters;
    pyopencv_ml_DTrees_Type.tp_methods = pyopencv_ml_DTrees_methods;
}

static PyObject* pyopencv_ml_RTrees_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<ml_RTrees %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_ml_RTrees_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_ml_ml_RTrees_getActiveVarCount(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_RTrees_Type))
        return failmsgp("Incorrect type of self (must be 'ml_RTrees' or its derivative)");
    cv::ml::RTrees* _self_ = dynamic_cast<cv::ml::RTrees*>(((pyopencv_ml_RTrees_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getActiveVarCount());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_RTrees_getCalculateVarImportance(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_RTrees_Type))
        return failmsgp("Incorrect type of self (must be 'ml_RTrees' or its derivative)");
    cv::ml::RTrees* _self_ = dynamic_cast<cv::ml::RTrees*>(((pyopencv_ml_RTrees_t*)self)->v.get());
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getCalculateVarImportance());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_RTrees_getTermCriteria(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_RTrees_Type))
        return failmsgp("Incorrect type of self (must be 'ml_RTrees' or its derivative)");
    cv::ml::RTrees* _self_ = dynamic_cast<cv::ml::RTrees*>(((pyopencv_ml_RTrees_t*)self)->v.get());
    TermCriteria retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getTermCriteria());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_RTrees_getVarImportance(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_RTrees_Type))
        return failmsgp("Incorrect type of self (must be 'ml_RTrees' or its derivative)");
    cv::ml::RTrees* _self_ = dynamic_cast<cv::ml::RTrees*>(((pyopencv_ml_RTrees_t*)self)->v.get());
    Mat retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getVarImportance());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_RTrees_setActiveVarCount(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_RTrees_Type))
        return failmsgp("Incorrect type of self (must be 'ml_RTrees' or its derivative)");
    cv::ml::RTrees* _self_ = dynamic_cast<cv::ml::RTrees*>(((pyopencv_ml_RTrees_t*)self)->v.get());
    int val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:ml_RTrees.setActiveVarCount", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setActiveVarCount(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_RTrees_setCalculateVarImportance(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_RTrees_Type))
        return failmsgp("Incorrect type of self (must be 'ml_RTrees' or its derivative)");
    cv::ml::RTrees* _self_ = dynamic_cast<cv::ml::RTrees*>(((pyopencv_ml_RTrees_t*)self)->v.get());
    bool val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "b:ml_RTrees.setCalculateVarImportance", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setCalculateVarImportance(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_RTrees_setTermCriteria(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_RTrees_Type))
        return failmsgp("Incorrect type of self (must be 'ml_RTrees' or its derivative)");
    cv::ml::RTrees* _self_ = dynamic_cast<cv::ml::RTrees*>(((pyopencv_ml_RTrees_t*)self)->v.get());
    PyObject* pyobj_val = NULL;
    TermCriteria val;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:ml_RTrees.setTermCriteria", (char**)keywords, &pyobj_val) &&
        pyopencv_to(pyobj_val, val, ArgInfo("val", 0)) )
    {
        ERRWRAP2(_self_->setTermCriteria(val));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_ml_RTrees_methods[] =
{
    {"getActiveVarCount", (PyCFunction)pyopencv_cv_ml_ml_RTrees_getActiveVarCount, METH_VARARGS | METH_KEYWORDS, "getActiveVarCount() -> retval"},
    {"getCalculateVarImportance", (PyCFunction)pyopencv_cv_ml_ml_RTrees_getCalculateVarImportance, METH_VARARGS | METH_KEYWORDS, "getCalculateVarImportance() -> retval"},
    {"getTermCriteria", (PyCFunction)pyopencv_cv_ml_ml_RTrees_getTermCriteria, METH_VARARGS | METH_KEYWORDS, "getTermCriteria() -> retval"},
    {"getVarImportance", (PyCFunction)pyopencv_cv_ml_ml_RTrees_getVarImportance, METH_VARARGS | METH_KEYWORDS, "getVarImportance() -> retval"},
    {"setActiveVarCount", (PyCFunction)pyopencv_cv_ml_ml_RTrees_setActiveVarCount, METH_VARARGS | METH_KEYWORDS, "setActiveVarCount(val) -> None"},
    {"setCalculateVarImportance", (PyCFunction)pyopencv_cv_ml_ml_RTrees_setCalculateVarImportance, METH_VARARGS | METH_KEYWORDS, "setCalculateVarImportance(val) -> None"},
    {"setTermCriteria", (PyCFunction)pyopencv_cv_ml_ml_RTrees_setTermCriteria, METH_VARARGS | METH_KEYWORDS, "setTermCriteria(val) -> None"},

    {NULL,          NULL}
};

static void pyopencv_ml_RTrees_specials(void)
{
    pyopencv_ml_RTrees_Type.tp_base = &pyopencv_ml_DTrees_Type;
    pyopencv_ml_RTrees_Type.tp_dealloc = pyopencv_ml_RTrees_dealloc;
    pyopencv_ml_RTrees_Type.tp_repr = pyopencv_ml_RTrees_repr;
    pyopencv_ml_RTrees_Type.tp_getset = pyopencv_ml_RTrees_getseters;
    pyopencv_ml_RTrees_Type.tp_methods = pyopencv_ml_RTrees_methods;
}

static PyObject* pyopencv_ml_Boost_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<ml_Boost %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_ml_Boost_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_ml_ml_Boost_getBoostType(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_Boost_Type))
        return failmsgp("Incorrect type of self (must be 'ml_Boost' or its derivative)");
    cv::ml::Boost* _self_ = ((pyopencv_ml_Boost_t*)self)->v.get();
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getBoostType());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_Boost_getWeakCount(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_Boost_Type))
        return failmsgp("Incorrect type of self (must be 'ml_Boost' or its derivative)");
    cv::ml::Boost* _self_ = ((pyopencv_ml_Boost_t*)self)->v.get();
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getWeakCount());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_Boost_getWeightTrimRate(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_Boost_Type))
        return failmsgp("Incorrect type of self (must be 'ml_Boost' or its derivative)");
    cv::ml::Boost* _self_ = ((pyopencv_ml_Boost_t*)self)->v.get();
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getWeightTrimRate());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_Boost_setBoostType(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_Boost_Type))
        return failmsgp("Incorrect type of self (must be 'ml_Boost' or its derivative)");
    cv::ml::Boost* _self_ = ((pyopencv_ml_Boost_t*)self)->v.get();
    int val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:ml_Boost.setBoostType", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setBoostType(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_Boost_setWeakCount(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_Boost_Type))
        return failmsgp("Incorrect type of self (must be 'ml_Boost' or its derivative)");
    cv::ml::Boost* _self_ = ((pyopencv_ml_Boost_t*)self)->v.get();
    int val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:ml_Boost.setWeakCount", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setWeakCount(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_Boost_setWeightTrimRate(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_Boost_Type))
        return failmsgp("Incorrect type of self (must be 'ml_Boost' or its derivative)");
    cv::ml::Boost* _self_ = ((pyopencv_ml_Boost_t*)self)->v.get();
    double val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:ml_Boost.setWeightTrimRate", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setWeightTrimRate(val));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_ml_Boost_methods[] =
{
    {"getBoostType", (PyCFunction)pyopencv_cv_ml_ml_Boost_getBoostType, METH_VARARGS | METH_KEYWORDS, "getBoostType() -> retval"},
    {"getWeakCount", (PyCFunction)pyopencv_cv_ml_ml_Boost_getWeakCount, METH_VARARGS | METH_KEYWORDS, "getWeakCount() -> retval"},
    {"getWeightTrimRate", (PyCFunction)pyopencv_cv_ml_ml_Boost_getWeightTrimRate, METH_VARARGS | METH_KEYWORDS, "getWeightTrimRate() -> retval"},
    {"setBoostType", (PyCFunction)pyopencv_cv_ml_ml_Boost_setBoostType, METH_VARARGS | METH_KEYWORDS, "setBoostType(val) -> None"},
    {"setWeakCount", (PyCFunction)pyopencv_cv_ml_ml_Boost_setWeakCount, METH_VARARGS | METH_KEYWORDS, "setWeakCount(val) -> None"},
    {"setWeightTrimRate", (PyCFunction)pyopencv_cv_ml_ml_Boost_setWeightTrimRate, METH_VARARGS | METH_KEYWORDS, "setWeightTrimRate(val) -> None"},

    {NULL,          NULL}
};

static void pyopencv_ml_Boost_specials(void)
{
    pyopencv_ml_Boost_Type.tp_base = &pyopencv_ml_DTrees_Type;
    pyopencv_ml_Boost_Type.tp_dealloc = pyopencv_ml_Boost_dealloc;
    pyopencv_ml_Boost_Type.tp_repr = pyopencv_ml_Boost_repr;
    pyopencv_ml_Boost_Type.tp_getset = pyopencv_ml_Boost_getseters;
    pyopencv_ml_Boost_Type.tp_methods = pyopencv_ml_Boost_methods;
}

static PyObject* pyopencv_ml_ANN_MLP_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<ml_ANN_MLP %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_ml_ANN_MLP_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_ml_ml_ANN_MLP_getBackpropMomentumScale(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_ANN_MLP_Type))
        return failmsgp("Incorrect type of self (must be 'ml_ANN_MLP' or its derivative)");
    cv::ml::ANN_MLP* _self_ = dynamic_cast<cv::ml::ANN_MLP*>(((pyopencv_ml_ANN_MLP_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getBackpropMomentumScale());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_ANN_MLP_getBackpropWeightScale(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_ANN_MLP_Type))
        return failmsgp("Incorrect type of self (must be 'ml_ANN_MLP' or its derivative)");
    cv::ml::ANN_MLP* _self_ = dynamic_cast<cv::ml::ANN_MLP*>(((pyopencv_ml_ANN_MLP_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getBackpropWeightScale());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_ANN_MLP_getLayerSizes(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_ANN_MLP_Type))
        return failmsgp("Incorrect type of self (must be 'ml_ANN_MLP' or its derivative)");
    cv::ml::ANN_MLP* _self_ = dynamic_cast<cv::ml::ANN_MLP*>(((pyopencv_ml_ANN_MLP_t*)self)->v.get());
    cv::Mat retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getLayerSizes());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_ANN_MLP_getRpropDW0(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_ANN_MLP_Type))
        return failmsgp("Incorrect type of self (must be 'ml_ANN_MLP' or its derivative)");
    cv::ml::ANN_MLP* _self_ = dynamic_cast<cv::ml::ANN_MLP*>(((pyopencv_ml_ANN_MLP_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getRpropDW0());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_ANN_MLP_getRpropDWMax(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_ANN_MLP_Type))
        return failmsgp("Incorrect type of self (must be 'ml_ANN_MLP' or its derivative)");
    cv::ml::ANN_MLP* _self_ = dynamic_cast<cv::ml::ANN_MLP*>(((pyopencv_ml_ANN_MLP_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getRpropDWMax());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_ANN_MLP_getRpropDWMin(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_ANN_MLP_Type))
        return failmsgp("Incorrect type of self (must be 'ml_ANN_MLP' or its derivative)");
    cv::ml::ANN_MLP* _self_ = dynamic_cast<cv::ml::ANN_MLP*>(((pyopencv_ml_ANN_MLP_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getRpropDWMin());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_ANN_MLP_getRpropDWMinus(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_ANN_MLP_Type))
        return failmsgp("Incorrect type of self (must be 'ml_ANN_MLP' or its derivative)");
    cv::ml::ANN_MLP* _self_ = dynamic_cast<cv::ml::ANN_MLP*>(((pyopencv_ml_ANN_MLP_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getRpropDWMinus());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_ANN_MLP_getRpropDWPlus(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_ANN_MLP_Type))
        return failmsgp("Incorrect type of self (must be 'ml_ANN_MLP' or its derivative)");
    cv::ml::ANN_MLP* _self_ = dynamic_cast<cv::ml::ANN_MLP*>(((pyopencv_ml_ANN_MLP_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getRpropDWPlus());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_ANN_MLP_getTermCriteria(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_ANN_MLP_Type))
        return failmsgp("Incorrect type of self (must be 'ml_ANN_MLP' or its derivative)");
    cv::ml::ANN_MLP* _self_ = dynamic_cast<cv::ml::ANN_MLP*>(((pyopencv_ml_ANN_MLP_t*)self)->v.get());
    TermCriteria retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getTermCriteria());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_ANN_MLP_getTrainMethod(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_ANN_MLP_Type))
        return failmsgp("Incorrect type of self (must be 'ml_ANN_MLP' or its derivative)");
    cv::ml::ANN_MLP* _self_ = dynamic_cast<cv::ml::ANN_MLP*>(((pyopencv_ml_ANN_MLP_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getTrainMethod());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_ANN_MLP_getWeights(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_ANN_MLP_Type))
        return failmsgp("Incorrect type of self (must be 'ml_ANN_MLP' or its derivative)");
    cv::ml::ANN_MLP* _self_ = dynamic_cast<cv::ml::ANN_MLP*>(((pyopencv_ml_ANN_MLP_t*)self)->v.get());
    int layerIdx=0;
    Mat retval;

    const char* keywords[] = { "layerIdx", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:ml_ANN_MLP.getWeights", (char**)keywords, &layerIdx) )
    {
        ERRWRAP2(retval = _self_->getWeights(layerIdx));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_ANN_MLP_setActivationFunction(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_ANN_MLP_Type))
        return failmsgp("Incorrect type of self (must be 'ml_ANN_MLP' or its derivative)");
    cv::ml::ANN_MLP* _self_ = dynamic_cast<cv::ml::ANN_MLP*>(((pyopencv_ml_ANN_MLP_t*)self)->v.get());
    int type=0;
    double param1=0;
    double param2=0;

    const char* keywords[] = { "type", "param1", "param2", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i|dd:ml_ANN_MLP.setActivationFunction", (char**)keywords, &type, &param1, &param2) )
    {
        ERRWRAP2(_self_->setActivationFunction(type, param1, param2));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_ANN_MLP_setBackpropMomentumScale(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_ANN_MLP_Type))
        return failmsgp("Incorrect type of self (must be 'ml_ANN_MLP' or its derivative)");
    cv::ml::ANN_MLP* _self_ = dynamic_cast<cv::ml::ANN_MLP*>(((pyopencv_ml_ANN_MLP_t*)self)->v.get());
    double val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:ml_ANN_MLP.setBackpropMomentumScale", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setBackpropMomentumScale(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_ANN_MLP_setBackpropWeightScale(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_ANN_MLP_Type))
        return failmsgp("Incorrect type of self (must be 'ml_ANN_MLP' or its derivative)");
    cv::ml::ANN_MLP* _self_ = dynamic_cast<cv::ml::ANN_MLP*>(((pyopencv_ml_ANN_MLP_t*)self)->v.get());
    double val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:ml_ANN_MLP.setBackpropWeightScale", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setBackpropWeightScale(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_ANN_MLP_setLayerSizes(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_ANN_MLP_Type))
        return failmsgp("Incorrect type of self (must be 'ml_ANN_MLP' or its derivative)");
    cv::ml::ANN_MLP* _self_ = dynamic_cast<cv::ml::ANN_MLP*>(((pyopencv_ml_ANN_MLP_t*)self)->v.get());
    {
    PyObject* pyobj__layer_sizes = NULL;
    Mat _layer_sizes;

    const char* keywords[] = { "_layer_sizes", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:ml_ANN_MLP.setLayerSizes", (char**)keywords, &pyobj__layer_sizes) &&
        pyopencv_to(pyobj__layer_sizes, _layer_sizes, ArgInfo("_layer_sizes", 0)) )
    {
        ERRWRAP2(_self_->setLayerSizes(_layer_sizes));
        Py_RETURN_NONE;
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj__layer_sizes = NULL;
    UMat _layer_sizes;

    const char* keywords[] = { "_layer_sizes", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:ml_ANN_MLP.setLayerSizes", (char**)keywords, &pyobj__layer_sizes) &&
        pyopencv_to(pyobj__layer_sizes, _layer_sizes, ArgInfo("_layer_sizes", 0)) )
    {
        ERRWRAP2(_self_->setLayerSizes(_layer_sizes));
        Py_RETURN_NONE;
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_ANN_MLP_setRpropDW0(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_ANN_MLP_Type))
        return failmsgp("Incorrect type of self (must be 'ml_ANN_MLP' or its derivative)");
    cv::ml::ANN_MLP* _self_ = dynamic_cast<cv::ml::ANN_MLP*>(((pyopencv_ml_ANN_MLP_t*)self)->v.get());
    double val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:ml_ANN_MLP.setRpropDW0", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setRpropDW0(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_ANN_MLP_setRpropDWMax(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_ANN_MLP_Type))
        return failmsgp("Incorrect type of self (must be 'ml_ANN_MLP' or its derivative)");
    cv::ml::ANN_MLP* _self_ = dynamic_cast<cv::ml::ANN_MLP*>(((pyopencv_ml_ANN_MLP_t*)self)->v.get());
    double val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:ml_ANN_MLP.setRpropDWMax", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setRpropDWMax(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_ANN_MLP_setRpropDWMin(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_ANN_MLP_Type))
        return failmsgp("Incorrect type of self (must be 'ml_ANN_MLP' or its derivative)");
    cv::ml::ANN_MLP* _self_ = dynamic_cast<cv::ml::ANN_MLP*>(((pyopencv_ml_ANN_MLP_t*)self)->v.get());
    double val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:ml_ANN_MLP.setRpropDWMin", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setRpropDWMin(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_ANN_MLP_setRpropDWMinus(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_ANN_MLP_Type))
        return failmsgp("Incorrect type of self (must be 'ml_ANN_MLP' or its derivative)");
    cv::ml::ANN_MLP* _self_ = dynamic_cast<cv::ml::ANN_MLP*>(((pyopencv_ml_ANN_MLP_t*)self)->v.get());
    double val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:ml_ANN_MLP.setRpropDWMinus", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setRpropDWMinus(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_ANN_MLP_setRpropDWPlus(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_ANN_MLP_Type))
        return failmsgp("Incorrect type of self (must be 'ml_ANN_MLP' or its derivative)");
    cv::ml::ANN_MLP* _self_ = dynamic_cast<cv::ml::ANN_MLP*>(((pyopencv_ml_ANN_MLP_t*)self)->v.get());
    double val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:ml_ANN_MLP.setRpropDWPlus", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setRpropDWPlus(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_ANN_MLP_setTermCriteria(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_ANN_MLP_Type))
        return failmsgp("Incorrect type of self (must be 'ml_ANN_MLP' or its derivative)");
    cv::ml::ANN_MLP* _self_ = dynamic_cast<cv::ml::ANN_MLP*>(((pyopencv_ml_ANN_MLP_t*)self)->v.get());
    PyObject* pyobj_val = NULL;
    TermCriteria val;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:ml_ANN_MLP.setTermCriteria", (char**)keywords, &pyobj_val) &&
        pyopencv_to(pyobj_val, val, ArgInfo("val", 0)) )
    {
        ERRWRAP2(_self_->setTermCriteria(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_ANN_MLP_setTrainMethod(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_ANN_MLP_Type))
        return failmsgp("Incorrect type of self (must be 'ml_ANN_MLP' or its derivative)");
    cv::ml::ANN_MLP* _self_ = dynamic_cast<cv::ml::ANN_MLP*>(((pyopencv_ml_ANN_MLP_t*)self)->v.get());
    int method=0;
    double param1=0;
    double param2=0;

    const char* keywords[] = { "method", "param1", "param2", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i|dd:ml_ANN_MLP.setTrainMethod", (char**)keywords, &method, &param1, &param2) )
    {
        ERRWRAP2(_self_->setTrainMethod(method, param1, param2));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_ml_ANN_MLP_methods[] =
{
    {"getBackpropMomentumScale", (PyCFunction)pyopencv_cv_ml_ml_ANN_MLP_getBackpropMomentumScale, METH_VARARGS | METH_KEYWORDS, "getBackpropMomentumScale() -> retval"},
    {"getBackpropWeightScale", (PyCFunction)pyopencv_cv_ml_ml_ANN_MLP_getBackpropWeightScale, METH_VARARGS | METH_KEYWORDS, "getBackpropWeightScale() -> retval"},
    {"getLayerSizes", (PyCFunction)pyopencv_cv_ml_ml_ANN_MLP_getLayerSizes, METH_VARARGS | METH_KEYWORDS, "getLayerSizes() -> retval"},
    {"getRpropDW0", (PyCFunction)pyopencv_cv_ml_ml_ANN_MLP_getRpropDW0, METH_VARARGS | METH_KEYWORDS, "getRpropDW0() -> retval"},
    {"getRpropDWMax", (PyCFunction)pyopencv_cv_ml_ml_ANN_MLP_getRpropDWMax, METH_VARARGS | METH_KEYWORDS, "getRpropDWMax() -> retval"},
    {"getRpropDWMin", (PyCFunction)pyopencv_cv_ml_ml_ANN_MLP_getRpropDWMin, METH_VARARGS | METH_KEYWORDS, "getRpropDWMin() -> retval"},
    {"getRpropDWMinus", (PyCFunction)pyopencv_cv_ml_ml_ANN_MLP_getRpropDWMinus, METH_VARARGS | METH_KEYWORDS, "getRpropDWMinus() -> retval"},
    {"getRpropDWPlus", (PyCFunction)pyopencv_cv_ml_ml_ANN_MLP_getRpropDWPlus, METH_VARARGS | METH_KEYWORDS, "getRpropDWPlus() -> retval"},
    {"getTermCriteria", (PyCFunction)pyopencv_cv_ml_ml_ANN_MLP_getTermCriteria, METH_VARARGS | METH_KEYWORDS, "getTermCriteria() -> retval"},
    {"getTrainMethod", (PyCFunction)pyopencv_cv_ml_ml_ANN_MLP_getTrainMethod, METH_VARARGS | METH_KEYWORDS, "getTrainMethod() -> retval"},
    {"getWeights", (PyCFunction)pyopencv_cv_ml_ml_ANN_MLP_getWeights, METH_VARARGS | METH_KEYWORDS, "getWeights(layerIdx) -> retval"},
    {"setActivationFunction", (PyCFunction)pyopencv_cv_ml_ml_ANN_MLP_setActivationFunction, METH_VARARGS | METH_KEYWORDS, "setActivationFunction(type[, param1[, param2]]) -> None"},
    {"setBackpropMomentumScale", (PyCFunction)pyopencv_cv_ml_ml_ANN_MLP_setBackpropMomentumScale, METH_VARARGS | METH_KEYWORDS, "setBackpropMomentumScale(val) -> None"},
    {"setBackpropWeightScale", (PyCFunction)pyopencv_cv_ml_ml_ANN_MLP_setBackpropWeightScale, METH_VARARGS | METH_KEYWORDS, "setBackpropWeightScale(val) -> None"},
    {"setLayerSizes", (PyCFunction)pyopencv_cv_ml_ml_ANN_MLP_setLayerSizes, METH_VARARGS | METH_KEYWORDS, "setLayerSizes(_layer_sizes) -> None"},
    {"setRpropDW0", (PyCFunction)pyopencv_cv_ml_ml_ANN_MLP_setRpropDW0, METH_VARARGS | METH_KEYWORDS, "setRpropDW0(val) -> None"},
    {"setRpropDWMax", (PyCFunction)pyopencv_cv_ml_ml_ANN_MLP_setRpropDWMax, METH_VARARGS | METH_KEYWORDS, "setRpropDWMax(val) -> None"},
    {"setRpropDWMin", (PyCFunction)pyopencv_cv_ml_ml_ANN_MLP_setRpropDWMin, METH_VARARGS | METH_KEYWORDS, "setRpropDWMin(val) -> None"},
    {"setRpropDWMinus", (PyCFunction)pyopencv_cv_ml_ml_ANN_MLP_setRpropDWMinus, METH_VARARGS | METH_KEYWORDS, "setRpropDWMinus(val) -> None"},
    {"setRpropDWPlus", (PyCFunction)pyopencv_cv_ml_ml_ANN_MLP_setRpropDWPlus, METH_VARARGS | METH_KEYWORDS, "setRpropDWPlus(val) -> None"},
    {"setTermCriteria", (PyCFunction)pyopencv_cv_ml_ml_ANN_MLP_setTermCriteria, METH_VARARGS | METH_KEYWORDS, "setTermCriteria(val) -> None"},
    {"setTrainMethod", (PyCFunction)pyopencv_cv_ml_ml_ANN_MLP_setTrainMethod, METH_VARARGS | METH_KEYWORDS, "setTrainMethod(method[, param1[, param2]]) -> None"},

    {NULL,          NULL}
};

static void pyopencv_ml_ANN_MLP_specials(void)
{
    pyopencv_ml_ANN_MLP_Type.tp_base = &pyopencv_ml_StatModel_Type;
    pyopencv_ml_ANN_MLP_Type.tp_dealloc = pyopencv_ml_ANN_MLP_dealloc;
    pyopencv_ml_ANN_MLP_Type.tp_repr = pyopencv_ml_ANN_MLP_repr;
    pyopencv_ml_ANN_MLP_Type.tp_getset = pyopencv_ml_ANN_MLP_getseters;
    pyopencv_ml_ANN_MLP_Type.tp_methods = pyopencv_ml_ANN_MLP_methods;
}

static PyObject* pyopencv_ml_LogisticRegression_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<ml_LogisticRegression %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_ml_LogisticRegression_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_ml_ml_LogisticRegression_getIterations(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_LogisticRegression_Type))
        return failmsgp("Incorrect type of self (must be 'ml_LogisticRegression' or its derivative)");
    cv::ml::LogisticRegression* _self_ = dynamic_cast<cv::ml::LogisticRegression*>(((pyopencv_ml_LogisticRegression_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getIterations());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_LogisticRegression_getLearningRate(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_LogisticRegression_Type))
        return failmsgp("Incorrect type of self (must be 'ml_LogisticRegression' or its derivative)");
    cv::ml::LogisticRegression* _self_ = dynamic_cast<cv::ml::LogisticRegression*>(((pyopencv_ml_LogisticRegression_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getLearningRate());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_LogisticRegression_getMiniBatchSize(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_LogisticRegression_Type))
        return failmsgp("Incorrect type of self (must be 'ml_LogisticRegression' or its derivative)");
    cv::ml::LogisticRegression* _self_ = dynamic_cast<cv::ml::LogisticRegression*>(((pyopencv_ml_LogisticRegression_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getMiniBatchSize());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_LogisticRegression_getRegularization(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_LogisticRegression_Type))
        return failmsgp("Incorrect type of self (must be 'ml_LogisticRegression' or its derivative)");
    cv::ml::LogisticRegression* _self_ = dynamic_cast<cv::ml::LogisticRegression*>(((pyopencv_ml_LogisticRegression_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getRegularization());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_LogisticRegression_getTermCriteria(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_LogisticRegression_Type))
        return failmsgp("Incorrect type of self (must be 'ml_LogisticRegression' or its derivative)");
    cv::ml::LogisticRegression* _self_ = dynamic_cast<cv::ml::LogisticRegression*>(((pyopencv_ml_LogisticRegression_t*)self)->v.get());
    TermCriteria retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getTermCriteria());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_LogisticRegression_getTrainMethod(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_LogisticRegression_Type))
        return failmsgp("Incorrect type of self (must be 'ml_LogisticRegression' or its derivative)");
    cv::ml::LogisticRegression* _self_ = dynamic_cast<cv::ml::LogisticRegression*>(((pyopencv_ml_LogisticRegression_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getTrainMethod());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_LogisticRegression_get_learnt_thetas(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_LogisticRegression_Type))
        return failmsgp("Incorrect type of self (must be 'ml_LogisticRegression' or its derivative)");
    cv::ml::LogisticRegression* _self_ = dynamic_cast<cv::ml::LogisticRegression*>(((pyopencv_ml_LogisticRegression_t*)self)->v.get());
    Mat retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->get_learnt_thetas());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_LogisticRegression_predict(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_LogisticRegression_Type))
        return failmsgp("Incorrect type of self (must be 'ml_LogisticRegression' or its derivative)");
    cv::ml::LogisticRegression* _self_ = dynamic_cast<cv::ml::LogisticRegression*>(((pyopencv_ml_LogisticRegression_t*)self)->v.get());
    {
    PyObject* pyobj_samples = NULL;
    Mat samples;
    PyObject* pyobj_results = NULL;
    Mat results;
    int flags=0;
    float retval;

    const char* keywords[] = { "samples", "results", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|Oi:ml_LogisticRegression.predict", (char**)keywords, &pyobj_samples, &pyobj_results, &flags) &&
        pyopencv_to(pyobj_samples, samples, ArgInfo("samples", 0)) &&
        pyopencv_to(pyobj_results, results, ArgInfo("results", 1)) )
    {
        ERRWRAP2(retval = _self_->predict(samples, results, flags));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(results));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_samples = NULL;
    UMat samples;
    PyObject* pyobj_results = NULL;
    UMat results;
    int flags=0;
    float retval;

    const char* keywords[] = { "samples", "results", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|Oi:ml_LogisticRegression.predict", (char**)keywords, &pyobj_samples, &pyobj_results, &flags) &&
        pyopencv_to(pyobj_samples, samples, ArgInfo("samples", 0)) &&
        pyopencv_to(pyobj_results, results, ArgInfo("results", 1)) )
    {
        ERRWRAP2(retval = _self_->predict(samples, results, flags));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(results));
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_LogisticRegression_setIterations(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_LogisticRegression_Type))
        return failmsgp("Incorrect type of self (must be 'ml_LogisticRegression' or its derivative)");
    cv::ml::LogisticRegression* _self_ = dynamic_cast<cv::ml::LogisticRegression*>(((pyopencv_ml_LogisticRegression_t*)self)->v.get());
    int val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:ml_LogisticRegression.setIterations", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setIterations(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_LogisticRegression_setLearningRate(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_LogisticRegression_Type))
        return failmsgp("Incorrect type of self (must be 'ml_LogisticRegression' or its derivative)");
    cv::ml::LogisticRegression* _self_ = dynamic_cast<cv::ml::LogisticRegression*>(((pyopencv_ml_LogisticRegression_t*)self)->v.get());
    double val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:ml_LogisticRegression.setLearningRate", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setLearningRate(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_LogisticRegression_setMiniBatchSize(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_LogisticRegression_Type))
        return failmsgp("Incorrect type of self (must be 'ml_LogisticRegression' or its derivative)");
    cv::ml::LogisticRegression* _self_ = dynamic_cast<cv::ml::LogisticRegression*>(((pyopencv_ml_LogisticRegression_t*)self)->v.get());
    int val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:ml_LogisticRegression.setMiniBatchSize", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setMiniBatchSize(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_LogisticRegression_setRegularization(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_LogisticRegression_Type))
        return failmsgp("Incorrect type of self (must be 'ml_LogisticRegression' or its derivative)");
    cv::ml::LogisticRegression* _self_ = dynamic_cast<cv::ml::LogisticRegression*>(((pyopencv_ml_LogisticRegression_t*)self)->v.get());
    int val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:ml_LogisticRegression.setRegularization", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setRegularization(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_LogisticRegression_setTermCriteria(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_LogisticRegression_Type))
        return failmsgp("Incorrect type of self (must be 'ml_LogisticRegression' or its derivative)");
    cv::ml::LogisticRegression* _self_ = dynamic_cast<cv::ml::LogisticRegression*>(((pyopencv_ml_LogisticRegression_t*)self)->v.get());
    PyObject* pyobj_val = NULL;
    TermCriteria val;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:ml_LogisticRegression.setTermCriteria", (char**)keywords, &pyobj_val) &&
        pyopencv_to(pyobj_val, val, ArgInfo("val", 0)) )
    {
        ERRWRAP2(_self_->setTermCriteria(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_LogisticRegression_setTrainMethod(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_LogisticRegression_Type))
        return failmsgp("Incorrect type of self (must be 'ml_LogisticRegression' or its derivative)");
    cv::ml::LogisticRegression* _self_ = dynamic_cast<cv::ml::LogisticRegression*>(((pyopencv_ml_LogisticRegression_t*)self)->v.get());
    int val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:ml_LogisticRegression.setTrainMethod", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setTrainMethod(val));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_ml_LogisticRegression_methods[] =
{
    {"getIterations", (PyCFunction)pyopencv_cv_ml_ml_LogisticRegression_getIterations, METH_VARARGS | METH_KEYWORDS, "getIterations() -> retval"},
    {"getLearningRate", (PyCFunction)pyopencv_cv_ml_ml_LogisticRegression_getLearningRate, METH_VARARGS | METH_KEYWORDS, "getLearningRate() -> retval"},
    {"getMiniBatchSize", (PyCFunction)pyopencv_cv_ml_ml_LogisticRegression_getMiniBatchSize, METH_VARARGS | METH_KEYWORDS, "getMiniBatchSize() -> retval"},
    {"getRegularization", (PyCFunction)pyopencv_cv_ml_ml_LogisticRegression_getRegularization, METH_VARARGS | METH_KEYWORDS, "getRegularization() -> retval"},
    {"getTermCriteria", (PyCFunction)pyopencv_cv_ml_ml_LogisticRegression_getTermCriteria, METH_VARARGS | METH_KEYWORDS, "getTermCriteria() -> retval"},
    {"getTrainMethod", (PyCFunction)pyopencv_cv_ml_ml_LogisticRegression_getTrainMethod, METH_VARARGS | METH_KEYWORDS, "getTrainMethod() -> retval"},
    {"get_learnt_thetas", (PyCFunction)pyopencv_cv_ml_ml_LogisticRegression_get_learnt_thetas, METH_VARARGS | METH_KEYWORDS, "get_learnt_thetas() -> retval"},
    {"predict", (PyCFunction)pyopencv_cv_ml_ml_LogisticRegression_predict, METH_VARARGS | METH_KEYWORDS, "predict(samples[, results[, flags]]) -> retval, results"},
    {"setIterations", (PyCFunction)pyopencv_cv_ml_ml_LogisticRegression_setIterations, METH_VARARGS | METH_KEYWORDS, "setIterations(val) -> None"},
    {"setLearningRate", (PyCFunction)pyopencv_cv_ml_ml_LogisticRegression_setLearningRate, METH_VARARGS | METH_KEYWORDS, "setLearningRate(val) -> None"},
    {"setMiniBatchSize", (PyCFunction)pyopencv_cv_ml_ml_LogisticRegression_setMiniBatchSize, METH_VARARGS | METH_KEYWORDS, "setMiniBatchSize(val) -> None"},
    {"setRegularization", (PyCFunction)pyopencv_cv_ml_ml_LogisticRegression_setRegularization, METH_VARARGS | METH_KEYWORDS, "setRegularization(val) -> None"},
    {"setTermCriteria", (PyCFunction)pyopencv_cv_ml_ml_LogisticRegression_setTermCriteria, METH_VARARGS | METH_KEYWORDS, "setTermCriteria(val) -> None"},
    {"setTrainMethod", (PyCFunction)pyopencv_cv_ml_ml_LogisticRegression_setTrainMethod, METH_VARARGS | METH_KEYWORDS, "setTrainMethod(val) -> None"},

    {NULL,          NULL}
};

static void pyopencv_ml_LogisticRegression_specials(void)
{
    pyopencv_ml_LogisticRegression_Type.tp_base = &pyopencv_ml_StatModel_Type;
    pyopencv_ml_LogisticRegression_Type.tp_dealloc = pyopencv_ml_LogisticRegression_dealloc;
    pyopencv_ml_LogisticRegression_Type.tp_repr = pyopencv_ml_LogisticRegression_repr;
    pyopencv_ml_LogisticRegression_Type.tp_getset = pyopencv_ml_LogisticRegression_getseters;
    pyopencv_ml_LogisticRegression_Type.tp_methods = pyopencv_ml_LogisticRegression_methods;
}

static PyObject* pyopencv_ml_SVMSGD_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<ml_SVMSGD %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_ml_SVMSGD_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_ml_ml_SVMSGD_getInitialStepSize(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_SVMSGD_Type))
        return failmsgp("Incorrect type of self (must be 'ml_SVMSGD' or its derivative)");
    cv::ml::SVMSGD* _self_ = dynamic_cast<cv::ml::SVMSGD*>(((pyopencv_ml_SVMSGD_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getInitialStepSize());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_SVMSGD_getMarginRegularization(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_SVMSGD_Type))
        return failmsgp("Incorrect type of self (must be 'ml_SVMSGD' or its derivative)");
    cv::ml::SVMSGD* _self_ = dynamic_cast<cv::ml::SVMSGD*>(((pyopencv_ml_SVMSGD_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getMarginRegularization());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_SVMSGD_getMarginType(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_SVMSGD_Type))
        return failmsgp("Incorrect type of self (must be 'ml_SVMSGD' or its derivative)");
    cv::ml::SVMSGD* _self_ = dynamic_cast<cv::ml::SVMSGD*>(((pyopencv_ml_SVMSGD_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getMarginType());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_SVMSGD_getShift(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_SVMSGD_Type))
        return failmsgp("Incorrect type of self (must be 'ml_SVMSGD' or its derivative)");
    cv::ml::SVMSGD* _self_ = dynamic_cast<cv::ml::SVMSGD*>(((pyopencv_ml_SVMSGD_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getShift());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_SVMSGD_getStepDecreasingPower(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_SVMSGD_Type))
        return failmsgp("Incorrect type of self (must be 'ml_SVMSGD' or its derivative)");
    cv::ml::SVMSGD* _self_ = dynamic_cast<cv::ml::SVMSGD*>(((pyopencv_ml_SVMSGD_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getStepDecreasingPower());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_SVMSGD_getSvmsgdType(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_SVMSGD_Type))
        return failmsgp("Incorrect type of self (must be 'ml_SVMSGD' or its derivative)");
    cv::ml::SVMSGD* _self_ = dynamic_cast<cv::ml::SVMSGD*>(((pyopencv_ml_SVMSGD_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getSvmsgdType());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_SVMSGD_getTermCriteria(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_SVMSGD_Type))
        return failmsgp("Incorrect type of self (must be 'ml_SVMSGD' or its derivative)");
    cv::ml::SVMSGD* _self_ = dynamic_cast<cv::ml::SVMSGD*>(((pyopencv_ml_SVMSGD_t*)self)->v.get());
    TermCriteria retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getTermCriteria());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_SVMSGD_getWeights(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_SVMSGD_Type))
        return failmsgp("Incorrect type of self (must be 'ml_SVMSGD' or its derivative)");
    cv::ml::SVMSGD* _self_ = dynamic_cast<cv::ml::SVMSGD*>(((pyopencv_ml_SVMSGD_t*)self)->v.get());
    Mat retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getWeights());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_SVMSGD_setInitialStepSize(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_SVMSGD_Type))
        return failmsgp("Incorrect type of self (must be 'ml_SVMSGD' or its derivative)");
    cv::ml::SVMSGD* _self_ = dynamic_cast<cv::ml::SVMSGD*>(((pyopencv_ml_SVMSGD_t*)self)->v.get());
    float InitialStepSize=0.f;

    const char* keywords[] = { "InitialStepSize", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:ml_SVMSGD.setInitialStepSize", (char**)keywords, &InitialStepSize) )
    {
        ERRWRAP2(_self_->setInitialStepSize(InitialStepSize));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_SVMSGD_setMarginRegularization(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_SVMSGD_Type))
        return failmsgp("Incorrect type of self (must be 'ml_SVMSGD' or its derivative)");
    cv::ml::SVMSGD* _self_ = dynamic_cast<cv::ml::SVMSGD*>(((pyopencv_ml_SVMSGD_t*)self)->v.get());
    float marginRegularization=0.f;

    const char* keywords[] = { "marginRegularization", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:ml_SVMSGD.setMarginRegularization", (char**)keywords, &marginRegularization) )
    {
        ERRWRAP2(_self_->setMarginRegularization(marginRegularization));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_SVMSGD_setMarginType(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_SVMSGD_Type))
        return failmsgp("Incorrect type of self (must be 'ml_SVMSGD' or its derivative)");
    cv::ml::SVMSGD* _self_ = dynamic_cast<cv::ml::SVMSGD*>(((pyopencv_ml_SVMSGD_t*)self)->v.get());
    int marginType=0;

    const char* keywords[] = { "marginType", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:ml_SVMSGD.setMarginType", (char**)keywords, &marginType) )
    {
        ERRWRAP2(_self_->setMarginType(marginType));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_SVMSGD_setOptimalParameters(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_SVMSGD_Type))
        return failmsgp("Incorrect type of self (must be 'ml_SVMSGD' or its derivative)");
    cv::ml::SVMSGD* _self_ = dynamic_cast<cv::ml::SVMSGD*>(((pyopencv_ml_SVMSGD_t*)self)->v.get());
    int svmsgdType=SVMSGD::ASGD;
    int marginType=SVMSGD::SOFT_MARGIN;

    const char* keywords[] = { "svmsgdType", "marginType", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|ii:ml_SVMSGD.setOptimalParameters", (char**)keywords, &svmsgdType, &marginType) )
    {
        ERRWRAP2(_self_->setOptimalParameters(svmsgdType, marginType));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_SVMSGD_setStepDecreasingPower(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_SVMSGD_Type))
        return failmsgp("Incorrect type of self (must be 'ml_SVMSGD' or its derivative)");
    cv::ml::SVMSGD* _self_ = dynamic_cast<cv::ml::SVMSGD*>(((pyopencv_ml_SVMSGD_t*)self)->v.get());
    float stepDecreasingPower=0.f;

    const char* keywords[] = { "stepDecreasingPower", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:ml_SVMSGD.setStepDecreasingPower", (char**)keywords, &stepDecreasingPower) )
    {
        ERRWRAP2(_self_->setStepDecreasingPower(stepDecreasingPower));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_SVMSGD_setSvmsgdType(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_SVMSGD_Type))
        return failmsgp("Incorrect type of self (must be 'ml_SVMSGD' or its derivative)");
    cv::ml::SVMSGD* _self_ = dynamic_cast<cv::ml::SVMSGD*>(((pyopencv_ml_SVMSGD_t*)self)->v.get());
    int svmsgdType=0;

    const char* keywords[] = { "svmsgdType", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:ml_SVMSGD.setSvmsgdType", (char**)keywords, &svmsgdType) )
    {
        ERRWRAP2(_self_->setSvmsgdType(svmsgdType));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ml_SVMSGD_setTermCriteria(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ml;

    if(!PyObject_TypeCheck(self, &pyopencv_ml_SVMSGD_Type))
        return failmsgp("Incorrect type of self (must be 'ml_SVMSGD' or its derivative)");
    cv::ml::SVMSGD* _self_ = dynamic_cast<cv::ml::SVMSGD*>(((pyopencv_ml_SVMSGD_t*)self)->v.get());
    PyObject* pyobj_val = NULL;
    TermCriteria val;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:ml_SVMSGD.setTermCriteria", (char**)keywords, &pyobj_val) &&
        pyopencv_to(pyobj_val, val, ArgInfo("val", 0)) )
    {
        ERRWRAP2(_self_->setTermCriteria(val));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_ml_SVMSGD_methods[] =
{
    {"getInitialStepSize", (PyCFunction)pyopencv_cv_ml_ml_SVMSGD_getInitialStepSize, METH_VARARGS | METH_KEYWORDS, "getInitialStepSize() -> retval"},
    {"getMarginRegularization", (PyCFunction)pyopencv_cv_ml_ml_SVMSGD_getMarginRegularization, METH_VARARGS | METH_KEYWORDS, "getMarginRegularization() -> retval"},
    {"getMarginType", (PyCFunction)pyopencv_cv_ml_ml_SVMSGD_getMarginType, METH_VARARGS | METH_KEYWORDS, "getMarginType() -> retval"},
    {"getShift", (PyCFunction)pyopencv_cv_ml_ml_SVMSGD_getShift, METH_VARARGS | METH_KEYWORDS, "getShift() -> retval"},
    {"getStepDecreasingPower", (PyCFunction)pyopencv_cv_ml_ml_SVMSGD_getStepDecreasingPower, METH_VARARGS | METH_KEYWORDS, "getStepDecreasingPower() -> retval"},
    {"getSvmsgdType", (PyCFunction)pyopencv_cv_ml_ml_SVMSGD_getSvmsgdType, METH_VARARGS | METH_KEYWORDS, "getSvmsgdType() -> retval"},
    {"getTermCriteria", (PyCFunction)pyopencv_cv_ml_ml_SVMSGD_getTermCriteria, METH_VARARGS | METH_KEYWORDS, "getTermCriteria() -> retval"},
    {"getWeights", (PyCFunction)pyopencv_cv_ml_ml_SVMSGD_getWeights, METH_VARARGS | METH_KEYWORDS, "getWeights() -> retval"},
    {"setInitialStepSize", (PyCFunction)pyopencv_cv_ml_ml_SVMSGD_setInitialStepSize, METH_VARARGS | METH_KEYWORDS, "setInitialStepSize(InitialStepSize) -> None"},
    {"setMarginRegularization", (PyCFunction)pyopencv_cv_ml_ml_SVMSGD_setMarginRegularization, METH_VARARGS | METH_KEYWORDS, "setMarginRegularization(marginRegularization) -> None"},
    {"setMarginType", (PyCFunction)pyopencv_cv_ml_ml_SVMSGD_setMarginType, METH_VARARGS | METH_KEYWORDS, "setMarginType(marginType) -> None"},
    {"setOptimalParameters", (PyCFunction)pyopencv_cv_ml_ml_SVMSGD_setOptimalParameters, METH_VARARGS | METH_KEYWORDS, "setOptimalParameters([, svmsgdType[, marginType]]) -> None"},
    {"setStepDecreasingPower", (PyCFunction)pyopencv_cv_ml_ml_SVMSGD_setStepDecreasingPower, METH_VARARGS | METH_KEYWORDS, "setStepDecreasingPower(stepDecreasingPower) -> None"},
    {"setSvmsgdType", (PyCFunction)pyopencv_cv_ml_ml_SVMSGD_setSvmsgdType, METH_VARARGS | METH_KEYWORDS, "setSvmsgdType(svmsgdType) -> None"},
    {"setTermCriteria", (PyCFunction)pyopencv_cv_ml_ml_SVMSGD_setTermCriteria, METH_VARARGS | METH_KEYWORDS, "setTermCriteria(val) -> None"},

    {NULL,          NULL}
};

static void pyopencv_ml_SVMSGD_specials(void)
{
    pyopencv_ml_SVMSGD_Type.tp_base = &pyopencv_ml_StatModel_Type;
    pyopencv_ml_SVMSGD_Type.tp_dealloc = pyopencv_ml_SVMSGD_dealloc;
    pyopencv_ml_SVMSGD_Type.tp_repr = pyopencv_ml_SVMSGD_repr;
    pyopencv_ml_SVMSGD_Type.tp_getset = pyopencv_ml_SVMSGD_getseters;
    pyopencv_ml_SVMSGD_Type.tp_methods = pyopencv_ml_SVMSGD_methods;
}

static PyObject* pyopencv_Tonemap_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<Tonemap %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_Tonemap_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_Tonemap_getGamma(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_Tonemap_Type))
        return failmsgp("Incorrect type of self (must be 'Tonemap' or its derivative)");
    cv::Tonemap* _self_ = dynamic_cast<cv::Tonemap*>(((pyopencv_Tonemap_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getGamma());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_Tonemap_process(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_Tonemap_Type))
        return failmsgp("Incorrect type of self (must be 'Tonemap' or its derivative)");
    cv::Tonemap* _self_ = dynamic_cast<cv::Tonemap*>(((pyopencv_Tonemap_t*)self)->v.get());
    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;

    const char* keywords[] = { "src", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:Tonemap.process", (char**)keywords, &pyobj_src, &pyobj_dst) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(_self_->process(src, dst));
        return pyopencv_from(dst);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;

    const char* keywords[] = { "src", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:Tonemap.process", (char**)keywords, &pyobj_src, &pyobj_dst) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(_self_->process(src, dst));
        return pyopencv_from(dst);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_Tonemap_setGamma(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_Tonemap_Type))
        return failmsgp("Incorrect type of self (must be 'Tonemap' or its derivative)");
    cv::Tonemap* _self_ = dynamic_cast<cv::Tonemap*>(((pyopencv_Tonemap_t*)self)->v.get());
    float gamma=0.f;

    const char* keywords[] = { "gamma", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:Tonemap.setGamma", (char**)keywords, &gamma) )
    {
        ERRWRAP2(_self_->setGamma(gamma));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_Tonemap_methods[] =
{
    {"getGamma", (PyCFunction)pyopencv_cv_Tonemap_getGamma, METH_VARARGS | METH_KEYWORDS, "getGamma() -> retval"},
    {"process", (PyCFunction)pyopencv_cv_Tonemap_process, METH_VARARGS | METH_KEYWORDS, "process(src[, dst]) -> dst"},
    {"setGamma", (PyCFunction)pyopencv_cv_Tonemap_setGamma, METH_VARARGS | METH_KEYWORDS, "setGamma(gamma) -> None"},

    {NULL,          NULL}
};

static void pyopencv_Tonemap_specials(void)
{
    pyopencv_Tonemap_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_Tonemap_Type.tp_dealloc = pyopencv_Tonemap_dealloc;
    pyopencv_Tonemap_Type.tp_repr = pyopencv_Tonemap_repr;
    pyopencv_Tonemap_Type.tp_getset = pyopencv_Tonemap_getseters;
    pyopencv_Tonemap_Type.tp_methods = pyopencv_Tonemap_methods;
}

static PyObject* pyopencv_TonemapDrago_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<TonemapDrago %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_TonemapDrago_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_TonemapDrago_getBias(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_TonemapDrago_Type))
        return failmsgp("Incorrect type of self (must be 'TonemapDrago' or its derivative)");
    cv::TonemapDrago* _self_ = dynamic_cast<cv::TonemapDrago*>(((pyopencv_TonemapDrago_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getBias());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_TonemapDrago_getSaturation(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_TonemapDrago_Type))
        return failmsgp("Incorrect type of self (must be 'TonemapDrago' or its derivative)");
    cv::TonemapDrago* _self_ = dynamic_cast<cv::TonemapDrago*>(((pyopencv_TonemapDrago_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getSaturation());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_TonemapDrago_setBias(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_TonemapDrago_Type))
        return failmsgp("Incorrect type of self (must be 'TonemapDrago' or its derivative)");
    cv::TonemapDrago* _self_ = dynamic_cast<cv::TonemapDrago*>(((pyopencv_TonemapDrago_t*)self)->v.get());
    float bias=0.f;

    const char* keywords[] = { "bias", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:TonemapDrago.setBias", (char**)keywords, &bias) )
    {
        ERRWRAP2(_self_->setBias(bias));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_TonemapDrago_setSaturation(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_TonemapDrago_Type))
        return failmsgp("Incorrect type of self (must be 'TonemapDrago' or its derivative)");
    cv::TonemapDrago* _self_ = dynamic_cast<cv::TonemapDrago*>(((pyopencv_TonemapDrago_t*)self)->v.get());
    float saturation=0.f;

    const char* keywords[] = { "saturation", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:TonemapDrago.setSaturation", (char**)keywords, &saturation) )
    {
        ERRWRAP2(_self_->setSaturation(saturation));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_TonemapDrago_methods[] =
{
    {"getBias", (PyCFunction)pyopencv_cv_TonemapDrago_getBias, METH_VARARGS | METH_KEYWORDS, "getBias() -> retval"},
    {"getSaturation", (PyCFunction)pyopencv_cv_TonemapDrago_getSaturation, METH_VARARGS | METH_KEYWORDS, "getSaturation() -> retval"},
    {"setBias", (PyCFunction)pyopencv_cv_TonemapDrago_setBias, METH_VARARGS | METH_KEYWORDS, "setBias(bias) -> None"},
    {"setSaturation", (PyCFunction)pyopencv_cv_TonemapDrago_setSaturation, METH_VARARGS | METH_KEYWORDS, "setSaturation(saturation) -> None"},

    {NULL,          NULL}
};

static void pyopencv_TonemapDrago_specials(void)
{
    pyopencv_TonemapDrago_Type.tp_base = &pyopencv_Tonemap_Type;
    pyopencv_TonemapDrago_Type.tp_dealloc = pyopencv_TonemapDrago_dealloc;
    pyopencv_TonemapDrago_Type.tp_repr = pyopencv_TonemapDrago_repr;
    pyopencv_TonemapDrago_Type.tp_getset = pyopencv_TonemapDrago_getseters;
    pyopencv_TonemapDrago_Type.tp_methods = pyopencv_TonemapDrago_methods;
}

static PyObject* pyopencv_TonemapDurand_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<TonemapDurand %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_TonemapDurand_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_TonemapDurand_getContrast(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_TonemapDurand_Type))
        return failmsgp("Incorrect type of self (must be 'TonemapDurand' or its derivative)");
    cv::TonemapDurand* _self_ = dynamic_cast<cv::TonemapDurand*>(((pyopencv_TonemapDurand_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getContrast());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_TonemapDurand_getSaturation(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_TonemapDurand_Type))
        return failmsgp("Incorrect type of self (must be 'TonemapDurand' or its derivative)");
    cv::TonemapDurand* _self_ = dynamic_cast<cv::TonemapDurand*>(((pyopencv_TonemapDurand_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getSaturation());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_TonemapDurand_getSigmaColor(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_TonemapDurand_Type))
        return failmsgp("Incorrect type of self (must be 'TonemapDurand' or its derivative)");
    cv::TonemapDurand* _self_ = dynamic_cast<cv::TonemapDurand*>(((pyopencv_TonemapDurand_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getSigmaColor());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_TonemapDurand_getSigmaSpace(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_TonemapDurand_Type))
        return failmsgp("Incorrect type of self (must be 'TonemapDurand' or its derivative)");
    cv::TonemapDurand* _self_ = dynamic_cast<cv::TonemapDurand*>(((pyopencv_TonemapDurand_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getSigmaSpace());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_TonemapDurand_setContrast(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_TonemapDurand_Type))
        return failmsgp("Incorrect type of self (must be 'TonemapDurand' or its derivative)");
    cv::TonemapDurand* _self_ = dynamic_cast<cv::TonemapDurand*>(((pyopencv_TonemapDurand_t*)self)->v.get());
    float contrast=0.f;

    const char* keywords[] = { "contrast", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:TonemapDurand.setContrast", (char**)keywords, &contrast) )
    {
        ERRWRAP2(_self_->setContrast(contrast));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_TonemapDurand_setSaturation(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_TonemapDurand_Type))
        return failmsgp("Incorrect type of self (must be 'TonemapDurand' or its derivative)");
    cv::TonemapDurand* _self_ = dynamic_cast<cv::TonemapDurand*>(((pyopencv_TonemapDurand_t*)self)->v.get());
    float saturation=0.f;

    const char* keywords[] = { "saturation", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:TonemapDurand.setSaturation", (char**)keywords, &saturation) )
    {
        ERRWRAP2(_self_->setSaturation(saturation));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_TonemapDurand_setSigmaColor(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_TonemapDurand_Type))
        return failmsgp("Incorrect type of self (must be 'TonemapDurand' or its derivative)");
    cv::TonemapDurand* _self_ = dynamic_cast<cv::TonemapDurand*>(((pyopencv_TonemapDurand_t*)self)->v.get());
    float sigma_color=0.f;

    const char* keywords[] = { "sigma_color", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:TonemapDurand.setSigmaColor", (char**)keywords, &sigma_color) )
    {
        ERRWRAP2(_self_->setSigmaColor(sigma_color));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_TonemapDurand_setSigmaSpace(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_TonemapDurand_Type))
        return failmsgp("Incorrect type of self (must be 'TonemapDurand' or its derivative)");
    cv::TonemapDurand* _self_ = dynamic_cast<cv::TonemapDurand*>(((pyopencv_TonemapDurand_t*)self)->v.get());
    float sigma_space=0.f;

    const char* keywords[] = { "sigma_space", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:TonemapDurand.setSigmaSpace", (char**)keywords, &sigma_space) )
    {
        ERRWRAP2(_self_->setSigmaSpace(sigma_space));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_TonemapDurand_methods[] =
{
    {"getContrast", (PyCFunction)pyopencv_cv_TonemapDurand_getContrast, METH_VARARGS | METH_KEYWORDS, "getContrast() -> retval"},
    {"getSaturation", (PyCFunction)pyopencv_cv_TonemapDurand_getSaturation, METH_VARARGS | METH_KEYWORDS, "getSaturation() -> retval"},
    {"getSigmaColor", (PyCFunction)pyopencv_cv_TonemapDurand_getSigmaColor, METH_VARARGS | METH_KEYWORDS, "getSigmaColor() -> retval"},
    {"getSigmaSpace", (PyCFunction)pyopencv_cv_TonemapDurand_getSigmaSpace, METH_VARARGS | METH_KEYWORDS, "getSigmaSpace() -> retval"},
    {"setContrast", (PyCFunction)pyopencv_cv_TonemapDurand_setContrast, METH_VARARGS | METH_KEYWORDS, "setContrast(contrast) -> None"},
    {"setSaturation", (PyCFunction)pyopencv_cv_TonemapDurand_setSaturation, METH_VARARGS | METH_KEYWORDS, "setSaturation(saturation) -> None"},
    {"setSigmaColor", (PyCFunction)pyopencv_cv_TonemapDurand_setSigmaColor, METH_VARARGS | METH_KEYWORDS, "setSigmaColor(sigma_color) -> None"},
    {"setSigmaSpace", (PyCFunction)pyopencv_cv_TonemapDurand_setSigmaSpace, METH_VARARGS | METH_KEYWORDS, "setSigmaSpace(sigma_space) -> None"},

    {NULL,          NULL}
};

static void pyopencv_TonemapDurand_specials(void)
{
    pyopencv_TonemapDurand_Type.tp_base = &pyopencv_Tonemap_Type;
    pyopencv_TonemapDurand_Type.tp_dealloc = pyopencv_TonemapDurand_dealloc;
    pyopencv_TonemapDurand_Type.tp_repr = pyopencv_TonemapDurand_repr;
    pyopencv_TonemapDurand_Type.tp_getset = pyopencv_TonemapDurand_getseters;
    pyopencv_TonemapDurand_Type.tp_methods = pyopencv_TonemapDurand_methods;
}

static PyObject* pyopencv_TonemapReinhard_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<TonemapReinhard %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_TonemapReinhard_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_TonemapReinhard_getColorAdaptation(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_TonemapReinhard_Type))
        return failmsgp("Incorrect type of self (must be 'TonemapReinhard' or its derivative)");
    cv::TonemapReinhard* _self_ = dynamic_cast<cv::TonemapReinhard*>(((pyopencv_TonemapReinhard_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getColorAdaptation());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_TonemapReinhard_getIntensity(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_TonemapReinhard_Type))
        return failmsgp("Incorrect type of self (must be 'TonemapReinhard' or its derivative)");
    cv::TonemapReinhard* _self_ = dynamic_cast<cv::TonemapReinhard*>(((pyopencv_TonemapReinhard_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getIntensity());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_TonemapReinhard_getLightAdaptation(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_TonemapReinhard_Type))
        return failmsgp("Incorrect type of self (must be 'TonemapReinhard' or its derivative)");
    cv::TonemapReinhard* _self_ = dynamic_cast<cv::TonemapReinhard*>(((pyopencv_TonemapReinhard_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getLightAdaptation());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_TonemapReinhard_setColorAdaptation(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_TonemapReinhard_Type))
        return failmsgp("Incorrect type of self (must be 'TonemapReinhard' or its derivative)");
    cv::TonemapReinhard* _self_ = dynamic_cast<cv::TonemapReinhard*>(((pyopencv_TonemapReinhard_t*)self)->v.get());
    float color_adapt=0.f;

    const char* keywords[] = { "color_adapt", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:TonemapReinhard.setColorAdaptation", (char**)keywords, &color_adapt) )
    {
        ERRWRAP2(_self_->setColorAdaptation(color_adapt));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_TonemapReinhard_setIntensity(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_TonemapReinhard_Type))
        return failmsgp("Incorrect type of self (must be 'TonemapReinhard' or its derivative)");
    cv::TonemapReinhard* _self_ = dynamic_cast<cv::TonemapReinhard*>(((pyopencv_TonemapReinhard_t*)self)->v.get());
    float intensity=0.f;

    const char* keywords[] = { "intensity", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:TonemapReinhard.setIntensity", (char**)keywords, &intensity) )
    {
        ERRWRAP2(_self_->setIntensity(intensity));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_TonemapReinhard_setLightAdaptation(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_TonemapReinhard_Type))
        return failmsgp("Incorrect type of self (must be 'TonemapReinhard' or its derivative)");
    cv::TonemapReinhard* _self_ = dynamic_cast<cv::TonemapReinhard*>(((pyopencv_TonemapReinhard_t*)self)->v.get());
    float light_adapt=0.f;

    const char* keywords[] = { "light_adapt", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:TonemapReinhard.setLightAdaptation", (char**)keywords, &light_adapt) )
    {
        ERRWRAP2(_self_->setLightAdaptation(light_adapt));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_TonemapReinhard_methods[] =
{
    {"getColorAdaptation", (PyCFunction)pyopencv_cv_TonemapReinhard_getColorAdaptation, METH_VARARGS | METH_KEYWORDS, "getColorAdaptation() -> retval"},
    {"getIntensity", (PyCFunction)pyopencv_cv_TonemapReinhard_getIntensity, METH_VARARGS | METH_KEYWORDS, "getIntensity() -> retval"},
    {"getLightAdaptation", (PyCFunction)pyopencv_cv_TonemapReinhard_getLightAdaptation, METH_VARARGS | METH_KEYWORDS, "getLightAdaptation() -> retval"},
    {"setColorAdaptation", (PyCFunction)pyopencv_cv_TonemapReinhard_setColorAdaptation, METH_VARARGS | METH_KEYWORDS, "setColorAdaptation(color_adapt) -> None"},
    {"setIntensity", (PyCFunction)pyopencv_cv_TonemapReinhard_setIntensity, METH_VARARGS | METH_KEYWORDS, "setIntensity(intensity) -> None"},
    {"setLightAdaptation", (PyCFunction)pyopencv_cv_TonemapReinhard_setLightAdaptation, METH_VARARGS | METH_KEYWORDS, "setLightAdaptation(light_adapt) -> None"},

    {NULL,          NULL}
};

static void pyopencv_TonemapReinhard_specials(void)
{
    pyopencv_TonemapReinhard_Type.tp_base = &pyopencv_Tonemap_Type;
    pyopencv_TonemapReinhard_Type.tp_dealloc = pyopencv_TonemapReinhard_dealloc;
    pyopencv_TonemapReinhard_Type.tp_repr = pyopencv_TonemapReinhard_repr;
    pyopencv_TonemapReinhard_Type.tp_getset = pyopencv_TonemapReinhard_getseters;
    pyopencv_TonemapReinhard_Type.tp_methods = pyopencv_TonemapReinhard_methods;
}

static PyObject* pyopencv_TonemapMantiuk_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<TonemapMantiuk %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_TonemapMantiuk_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_TonemapMantiuk_getSaturation(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_TonemapMantiuk_Type))
        return failmsgp("Incorrect type of self (must be 'TonemapMantiuk' or its derivative)");
    cv::TonemapMantiuk* _self_ = dynamic_cast<cv::TonemapMantiuk*>(((pyopencv_TonemapMantiuk_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getSaturation());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_TonemapMantiuk_getScale(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_TonemapMantiuk_Type))
        return failmsgp("Incorrect type of self (must be 'TonemapMantiuk' or its derivative)");
    cv::TonemapMantiuk* _self_ = dynamic_cast<cv::TonemapMantiuk*>(((pyopencv_TonemapMantiuk_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getScale());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_TonemapMantiuk_setSaturation(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_TonemapMantiuk_Type))
        return failmsgp("Incorrect type of self (must be 'TonemapMantiuk' or its derivative)");
    cv::TonemapMantiuk* _self_ = dynamic_cast<cv::TonemapMantiuk*>(((pyopencv_TonemapMantiuk_t*)self)->v.get());
    float saturation=0.f;

    const char* keywords[] = { "saturation", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:TonemapMantiuk.setSaturation", (char**)keywords, &saturation) )
    {
        ERRWRAP2(_self_->setSaturation(saturation));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_TonemapMantiuk_setScale(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_TonemapMantiuk_Type))
        return failmsgp("Incorrect type of self (must be 'TonemapMantiuk' or its derivative)");
    cv::TonemapMantiuk* _self_ = dynamic_cast<cv::TonemapMantiuk*>(((pyopencv_TonemapMantiuk_t*)self)->v.get());
    float scale=0.f;

    const char* keywords[] = { "scale", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:TonemapMantiuk.setScale", (char**)keywords, &scale) )
    {
        ERRWRAP2(_self_->setScale(scale));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_TonemapMantiuk_methods[] =
{
    {"getSaturation", (PyCFunction)pyopencv_cv_TonemapMantiuk_getSaturation, METH_VARARGS | METH_KEYWORDS, "getSaturation() -> retval"},
    {"getScale", (PyCFunction)pyopencv_cv_TonemapMantiuk_getScale, METH_VARARGS | METH_KEYWORDS, "getScale() -> retval"},
    {"setSaturation", (PyCFunction)pyopencv_cv_TonemapMantiuk_setSaturation, METH_VARARGS | METH_KEYWORDS, "setSaturation(saturation) -> None"},
    {"setScale", (PyCFunction)pyopencv_cv_TonemapMantiuk_setScale, METH_VARARGS | METH_KEYWORDS, "setScale(scale) -> None"},

    {NULL,          NULL}
};

static void pyopencv_TonemapMantiuk_specials(void)
{
    pyopencv_TonemapMantiuk_Type.tp_base = &pyopencv_Tonemap_Type;
    pyopencv_TonemapMantiuk_Type.tp_dealloc = pyopencv_TonemapMantiuk_dealloc;
    pyopencv_TonemapMantiuk_Type.tp_repr = pyopencv_TonemapMantiuk_repr;
    pyopencv_TonemapMantiuk_Type.tp_getset = pyopencv_TonemapMantiuk_getseters;
    pyopencv_TonemapMantiuk_Type.tp_methods = pyopencv_TonemapMantiuk_methods;
}

static PyObject* pyopencv_AlignExposures_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<AlignExposures %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_AlignExposures_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_AlignExposures_process(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_AlignExposures_Type))
        return failmsgp("Incorrect type of self (must be 'AlignExposures' or its derivative)");
    cv::AlignExposures* _self_ = dynamic_cast<cv::AlignExposures*>(((pyopencv_AlignExposures_t*)self)->v.get());
    {
    PyObject* pyobj_src = NULL;
    vector_Mat src;
    PyObject* pyobj_dst = NULL;
    vector_Mat dst;
    PyObject* pyobj_times = NULL;
    Mat times;
    PyObject* pyobj_response = NULL;
    Mat response;

    const char* keywords[] = { "src", "dst", "times", "response", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OOOO:AlignExposures.process", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_times, &pyobj_response) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_dst, dst, ArgInfo("dst", 0)) &&
        pyopencv_to(pyobj_times, times, ArgInfo("times", 0)) &&
        pyopencv_to(pyobj_response, response, ArgInfo("response", 0)) )
    {
        ERRWRAP2(_self_->process(src, dst, times, response));
        Py_RETURN_NONE;
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_src = NULL;
    vector_Mat src;
    PyObject* pyobj_dst = NULL;
    vector_Mat dst;
    PyObject* pyobj_times = NULL;
    UMat times;
    PyObject* pyobj_response = NULL;
    UMat response;

    const char* keywords[] = { "src", "dst", "times", "response", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OOOO:AlignExposures.process", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_times, &pyobj_response) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_dst, dst, ArgInfo("dst", 0)) &&
        pyopencv_to(pyobj_times, times, ArgInfo("times", 0)) &&
        pyopencv_to(pyobj_response, response, ArgInfo("response", 0)) )
    {
        ERRWRAP2(_self_->process(src, dst, times, response));
        Py_RETURN_NONE;
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_AlignExposures_methods[] =
{
    {"process", (PyCFunction)pyopencv_cv_AlignExposures_process, METH_VARARGS | METH_KEYWORDS, "process(src, dst, times, response) -> None"},

    {NULL,          NULL}
};

static void pyopencv_AlignExposures_specials(void)
{
    pyopencv_AlignExposures_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_AlignExposures_Type.tp_dealloc = pyopencv_AlignExposures_dealloc;
    pyopencv_AlignExposures_Type.tp_repr = pyopencv_AlignExposures_repr;
    pyopencv_AlignExposures_Type.tp_getset = pyopencv_AlignExposures_getseters;
    pyopencv_AlignExposures_Type.tp_methods = pyopencv_AlignExposures_methods;
}

static PyObject* pyopencv_AlignMTB_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<AlignMTB %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_AlignMTB_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_AlignMTB_calculateShift(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_AlignMTB_Type))
        return failmsgp("Incorrect type of self (must be 'AlignMTB' or its derivative)");
    cv::AlignMTB* _self_ = dynamic_cast<cv::AlignMTB*>(((pyopencv_AlignMTB_t*)self)->v.get());
    {
    PyObject* pyobj_img0 = NULL;
    Mat img0;
    PyObject* pyobj_img1 = NULL;
    Mat img1;
    Point retval;

    const char* keywords[] = { "img0", "img1", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO:AlignMTB.calculateShift", (char**)keywords, &pyobj_img0, &pyobj_img1) &&
        pyopencv_to(pyobj_img0, img0, ArgInfo("img0", 0)) &&
        pyopencv_to(pyobj_img1, img1, ArgInfo("img1", 0)) )
    {
        ERRWRAP2(retval = _self_->calculateShift(img0, img1));
        return pyopencv_from(retval);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_img0 = NULL;
    UMat img0;
    PyObject* pyobj_img1 = NULL;
    UMat img1;
    Point retval;

    const char* keywords[] = { "img0", "img1", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO:AlignMTB.calculateShift", (char**)keywords, &pyobj_img0, &pyobj_img1) &&
        pyopencv_to(pyobj_img0, img0, ArgInfo("img0", 0)) &&
        pyopencv_to(pyobj_img1, img1, ArgInfo("img1", 0)) )
    {
        ERRWRAP2(retval = _self_->calculateShift(img0, img1));
        return pyopencv_from(retval);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_AlignMTB_computeBitmaps(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_AlignMTB_Type))
        return failmsgp("Incorrect type of self (must be 'AlignMTB' or its derivative)");
    cv::AlignMTB* _self_ = dynamic_cast<cv::AlignMTB*>(((pyopencv_AlignMTB_t*)self)->v.get());
    {
    PyObject* pyobj_img = NULL;
    Mat img;
    PyObject* pyobj_tb = NULL;
    Mat tb;
    PyObject* pyobj_eb = NULL;
    Mat eb;

    const char* keywords[] = { "img", "tb", "eb", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|OO:AlignMTB.computeBitmaps", (char**)keywords, &pyobj_img, &pyobj_tb, &pyobj_eb) &&
        pyopencv_to(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to(pyobj_tb, tb, ArgInfo("tb", 1)) &&
        pyopencv_to(pyobj_eb, eb, ArgInfo("eb", 1)) )
    {
        ERRWRAP2(_self_->computeBitmaps(img, tb, eb));
        return Py_BuildValue("(NN)", pyopencv_from(tb), pyopencv_from(eb));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_img = NULL;
    UMat img;
    PyObject* pyobj_tb = NULL;
    UMat tb;
    PyObject* pyobj_eb = NULL;
    UMat eb;

    const char* keywords[] = { "img", "tb", "eb", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|OO:AlignMTB.computeBitmaps", (char**)keywords, &pyobj_img, &pyobj_tb, &pyobj_eb) &&
        pyopencv_to(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to(pyobj_tb, tb, ArgInfo("tb", 1)) &&
        pyopencv_to(pyobj_eb, eb, ArgInfo("eb", 1)) )
    {
        ERRWRAP2(_self_->computeBitmaps(img, tb, eb));
        return Py_BuildValue("(NN)", pyopencv_from(tb), pyopencv_from(eb));
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_AlignMTB_getCut(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_AlignMTB_Type))
        return failmsgp("Incorrect type of self (must be 'AlignMTB' or its derivative)");
    cv::AlignMTB* _self_ = dynamic_cast<cv::AlignMTB*>(((pyopencv_AlignMTB_t*)self)->v.get());
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getCut());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_AlignMTB_getExcludeRange(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_AlignMTB_Type))
        return failmsgp("Incorrect type of self (must be 'AlignMTB' or its derivative)");
    cv::AlignMTB* _self_ = dynamic_cast<cv::AlignMTB*>(((pyopencv_AlignMTB_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getExcludeRange());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_AlignMTB_getMaxBits(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_AlignMTB_Type))
        return failmsgp("Incorrect type of self (must be 'AlignMTB' or its derivative)");
    cv::AlignMTB* _self_ = dynamic_cast<cv::AlignMTB*>(((pyopencv_AlignMTB_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getMaxBits());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_AlignMTB_process(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_AlignMTB_Type))
        return failmsgp("Incorrect type of self (must be 'AlignMTB' or its derivative)");
    cv::AlignMTB* _self_ = dynamic_cast<cv::AlignMTB*>(((pyopencv_AlignMTB_t*)self)->v.get());
    {
    PyObject* pyobj_src = NULL;
    vector_Mat src;
    PyObject* pyobj_dst = NULL;
    vector_Mat dst;
    PyObject* pyobj_times = NULL;
    Mat times;
    PyObject* pyobj_response = NULL;
    Mat response;

    const char* keywords[] = { "src", "dst", "times", "response", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OOOO:AlignMTB.process", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_times, &pyobj_response) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_dst, dst, ArgInfo("dst", 0)) &&
        pyopencv_to(pyobj_times, times, ArgInfo("times", 0)) &&
        pyopencv_to(pyobj_response, response, ArgInfo("response", 0)) )
    {
        ERRWRAP2(_self_->process(src, dst, times, response));
        Py_RETURN_NONE;
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_src = NULL;
    vector_Mat src;
    PyObject* pyobj_dst = NULL;
    vector_Mat dst;
    PyObject* pyobj_times = NULL;
    UMat times;
    PyObject* pyobj_response = NULL;
    UMat response;

    const char* keywords[] = { "src", "dst", "times", "response", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OOOO:AlignMTB.process", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_times, &pyobj_response) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_dst, dst, ArgInfo("dst", 0)) &&
        pyopencv_to(pyobj_times, times, ArgInfo("times", 0)) &&
        pyopencv_to(pyobj_response, response, ArgInfo("response", 0)) )
    {
        ERRWRAP2(_self_->process(src, dst, times, response));
        Py_RETURN_NONE;
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_src = NULL;
    vector_Mat src;
    PyObject* pyobj_dst = NULL;
    vector_Mat dst;

    const char* keywords[] = { "src", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO:AlignMTB.process", (char**)keywords, &pyobj_src, &pyobj_dst) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_dst, dst, ArgInfo("dst", 0)) )
    {
        ERRWRAP2(_self_->process(src, dst));
        Py_RETURN_NONE;
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_src = NULL;
    vector_Mat src;
    PyObject* pyobj_dst = NULL;
    vector_Mat dst;

    const char* keywords[] = { "src", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO:AlignMTB.process", (char**)keywords, &pyobj_src, &pyobj_dst) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_dst, dst, ArgInfo("dst", 0)) )
    {
        ERRWRAP2(_self_->process(src, dst));
        Py_RETURN_NONE;
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_AlignMTB_setCut(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_AlignMTB_Type))
        return failmsgp("Incorrect type of self (must be 'AlignMTB' or its derivative)");
    cv::AlignMTB* _self_ = dynamic_cast<cv::AlignMTB*>(((pyopencv_AlignMTB_t*)self)->v.get());
    bool value=0;

    const char* keywords[] = { "value", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "b:AlignMTB.setCut", (char**)keywords, &value) )
    {
        ERRWRAP2(_self_->setCut(value));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_AlignMTB_setExcludeRange(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_AlignMTB_Type))
        return failmsgp("Incorrect type of self (must be 'AlignMTB' or its derivative)");
    cv::AlignMTB* _self_ = dynamic_cast<cv::AlignMTB*>(((pyopencv_AlignMTB_t*)self)->v.get());
    int exclude_range=0;

    const char* keywords[] = { "exclude_range", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:AlignMTB.setExcludeRange", (char**)keywords, &exclude_range) )
    {
        ERRWRAP2(_self_->setExcludeRange(exclude_range));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_AlignMTB_setMaxBits(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_AlignMTB_Type))
        return failmsgp("Incorrect type of self (must be 'AlignMTB' or its derivative)");
    cv::AlignMTB* _self_ = dynamic_cast<cv::AlignMTB*>(((pyopencv_AlignMTB_t*)self)->v.get());
    int max_bits=0;

    const char* keywords[] = { "max_bits", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:AlignMTB.setMaxBits", (char**)keywords, &max_bits) )
    {
        ERRWRAP2(_self_->setMaxBits(max_bits));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_AlignMTB_shiftMat(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_AlignMTB_Type))
        return failmsgp("Incorrect type of self (must be 'AlignMTB' or its derivative)");
    cv::AlignMTB* _self_ = dynamic_cast<cv::AlignMTB*>(((pyopencv_AlignMTB_t*)self)->v.get());
    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_shift = NULL;
    Point shift;

    const char* keywords[] = { "src", "shift", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|O:AlignMTB.shiftMat", (char**)keywords, &pyobj_src, &pyobj_shift, &pyobj_dst) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to(pyobj_shift, shift, ArgInfo("shift", 0)) )
    {
        ERRWRAP2(_self_->shiftMat(src, dst, shift));
        return pyopencv_from(dst);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_shift = NULL;
    Point shift;

    const char* keywords[] = { "src", "shift", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|O:AlignMTB.shiftMat", (char**)keywords, &pyobj_src, &pyobj_shift, &pyobj_dst) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to(pyobj_shift, shift, ArgInfo("shift", 0)) )
    {
        ERRWRAP2(_self_->shiftMat(src, dst, shift));
        return pyopencv_from(dst);
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_AlignMTB_methods[] =
{
    {"calculateShift", (PyCFunction)pyopencv_cv_AlignMTB_calculateShift, METH_VARARGS | METH_KEYWORDS, "calculateShift(img0, img1) -> retval"},
    {"computeBitmaps", (PyCFunction)pyopencv_cv_AlignMTB_computeBitmaps, METH_VARARGS | METH_KEYWORDS, "computeBitmaps(img[, tb[, eb]]) -> tb, eb"},
    {"getCut", (PyCFunction)pyopencv_cv_AlignMTB_getCut, METH_VARARGS | METH_KEYWORDS, "getCut() -> retval"},
    {"getExcludeRange", (PyCFunction)pyopencv_cv_AlignMTB_getExcludeRange, METH_VARARGS | METH_KEYWORDS, "getExcludeRange() -> retval"},
    {"getMaxBits", (PyCFunction)pyopencv_cv_AlignMTB_getMaxBits, METH_VARARGS | METH_KEYWORDS, "getMaxBits() -> retval"},
    {"process", (PyCFunction)pyopencv_cv_AlignMTB_process, METH_VARARGS | METH_KEYWORDS, "process(src, dst, times, response) -> None  or  process(src, dst) -> None"},
    {"setCut", (PyCFunction)pyopencv_cv_AlignMTB_setCut, METH_VARARGS | METH_KEYWORDS, "setCut(value) -> None"},
    {"setExcludeRange", (PyCFunction)pyopencv_cv_AlignMTB_setExcludeRange, METH_VARARGS | METH_KEYWORDS, "setExcludeRange(exclude_range) -> None"},
    {"setMaxBits", (PyCFunction)pyopencv_cv_AlignMTB_setMaxBits, METH_VARARGS | METH_KEYWORDS, "setMaxBits(max_bits) -> None"},
    {"shiftMat", (PyCFunction)pyopencv_cv_AlignMTB_shiftMat, METH_VARARGS | METH_KEYWORDS, "shiftMat(src, shift[, dst]) -> dst"},

    {NULL,          NULL}
};

static void pyopencv_AlignMTB_specials(void)
{
    pyopencv_AlignMTB_Type.tp_base = &pyopencv_AlignExposures_Type;
    pyopencv_AlignMTB_Type.tp_dealloc = pyopencv_AlignMTB_dealloc;
    pyopencv_AlignMTB_Type.tp_repr = pyopencv_AlignMTB_repr;
    pyopencv_AlignMTB_Type.tp_getset = pyopencv_AlignMTB_getseters;
    pyopencv_AlignMTB_Type.tp_methods = pyopencv_AlignMTB_methods;
}

static PyObject* pyopencv_CalibrateCRF_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<CalibrateCRF %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_CalibrateCRF_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_CalibrateCRF_process(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_CalibrateCRF_Type))
        return failmsgp("Incorrect type of self (must be 'CalibrateCRF' or its derivative)");
    cv::CalibrateCRF* _self_ = dynamic_cast<cv::CalibrateCRF*>(((pyopencv_CalibrateCRF_t*)self)->v.get());
    {
    PyObject* pyobj_src = NULL;
    vector_Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_times = NULL;
    Mat times;

    const char* keywords[] = { "src", "times", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|O:CalibrateCRF.process", (char**)keywords, &pyobj_src, &pyobj_times, &pyobj_dst) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to(pyobj_times, times, ArgInfo("times", 0)) )
    {
        ERRWRAP2(_self_->process(src, dst, times));
        return pyopencv_from(dst);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_src = NULL;
    vector_Mat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_times = NULL;
    UMat times;

    const char* keywords[] = { "src", "times", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|O:CalibrateCRF.process", (char**)keywords, &pyobj_src, &pyobj_times, &pyobj_dst) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to(pyobj_times, times, ArgInfo("times", 0)) )
    {
        ERRWRAP2(_self_->process(src, dst, times));
        return pyopencv_from(dst);
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_CalibrateCRF_methods[] =
{
    {"process", (PyCFunction)pyopencv_cv_CalibrateCRF_process, METH_VARARGS | METH_KEYWORDS, "process(src, times[, dst]) -> dst"},

    {NULL,          NULL}
};

static void pyopencv_CalibrateCRF_specials(void)
{
    pyopencv_CalibrateCRF_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_CalibrateCRF_Type.tp_dealloc = pyopencv_CalibrateCRF_dealloc;
    pyopencv_CalibrateCRF_Type.tp_repr = pyopencv_CalibrateCRF_repr;
    pyopencv_CalibrateCRF_Type.tp_getset = pyopencv_CalibrateCRF_getseters;
    pyopencv_CalibrateCRF_Type.tp_methods = pyopencv_CalibrateCRF_methods;
}

static PyObject* pyopencv_CalibrateDebevec_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<CalibrateDebevec %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_CalibrateDebevec_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_CalibrateDebevec_getLambda(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_CalibrateDebevec_Type))
        return failmsgp("Incorrect type of self (must be 'CalibrateDebevec' or its derivative)");
    cv::CalibrateDebevec* _self_ = dynamic_cast<cv::CalibrateDebevec*>(((pyopencv_CalibrateDebevec_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getLambda());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_CalibrateDebevec_getRandom(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_CalibrateDebevec_Type))
        return failmsgp("Incorrect type of self (must be 'CalibrateDebevec' or its derivative)");
    cv::CalibrateDebevec* _self_ = dynamic_cast<cv::CalibrateDebevec*>(((pyopencv_CalibrateDebevec_t*)self)->v.get());
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getRandom());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_CalibrateDebevec_getSamples(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_CalibrateDebevec_Type))
        return failmsgp("Incorrect type of self (must be 'CalibrateDebevec' or its derivative)");
    cv::CalibrateDebevec* _self_ = dynamic_cast<cv::CalibrateDebevec*>(((pyopencv_CalibrateDebevec_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getSamples());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_CalibrateDebevec_setLambda(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_CalibrateDebevec_Type))
        return failmsgp("Incorrect type of self (must be 'CalibrateDebevec' or its derivative)");
    cv::CalibrateDebevec* _self_ = dynamic_cast<cv::CalibrateDebevec*>(((pyopencv_CalibrateDebevec_t*)self)->v.get());
    float lambda=0.f;

    const char* keywords[] = { "lambda", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:CalibrateDebevec.setLambda", (char**)keywords, &lambda) )
    {
        ERRWRAP2(_self_->setLambda(lambda));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_CalibrateDebevec_setRandom(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_CalibrateDebevec_Type))
        return failmsgp("Incorrect type of self (must be 'CalibrateDebevec' or its derivative)");
    cv::CalibrateDebevec* _self_ = dynamic_cast<cv::CalibrateDebevec*>(((pyopencv_CalibrateDebevec_t*)self)->v.get());
    bool random=0;

    const char* keywords[] = { "random", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "b:CalibrateDebevec.setRandom", (char**)keywords, &random) )
    {
        ERRWRAP2(_self_->setRandom(random));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_CalibrateDebevec_setSamples(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_CalibrateDebevec_Type))
        return failmsgp("Incorrect type of self (must be 'CalibrateDebevec' or its derivative)");
    cv::CalibrateDebevec* _self_ = dynamic_cast<cv::CalibrateDebevec*>(((pyopencv_CalibrateDebevec_t*)self)->v.get());
    int samples=0;

    const char* keywords[] = { "samples", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:CalibrateDebevec.setSamples", (char**)keywords, &samples) )
    {
        ERRWRAP2(_self_->setSamples(samples));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_CalibrateDebevec_methods[] =
{
    {"getLambda", (PyCFunction)pyopencv_cv_CalibrateDebevec_getLambda, METH_VARARGS | METH_KEYWORDS, "getLambda() -> retval"},
    {"getRandom", (PyCFunction)pyopencv_cv_CalibrateDebevec_getRandom, METH_VARARGS | METH_KEYWORDS, "getRandom() -> retval"},
    {"getSamples", (PyCFunction)pyopencv_cv_CalibrateDebevec_getSamples, METH_VARARGS | METH_KEYWORDS, "getSamples() -> retval"},
    {"setLambda", (PyCFunction)pyopencv_cv_CalibrateDebevec_setLambda, METH_VARARGS | METH_KEYWORDS, "setLambda(lambda) -> None"},
    {"setRandom", (PyCFunction)pyopencv_cv_CalibrateDebevec_setRandom, METH_VARARGS | METH_KEYWORDS, "setRandom(random) -> None"},
    {"setSamples", (PyCFunction)pyopencv_cv_CalibrateDebevec_setSamples, METH_VARARGS | METH_KEYWORDS, "setSamples(samples) -> None"},

    {NULL,          NULL}
};

static void pyopencv_CalibrateDebevec_specials(void)
{
    pyopencv_CalibrateDebevec_Type.tp_base = &pyopencv_CalibrateCRF_Type;
    pyopencv_CalibrateDebevec_Type.tp_dealloc = pyopencv_CalibrateDebevec_dealloc;
    pyopencv_CalibrateDebevec_Type.tp_repr = pyopencv_CalibrateDebevec_repr;
    pyopencv_CalibrateDebevec_Type.tp_getset = pyopencv_CalibrateDebevec_getseters;
    pyopencv_CalibrateDebevec_Type.tp_methods = pyopencv_CalibrateDebevec_methods;
}

static PyObject* pyopencv_CalibrateRobertson_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<CalibrateRobertson %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_CalibrateRobertson_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_CalibrateRobertson_getMaxIter(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_CalibrateRobertson_Type))
        return failmsgp("Incorrect type of self (must be 'CalibrateRobertson' or its derivative)");
    cv::CalibrateRobertson* _self_ = dynamic_cast<cv::CalibrateRobertson*>(((pyopencv_CalibrateRobertson_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getMaxIter());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_CalibrateRobertson_getRadiance(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_CalibrateRobertson_Type))
        return failmsgp("Incorrect type of self (must be 'CalibrateRobertson' or its derivative)");
    cv::CalibrateRobertson* _self_ = dynamic_cast<cv::CalibrateRobertson*>(((pyopencv_CalibrateRobertson_t*)self)->v.get());
    Mat retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getRadiance());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_CalibrateRobertson_getThreshold(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_CalibrateRobertson_Type))
        return failmsgp("Incorrect type of self (must be 'CalibrateRobertson' or its derivative)");
    cv::CalibrateRobertson* _self_ = dynamic_cast<cv::CalibrateRobertson*>(((pyopencv_CalibrateRobertson_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getThreshold());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_CalibrateRobertson_setMaxIter(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_CalibrateRobertson_Type))
        return failmsgp("Incorrect type of self (must be 'CalibrateRobertson' or its derivative)");
    cv::CalibrateRobertson* _self_ = dynamic_cast<cv::CalibrateRobertson*>(((pyopencv_CalibrateRobertson_t*)self)->v.get());
    int max_iter=0;

    const char* keywords[] = { "max_iter", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:CalibrateRobertson.setMaxIter", (char**)keywords, &max_iter) )
    {
        ERRWRAP2(_self_->setMaxIter(max_iter));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_CalibrateRobertson_setThreshold(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_CalibrateRobertson_Type))
        return failmsgp("Incorrect type of self (must be 'CalibrateRobertson' or its derivative)");
    cv::CalibrateRobertson* _self_ = dynamic_cast<cv::CalibrateRobertson*>(((pyopencv_CalibrateRobertson_t*)self)->v.get());
    float threshold=0.f;

    const char* keywords[] = { "threshold", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:CalibrateRobertson.setThreshold", (char**)keywords, &threshold) )
    {
        ERRWRAP2(_self_->setThreshold(threshold));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_CalibrateRobertson_methods[] =
{
    {"getMaxIter", (PyCFunction)pyopencv_cv_CalibrateRobertson_getMaxIter, METH_VARARGS | METH_KEYWORDS, "getMaxIter() -> retval"},
    {"getRadiance", (PyCFunction)pyopencv_cv_CalibrateRobertson_getRadiance, METH_VARARGS | METH_KEYWORDS, "getRadiance() -> retval"},
    {"getThreshold", (PyCFunction)pyopencv_cv_CalibrateRobertson_getThreshold, METH_VARARGS | METH_KEYWORDS, "getThreshold() -> retval"},
    {"setMaxIter", (PyCFunction)pyopencv_cv_CalibrateRobertson_setMaxIter, METH_VARARGS | METH_KEYWORDS, "setMaxIter(max_iter) -> None"},
    {"setThreshold", (PyCFunction)pyopencv_cv_CalibrateRobertson_setThreshold, METH_VARARGS | METH_KEYWORDS, "setThreshold(threshold) -> None"},

    {NULL,          NULL}
};

static void pyopencv_CalibrateRobertson_specials(void)
{
    pyopencv_CalibrateRobertson_Type.tp_base = &pyopencv_CalibrateCRF_Type;
    pyopencv_CalibrateRobertson_Type.tp_dealloc = pyopencv_CalibrateRobertson_dealloc;
    pyopencv_CalibrateRobertson_Type.tp_repr = pyopencv_CalibrateRobertson_repr;
    pyopencv_CalibrateRobertson_Type.tp_getset = pyopencv_CalibrateRobertson_getseters;
    pyopencv_CalibrateRobertson_Type.tp_methods = pyopencv_CalibrateRobertson_methods;
}

static PyObject* pyopencv_MergeExposures_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<MergeExposures %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_MergeExposures_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_MergeExposures_process(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_MergeExposures_Type))
        return failmsgp("Incorrect type of self (must be 'MergeExposures' or its derivative)");
    cv::MergeExposures* _self_ = dynamic_cast<cv::MergeExposures*>(((pyopencv_MergeExposures_t*)self)->v.get());
    {
    PyObject* pyobj_src = NULL;
    vector_Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_times = NULL;
    Mat times;
    PyObject* pyobj_response = NULL;
    Mat response;

    const char* keywords[] = { "src", "times", "response", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OOO|O:MergeExposures.process", (char**)keywords, &pyobj_src, &pyobj_times, &pyobj_response, &pyobj_dst) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to(pyobj_times, times, ArgInfo("times", 0)) &&
        pyopencv_to(pyobj_response, response, ArgInfo("response", 0)) )
    {
        ERRWRAP2(_self_->process(src, dst, times, response));
        return pyopencv_from(dst);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_src = NULL;
    vector_Mat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_times = NULL;
    UMat times;
    PyObject* pyobj_response = NULL;
    UMat response;

    const char* keywords[] = { "src", "times", "response", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OOO|O:MergeExposures.process", (char**)keywords, &pyobj_src, &pyobj_times, &pyobj_response, &pyobj_dst) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to(pyobj_times, times, ArgInfo("times", 0)) &&
        pyopencv_to(pyobj_response, response, ArgInfo("response", 0)) )
    {
        ERRWRAP2(_self_->process(src, dst, times, response));
        return pyopencv_from(dst);
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_MergeExposures_methods[] =
{
    {"process", (PyCFunction)pyopencv_cv_MergeExposures_process, METH_VARARGS | METH_KEYWORDS, "process(src, times, response[, dst]) -> dst"},

    {NULL,          NULL}
};

static void pyopencv_MergeExposures_specials(void)
{
    pyopencv_MergeExposures_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_MergeExposures_Type.tp_dealloc = pyopencv_MergeExposures_dealloc;
    pyopencv_MergeExposures_Type.tp_repr = pyopencv_MergeExposures_repr;
    pyopencv_MergeExposures_Type.tp_getset = pyopencv_MergeExposures_getseters;
    pyopencv_MergeExposures_Type.tp_methods = pyopencv_MergeExposures_methods;
}

static PyObject* pyopencv_MergeDebevec_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<MergeDebevec %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_MergeDebevec_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_MergeDebevec_process(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_MergeDebevec_Type))
        return failmsgp("Incorrect type of self (must be 'MergeDebevec' or its derivative)");
    cv::MergeDebevec* _self_ = dynamic_cast<cv::MergeDebevec*>(((pyopencv_MergeDebevec_t*)self)->v.get());
    {
    PyObject* pyobj_src = NULL;
    vector_Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_times = NULL;
    Mat times;
    PyObject* pyobj_response = NULL;
    Mat response;

    const char* keywords[] = { "src", "times", "response", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OOO|O:MergeDebevec.process", (char**)keywords, &pyobj_src, &pyobj_times, &pyobj_response, &pyobj_dst) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to(pyobj_times, times, ArgInfo("times", 0)) &&
        pyopencv_to(pyobj_response, response, ArgInfo("response", 0)) )
    {
        ERRWRAP2(_self_->process(src, dst, times, response));
        return pyopencv_from(dst);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_src = NULL;
    vector_Mat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_times = NULL;
    UMat times;
    PyObject* pyobj_response = NULL;
    UMat response;

    const char* keywords[] = { "src", "times", "response", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OOO|O:MergeDebevec.process", (char**)keywords, &pyobj_src, &pyobj_times, &pyobj_response, &pyobj_dst) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to(pyobj_times, times, ArgInfo("times", 0)) &&
        pyopencv_to(pyobj_response, response, ArgInfo("response", 0)) )
    {
        ERRWRAP2(_self_->process(src, dst, times, response));
        return pyopencv_from(dst);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_src = NULL;
    vector_Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_times = NULL;
    Mat times;

    const char* keywords[] = { "src", "times", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|O:MergeDebevec.process", (char**)keywords, &pyobj_src, &pyobj_times, &pyobj_dst) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to(pyobj_times, times, ArgInfo("times", 0)) )
    {
        ERRWRAP2(_self_->process(src, dst, times));
        return pyopencv_from(dst);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_src = NULL;
    vector_Mat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_times = NULL;
    UMat times;

    const char* keywords[] = { "src", "times", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|O:MergeDebevec.process", (char**)keywords, &pyobj_src, &pyobj_times, &pyobj_dst) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to(pyobj_times, times, ArgInfo("times", 0)) )
    {
        ERRWRAP2(_self_->process(src, dst, times));
        return pyopencv_from(dst);
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_MergeDebevec_methods[] =
{
    {"process", (PyCFunction)pyopencv_cv_MergeDebevec_process, METH_VARARGS | METH_KEYWORDS, "process(src, times, response[, dst]) -> dst  or  process(src, times[, dst]) -> dst"},

    {NULL,          NULL}
};

static void pyopencv_MergeDebevec_specials(void)
{
    pyopencv_MergeDebevec_Type.tp_base = &pyopencv_MergeExposures_Type;
    pyopencv_MergeDebevec_Type.tp_dealloc = pyopencv_MergeDebevec_dealloc;
    pyopencv_MergeDebevec_Type.tp_repr = pyopencv_MergeDebevec_repr;
    pyopencv_MergeDebevec_Type.tp_getset = pyopencv_MergeDebevec_getseters;
    pyopencv_MergeDebevec_Type.tp_methods = pyopencv_MergeDebevec_methods;
}

static PyObject* pyopencv_MergeMertens_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<MergeMertens %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_MergeMertens_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_MergeMertens_getContrastWeight(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_MergeMertens_Type))
        return failmsgp("Incorrect type of self (must be 'MergeMertens' or its derivative)");
    cv::MergeMertens* _self_ = dynamic_cast<cv::MergeMertens*>(((pyopencv_MergeMertens_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getContrastWeight());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_MergeMertens_getExposureWeight(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_MergeMertens_Type))
        return failmsgp("Incorrect type of self (must be 'MergeMertens' or its derivative)");
    cv::MergeMertens* _self_ = dynamic_cast<cv::MergeMertens*>(((pyopencv_MergeMertens_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getExposureWeight());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_MergeMertens_getSaturationWeight(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_MergeMertens_Type))
        return failmsgp("Incorrect type of self (must be 'MergeMertens' or its derivative)");
    cv::MergeMertens* _self_ = dynamic_cast<cv::MergeMertens*>(((pyopencv_MergeMertens_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getSaturationWeight());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_MergeMertens_process(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_MergeMertens_Type))
        return failmsgp("Incorrect type of self (must be 'MergeMertens' or its derivative)");
    cv::MergeMertens* _self_ = dynamic_cast<cv::MergeMertens*>(((pyopencv_MergeMertens_t*)self)->v.get());
    {
    PyObject* pyobj_src = NULL;
    vector_Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_times = NULL;
    Mat times;
    PyObject* pyobj_response = NULL;
    Mat response;

    const char* keywords[] = { "src", "times", "response", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OOO|O:MergeMertens.process", (char**)keywords, &pyobj_src, &pyobj_times, &pyobj_response, &pyobj_dst) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to(pyobj_times, times, ArgInfo("times", 0)) &&
        pyopencv_to(pyobj_response, response, ArgInfo("response", 0)) )
    {
        ERRWRAP2(_self_->process(src, dst, times, response));
        return pyopencv_from(dst);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_src = NULL;
    vector_Mat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_times = NULL;
    UMat times;
    PyObject* pyobj_response = NULL;
    UMat response;

    const char* keywords[] = { "src", "times", "response", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OOO|O:MergeMertens.process", (char**)keywords, &pyobj_src, &pyobj_times, &pyobj_response, &pyobj_dst) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to(pyobj_times, times, ArgInfo("times", 0)) &&
        pyopencv_to(pyobj_response, response, ArgInfo("response", 0)) )
    {
        ERRWRAP2(_self_->process(src, dst, times, response));
        return pyopencv_from(dst);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_src = NULL;
    vector_Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;

    const char* keywords[] = { "src", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:MergeMertens.process", (char**)keywords, &pyobj_src, &pyobj_dst) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(_self_->process(src, dst));
        return pyopencv_from(dst);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_src = NULL;
    vector_Mat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;

    const char* keywords[] = { "src", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:MergeMertens.process", (char**)keywords, &pyobj_src, &pyobj_dst) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(_self_->process(src, dst));
        return pyopencv_from(dst);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_MergeMertens_setContrastWeight(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_MergeMertens_Type))
        return failmsgp("Incorrect type of self (must be 'MergeMertens' or its derivative)");
    cv::MergeMertens* _self_ = dynamic_cast<cv::MergeMertens*>(((pyopencv_MergeMertens_t*)self)->v.get());
    float contrast_weiht=0.f;

    const char* keywords[] = { "contrast_weiht", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:MergeMertens.setContrastWeight", (char**)keywords, &contrast_weiht) )
    {
        ERRWRAP2(_self_->setContrastWeight(contrast_weiht));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_MergeMertens_setExposureWeight(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_MergeMertens_Type))
        return failmsgp("Incorrect type of self (must be 'MergeMertens' or its derivative)");
    cv::MergeMertens* _self_ = dynamic_cast<cv::MergeMertens*>(((pyopencv_MergeMertens_t*)self)->v.get());
    float exposure_weight=0.f;

    const char* keywords[] = { "exposure_weight", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:MergeMertens.setExposureWeight", (char**)keywords, &exposure_weight) )
    {
        ERRWRAP2(_self_->setExposureWeight(exposure_weight));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_MergeMertens_setSaturationWeight(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_MergeMertens_Type))
        return failmsgp("Incorrect type of self (must be 'MergeMertens' or its derivative)");
    cv::MergeMertens* _self_ = dynamic_cast<cv::MergeMertens*>(((pyopencv_MergeMertens_t*)self)->v.get());
    float saturation_weight=0.f;

    const char* keywords[] = { "saturation_weight", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:MergeMertens.setSaturationWeight", (char**)keywords, &saturation_weight) )
    {
        ERRWRAP2(_self_->setSaturationWeight(saturation_weight));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_MergeMertens_methods[] =
{
    {"getContrastWeight", (PyCFunction)pyopencv_cv_MergeMertens_getContrastWeight, METH_VARARGS | METH_KEYWORDS, "getContrastWeight() -> retval"},
    {"getExposureWeight", (PyCFunction)pyopencv_cv_MergeMertens_getExposureWeight, METH_VARARGS | METH_KEYWORDS, "getExposureWeight() -> retval"},
    {"getSaturationWeight", (PyCFunction)pyopencv_cv_MergeMertens_getSaturationWeight, METH_VARARGS | METH_KEYWORDS, "getSaturationWeight() -> retval"},
    {"process", (PyCFunction)pyopencv_cv_MergeMertens_process, METH_VARARGS | METH_KEYWORDS, "process(src, times, response[, dst]) -> dst  or  process(src[, dst]) -> dst"},
    {"setContrastWeight", (PyCFunction)pyopencv_cv_MergeMertens_setContrastWeight, METH_VARARGS | METH_KEYWORDS, "setContrastWeight(contrast_weiht) -> None"},
    {"setExposureWeight", (PyCFunction)pyopencv_cv_MergeMertens_setExposureWeight, METH_VARARGS | METH_KEYWORDS, "setExposureWeight(exposure_weight) -> None"},
    {"setSaturationWeight", (PyCFunction)pyopencv_cv_MergeMertens_setSaturationWeight, METH_VARARGS | METH_KEYWORDS, "setSaturationWeight(saturation_weight) -> None"},

    {NULL,          NULL}
};

static void pyopencv_MergeMertens_specials(void)
{
    pyopencv_MergeMertens_Type.tp_base = &pyopencv_MergeExposures_Type;
    pyopencv_MergeMertens_Type.tp_dealloc = pyopencv_MergeMertens_dealloc;
    pyopencv_MergeMertens_Type.tp_repr = pyopencv_MergeMertens_repr;
    pyopencv_MergeMertens_Type.tp_getset = pyopencv_MergeMertens_getseters;
    pyopencv_MergeMertens_Type.tp_methods = pyopencv_MergeMertens_methods;
}

static PyObject* pyopencv_MergeRobertson_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<MergeRobertson %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_MergeRobertson_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_MergeRobertson_process(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_MergeRobertson_Type))
        return failmsgp("Incorrect type of self (must be 'MergeRobertson' or its derivative)");
    cv::MergeRobertson* _self_ = dynamic_cast<cv::MergeRobertson*>(((pyopencv_MergeRobertson_t*)self)->v.get());
    {
    PyObject* pyobj_src = NULL;
    vector_Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_times = NULL;
    Mat times;
    PyObject* pyobj_response = NULL;
    Mat response;

    const char* keywords[] = { "src", "times", "response", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OOO|O:MergeRobertson.process", (char**)keywords, &pyobj_src, &pyobj_times, &pyobj_response, &pyobj_dst) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to(pyobj_times, times, ArgInfo("times", 0)) &&
        pyopencv_to(pyobj_response, response, ArgInfo("response", 0)) )
    {
        ERRWRAP2(_self_->process(src, dst, times, response));
        return pyopencv_from(dst);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_src = NULL;
    vector_Mat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_times = NULL;
    UMat times;
    PyObject* pyobj_response = NULL;
    UMat response;

    const char* keywords[] = { "src", "times", "response", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OOO|O:MergeRobertson.process", (char**)keywords, &pyobj_src, &pyobj_times, &pyobj_response, &pyobj_dst) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to(pyobj_times, times, ArgInfo("times", 0)) &&
        pyopencv_to(pyobj_response, response, ArgInfo("response", 0)) )
    {
        ERRWRAP2(_self_->process(src, dst, times, response));
        return pyopencv_from(dst);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_src = NULL;
    vector_Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_times = NULL;
    Mat times;

    const char* keywords[] = { "src", "times", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|O:MergeRobertson.process", (char**)keywords, &pyobj_src, &pyobj_times, &pyobj_dst) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to(pyobj_times, times, ArgInfo("times", 0)) )
    {
        ERRWRAP2(_self_->process(src, dst, times));
        return pyopencv_from(dst);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_src = NULL;
    vector_Mat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_times = NULL;
    UMat times;

    const char* keywords[] = { "src", "times", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|O:MergeRobertson.process", (char**)keywords, &pyobj_src, &pyobj_times, &pyobj_dst) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to(pyobj_times, times, ArgInfo("times", 0)) )
    {
        ERRWRAP2(_self_->process(src, dst, times));
        return pyopencv_from(dst);
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_MergeRobertson_methods[] =
{
    {"process", (PyCFunction)pyopencv_cv_MergeRobertson_process, METH_VARARGS | METH_KEYWORDS, "process(src, times, response[, dst]) -> dst  or  process(src, times[, dst]) -> dst"},

    {NULL,          NULL}
};

static void pyopencv_MergeRobertson_specials(void)
{
    pyopencv_MergeRobertson_Type.tp_base = &pyopencv_MergeExposures_Type;
    pyopencv_MergeRobertson_Type.tp_dealloc = pyopencv_MergeRobertson_dealloc;
    pyopencv_MergeRobertson_Type.tp_repr = pyopencv_MergeRobertson_repr;
    pyopencv_MergeRobertson_Type.tp_getset = pyopencv_MergeRobertson_getseters;
    pyopencv_MergeRobertson_Type.tp_methods = pyopencv_MergeRobertson_methods;
}

static PyObject* pyopencv_reg_Map_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<reg_Map %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_reg_Map_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_reg_reg_Map_compose(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::reg;

    if(!PyObject_TypeCheck(self, &pyopencv_reg_Map_Type))
        return failmsgp("Incorrect type of self (must be 'reg_Map' or its derivative)");
    cv::reg::Map* _self_ = ((pyopencv_reg_Map_t*)self)->v.get();
    PyObject* pyobj_map = NULL;
    Ptr<Map> map;

    const char* keywords[] = { "map", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:reg_Map.compose", (char**)keywords, &pyobj_map) &&
        pyopencv_to(pyobj_map, map, ArgInfo("map", 0)) )
    {
        ERRWRAP2(_self_->compose(map));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_reg_reg_Map_inverseMap(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::reg;

    if(!PyObject_TypeCheck(self, &pyopencv_reg_Map_Type))
        return failmsgp("Incorrect type of self (must be 'reg_Map' or its derivative)");
    cv::reg::Map* _self_ = ((pyopencv_reg_Map_t*)self)->v.get();
    cv::Ptr<Map> retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->inverseMap());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_reg_reg_Map_inverseWarp(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::reg;

    if(!PyObject_TypeCheck(self, &pyopencv_reg_Map_Type))
        return failmsgp("Incorrect type of self (must be 'reg_Map' or its derivative)");
    cv::reg::Map* _self_ = ((pyopencv_reg_Map_t*)self)->v.get();
    {
    PyObject* pyobj_img1 = NULL;
    Mat img1;
    PyObject* pyobj_img2 = NULL;
    Mat img2;

    const char* keywords[] = { "img1", "img2", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:reg_Map.inverseWarp", (char**)keywords, &pyobj_img1, &pyobj_img2) &&
        pyopencv_to(pyobj_img1, img1, ArgInfo("img1", 0)) &&
        pyopencv_to(pyobj_img2, img2, ArgInfo("img2", 1)) )
    {
        ERRWRAP2(_self_->inverseWarp(img1, img2));
        return pyopencv_from(img2);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_img1 = NULL;
    UMat img1;
    PyObject* pyobj_img2 = NULL;
    UMat img2;

    const char* keywords[] = { "img1", "img2", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:reg_Map.inverseWarp", (char**)keywords, &pyobj_img1, &pyobj_img2) &&
        pyopencv_to(pyobj_img1, img1, ArgInfo("img1", 0)) &&
        pyopencv_to(pyobj_img2, img2, ArgInfo("img2", 1)) )
    {
        ERRWRAP2(_self_->inverseWarp(img1, img2));
        return pyopencv_from(img2);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_reg_reg_Map_scale(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::reg;

    if(!PyObject_TypeCheck(self, &pyopencv_reg_Map_Type))
        return failmsgp("Incorrect type of self (must be 'reg_Map' or its derivative)");
    cv::reg::Map* _self_ = ((pyopencv_reg_Map_t*)self)->v.get();
    double factor=0;

    const char* keywords[] = { "factor", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:reg_Map.scale", (char**)keywords, &factor) )
    {
        ERRWRAP2(_self_->scale(factor));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_reg_reg_Map_warp(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::reg;

    if(!PyObject_TypeCheck(self, &pyopencv_reg_Map_Type))
        return failmsgp("Incorrect type of self (must be 'reg_Map' or its derivative)");
    cv::reg::Map* _self_ = ((pyopencv_reg_Map_t*)self)->v.get();
    {
    PyObject* pyobj_img1 = NULL;
    Mat img1;
    PyObject* pyobj_img2 = NULL;
    Mat img2;

    const char* keywords[] = { "img1", "img2", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:reg_Map.warp", (char**)keywords, &pyobj_img1, &pyobj_img2) &&
        pyopencv_to(pyobj_img1, img1, ArgInfo("img1", 0)) &&
        pyopencv_to(pyobj_img2, img2, ArgInfo("img2", 1)) )
    {
        ERRWRAP2(_self_->warp(img1, img2));
        return pyopencv_from(img2);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_img1 = NULL;
    UMat img1;
    PyObject* pyobj_img2 = NULL;
    UMat img2;

    const char* keywords[] = { "img1", "img2", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:reg_Map.warp", (char**)keywords, &pyobj_img1, &pyobj_img2) &&
        pyopencv_to(pyobj_img1, img1, ArgInfo("img1", 0)) &&
        pyopencv_to(pyobj_img2, img2, ArgInfo("img2", 1)) )
    {
        ERRWRAP2(_self_->warp(img1, img2));
        return pyopencv_from(img2);
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_reg_Map_methods[] =
{
    {"compose", (PyCFunction)pyopencv_cv_reg_reg_Map_compose, METH_VARARGS | METH_KEYWORDS, "compose(map) -> None"},
    {"inverseMap", (PyCFunction)pyopencv_cv_reg_reg_Map_inverseMap, METH_VARARGS | METH_KEYWORDS, "inverseMap() -> retval"},
    {"inverseWarp", (PyCFunction)pyopencv_cv_reg_reg_Map_inverseWarp, METH_VARARGS | METH_KEYWORDS, "inverseWarp(img1[, img2]) -> img2"},
    {"scale", (PyCFunction)pyopencv_cv_reg_reg_Map_scale, METH_VARARGS | METH_KEYWORDS, "scale(factor) -> None"},
    {"warp", (PyCFunction)pyopencv_cv_reg_reg_Map_warp, METH_VARARGS | METH_KEYWORDS, "warp(img1[, img2]) -> img2"},

    {NULL,          NULL}
};

static void pyopencv_reg_Map_specials(void)
{
    pyopencv_reg_Map_Type.tp_base = NULL;
    pyopencv_reg_Map_Type.tp_dealloc = pyopencv_reg_Map_dealloc;
    pyopencv_reg_Map_Type.tp_repr = pyopencv_reg_Map_repr;
    pyopencv_reg_Map_Type.tp_getset = pyopencv_reg_Map_getseters;
    pyopencv_reg_Map_Type.tp_methods = pyopencv_reg_Map_methods;
}

static PyObject* pyopencv_reg_MapAffine_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<reg_MapAffine %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_reg_MapAffine_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_reg_reg_MapAffine_compose(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::reg;

    if(!PyObject_TypeCheck(self, &pyopencv_reg_MapAffine_Type))
        return failmsgp("Incorrect type of self (must be 'reg_MapAffine' or its derivative)");
    cv::reg::MapAffine* _self_ = ((pyopencv_reg_MapAffine_t*)self)->v.get();
    PyObject* pyobj_map = NULL;
    Ptr<Map> map;

    const char* keywords[] = { "map", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:reg_MapAffine.compose", (char**)keywords, &pyobj_map) &&
        pyopencv_to(pyobj_map, map, ArgInfo("map", 0)) )
    {
        ERRWRAP2(_self_->compose(map));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_reg_reg_MapAffine_getLinTr(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::reg;

    if(!PyObject_TypeCheck(self, &pyopencv_reg_MapAffine_Type))
        return failmsgp("Incorrect type of self (must be 'reg_MapAffine' or its derivative)");
    cv::reg::MapAffine* _self_ = ((pyopencv_reg_MapAffine_t*)self)->v.get();
    {
    PyObject* pyobj_linTr = NULL;
    Mat linTr;

    const char* keywords[] = { "linTr", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|O:reg_MapAffine.getLinTr", (char**)keywords, &pyobj_linTr) &&
        pyopencv_to(pyobj_linTr, linTr, ArgInfo("linTr", 1)) )
    {
        ERRWRAP2(_self_->getLinTr(linTr));
        return pyopencv_from(linTr);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_linTr = NULL;
    UMat linTr;

    const char* keywords[] = { "linTr", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|O:reg_MapAffine.getLinTr", (char**)keywords, &pyobj_linTr) &&
        pyopencv_to(pyobj_linTr, linTr, ArgInfo("linTr", 1)) )
    {
        ERRWRAP2(_self_->getLinTr(linTr));
        return pyopencv_from(linTr);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_reg_reg_MapAffine_getShift(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::reg;

    if(!PyObject_TypeCheck(self, &pyopencv_reg_MapAffine_Type))
        return failmsgp("Incorrect type of self (must be 'reg_MapAffine' or its derivative)");
    cv::reg::MapAffine* _self_ = ((pyopencv_reg_MapAffine_t*)self)->v.get();
    {
    PyObject* pyobj_shift = NULL;
    Mat shift;

    const char* keywords[] = { "shift", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|O:reg_MapAffine.getShift", (char**)keywords, &pyobj_shift) &&
        pyopencv_to(pyobj_shift, shift, ArgInfo("shift", 1)) )
    {
        ERRWRAP2(_self_->getShift(shift));
        return pyopencv_from(shift);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_shift = NULL;
    UMat shift;

    const char* keywords[] = { "shift", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|O:reg_MapAffine.getShift", (char**)keywords, &pyobj_shift) &&
        pyopencv_to(pyobj_shift, shift, ArgInfo("shift", 1)) )
    {
        ERRWRAP2(_self_->getShift(shift));
        return pyopencv_from(shift);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_reg_reg_MapAffine_inverseMap(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::reg;

    if(!PyObject_TypeCheck(self, &pyopencv_reg_MapAffine_Type))
        return failmsgp("Incorrect type of self (must be 'reg_MapAffine' or its derivative)");
    cv::reg::MapAffine* _self_ = ((pyopencv_reg_MapAffine_t*)self)->v.get();
    cv::Ptr<Map> retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->inverseMap());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_reg_reg_MapAffine_inverseWarp(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::reg;

    if(!PyObject_TypeCheck(self, &pyopencv_reg_MapAffine_Type))
        return failmsgp("Incorrect type of self (must be 'reg_MapAffine' or its derivative)");
    cv::reg::MapAffine* _self_ = ((pyopencv_reg_MapAffine_t*)self)->v.get();
    {
    PyObject* pyobj_img1 = NULL;
    Mat img1;
    PyObject* pyobj_img2 = NULL;
    Mat img2;

    const char* keywords[] = { "img1", "img2", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:reg_MapAffine.inverseWarp", (char**)keywords, &pyobj_img1, &pyobj_img2) &&
        pyopencv_to(pyobj_img1, img1, ArgInfo("img1", 0)) &&
        pyopencv_to(pyobj_img2, img2, ArgInfo("img2", 1)) )
    {
        ERRWRAP2(_self_->inverseWarp(img1, img2));
        return pyopencv_from(img2);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_img1 = NULL;
    UMat img1;
    PyObject* pyobj_img2 = NULL;
    UMat img2;

    const char* keywords[] = { "img1", "img2", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:reg_MapAffine.inverseWarp", (char**)keywords, &pyobj_img1, &pyobj_img2) &&
        pyopencv_to(pyobj_img1, img1, ArgInfo("img1", 0)) &&
        pyopencv_to(pyobj_img2, img2, ArgInfo("img2", 1)) )
    {
        ERRWRAP2(_self_->inverseWarp(img1, img2));
        return pyopencv_from(img2);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_reg_reg_MapAffine_scale(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::reg;

    if(!PyObject_TypeCheck(self, &pyopencv_reg_MapAffine_Type))
        return failmsgp("Incorrect type of self (must be 'reg_MapAffine' or its derivative)");
    cv::reg::MapAffine* _self_ = ((pyopencv_reg_MapAffine_t*)self)->v.get();
    double factor=0;

    const char* keywords[] = { "factor", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:reg_MapAffine.scale", (char**)keywords, &factor) )
    {
        ERRWRAP2(_self_->scale(factor));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_reg_MapAffine_methods[] =
{
    {"compose", (PyCFunction)pyopencv_cv_reg_reg_MapAffine_compose, METH_VARARGS | METH_KEYWORDS, "compose(map) -> None"},
    {"getLinTr", (PyCFunction)pyopencv_cv_reg_reg_MapAffine_getLinTr, METH_VARARGS | METH_KEYWORDS, "getLinTr([, linTr]) -> linTr"},
    {"getShift", (PyCFunction)pyopencv_cv_reg_reg_MapAffine_getShift, METH_VARARGS | METH_KEYWORDS, "getShift([, shift]) -> shift"},
    {"inverseMap", (PyCFunction)pyopencv_cv_reg_reg_MapAffine_inverseMap, METH_VARARGS | METH_KEYWORDS, "inverseMap() -> retval"},
    {"inverseWarp", (PyCFunction)pyopencv_cv_reg_reg_MapAffine_inverseWarp, METH_VARARGS | METH_KEYWORDS, "inverseWarp(img1[, img2]) -> img2"},
    {"scale", (PyCFunction)pyopencv_cv_reg_reg_MapAffine_scale, METH_VARARGS | METH_KEYWORDS, "scale(factor) -> None"},

    {NULL,          NULL}
};

static void pyopencv_reg_MapAffine_specials(void)
{
    pyopencv_reg_MapAffine_Type.tp_base = &pyopencv_reg_Map_Type;
    pyopencv_reg_MapAffine_Type.tp_dealloc = pyopencv_reg_MapAffine_dealloc;
    pyopencv_reg_MapAffine_Type.tp_repr = pyopencv_reg_MapAffine_repr;
    pyopencv_reg_MapAffine_Type.tp_getset = pyopencv_reg_MapAffine_getseters;
    pyopencv_reg_MapAffine_Type.tp_methods = pyopencv_reg_MapAffine_methods;
}

static PyObject* pyopencv_reg_Mapper_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<reg_Mapper %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_reg_Mapper_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_reg_reg_Mapper_calculate(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::reg;

    if(!PyObject_TypeCheck(self, &pyopencv_reg_Mapper_Type))
        return failmsgp("Incorrect type of self (must be 'reg_Mapper' or its derivative)");
    cv::reg::Mapper* _self_ = ((pyopencv_reg_Mapper_t*)self)->v.get();
    {
    PyObject* pyobj_img1 = NULL;
    Mat img1;
    PyObject* pyobj_img2 = NULL;
    Mat img2;
    PyObject* pyobj_init = NULL;
    Ptr<Map> init=cv::Ptr<Map>();
    cv::Ptr<Map> retval;

    const char* keywords[] = { "img1", "img2", "init", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|O:reg_Mapper.calculate", (char**)keywords, &pyobj_img1, &pyobj_img2, &pyobj_init) &&
        pyopencv_to(pyobj_img1, img1, ArgInfo("img1", 0)) &&
        pyopencv_to(pyobj_img2, img2, ArgInfo("img2", 0)) &&
        pyopencv_to(pyobj_init, init, ArgInfo("init", 0)) )
    {
        ERRWRAP2(retval = _self_->calculate(img1, img2, init));
        return pyopencv_from(retval);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_img1 = NULL;
    UMat img1;
    PyObject* pyobj_img2 = NULL;
    UMat img2;
    PyObject* pyobj_init = NULL;
    Ptr<Map> init=cv::Ptr<Map>();
    cv::Ptr<Map> retval;

    const char* keywords[] = { "img1", "img2", "init", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|O:reg_Mapper.calculate", (char**)keywords, &pyobj_img1, &pyobj_img2, &pyobj_init) &&
        pyopencv_to(pyobj_img1, img1, ArgInfo("img1", 0)) &&
        pyopencv_to(pyobj_img2, img2, ArgInfo("img2", 0)) &&
        pyopencv_to(pyobj_init, init, ArgInfo("init", 0)) )
    {
        ERRWRAP2(retval = _self_->calculate(img1, img2, init));
        return pyopencv_from(retval);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_reg_reg_Mapper_getMap(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::reg;

    if(!PyObject_TypeCheck(self, &pyopencv_reg_Mapper_Type))
        return failmsgp("Incorrect type of self (must be 'reg_Mapper' or its derivative)");
    cv::reg::Mapper* _self_ = ((pyopencv_reg_Mapper_t*)self)->v.get();
    cv::Ptr<Map> retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getMap());
        return pyopencv_from(retval);
    }

    return NULL;
}



static PyMethodDef pyopencv_reg_Mapper_methods[] =
{
    {"calculate", (PyCFunction)pyopencv_cv_reg_reg_Mapper_calculate, METH_VARARGS | METH_KEYWORDS, "calculate(img1, img2[, init]) -> retval"},
    {"getMap", (PyCFunction)pyopencv_cv_reg_reg_Mapper_getMap, METH_VARARGS | METH_KEYWORDS, "getMap() -> retval"},

    {NULL,          NULL}
};

static void pyopencv_reg_Mapper_specials(void)
{
    pyopencv_reg_Mapper_Type.tp_base = NULL;
    pyopencv_reg_Mapper_Type.tp_dealloc = pyopencv_reg_Mapper_dealloc;
    pyopencv_reg_Mapper_Type.tp_repr = pyopencv_reg_Mapper_repr;
    pyopencv_reg_Mapper_Type.tp_getset = pyopencv_reg_Mapper_getseters;
    pyopencv_reg_Mapper_Type.tp_methods = pyopencv_reg_Mapper_methods;
}

static PyObject* pyopencv_reg_MapperGradAffine_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<reg_MapperGradAffine %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_reg_MapperGradAffine_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_reg_reg_MapperGradAffine_calculate(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::reg;

    if(!PyObject_TypeCheck(self, &pyopencv_reg_MapperGradAffine_Type))
        return failmsgp("Incorrect type of self (must be 'reg_MapperGradAffine' or its derivative)");
    cv::reg::MapperGradAffine* _self_ = ((pyopencv_reg_MapperGradAffine_t*)self)->v.get();
    {
    PyObject* pyobj_img1 = NULL;
    Mat img1;
    PyObject* pyobj_img2 = NULL;
    Mat img2;
    PyObject* pyobj_init = NULL;
    Ptr<Map> init=cv::Ptr<Map>();
    cv::Ptr<Map> retval;

    const char* keywords[] = { "img1", "img2", "init", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|O:reg_MapperGradAffine.calculate", (char**)keywords, &pyobj_img1, &pyobj_img2, &pyobj_init) &&
        pyopencv_to(pyobj_img1, img1, ArgInfo("img1", 0)) &&
        pyopencv_to(pyobj_img2, img2, ArgInfo("img2", 0)) &&
        pyopencv_to(pyobj_init, init, ArgInfo("init", 0)) )
    {
        ERRWRAP2(retval = _self_->calculate(img1, img2, init));
        return pyopencv_from(retval);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_img1 = NULL;
    UMat img1;
    PyObject* pyobj_img2 = NULL;
    UMat img2;
    PyObject* pyobj_init = NULL;
    Ptr<Map> init=cv::Ptr<Map>();
    cv::Ptr<Map> retval;

    const char* keywords[] = { "img1", "img2", "init", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|O:reg_MapperGradAffine.calculate", (char**)keywords, &pyobj_img1, &pyobj_img2, &pyobj_init) &&
        pyopencv_to(pyobj_img1, img1, ArgInfo("img1", 0)) &&
        pyopencv_to(pyobj_img2, img2, ArgInfo("img2", 0)) &&
        pyopencv_to(pyobj_init, init, ArgInfo("init", 0)) )
    {
        ERRWRAP2(retval = _self_->calculate(img1, img2, init));
        return pyopencv_from(retval);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_reg_reg_MapperGradAffine_getMap(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::reg;

    if(!PyObject_TypeCheck(self, &pyopencv_reg_MapperGradAffine_Type))
        return failmsgp("Incorrect type of self (must be 'reg_MapperGradAffine' or its derivative)");
    cv::reg::MapperGradAffine* _self_ = ((pyopencv_reg_MapperGradAffine_t*)self)->v.get();
    cv::Ptr<Map> retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getMap());
        return pyopencv_from(retval);
    }

    return NULL;
}



static PyMethodDef pyopencv_reg_MapperGradAffine_methods[] =
{
    {"calculate", (PyCFunction)pyopencv_cv_reg_reg_MapperGradAffine_calculate, METH_VARARGS | METH_KEYWORDS, "calculate(img1, img2[, init]) -> retval"},
    {"getMap", (PyCFunction)pyopencv_cv_reg_reg_MapperGradAffine_getMap, METH_VARARGS | METH_KEYWORDS, "getMap() -> retval"},

    {NULL,          NULL}
};

static void pyopencv_reg_MapperGradAffine_specials(void)
{
    pyopencv_reg_MapperGradAffine_Type.tp_base = &pyopencv_reg_Mapper_Type;
    pyopencv_reg_MapperGradAffine_Type.tp_dealloc = pyopencv_reg_MapperGradAffine_dealloc;
    pyopencv_reg_MapperGradAffine_Type.tp_repr = pyopencv_reg_MapperGradAffine_repr;
    pyopencv_reg_MapperGradAffine_Type.tp_getset = pyopencv_reg_MapperGradAffine_getseters;
    pyopencv_reg_MapperGradAffine_Type.tp_methods = pyopencv_reg_MapperGradAffine_methods;
}

static PyObject* pyopencv_reg_MapperGradEuclid_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<reg_MapperGradEuclid %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_reg_MapperGradEuclid_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_reg_reg_MapperGradEuclid_calculate(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::reg;

    if(!PyObject_TypeCheck(self, &pyopencv_reg_MapperGradEuclid_Type))
        return failmsgp("Incorrect type of self (must be 'reg_MapperGradEuclid' or its derivative)");
    cv::reg::MapperGradEuclid* _self_ = ((pyopencv_reg_MapperGradEuclid_t*)self)->v.get();
    {
    PyObject* pyobj_img1 = NULL;
    Mat img1;
    PyObject* pyobj_img2 = NULL;
    Mat img2;
    PyObject* pyobj_init = NULL;
    Ptr<Map> init=cv::Ptr<Map>();
    cv::Ptr<Map> retval;

    const char* keywords[] = { "img1", "img2", "init", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|O:reg_MapperGradEuclid.calculate", (char**)keywords, &pyobj_img1, &pyobj_img2, &pyobj_init) &&
        pyopencv_to(pyobj_img1, img1, ArgInfo("img1", 0)) &&
        pyopencv_to(pyobj_img2, img2, ArgInfo("img2", 0)) &&
        pyopencv_to(pyobj_init, init, ArgInfo("init", 0)) )
    {
        ERRWRAP2(retval = _self_->calculate(img1, img2, init));
        return pyopencv_from(retval);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_img1 = NULL;
    UMat img1;
    PyObject* pyobj_img2 = NULL;
    UMat img2;
    PyObject* pyobj_init = NULL;
    Ptr<Map> init=cv::Ptr<Map>();
    cv::Ptr<Map> retval;

    const char* keywords[] = { "img1", "img2", "init", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|O:reg_MapperGradEuclid.calculate", (char**)keywords, &pyobj_img1, &pyobj_img2, &pyobj_init) &&
        pyopencv_to(pyobj_img1, img1, ArgInfo("img1", 0)) &&
        pyopencv_to(pyobj_img2, img2, ArgInfo("img2", 0)) &&
        pyopencv_to(pyobj_init, init, ArgInfo("init", 0)) )
    {
        ERRWRAP2(retval = _self_->calculate(img1, img2, init));
        return pyopencv_from(retval);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_reg_reg_MapperGradEuclid_getMap(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::reg;

    if(!PyObject_TypeCheck(self, &pyopencv_reg_MapperGradEuclid_Type))
        return failmsgp("Incorrect type of self (must be 'reg_MapperGradEuclid' or its derivative)");
    cv::reg::MapperGradEuclid* _self_ = ((pyopencv_reg_MapperGradEuclid_t*)self)->v.get();
    cv::Ptr<Map> retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getMap());
        return pyopencv_from(retval);
    }

    return NULL;
}



static PyMethodDef pyopencv_reg_MapperGradEuclid_methods[] =
{
    {"calculate", (PyCFunction)pyopencv_cv_reg_reg_MapperGradEuclid_calculate, METH_VARARGS | METH_KEYWORDS, "calculate(img1, img2[, init]) -> retval"},
    {"getMap", (PyCFunction)pyopencv_cv_reg_reg_MapperGradEuclid_getMap, METH_VARARGS | METH_KEYWORDS, "getMap() -> retval"},

    {NULL,          NULL}
};

static void pyopencv_reg_MapperGradEuclid_specials(void)
{
    pyopencv_reg_MapperGradEuclid_Type.tp_base = &pyopencv_reg_Mapper_Type;
    pyopencv_reg_MapperGradEuclid_Type.tp_dealloc = pyopencv_reg_MapperGradEuclid_dealloc;
    pyopencv_reg_MapperGradEuclid_Type.tp_repr = pyopencv_reg_MapperGradEuclid_repr;
    pyopencv_reg_MapperGradEuclid_Type.tp_getset = pyopencv_reg_MapperGradEuclid_getseters;
    pyopencv_reg_MapperGradEuclid_Type.tp_methods = pyopencv_reg_MapperGradEuclid_methods;
}

static PyObject* pyopencv_reg_MapperGradProj_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<reg_MapperGradProj %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_reg_MapperGradProj_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_reg_reg_MapperGradProj_calculate(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::reg;

    if(!PyObject_TypeCheck(self, &pyopencv_reg_MapperGradProj_Type))
        return failmsgp("Incorrect type of self (must be 'reg_MapperGradProj' or its derivative)");
    cv::reg::MapperGradProj* _self_ = ((pyopencv_reg_MapperGradProj_t*)self)->v.get();
    {
    PyObject* pyobj_img1 = NULL;
    Mat img1;
    PyObject* pyobj_img2 = NULL;
    Mat img2;
    PyObject* pyobj_init = NULL;
    Ptr<Map> init=cv::Ptr<Map>();
    cv::Ptr<Map> retval;

    const char* keywords[] = { "img1", "img2", "init", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|O:reg_MapperGradProj.calculate", (char**)keywords, &pyobj_img1, &pyobj_img2, &pyobj_init) &&
        pyopencv_to(pyobj_img1, img1, ArgInfo("img1", 0)) &&
        pyopencv_to(pyobj_img2, img2, ArgInfo("img2", 0)) &&
        pyopencv_to(pyobj_init, init, ArgInfo("init", 0)) )
    {
        ERRWRAP2(retval = _self_->calculate(img1, img2, init));
        return pyopencv_from(retval);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_img1 = NULL;
    UMat img1;
    PyObject* pyobj_img2 = NULL;
    UMat img2;
    PyObject* pyobj_init = NULL;
    Ptr<Map> init=cv::Ptr<Map>();
    cv::Ptr<Map> retval;

    const char* keywords[] = { "img1", "img2", "init", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|O:reg_MapperGradProj.calculate", (char**)keywords, &pyobj_img1, &pyobj_img2, &pyobj_init) &&
        pyopencv_to(pyobj_img1, img1, ArgInfo("img1", 0)) &&
        pyopencv_to(pyobj_img2, img2, ArgInfo("img2", 0)) &&
        pyopencv_to(pyobj_init, init, ArgInfo("init", 0)) )
    {
        ERRWRAP2(retval = _self_->calculate(img1, img2, init));
        return pyopencv_from(retval);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_reg_reg_MapperGradProj_getMap(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::reg;

    if(!PyObject_TypeCheck(self, &pyopencv_reg_MapperGradProj_Type))
        return failmsgp("Incorrect type of self (must be 'reg_MapperGradProj' or its derivative)");
    cv::reg::MapperGradProj* _self_ = ((pyopencv_reg_MapperGradProj_t*)self)->v.get();
    cv::Ptr<Map> retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getMap());
        return pyopencv_from(retval);
    }

    return NULL;
}



static PyMethodDef pyopencv_reg_MapperGradProj_methods[] =
{
    {"calculate", (PyCFunction)pyopencv_cv_reg_reg_MapperGradProj_calculate, METH_VARARGS | METH_KEYWORDS, "calculate(img1, img2[, init]) -> retval"},
    {"getMap", (PyCFunction)pyopencv_cv_reg_reg_MapperGradProj_getMap, METH_VARARGS | METH_KEYWORDS, "getMap() -> retval"},

    {NULL,          NULL}
};

static void pyopencv_reg_MapperGradProj_specials(void)
{
    pyopencv_reg_MapperGradProj_Type.tp_base = &pyopencv_reg_Mapper_Type;
    pyopencv_reg_MapperGradProj_Type.tp_dealloc = pyopencv_reg_MapperGradProj_dealloc;
    pyopencv_reg_MapperGradProj_Type.tp_repr = pyopencv_reg_MapperGradProj_repr;
    pyopencv_reg_MapperGradProj_Type.tp_getset = pyopencv_reg_MapperGradProj_getseters;
    pyopencv_reg_MapperGradProj_Type.tp_methods = pyopencv_reg_MapperGradProj_methods;
}

static PyObject* pyopencv_reg_MapperGradShift_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<reg_MapperGradShift %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_reg_MapperGradShift_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_reg_reg_MapperGradShift_calculate(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::reg;

    if(!PyObject_TypeCheck(self, &pyopencv_reg_MapperGradShift_Type))
        return failmsgp("Incorrect type of self (must be 'reg_MapperGradShift' or its derivative)");
    cv::reg::MapperGradShift* _self_ = ((pyopencv_reg_MapperGradShift_t*)self)->v.get();
    {
    PyObject* pyobj_img1 = NULL;
    Mat img1;
    PyObject* pyobj_img2 = NULL;
    Mat img2;
    PyObject* pyobj_init = NULL;
    Ptr<Map> init=cv::Ptr<Map>();
    cv::Ptr<Map> retval;

    const char* keywords[] = { "img1", "img2", "init", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|O:reg_MapperGradShift.calculate", (char**)keywords, &pyobj_img1, &pyobj_img2, &pyobj_init) &&
        pyopencv_to(pyobj_img1, img1, ArgInfo("img1", 0)) &&
        pyopencv_to(pyobj_img2, img2, ArgInfo("img2", 0)) &&
        pyopencv_to(pyobj_init, init, ArgInfo("init", 0)) )
    {
        ERRWRAP2(retval = _self_->calculate(img1, img2, init));
        return pyopencv_from(retval);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_img1 = NULL;
    UMat img1;
    PyObject* pyobj_img2 = NULL;
    UMat img2;
    PyObject* pyobj_init = NULL;
    Ptr<Map> init=cv::Ptr<Map>();
    cv::Ptr<Map> retval;

    const char* keywords[] = { "img1", "img2", "init", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|O:reg_MapperGradShift.calculate", (char**)keywords, &pyobj_img1, &pyobj_img2, &pyobj_init) &&
        pyopencv_to(pyobj_img1, img1, ArgInfo("img1", 0)) &&
        pyopencv_to(pyobj_img2, img2, ArgInfo("img2", 0)) &&
        pyopencv_to(pyobj_init, init, ArgInfo("init", 0)) )
    {
        ERRWRAP2(retval = _self_->calculate(img1, img2, init));
        return pyopencv_from(retval);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_reg_reg_MapperGradShift_getMap(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::reg;

    if(!PyObject_TypeCheck(self, &pyopencv_reg_MapperGradShift_Type))
        return failmsgp("Incorrect type of self (must be 'reg_MapperGradShift' or its derivative)");
    cv::reg::MapperGradShift* _self_ = ((pyopencv_reg_MapperGradShift_t*)self)->v.get();
    cv::Ptr<Map> retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getMap());
        return pyopencv_from(retval);
    }

    return NULL;
}



static PyMethodDef pyopencv_reg_MapperGradShift_methods[] =
{
    {"calculate", (PyCFunction)pyopencv_cv_reg_reg_MapperGradShift_calculate, METH_VARARGS | METH_KEYWORDS, "calculate(img1, img2[, init]) -> retval"},
    {"getMap", (PyCFunction)pyopencv_cv_reg_reg_MapperGradShift_getMap, METH_VARARGS | METH_KEYWORDS, "getMap() -> retval"},

    {NULL,          NULL}
};

static void pyopencv_reg_MapperGradShift_specials(void)
{
    pyopencv_reg_MapperGradShift_Type.tp_base = &pyopencv_reg_Mapper_Type;
    pyopencv_reg_MapperGradShift_Type.tp_dealloc = pyopencv_reg_MapperGradShift_dealloc;
    pyopencv_reg_MapperGradShift_Type.tp_repr = pyopencv_reg_MapperGradShift_repr;
    pyopencv_reg_MapperGradShift_Type.tp_getset = pyopencv_reg_MapperGradShift_getseters;
    pyopencv_reg_MapperGradShift_Type.tp_methods = pyopencv_reg_MapperGradShift_methods;
}

static PyObject* pyopencv_reg_MapperGradSimilar_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<reg_MapperGradSimilar %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_reg_MapperGradSimilar_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_reg_reg_MapperGradSimilar_calculate(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::reg;

    if(!PyObject_TypeCheck(self, &pyopencv_reg_MapperGradSimilar_Type))
        return failmsgp("Incorrect type of self (must be 'reg_MapperGradSimilar' or its derivative)");
    cv::reg::MapperGradSimilar* _self_ = ((pyopencv_reg_MapperGradSimilar_t*)self)->v.get();
    {
    PyObject* pyobj_img1 = NULL;
    Mat img1;
    PyObject* pyobj_img2 = NULL;
    Mat img2;
    PyObject* pyobj_init = NULL;
    Ptr<Map> init=cv::Ptr<Map>();
    cv::Ptr<Map> retval;

    const char* keywords[] = { "img1", "img2", "init", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|O:reg_MapperGradSimilar.calculate", (char**)keywords, &pyobj_img1, &pyobj_img2, &pyobj_init) &&
        pyopencv_to(pyobj_img1, img1, ArgInfo("img1", 0)) &&
        pyopencv_to(pyobj_img2, img2, ArgInfo("img2", 0)) &&
        pyopencv_to(pyobj_init, init, ArgInfo("init", 0)) )
    {
        ERRWRAP2(retval = _self_->calculate(img1, img2, init));
        return pyopencv_from(retval);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_img1 = NULL;
    UMat img1;
    PyObject* pyobj_img2 = NULL;
    UMat img2;
    PyObject* pyobj_init = NULL;
    Ptr<Map> init=cv::Ptr<Map>();
    cv::Ptr<Map> retval;

    const char* keywords[] = { "img1", "img2", "init", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|O:reg_MapperGradSimilar.calculate", (char**)keywords, &pyobj_img1, &pyobj_img2, &pyobj_init) &&
        pyopencv_to(pyobj_img1, img1, ArgInfo("img1", 0)) &&
        pyopencv_to(pyobj_img2, img2, ArgInfo("img2", 0)) &&
        pyopencv_to(pyobj_init, init, ArgInfo("init", 0)) )
    {
        ERRWRAP2(retval = _self_->calculate(img1, img2, init));
        return pyopencv_from(retval);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_reg_reg_MapperGradSimilar_getMap(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::reg;

    if(!PyObject_TypeCheck(self, &pyopencv_reg_MapperGradSimilar_Type))
        return failmsgp("Incorrect type of self (must be 'reg_MapperGradSimilar' or its derivative)");
    cv::reg::MapperGradSimilar* _self_ = ((pyopencv_reg_MapperGradSimilar_t*)self)->v.get();
    cv::Ptr<Map> retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getMap());
        return pyopencv_from(retval);
    }

    return NULL;
}



static PyMethodDef pyopencv_reg_MapperGradSimilar_methods[] =
{
    {"calculate", (PyCFunction)pyopencv_cv_reg_reg_MapperGradSimilar_calculate, METH_VARARGS | METH_KEYWORDS, "calculate(img1, img2[, init]) -> retval"},
    {"getMap", (PyCFunction)pyopencv_cv_reg_reg_MapperGradSimilar_getMap, METH_VARARGS | METH_KEYWORDS, "getMap() -> retval"},

    {NULL,          NULL}
};

static void pyopencv_reg_MapperGradSimilar_specials(void)
{
    pyopencv_reg_MapperGradSimilar_Type.tp_base = &pyopencv_reg_Mapper_Type;
    pyopencv_reg_MapperGradSimilar_Type.tp_dealloc = pyopencv_reg_MapperGradSimilar_dealloc;
    pyopencv_reg_MapperGradSimilar_Type.tp_repr = pyopencv_reg_MapperGradSimilar_repr;
    pyopencv_reg_MapperGradSimilar_Type.tp_getset = pyopencv_reg_MapperGradSimilar_getseters;
    pyopencv_reg_MapperGradSimilar_Type.tp_methods = pyopencv_reg_MapperGradSimilar_methods;
}

static PyObject* pyopencv_reg_MapperPyramid_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<reg_MapperPyramid %p>", self);
    return PyString_FromString(str);
}


static PyObject* pyopencv_reg_MapperPyramid_get_numIterPerScale_(pyopencv_reg_MapperPyramid_t* p, void *closure)
{
    return pyopencv_from(p->v->numIterPerScale_);
}

static int pyopencv_reg_MapperPyramid_set_numIterPerScale_(pyopencv_reg_MapperPyramid_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the numIterPerScale_ attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->numIterPerScale_) ? 0 : -1;
}

static PyObject* pyopencv_reg_MapperPyramid_get_numLev_(pyopencv_reg_MapperPyramid_t* p, void *closure)
{
    return pyopencv_from(p->v->numLev_);
}

static int pyopencv_reg_MapperPyramid_set_numLev_(pyopencv_reg_MapperPyramid_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the numLev_ attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->numLev_) ? 0 : -1;
}


static PyGetSetDef pyopencv_reg_MapperPyramid_getseters[] =
{
    {(char*)"numIterPerScale_", (getter)pyopencv_reg_MapperPyramid_get_numIterPerScale_, (setter)pyopencv_reg_MapperPyramid_set_numIterPerScale_, (char*)"numIterPerScale_", NULL},
    {(char*)"numLev_", (getter)pyopencv_reg_MapperPyramid_get_numLev_, (setter)pyopencv_reg_MapperPyramid_set_numLev_, (char*)"numLev_", NULL},
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_reg_reg_MapperPyramid_calculate(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::reg;

    if(!PyObject_TypeCheck(self, &pyopencv_reg_MapperPyramid_Type))
        return failmsgp("Incorrect type of self (must be 'reg_MapperPyramid' or its derivative)");
    cv::reg::MapperPyramid* _self_ = ((pyopencv_reg_MapperPyramid_t*)self)->v.get();
    {
    PyObject* pyobj_img1 = NULL;
    Mat img1;
    PyObject* pyobj_img2 = NULL;
    Mat img2;
    PyObject* pyobj_init = NULL;
    Ptr<Map> init=cv::Ptr<Map>();
    cv::Ptr<Map> retval;

    const char* keywords[] = { "img1", "img2", "init", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|O:reg_MapperPyramid.calculate", (char**)keywords, &pyobj_img1, &pyobj_img2, &pyobj_init) &&
        pyopencv_to(pyobj_img1, img1, ArgInfo("img1", 0)) &&
        pyopencv_to(pyobj_img2, img2, ArgInfo("img2", 0)) &&
        pyopencv_to(pyobj_init, init, ArgInfo("init", 0)) )
    {
        ERRWRAP2(retval = _self_->calculate(img1, img2, init));
        return pyopencv_from(retval);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_img1 = NULL;
    UMat img1;
    PyObject* pyobj_img2 = NULL;
    UMat img2;
    PyObject* pyobj_init = NULL;
    Ptr<Map> init=cv::Ptr<Map>();
    cv::Ptr<Map> retval;

    const char* keywords[] = { "img1", "img2", "init", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|O:reg_MapperPyramid.calculate", (char**)keywords, &pyobj_img1, &pyobj_img2, &pyobj_init) &&
        pyopencv_to(pyobj_img1, img1, ArgInfo("img1", 0)) &&
        pyopencv_to(pyobj_img2, img2, ArgInfo("img2", 0)) &&
        pyopencv_to(pyobj_init, init, ArgInfo("init", 0)) )
    {
        ERRWRAP2(retval = _self_->calculate(img1, img2, init));
        return pyopencv_from(retval);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_reg_reg_MapperPyramid_getMap(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::reg;

    if(!PyObject_TypeCheck(self, &pyopencv_reg_MapperPyramid_Type))
        return failmsgp("Incorrect type of self (must be 'reg_MapperPyramid' or its derivative)");
    cv::reg::MapperPyramid* _self_ = ((pyopencv_reg_MapperPyramid_t*)self)->v.get();
    cv::Ptr<Map> retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getMap());
        return pyopencv_from(retval);
    }

    return NULL;
}



static PyMethodDef pyopencv_reg_MapperPyramid_methods[] =
{
    {"calculate", (PyCFunction)pyopencv_cv_reg_reg_MapperPyramid_calculate, METH_VARARGS | METH_KEYWORDS, "calculate(img1, img2[, init]) -> retval"},
    {"getMap", (PyCFunction)pyopencv_cv_reg_reg_MapperPyramid_getMap, METH_VARARGS | METH_KEYWORDS, "getMap() -> retval"},

    {NULL,          NULL}
};

static void pyopencv_reg_MapperPyramid_specials(void)
{
    pyopencv_reg_MapperPyramid_Type.tp_base = &pyopencv_reg_Mapper_Type;
    pyopencv_reg_MapperPyramid_Type.tp_dealloc = pyopencv_reg_MapperPyramid_dealloc;
    pyopencv_reg_MapperPyramid_Type.tp_repr = pyopencv_reg_MapperPyramid_repr;
    pyopencv_reg_MapperPyramid_Type.tp_getset = pyopencv_reg_MapperPyramid_getseters;
    pyopencv_reg_MapperPyramid_Type.tp_methods = pyopencv_reg_MapperPyramid_methods;
}

static PyObject* pyopencv_reg_MapTypeCaster_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<reg_MapTypeCaster %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_reg_MapTypeCaster_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_reg_MapTypeCaster_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_reg_MapTypeCaster_specials(void)
{
    pyopencv_reg_MapTypeCaster_Type.tp_base = NULL;
    pyopencv_reg_MapTypeCaster_Type.tp_dealloc = pyopencv_reg_MapTypeCaster_dealloc;
    pyopencv_reg_MapTypeCaster_Type.tp_repr = pyopencv_reg_MapTypeCaster_repr;
    pyopencv_reg_MapTypeCaster_Type.tp_getset = pyopencv_reg_MapTypeCaster_getseters;
    pyopencv_reg_MapTypeCaster_Type.tp_methods = pyopencv_reg_MapTypeCaster_methods;
}

static PyObject* pyopencv_reg_MapProjec_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<reg_MapProjec %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_reg_MapProjec_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_reg_reg_MapProjec_compose(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::reg;

    if(!PyObject_TypeCheck(self, &pyopencv_reg_MapProjec_Type))
        return failmsgp("Incorrect type of self (must be 'reg_MapProjec' or its derivative)");
    cv::reg::MapProjec* _self_ = ((pyopencv_reg_MapProjec_t*)self)->v.get();
    PyObject* pyobj_map = NULL;
    Ptr<Map> map;

    const char* keywords[] = { "map", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:reg_MapProjec.compose", (char**)keywords, &pyobj_map) &&
        pyopencv_to(pyobj_map, map, ArgInfo("map", 0)) )
    {
        ERRWRAP2(_self_->compose(map));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_reg_reg_MapProjec_getProjTr(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::reg;

    if(!PyObject_TypeCheck(self, &pyopencv_reg_MapProjec_Type))
        return failmsgp("Incorrect type of self (must be 'reg_MapProjec' or its derivative)");
    cv::reg::MapProjec* _self_ = ((pyopencv_reg_MapProjec_t*)self)->v.get();
    {
    PyObject* pyobj_projTr = NULL;
    Mat projTr;

    const char* keywords[] = { "projTr", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|O:reg_MapProjec.getProjTr", (char**)keywords, &pyobj_projTr) &&
        pyopencv_to(pyobj_projTr, projTr, ArgInfo("projTr", 1)) )
    {
        ERRWRAP2(_self_->getProjTr(projTr));
        return pyopencv_from(projTr);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_projTr = NULL;
    UMat projTr;

    const char* keywords[] = { "projTr", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|O:reg_MapProjec.getProjTr", (char**)keywords, &pyobj_projTr) &&
        pyopencv_to(pyobj_projTr, projTr, ArgInfo("projTr", 1)) )
    {
        ERRWRAP2(_self_->getProjTr(projTr));
        return pyopencv_from(projTr);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_reg_reg_MapProjec_inverseMap(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::reg;

    if(!PyObject_TypeCheck(self, &pyopencv_reg_MapProjec_Type))
        return failmsgp("Incorrect type of self (must be 'reg_MapProjec' or its derivative)");
    cv::reg::MapProjec* _self_ = ((pyopencv_reg_MapProjec_t*)self)->v.get();
    cv::Ptr<Map> retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->inverseMap());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_reg_reg_MapProjec_inverseWarp(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::reg;

    if(!PyObject_TypeCheck(self, &pyopencv_reg_MapProjec_Type))
        return failmsgp("Incorrect type of self (must be 'reg_MapProjec' or its derivative)");
    cv::reg::MapProjec* _self_ = ((pyopencv_reg_MapProjec_t*)self)->v.get();
    {
    PyObject* pyobj_img1 = NULL;
    Mat img1;
    PyObject* pyobj_img2 = NULL;
    Mat img2;

    const char* keywords[] = { "img1", "img2", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:reg_MapProjec.inverseWarp", (char**)keywords, &pyobj_img1, &pyobj_img2) &&
        pyopencv_to(pyobj_img1, img1, ArgInfo("img1", 0)) &&
        pyopencv_to(pyobj_img2, img2, ArgInfo("img2", 1)) )
    {
        ERRWRAP2(_self_->inverseWarp(img1, img2));
        return pyopencv_from(img2);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_img1 = NULL;
    UMat img1;
    PyObject* pyobj_img2 = NULL;
    UMat img2;

    const char* keywords[] = { "img1", "img2", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:reg_MapProjec.inverseWarp", (char**)keywords, &pyobj_img1, &pyobj_img2) &&
        pyopencv_to(pyobj_img1, img1, ArgInfo("img1", 0)) &&
        pyopencv_to(pyobj_img2, img2, ArgInfo("img2", 1)) )
    {
        ERRWRAP2(_self_->inverseWarp(img1, img2));
        return pyopencv_from(img2);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_reg_reg_MapProjec_normalize(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::reg;

    if(!PyObject_TypeCheck(self, &pyopencv_reg_MapProjec_Type))
        return failmsgp("Incorrect type of self (must be 'reg_MapProjec' or its derivative)");
    cv::reg::MapProjec* _self_ = ((pyopencv_reg_MapProjec_t*)self)->v.get();

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(_self_->normalize());
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_reg_reg_MapProjec_scale(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::reg;

    if(!PyObject_TypeCheck(self, &pyopencv_reg_MapProjec_Type))
        return failmsgp("Incorrect type of self (must be 'reg_MapProjec' or its derivative)");
    cv::reg::MapProjec* _self_ = ((pyopencv_reg_MapProjec_t*)self)->v.get();
    double factor=0;

    const char* keywords[] = { "factor", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:reg_MapProjec.scale", (char**)keywords, &factor) )
    {
        ERRWRAP2(_self_->scale(factor));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_reg_MapProjec_methods[] =
{
    {"compose", (PyCFunction)pyopencv_cv_reg_reg_MapProjec_compose, METH_VARARGS | METH_KEYWORDS, "compose(map) -> None"},
    {"getProjTr", (PyCFunction)pyopencv_cv_reg_reg_MapProjec_getProjTr, METH_VARARGS | METH_KEYWORDS, "getProjTr([, projTr]) -> projTr"},
    {"inverseMap", (PyCFunction)pyopencv_cv_reg_reg_MapProjec_inverseMap, METH_VARARGS | METH_KEYWORDS, "inverseMap() -> retval"},
    {"inverseWarp", (PyCFunction)pyopencv_cv_reg_reg_MapProjec_inverseWarp, METH_VARARGS | METH_KEYWORDS, "inverseWarp(img1[, img2]) -> img2"},
    {"normalize", (PyCFunction)pyopencv_cv_reg_reg_MapProjec_normalize, METH_VARARGS | METH_KEYWORDS, "normalize() -> None"},
    {"scale", (PyCFunction)pyopencv_cv_reg_reg_MapProjec_scale, METH_VARARGS | METH_KEYWORDS, "scale(factor) -> None"},

    {NULL,          NULL}
};

static void pyopencv_reg_MapProjec_specials(void)
{
    pyopencv_reg_MapProjec_Type.tp_base = &pyopencv_reg_Map_Type;
    pyopencv_reg_MapProjec_Type.tp_dealloc = pyopencv_reg_MapProjec_dealloc;
    pyopencv_reg_MapProjec_Type.tp_repr = pyopencv_reg_MapProjec_repr;
    pyopencv_reg_MapProjec_Type.tp_getset = pyopencv_reg_MapProjec_getseters;
    pyopencv_reg_MapProjec_Type.tp_methods = pyopencv_reg_MapProjec_methods;
}

static PyObject* pyopencv_reg_MapShift_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<reg_MapShift %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_reg_MapShift_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_reg_reg_MapShift_compose(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::reg;

    if(!PyObject_TypeCheck(self, &pyopencv_reg_MapShift_Type))
        return failmsgp("Incorrect type of self (must be 'reg_MapShift' or its derivative)");
    cv::reg::MapShift* _self_ = ((pyopencv_reg_MapShift_t*)self)->v.get();
    PyObject* pyobj_map = NULL;
    Ptr<Map> map;

    const char* keywords[] = { "map", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:reg_MapShift.compose", (char**)keywords, &pyobj_map) &&
        pyopencv_to(pyobj_map, map, ArgInfo("map", 0)) )
    {
        ERRWRAP2(_self_->compose(map));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_reg_reg_MapShift_getShift(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::reg;

    if(!PyObject_TypeCheck(self, &pyopencv_reg_MapShift_Type))
        return failmsgp("Incorrect type of self (must be 'reg_MapShift' or its derivative)");
    cv::reg::MapShift* _self_ = ((pyopencv_reg_MapShift_t*)self)->v.get();
    {
    PyObject* pyobj_shift = NULL;
    Mat shift;

    const char* keywords[] = { "shift", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|O:reg_MapShift.getShift", (char**)keywords, &pyobj_shift) &&
        pyopencv_to(pyobj_shift, shift, ArgInfo("shift", 1)) )
    {
        ERRWRAP2(_self_->getShift(shift));
        return pyopencv_from(shift);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_shift = NULL;
    UMat shift;

    const char* keywords[] = { "shift", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|O:reg_MapShift.getShift", (char**)keywords, &pyobj_shift) &&
        pyopencv_to(pyobj_shift, shift, ArgInfo("shift", 1)) )
    {
        ERRWRAP2(_self_->getShift(shift));
        return pyopencv_from(shift);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_reg_reg_MapShift_inverseMap(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::reg;

    if(!PyObject_TypeCheck(self, &pyopencv_reg_MapShift_Type))
        return failmsgp("Incorrect type of self (must be 'reg_MapShift' or its derivative)");
    cv::reg::MapShift* _self_ = ((pyopencv_reg_MapShift_t*)self)->v.get();
    cv::Ptr<Map> retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->inverseMap());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_reg_reg_MapShift_inverseWarp(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::reg;

    if(!PyObject_TypeCheck(self, &pyopencv_reg_MapShift_Type))
        return failmsgp("Incorrect type of self (must be 'reg_MapShift' or its derivative)");
    cv::reg::MapShift* _self_ = ((pyopencv_reg_MapShift_t*)self)->v.get();
    {
    PyObject* pyobj_img1 = NULL;
    Mat img1;
    PyObject* pyobj_img2 = NULL;
    Mat img2;

    const char* keywords[] = { "img1", "img2", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:reg_MapShift.inverseWarp", (char**)keywords, &pyobj_img1, &pyobj_img2) &&
        pyopencv_to(pyobj_img1, img1, ArgInfo("img1", 0)) &&
        pyopencv_to(pyobj_img2, img2, ArgInfo("img2", 1)) )
    {
        ERRWRAP2(_self_->inverseWarp(img1, img2));
        return pyopencv_from(img2);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_img1 = NULL;
    UMat img1;
    PyObject* pyobj_img2 = NULL;
    UMat img2;

    const char* keywords[] = { "img1", "img2", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:reg_MapShift.inverseWarp", (char**)keywords, &pyobj_img1, &pyobj_img2) &&
        pyopencv_to(pyobj_img1, img1, ArgInfo("img1", 0)) &&
        pyopencv_to(pyobj_img2, img2, ArgInfo("img2", 1)) )
    {
        ERRWRAP2(_self_->inverseWarp(img1, img2));
        return pyopencv_from(img2);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_reg_reg_MapShift_scale(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::reg;

    if(!PyObject_TypeCheck(self, &pyopencv_reg_MapShift_Type))
        return failmsgp("Incorrect type of self (must be 'reg_MapShift' or its derivative)");
    cv::reg::MapShift* _self_ = ((pyopencv_reg_MapShift_t*)self)->v.get();
    double factor=0;

    const char* keywords[] = { "factor", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:reg_MapShift.scale", (char**)keywords, &factor) )
    {
        ERRWRAP2(_self_->scale(factor));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_reg_MapShift_methods[] =
{
    {"compose", (PyCFunction)pyopencv_cv_reg_reg_MapShift_compose, METH_VARARGS | METH_KEYWORDS, "compose(map) -> None"},
    {"getShift", (PyCFunction)pyopencv_cv_reg_reg_MapShift_getShift, METH_VARARGS | METH_KEYWORDS, "getShift([, shift]) -> shift"},
    {"inverseMap", (PyCFunction)pyopencv_cv_reg_reg_MapShift_inverseMap, METH_VARARGS | METH_KEYWORDS, "inverseMap() -> retval"},
    {"inverseWarp", (PyCFunction)pyopencv_cv_reg_reg_MapShift_inverseWarp, METH_VARARGS | METH_KEYWORDS, "inverseWarp(img1[, img2]) -> img2"},
    {"scale", (PyCFunction)pyopencv_cv_reg_reg_MapShift_scale, METH_VARARGS | METH_KEYWORDS, "scale(factor) -> None"},

    {NULL,          NULL}
};

static void pyopencv_reg_MapShift_specials(void)
{
    pyopencv_reg_MapShift_Type.tp_base = &pyopencv_reg_Map_Type;
    pyopencv_reg_MapShift_Type.tp_dealloc = pyopencv_reg_MapShift_dealloc;
    pyopencv_reg_MapShift_Type.tp_repr = pyopencv_reg_MapShift_repr;
    pyopencv_reg_MapShift_Type.tp_getset = pyopencv_reg_MapShift_getseters;
    pyopencv_reg_MapShift_Type.tp_methods = pyopencv_reg_MapShift_methods;
}

static PyObject* pyopencv_ppf_match_3d_ICP_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<ppf_match_3d_ICP %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_ppf_match_3d_ICP_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_ppf_match_3d_ppf_match_3d_ICP_registerModelToScene(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ppf_match_3d;

    if(!PyObject_TypeCheck(self, &pyopencv_ppf_match_3d_ICP_Type))
        return failmsgp("Incorrect type of self (must be 'ppf_match_3d_ICP' or its derivative)");
    cv::ppf_match_3d::ICP* _self_ = ((pyopencv_ppf_match_3d_ICP_t*)self)->v.get();
    {
    PyObject* pyobj_srcPC = NULL;
    Mat srcPC;
    PyObject* pyobj_dstPC = NULL;
    Mat dstPC;
    double residual;
    Matx44d pose;
    int retval;

    const char* keywords[] = { "srcPC", "dstPC", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO:ppf_match_3d_ICP.registerModelToScene", (char**)keywords, &pyobj_srcPC, &pyobj_dstPC) &&
        pyopencv_to(pyobj_srcPC, srcPC, ArgInfo("srcPC", 0)) &&
        pyopencv_to(pyobj_dstPC, dstPC, ArgInfo("dstPC", 0)) )
    {
        ERRWRAP2(retval = _self_->registerModelToScene(srcPC, dstPC, residual, pose));
        return Py_BuildValue("(NNN)", pyopencv_from(retval), pyopencv_from(residual), pyopencv_from(pose));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_srcPC = NULL;
    Mat srcPC;
    PyObject* pyobj_dstPC = NULL;
    Mat dstPC;
    double residual;
    Matx44d pose;
    int retval;

    const char* keywords[] = { "srcPC", "dstPC", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO:ppf_match_3d_ICP.registerModelToScene", (char**)keywords, &pyobj_srcPC, &pyobj_dstPC) &&
        pyopencv_to(pyobj_srcPC, srcPC, ArgInfo("srcPC", 0)) &&
        pyopencv_to(pyobj_dstPC, dstPC, ArgInfo("dstPC", 0)) )
    {
        ERRWRAP2(retval = _self_->registerModelToScene(srcPC, dstPC, residual, pose));
        return Py_BuildValue("(NNN)", pyopencv_from(retval), pyopencv_from(residual), pyopencv_from(pose));
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_ppf_match_3d_ICP_methods[] =
{
    {"registerModelToScene", (PyCFunction)pyopencv_cv_ppf_match_3d_ppf_match_3d_ICP_registerModelToScene, METH_VARARGS | METH_KEYWORDS, "registerModelToScene(srcPC, dstPC) -> retval, residual, pose"},

    {NULL,          NULL}
};

static void pyopencv_ppf_match_3d_ICP_specials(void)
{
    pyopencv_ppf_match_3d_ICP_Type.tp_base = NULL;
    pyopencv_ppf_match_3d_ICP_Type.tp_dealloc = pyopencv_ppf_match_3d_ICP_dealloc;
    pyopencv_ppf_match_3d_ICP_Type.tp_repr = pyopencv_ppf_match_3d_ICP_repr;
    pyopencv_ppf_match_3d_ICP_Type.tp_getset = pyopencv_ppf_match_3d_ICP_getseters;
    pyopencv_ppf_match_3d_ICP_Type.tp_methods = pyopencv_ppf_match_3d_ICP_methods;
}

static PyObject* pyopencv_BackgroundSubtractor_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<BackgroundSubtractor %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_BackgroundSubtractor_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_BackgroundSubtractor_apply(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BackgroundSubtractor_Type))
        return failmsgp("Incorrect type of self (must be 'BackgroundSubtractor' or its derivative)");
    cv::BackgroundSubtractor* _self_ = dynamic_cast<cv::BackgroundSubtractor*>(((pyopencv_BackgroundSubtractor_t*)self)->v.get());
    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_fgmask = NULL;
    Mat fgmask;
    double learningRate=-1;

    const char* keywords[] = { "image", "fgmask", "learningRate", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|Od:BackgroundSubtractor.apply", (char**)keywords, &pyobj_image, &pyobj_fgmask, &learningRate) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_fgmask, fgmask, ArgInfo("fgmask", 1)) )
    {
        ERRWRAP2(_self_->apply(image, fgmask, learningRate));
        return pyopencv_from(fgmask);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_fgmask = NULL;
    UMat fgmask;
    double learningRate=-1;

    const char* keywords[] = { "image", "fgmask", "learningRate", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|Od:BackgroundSubtractor.apply", (char**)keywords, &pyobj_image, &pyobj_fgmask, &learningRate) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_fgmask, fgmask, ArgInfo("fgmask", 1)) )
    {
        ERRWRAP2(_self_->apply(image, fgmask, learningRate));
        return pyopencv_from(fgmask);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_BackgroundSubtractor_getBackgroundImage(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BackgroundSubtractor_Type))
        return failmsgp("Incorrect type of self (must be 'BackgroundSubtractor' or its derivative)");
    cv::BackgroundSubtractor* _self_ = dynamic_cast<cv::BackgroundSubtractor*>(((pyopencv_BackgroundSubtractor_t*)self)->v.get());
    {
    PyObject* pyobj_backgroundImage = NULL;
    Mat backgroundImage;

    const char* keywords[] = { "backgroundImage", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|O:BackgroundSubtractor.getBackgroundImage", (char**)keywords, &pyobj_backgroundImage) &&
        pyopencv_to(pyobj_backgroundImage, backgroundImage, ArgInfo("backgroundImage", 1)) )
    {
        ERRWRAP2(_self_->getBackgroundImage(backgroundImage));
        return pyopencv_from(backgroundImage);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_backgroundImage = NULL;
    UMat backgroundImage;

    const char* keywords[] = { "backgroundImage", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|O:BackgroundSubtractor.getBackgroundImage", (char**)keywords, &pyobj_backgroundImage) &&
        pyopencv_to(pyobj_backgroundImage, backgroundImage, ArgInfo("backgroundImage", 1)) )
    {
        ERRWRAP2(_self_->getBackgroundImage(backgroundImage));
        return pyopencv_from(backgroundImage);
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_BackgroundSubtractor_methods[] =
{
    {"apply", (PyCFunction)pyopencv_cv_BackgroundSubtractor_apply, METH_VARARGS | METH_KEYWORDS, "apply(image[, fgmask[, learningRate]]) -> fgmask"},
    {"getBackgroundImage", (PyCFunction)pyopencv_cv_BackgroundSubtractor_getBackgroundImage, METH_VARARGS | METH_KEYWORDS, "getBackgroundImage([, backgroundImage]) -> backgroundImage"},

    {NULL,          NULL}
};

static void pyopencv_BackgroundSubtractor_specials(void)
{
    pyopencv_BackgroundSubtractor_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_BackgroundSubtractor_Type.tp_dealloc = pyopencv_BackgroundSubtractor_dealloc;
    pyopencv_BackgroundSubtractor_Type.tp_repr = pyopencv_BackgroundSubtractor_repr;
    pyopencv_BackgroundSubtractor_Type.tp_getset = pyopencv_BackgroundSubtractor_getseters;
    pyopencv_BackgroundSubtractor_Type.tp_methods = pyopencv_BackgroundSubtractor_methods;
}

static PyObject* pyopencv_BackgroundSubtractorMOG2_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<BackgroundSubtractorMOG2 %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_BackgroundSubtractorMOG2_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_BackgroundSubtractorMOG2_apply(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BackgroundSubtractorMOG2_Type))
        return failmsgp("Incorrect type of self (must be 'BackgroundSubtractorMOG2' or its derivative)");
    cv::BackgroundSubtractorMOG2* _self_ = dynamic_cast<cv::BackgroundSubtractorMOG2*>(((pyopencv_BackgroundSubtractorMOG2_t*)self)->v.get());
    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_fgmask = NULL;
    Mat fgmask;
    double learningRate=-1;

    const char* keywords[] = { "image", "fgmask", "learningRate", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|Od:BackgroundSubtractorMOG2.apply", (char**)keywords, &pyobj_image, &pyobj_fgmask, &learningRate) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_fgmask, fgmask, ArgInfo("fgmask", 1)) )
    {
        ERRWRAP2(_self_->apply(image, fgmask, learningRate));
        return pyopencv_from(fgmask);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_fgmask = NULL;
    UMat fgmask;
    double learningRate=-1;

    const char* keywords[] = { "image", "fgmask", "learningRate", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|Od:BackgroundSubtractorMOG2.apply", (char**)keywords, &pyobj_image, &pyobj_fgmask, &learningRate) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_fgmask, fgmask, ArgInfo("fgmask", 1)) )
    {
        ERRWRAP2(_self_->apply(image, fgmask, learningRate));
        return pyopencv_from(fgmask);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_BackgroundSubtractorMOG2_getBackgroundRatio(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BackgroundSubtractorMOG2_Type))
        return failmsgp("Incorrect type of self (must be 'BackgroundSubtractorMOG2' or its derivative)");
    cv::BackgroundSubtractorMOG2* _self_ = dynamic_cast<cv::BackgroundSubtractorMOG2*>(((pyopencv_BackgroundSubtractorMOG2_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getBackgroundRatio());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_BackgroundSubtractorMOG2_getComplexityReductionThreshold(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BackgroundSubtractorMOG2_Type))
        return failmsgp("Incorrect type of self (must be 'BackgroundSubtractorMOG2' or its derivative)");
    cv::BackgroundSubtractorMOG2* _self_ = dynamic_cast<cv::BackgroundSubtractorMOG2*>(((pyopencv_BackgroundSubtractorMOG2_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getComplexityReductionThreshold());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_BackgroundSubtractorMOG2_getDetectShadows(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BackgroundSubtractorMOG2_Type))
        return failmsgp("Incorrect type of self (must be 'BackgroundSubtractorMOG2' or its derivative)");
    cv::BackgroundSubtractorMOG2* _self_ = dynamic_cast<cv::BackgroundSubtractorMOG2*>(((pyopencv_BackgroundSubtractorMOG2_t*)self)->v.get());
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getDetectShadows());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_BackgroundSubtractorMOG2_getHistory(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BackgroundSubtractorMOG2_Type))
        return failmsgp("Incorrect type of self (must be 'BackgroundSubtractorMOG2' or its derivative)");
    cv::BackgroundSubtractorMOG2* _self_ = dynamic_cast<cv::BackgroundSubtractorMOG2*>(((pyopencv_BackgroundSubtractorMOG2_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getHistory());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_BackgroundSubtractorMOG2_getNMixtures(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BackgroundSubtractorMOG2_Type))
        return failmsgp("Incorrect type of self (must be 'BackgroundSubtractorMOG2' or its derivative)");
    cv::BackgroundSubtractorMOG2* _self_ = dynamic_cast<cv::BackgroundSubtractorMOG2*>(((pyopencv_BackgroundSubtractorMOG2_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getNMixtures());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_BackgroundSubtractorMOG2_getShadowThreshold(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BackgroundSubtractorMOG2_Type))
        return failmsgp("Incorrect type of self (must be 'BackgroundSubtractorMOG2' or its derivative)");
    cv::BackgroundSubtractorMOG2* _self_ = dynamic_cast<cv::BackgroundSubtractorMOG2*>(((pyopencv_BackgroundSubtractorMOG2_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getShadowThreshold());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_BackgroundSubtractorMOG2_getShadowValue(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BackgroundSubtractorMOG2_Type))
        return failmsgp("Incorrect type of self (must be 'BackgroundSubtractorMOG2' or its derivative)");
    cv::BackgroundSubtractorMOG2* _self_ = dynamic_cast<cv::BackgroundSubtractorMOG2*>(((pyopencv_BackgroundSubtractorMOG2_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getShadowValue());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_BackgroundSubtractorMOG2_getVarInit(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BackgroundSubtractorMOG2_Type))
        return failmsgp("Incorrect type of self (must be 'BackgroundSubtractorMOG2' or its derivative)");
    cv::BackgroundSubtractorMOG2* _self_ = dynamic_cast<cv::BackgroundSubtractorMOG2*>(((pyopencv_BackgroundSubtractorMOG2_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getVarInit());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_BackgroundSubtractorMOG2_getVarMax(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BackgroundSubtractorMOG2_Type))
        return failmsgp("Incorrect type of self (must be 'BackgroundSubtractorMOG2' or its derivative)");
    cv::BackgroundSubtractorMOG2* _self_ = dynamic_cast<cv::BackgroundSubtractorMOG2*>(((pyopencv_BackgroundSubtractorMOG2_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getVarMax());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_BackgroundSubtractorMOG2_getVarMin(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BackgroundSubtractorMOG2_Type))
        return failmsgp("Incorrect type of self (must be 'BackgroundSubtractorMOG2' or its derivative)");
    cv::BackgroundSubtractorMOG2* _self_ = dynamic_cast<cv::BackgroundSubtractorMOG2*>(((pyopencv_BackgroundSubtractorMOG2_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getVarMin());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_BackgroundSubtractorMOG2_getVarThreshold(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BackgroundSubtractorMOG2_Type))
        return failmsgp("Incorrect type of self (must be 'BackgroundSubtractorMOG2' or its derivative)");
    cv::BackgroundSubtractorMOG2* _self_ = dynamic_cast<cv::BackgroundSubtractorMOG2*>(((pyopencv_BackgroundSubtractorMOG2_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getVarThreshold());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_BackgroundSubtractorMOG2_getVarThresholdGen(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BackgroundSubtractorMOG2_Type))
        return failmsgp("Incorrect type of self (must be 'BackgroundSubtractorMOG2' or its derivative)");
    cv::BackgroundSubtractorMOG2* _self_ = dynamic_cast<cv::BackgroundSubtractorMOG2*>(((pyopencv_BackgroundSubtractorMOG2_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getVarThresholdGen());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_BackgroundSubtractorMOG2_setBackgroundRatio(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BackgroundSubtractorMOG2_Type))
        return failmsgp("Incorrect type of self (must be 'BackgroundSubtractorMOG2' or its derivative)");
    cv::BackgroundSubtractorMOG2* _self_ = dynamic_cast<cv::BackgroundSubtractorMOG2*>(((pyopencv_BackgroundSubtractorMOG2_t*)self)->v.get());
    double ratio=0;

    const char* keywords[] = { "ratio", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:BackgroundSubtractorMOG2.setBackgroundRatio", (char**)keywords, &ratio) )
    {
        ERRWRAP2(_self_->setBackgroundRatio(ratio));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_BackgroundSubtractorMOG2_setComplexityReductionThreshold(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BackgroundSubtractorMOG2_Type))
        return failmsgp("Incorrect type of self (must be 'BackgroundSubtractorMOG2' or its derivative)");
    cv::BackgroundSubtractorMOG2* _self_ = dynamic_cast<cv::BackgroundSubtractorMOG2*>(((pyopencv_BackgroundSubtractorMOG2_t*)self)->v.get());
    double ct=0;

    const char* keywords[] = { "ct", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:BackgroundSubtractorMOG2.setComplexityReductionThreshold", (char**)keywords, &ct) )
    {
        ERRWRAP2(_self_->setComplexityReductionThreshold(ct));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_BackgroundSubtractorMOG2_setDetectShadows(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BackgroundSubtractorMOG2_Type))
        return failmsgp("Incorrect type of self (must be 'BackgroundSubtractorMOG2' or its derivative)");
    cv::BackgroundSubtractorMOG2* _self_ = dynamic_cast<cv::BackgroundSubtractorMOG2*>(((pyopencv_BackgroundSubtractorMOG2_t*)self)->v.get());
    bool detectShadows=0;

    const char* keywords[] = { "detectShadows", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "b:BackgroundSubtractorMOG2.setDetectShadows", (char**)keywords, &detectShadows) )
    {
        ERRWRAP2(_self_->setDetectShadows(detectShadows));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_BackgroundSubtractorMOG2_setHistory(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BackgroundSubtractorMOG2_Type))
        return failmsgp("Incorrect type of self (must be 'BackgroundSubtractorMOG2' or its derivative)");
    cv::BackgroundSubtractorMOG2* _self_ = dynamic_cast<cv::BackgroundSubtractorMOG2*>(((pyopencv_BackgroundSubtractorMOG2_t*)self)->v.get());
    int history=0;

    const char* keywords[] = { "history", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:BackgroundSubtractorMOG2.setHistory", (char**)keywords, &history) )
    {
        ERRWRAP2(_self_->setHistory(history));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_BackgroundSubtractorMOG2_setNMixtures(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BackgroundSubtractorMOG2_Type))
        return failmsgp("Incorrect type of self (must be 'BackgroundSubtractorMOG2' or its derivative)");
    cv::BackgroundSubtractorMOG2* _self_ = dynamic_cast<cv::BackgroundSubtractorMOG2*>(((pyopencv_BackgroundSubtractorMOG2_t*)self)->v.get());
    int nmixtures=0;

    const char* keywords[] = { "nmixtures", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:BackgroundSubtractorMOG2.setNMixtures", (char**)keywords, &nmixtures) )
    {
        ERRWRAP2(_self_->setNMixtures(nmixtures));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_BackgroundSubtractorMOG2_setShadowThreshold(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BackgroundSubtractorMOG2_Type))
        return failmsgp("Incorrect type of self (must be 'BackgroundSubtractorMOG2' or its derivative)");
    cv::BackgroundSubtractorMOG2* _self_ = dynamic_cast<cv::BackgroundSubtractorMOG2*>(((pyopencv_BackgroundSubtractorMOG2_t*)self)->v.get());
    double threshold=0;

    const char* keywords[] = { "threshold", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:BackgroundSubtractorMOG2.setShadowThreshold", (char**)keywords, &threshold) )
    {
        ERRWRAP2(_self_->setShadowThreshold(threshold));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_BackgroundSubtractorMOG2_setShadowValue(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BackgroundSubtractorMOG2_Type))
        return failmsgp("Incorrect type of self (must be 'BackgroundSubtractorMOG2' or its derivative)");
    cv::BackgroundSubtractorMOG2* _self_ = dynamic_cast<cv::BackgroundSubtractorMOG2*>(((pyopencv_BackgroundSubtractorMOG2_t*)self)->v.get());
    int value=0;

    const char* keywords[] = { "value", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:BackgroundSubtractorMOG2.setShadowValue", (char**)keywords, &value) )
    {
        ERRWRAP2(_self_->setShadowValue(value));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_BackgroundSubtractorMOG2_setVarInit(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BackgroundSubtractorMOG2_Type))
        return failmsgp("Incorrect type of self (must be 'BackgroundSubtractorMOG2' or its derivative)");
    cv::BackgroundSubtractorMOG2* _self_ = dynamic_cast<cv::BackgroundSubtractorMOG2*>(((pyopencv_BackgroundSubtractorMOG2_t*)self)->v.get());
    double varInit=0;

    const char* keywords[] = { "varInit", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:BackgroundSubtractorMOG2.setVarInit", (char**)keywords, &varInit) )
    {
        ERRWRAP2(_self_->setVarInit(varInit));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_BackgroundSubtractorMOG2_setVarMax(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BackgroundSubtractorMOG2_Type))
        return failmsgp("Incorrect type of self (must be 'BackgroundSubtractorMOG2' or its derivative)");
    cv::BackgroundSubtractorMOG2* _self_ = dynamic_cast<cv::BackgroundSubtractorMOG2*>(((pyopencv_BackgroundSubtractorMOG2_t*)self)->v.get());
    double varMax=0;

    const char* keywords[] = { "varMax", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:BackgroundSubtractorMOG2.setVarMax", (char**)keywords, &varMax) )
    {
        ERRWRAP2(_self_->setVarMax(varMax));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_BackgroundSubtractorMOG2_setVarMin(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BackgroundSubtractorMOG2_Type))
        return failmsgp("Incorrect type of self (must be 'BackgroundSubtractorMOG2' or its derivative)");
    cv::BackgroundSubtractorMOG2* _self_ = dynamic_cast<cv::BackgroundSubtractorMOG2*>(((pyopencv_BackgroundSubtractorMOG2_t*)self)->v.get());
    double varMin=0;

    const char* keywords[] = { "varMin", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:BackgroundSubtractorMOG2.setVarMin", (char**)keywords, &varMin) )
    {
        ERRWRAP2(_self_->setVarMin(varMin));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_BackgroundSubtractorMOG2_setVarThreshold(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BackgroundSubtractorMOG2_Type))
        return failmsgp("Incorrect type of self (must be 'BackgroundSubtractorMOG2' or its derivative)");
    cv::BackgroundSubtractorMOG2* _self_ = dynamic_cast<cv::BackgroundSubtractorMOG2*>(((pyopencv_BackgroundSubtractorMOG2_t*)self)->v.get());
    double varThreshold=0;

    const char* keywords[] = { "varThreshold", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:BackgroundSubtractorMOG2.setVarThreshold", (char**)keywords, &varThreshold) )
    {
        ERRWRAP2(_self_->setVarThreshold(varThreshold));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_BackgroundSubtractorMOG2_setVarThresholdGen(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BackgroundSubtractorMOG2_Type))
        return failmsgp("Incorrect type of self (must be 'BackgroundSubtractorMOG2' or its derivative)");
    cv::BackgroundSubtractorMOG2* _self_ = dynamic_cast<cv::BackgroundSubtractorMOG2*>(((pyopencv_BackgroundSubtractorMOG2_t*)self)->v.get());
    double varThresholdGen=0;

    const char* keywords[] = { "varThresholdGen", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:BackgroundSubtractorMOG2.setVarThresholdGen", (char**)keywords, &varThresholdGen) )
    {
        ERRWRAP2(_self_->setVarThresholdGen(varThresholdGen));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_BackgroundSubtractorMOG2_methods[] =
{
    {"apply", (PyCFunction)pyopencv_cv_BackgroundSubtractorMOG2_apply, METH_VARARGS | METH_KEYWORDS, "apply(image[, fgmask[, learningRate]]) -> fgmask"},
    {"getBackgroundRatio", (PyCFunction)pyopencv_cv_BackgroundSubtractorMOG2_getBackgroundRatio, METH_VARARGS | METH_KEYWORDS, "getBackgroundRatio() -> retval"},
    {"getComplexityReductionThreshold", (PyCFunction)pyopencv_cv_BackgroundSubtractorMOG2_getComplexityReductionThreshold, METH_VARARGS | METH_KEYWORDS, "getComplexityReductionThreshold() -> retval"},
    {"getDetectShadows", (PyCFunction)pyopencv_cv_BackgroundSubtractorMOG2_getDetectShadows, METH_VARARGS | METH_KEYWORDS, "getDetectShadows() -> retval"},
    {"getHistory", (PyCFunction)pyopencv_cv_BackgroundSubtractorMOG2_getHistory, METH_VARARGS | METH_KEYWORDS, "getHistory() -> retval"},
    {"getNMixtures", (PyCFunction)pyopencv_cv_BackgroundSubtractorMOG2_getNMixtures, METH_VARARGS | METH_KEYWORDS, "getNMixtures() -> retval"},
    {"getShadowThreshold", (PyCFunction)pyopencv_cv_BackgroundSubtractorMOG2_getShadowThreshold, METH_VARARGS | METH_KEYWORDS, "getShadowThreshold() -> retval"},
    {"getShadowValue", (PyCFunction)pyopencv_cv_BackgroundSubtractorMOG2_getShadowValue, METH_VARARGS | METH_KEYWORDS, "getShadowValue() -> retval"},
    {"getVarInit", (PyCFunction)pyopencv_cv_BackgroundSubtractorMOG2_getVarInit, METH_VARARGS | METH_KEYWORDS, "getVarInit() -> retval"},
    {"getVarMax", (PyCFunction)pyopencv_cv_BackgroundSubtractorMOG2_getVarMax, METH_VARARGS | METH_KEYWORDS, "getVarMax() -> retval"},
    {"getVarMin", (PyCFunction)pyopencv_cv_BackgroundSubtractorMOG2_getVarMin, METH_VARARGS | METH_KEYWORDS, "getVarMin() -> retval"},
    {"getVarThreshold", (PyCFunction)pyopencv_cv_BackgroundSubtractorMOG2_getVarThreshold, METH_VARARGS | METH_KEYWORDS, "getVarThreshold() -> retval"},
    {"getVarThresholdGen", (PyCFunction)pyopencv_cv_BackgroundSubtractorMOG2_getVarThresholdGen, METH_VARARGS | METH_KEYWORDS, "getVarThresholdGen() -> retval"},
    {"setBackgroundRatio", (PyCFunction)pyopencv_cv_BackgroundSubtractorMOG2_setBackgroundRatio, METH_VARARGS | METH_KEYWORDS, "setBackgroundRatio(ratio) -> None"},
    {"setComplexityReductionThreshold", (PyCFunction)pyopencv_cv_BackgroundSubtractorMOG2_setComplexityReductionThreshold, METH_VARARGS | METH_KEYWORDS, "setComplexityReductionThreshold(ct) -> None"},
    {"setDetectShadows", (PyCFunction)pyopencv_cv_BackgroundSubtractorMOG2_setDetectShadows, METH_VARARGS | METH_KEYWORDS, "setDetectShadows(detectShadows) -> None"},
    {"setHistory", (PyCFunction)pyopencv_cv_BackgroundSubtractorMOG2_setHistory, METH_VARARGS | METH_KEYWORDS, "setHistory(history) -> None"},
    {"setNMixtures", (PyCFunction)pyopencv_cv_BackgroundSubtractorMOG2_setNMixtures, METH_VARARGS | METH_KEYWORDS, "setNMixtures(nmixtures) -> None"},
    {"setShadowThreshold", (PyCFunction)pyopencv_cv_BackgroundSubtractorMOG2_setShadowThreshold, METH_VARARGS | METH_KEYWORDS, "setShadowThreshold(threshold) -> None"},
    {"setShadowValue", (PyCFunction)pyopencv_cv_BackgroundSubtractorMOG2_setShadowValue, METH_VARARGS | METH_KEYWORDS, "setShadowValue(value) -> None"},
    {"setVarInit", (PyCFunction)pyopencv_cv_BackgroundSubtractorMOG2_setVarInit, METH_VARARGS | METH_KEYWORDS, "setVarInit(varInit) -> None"},
    {"setVarMax", (PyCFunction)pyopencv_cv_BackgroundSubtractorMOG2_setVarMax, METH_VARARGS | METH_KEYWORDS, "setVarMax(varMax) -> None"},
    {"setVarMin", (PyCFunction)pyopencv_cv_BackgroundSubtractorMOG2_setVarMin, METH_VARARGS | METH_KEYWORDS, "setVarMin(varMin) -> None"},
    {"setVarThreshold", (PyCFunction)pyopencv_cv_BackgroundSubtractorMOG2_setVarThreshold, METH_VARARGS | METH_KEYWORDS, "setVarThreshold(varThreshold) -> None"},
    {"setVarThresholdGen", (PyCFunction)pyopencv_cv_BackgroundSubtractorMOG2_setVarThresholdGen, METH_VARARGS | METH_KEYWORDS, "setVarThresholdGen(varThresholdGen) -> None"},

    {NULL,          NULL}
};

static void pyopencv_BackgroundSubtractorMOG2_specials(void)
{
    pyopencv_BackgroundSubtractorMOG2_Type.tp_base = &pyopencv_BackgroundSubtractor_Type;
    pyopencv_BackgroundSubtractorMOG2_Type.tp_dealloc = pyopencv_BackgroundSubtractorMOG2_dealloc;
    pyopencv_BackgroundSubtractorMOG2_Type.tp_repr = pyopencv_BackgroundSubtractorMOG2_repr;
    pyopencv_BackgroundSubtractorMOG2_Type.tp_getset = pyopencv_BackgroundSubtractorMOG2_getseters;
    pyopencv_BackgroundSubtractorMOG2_Type.tp_methods = pyopencv_BackgroundSubtractorMOG2_methods;
}

static PyObject* pyopencv_BackgroundSubtractorKNN_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<BackgroundSubtractorKNN %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_BackgroundSubtractorKNN_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_BackgroundSubtractorKNN_getDetectShadows(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BackgroundSubtractorKNN_Type))
        return failmsgp("Incorrect type of self (must be 'BackgroundSubtractorKNN' or its derivative)");
    cv::BackgroundSubtractorKNN* _self_ = dynamic_cast<cv::BackgroundSubtractorKNN*>(((pyopencv_BackgroundSubtractorKNN_t*)self)->v.get());
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getDetectShadows());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_BackgroundSubtractorKNN_getDist2Threshold(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BackgroundSubtractorKNN_Type))
        return failmsgp("Incorrect type of self (must be 'BackgroundSubtractorKNN' or its derivative)");
    cv::BackgroundSubtractorKNN* _self_ = dynamic_cast<cv::BackgroundSubtractorKNN*>(((pyopencv_BackgroundSubtractorKNN_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getDist2Threshold());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_BackgroundSubtractorKNN_getHistory(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BackgroundSubtractorKNN_Type))
        return failmsgp("Incorrect type of self (must be 'BackgroundSubtractorKNN' or its derivative)");
    cv::BackgroundSubtractorKNN* _self_ = dynamic_cast<cv::BackgroundSubtractorKNN*>(((pyopencv_BackgroundSubtractorKNN_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getHistory());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_BackgroundSubtractorKNN_getNSamples(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BackgroundSubtractorKNN_Type))
        return failmsgp("Incorrect type of self (must be 'BackgroundSubtractorKNN' or its derivative)");
    cv::BackgroundSubtractorKNN* _self_ = dynamic_cast<cv::BackgroundSubtractorKNN*>(((pyopencv_BackgroundSubtractorKNN_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getNSamples());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_BackgroundSubtractorKNN_getShadowThreshold(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BackgroundSubtractorKNN_Type))
        return failmsgp("Incorrect type of self (must be 'BackgroundSubtractorKNN' or its derivative)");
    cv::BackgroundSubtractorKNN* _self_ = dynamic_cast<cv::BackgroundSubtractorKNN*>(((pyopencv_BackgroundSubtractorKNN_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getShadowThreshold());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_BackgroundSubtractorKNN_getShadowValue(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BackgroundSubtractorKNN_Type))
        return failmsgp("Incorrect type of self (must be 'BackgroundSubtractorKNN' or its derivative)");
    cv::BackgroundSubtractorKNN* _self_ = dynamic_cast<cv::BackgroundSubtractorKNN*>(((pyopencv_BackgroundSubtractorKNN_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getShadowValue());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_BackgroundSubtractorKNN_getkNNSamples(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BackgroundSubtractorKNN_Type))
        return failmsgp("Incorrect type of self (must be 'BackgroundSubtractorKNN' or its derivative)");
    cv::BackgroundSubtractorKNN* _self_ = dynamic_cast<cv::BackgroundSubtractorKNN*>(((pyopencv_BackgroundSubtractorKNN_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getkNNSamples());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_BackgroundSubtractorKNN_setDetectShadows(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BackgroundSubtractorKNN_Type))
        return failmsgp("Incorrect type of self (must be 'BackgroundSubtractorKNN' or its derivative)");
    cv::BackgroundSubtractorKNN* _self_ = dynamic_cast<cv::BackgroundSubtractorKNN*>(((pyopencv_BackgroundSubtractorKNN_t*)self)->v.get());
    bool detectShadows=0;

    const char* keywords[] = { "detectShadows", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "b:BackgroundSubtractorKNN.setDetectShadows", (char**)keywords, &detectShadows) )
    {
        ERRWRAP2(_self_->setDetectShadows(detectShadows));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_BackgroundSubtractorKNN_setDist2Threshold(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BackgroundSubtractorKNN_Type))
        return failmsgp("Incorrect type of self (must be 'BackgroundSubtractorKNN' or its derivative)");
    cv::BackgroundSubtractorKNN* _self_ = dynamic_cast<cv::BackgroundSubtractorKNN*>(((pyopencv_BackgroundSubtractorKNN_t*)self)->v.get());
    double _dist2Threshold=0;

    const char* keywords[] = { "_dist2Threshold", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:BackgroundSubtractorKNN.setDist2Threshold", (char**)keywords, &_dist2Threshold) )
    {
        ERRWRAP2(_self_->setDist2Threshold(_dist2Threshold));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_BackgroundSubtractorKNN_setHistory(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BackgroundSubtractorKNN_Type))
        return failmsgp("Incorrect type of self (must be 'BackgroundSubtractorKNN' or its derivative)");
    cv::BackgroundSubtractorKNN* _self_ = dynamic_cast<cv::BackgroundSubtractorKNN*>(((pyopencv_BackgroundSubtractorKNN_t*)self)->v.get());
    int history=0;

    const char* keywords[] = { "history", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:BackgroundSubtractorKNN.setHistory", (char**)keywords, &history) )
    {
        ERRWRAP2(_self_->setHistory(history));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_BackgroundSubtractorKNN_setNSamples(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BackgroundSubtractorKNN_Type))
        return failmsgp("Incorrect type of self (must be 'BackgroundSubtractorKNN' or its derivative)");
    cv::BackgroundSubtractorKNN* _self_ = dynamic_cast<cv::BackgroundSubtractorKNN*>(((pyopencv_BackgroundSubtractorKNN_t*)self)->v.get());
    int _nN=0;

    const char* keywords[] = { "_nN", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:BackgroundSubtractorKNN.setNSamples", (char**)keywords, &_nN) )
    {
        ERRWRAP2(_self_->setNSamples(_nN));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_BackgroundSubtractorKNN_setShadowThreshold(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BackgroundSubtractorKNN_Type))
        return failmsgp("Incorrect type of self (must be 'BackgroundSubtractorKNN' or its derivative)");
    cv::BackgroundSubtractorKNN* _self_ = dynamic_cast<cv::BackgroundSubtractorKNN*>(((pyopencv_BackgroundSubtractorKNN_t*)self)->v.get());
    double threshold=0;

    const char* keywords[] = { "threshold", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:BackgroundSubtractorKNN.setShadowThreshold", (char**)keywords, &threshold) )
    {
        ERRWRAP2(_self_->setShadowThreshold(threshold));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_BackgroundSubtractorKNN_setShadowValue(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BackgroundSubtractorKNN_Type))
        return failmsgp("Incorrect type of self (must be 'BackgroundSubtractorKNN' or its derivative)");
    cv::BackgroundSubtractorKNN* _self_ = dynamic_cast<cv::BackgroundSubtractorKNN*>(((pyopencv_BackgroundSubtractorKNN_t*)self)->v.get());
    int value=0;

    const char* keywords[] = { "value", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:BackgroundSubtractorKNN.setShadowValue", (char**)keywords, &value) )
    {
        ERRWRAP2(_self_->setShadowValue(value));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_BackgroundSubtractorKNN_setkNNSamples(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BackgroundSubtractorKNN_Type))
        return failmsgp("Incorrect type of self (must be 'BackgroundSubtractorKNN' or its derivative)");
    cv::BackgroundSubtractorKNN* _self_ = dynamic_cast<cv::BackgroundSubtractorKNN*>(((pyopencv_BackgroundSubtractorKNN_t*)self)->v.get());
    int _nkNN=0;

    const char* keywords[] = { "_nkNN", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:BackgroundSubtractorKNN.setkNNSamples", (char**)keywords, &_nkNN) )
    {
        ERRWRAP2(_self_->setkNNSamples(_nkNN));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_BackgroundSubtractorKNN_methods[] =
{
    {"getDetectShadows", (PyCFunction)pyopencv_cv_BackgroundSubtractorKNN_getDetectShadows, METH_VARARGS | METH_KEYWORDS, "getDetectShadows() -> retval"},
    {"getDist2Threshold", (PyCFunction)pyopencv_cv_BackgroundSubtractorKNN_getDist2Threshold, METH_VARARGS | METH_KEYWORDS, "getDist2Threshold() -> retval"},
    {"getHistory", (PyCFunction)pyopencv_cv_BackgroundSubtractorKNN_getHistory, METH_VARARGS | METH_KEYWORDS, "getHistory() -> retval"},
    {"getNSamples", (PyCFunction)pyopencv_cv_BackgroundSubtractorKNN_getNSamples, METH_VARARGS | METH_KEYWORDS, "getNSamples() -> retval"},
    {"getShadowThreshold", (PyCFunction)pyopencv_cv_BackgroundSubtractorKNN_getShadowThreshold, METH_VARARGS | METH_KEYWORDS, "getShadowThreshold() -> retval"},
    {"getShadowValue", (PyCFunction)pyopencv_cv_BackgroundSubtractorKNN_getShadowValue, METH_VARARGS | METH_KEYWORDS, "getShadowValue() -> retval"},
    {"getkNNSamples", (PyCFunction)pyopencv_cv_BackgroundSubtractorKNN_getkNNSamples, METH_VARARGS | METH_KEYWORDS, "getkNNSamples() -> retval"},
    {"setDetectShadows", (PyCFunction)pyopencv_cv_BackgroundSubtractorKNN_setDetectShadows, METH_VARARGS | METH_KEYWORDS, "setDetectShadows(detectShadows) -> None"},
    {"setDist2Threshold", (PyCFunction)pyopencv_cv_BackgroundSubtractorKNN_setDist2Threshold, METH_VARARGS | METH_KEYWORDS, "setDist2Threshold(_dist2Threshold) -> None"},
    {"setHistory", (PyCFunction)pyopencv_cv_BackgroundSubtractorKNN_setHistory, METH_VARARGS | METH_KEYWORDS, "setHistory(history) -> None"},
    {"setNSamples", (PyCFunction)pyopencv_cv_BackgroundSubtractorKNN_setNSamples, METH_VARARGS | METH_KEYWORDS, "setNSamples(_nN) -> None"},
    {"setShadowThreshold", (PyCFunction)pyopencv_cv_BackgroundSubtractorKNN_setShadowThreshold, METH_VARARGS | METH_KEYWORDS, "setShadowThreshold(threshold) -> None"},
    {"setShadowValue", (PyCFunction)pyopencv_cv_BackgroundSubtractorKNN_setShadowValue, METH_VARARGS | METH_KEYWORDS, "setShadowValue(value) -> None"},
    {"setkNNSamples", (PyCFunction)pyopencv_cv_BackgroundSubtractorKNN_setkNNSamples, METH_VARARGS | METH_KEYWORDS, "setkNNSamples(_nkNN) -> None"},

    {NULL,          NULL}
};

static void pyopencv_BackgroundSubtractorKNN_specials(void)
{
    pyopencv_BackgroundSubtractorKNN_Type.tp_base = &pyopencv_BackgroundSubtractor_Type;
    pyopencv_BackgroundSubtractorKNN_Type.tp_dealloc = pyopencv_BackgroundSubtractorKNN_dealloc;
    pyopencv_BackgroundSubtractorKNN_Type.tp_repr = pyopencv_BackgroundSubtractorKNN_repr;
    pyopencv_BackgroundSubtractorKNN_Type.tp_getset = pyopencv_BackgroundSubtractorKNN_getseters;
    pyopencv_BackgroundSubtractorKNN_Type.tp_methods = pyopencv_BackgroundSubtractorKNN_methods;
}

static PyObject* pyopencv_KalmanFilter_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<KalmanFilter %p>", self);
    return PyString_FromString(str);
}


static PyObject* pyopencv_KalmanFilter_get_controlMatrix(pyopencv_KalmanFilter_t* p, void *closure)
{
    return pyopencv_from(p->v->controlMatrix);
}

static int pyopencv_KalmanFilter_set_controlMatrix(pyopencv_KalmanFilter_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the controlMatrix attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->controlMatrix) ? 0 : -1;
}

static PyObject* pyopencv_KalmanFilter_get_errorCovPost(pyopencv_KalmanFilter_t* p, void *closure)
{
    return pyopencv_from(p->v->errorCovPost);
}

static int pyopencv_KalmanFilter_set_errorCovPost(pyopencv_KalmanFilter_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the errorCovPost attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->errorCovPost) ? 0 : -1;
}

static PyObject* pyopencv_KalmanFilter_get_errorCovPre(pyopencv_KalmanFilter_t* p, void *closure)
{
    return pyopencv_from(p->v->errorCovPre);
}

static int pyopencv_KalmanFilter_set_errorCovPre(pyopencv_KalmanFilter_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the errorCovPre attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->errorCovPre) ? 0 : -1;
}

static PyObject* pyopencv_KalmanFilter_get_gain(pyopencv_KalmanFilter_t* p, void *closure)
{
    return pyopencv_from(p->v->gain);
}

static int pyopencv_KalmanFilter_set_gain(pyopencv_KalmanFilter_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the gain attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->gain) ? 0 : -1;
}

static PyObject* pyopencv_KalmanFilter_get_measurementMatrix(pyopencv_KalmanFilter_t* p, void *closure)
{
    return pyopencv_from(p->v->measurementMatrix);
}

static int pyopencv_KalmanFilter_set_measurementMatrix(pyopencv_KalmanFilter_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the measurementMatrix attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->measurementMatrix) ? 0 : -1;
}

static PyObject* pyopencv_KalmanFilter_get_measurementNoiseCov(pyopencv_KalmanFilter_t* p, void *closure)
{
    return pyopencv_from(p->v->measurementNoiseCov);
}

static int pyopencv_KalmanFilter_set_measurementNoiseCov(pyopencv_KalmanFilter_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the measurementNoiseCov attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->measurementNoiseCov) ? 0 : -1;
}

static PyObject* pyopencv_KalmanFilter_get_processNoiseCov(pyopencv_KalmanFilter_t* p, void *closure)
{
    return pyopencv_from(p->v->processNoiseCov);
}

static int pyopencv_KalmanFilter_set_processNoiseCov(pyopencv_KalmanFilter_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the processNoiseCov attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->processNoiseCov) ? 0 : -1;
}

static PyObject* pyopencv_KalmanFilter_get_statePost(pyopencv_KalmanFilter_t* p, void *closure)
{
    return pyopencv_from(p->v->statePost);
}

static int pyopencv_KalmanFilter_set_statePost(pyopencv_KalmanFilter_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the statePost attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->statePost) ? 0 : -1;
}

static PyObject* pyopencv_KalmanFilter_get_statePre(pyopencv_KalmanFilter_t* p, void *closure)
{
    return pyopencv_from(p->v->statePre);
}

static int pyopencv_KalmanFilter_set_statePre(pyopencv_KalmanFilter_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the statePre attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->statePre) ? 0 : -1;
}

static PyObject* pyopencv_KalmanFilter_get_transitionMatrix(pyopencv_KalmanFilter_t* p, void *closure)
{
    return pyopencv_from(p->v->transitionMatrix);
}

static int pyopencv_KalmanFilter_set_transitionMatrix(pyopencv_KalmanFilter_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the transitionMatrix attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->transitionMatrix) ? 0 : -1;
}


static PyGetSetDef pyopencv_KalmanFilter_getseters[] =
{
    {(char*)"controlMatrix", (getter)pyopencv_KalmanFilter_get_controlMatrix, (setter)pyopencv_KalmanFilter_set_controlMatrix, (char*)"controlMatrix", NULL},
    {(char*)"errorCovPost", (getter)pyopencv_KalmanFilter_get_errorCovPost, (setter)pyopencv_KalmanFilter_set_errorCovPost, (char*)"errorCovPost", NULL},
    {(char*)"errorCovPre", (getter)pyopencv_KalmanFilter_get_errorCovPre, (setter)pyopencv_KalmanFilter_set_errorCovPre, (char*)"errorCovPre", NULL},
    {(char*)"gain", (getter)pyopencv_KalmanFilter_get_gain, (setter)pyopencv_KalmanFilter_set_gain, (char*)"gain", NULL},
    {(char*)"measurementMatrix", (getter)pyopencv_KalmanFilter_get_measurementMatrix, (setter)pyopencv_KalmanFilter_set_measurementMatrix, (char*)"measurementMatrix", NULL},
    {(char*)"measurementNoiseCov", (getter)pyopencv_KalmanFilter_get_measurementNoiseCov, (setter)pyopencv_KalmanFilter_set_measurementNoiseCov, (char*)"measurementNoiseCov", NULL},
    {(char*)"processNoiseCov", (getter)pyopencv_KalmanFilter_get_processNoiseCov, (setter)pyopencv_KalmanFilter_set_processNoiseCov, (char*)"processNoiseCov", NULL},
    {(char*)"statePost", (getter)pyopencv_KalmanFilter_get_statePost, (setter)pyopencv_KalmanFilter_set_statePost, (char*)"statePost", NULL},
    {(char*)"statePre", (getter)pyopencv_KalmanFilter_get_statePre, (setter)pyopencv_KalmanFilter_set_statePre, (char*)"statePre", NULL},
    {(char*)"transitionMatrix", (getter)pyopencv_KalmanFilter_get_transitionMatrix, (setter)pyopencv_KalmanFilter_set_transitionMatrix, (char*)"transitionMatrix", NULL},
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_KalmanFilter_correct(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_KalmanFilter_Type))
        return failmsgp("Incorrect type of self (must be 'KalmanFilter' or its derivative)");
    cv::KalmanFilter* _self_ = ((pyopencv_KalmanFilter_t*)self)->v.get();
    {
    PyObject* pyobj_measurement = NULL;
    Mat measurement;
    Mat retval;

    const char* keywords[] = { "measurement", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:KalmanFilter.correct", (char**)keywords, &pyobj_measurement) &&
        pyopencv_to(pyobj_measurement, measurement, ArgInfo("measurement", 0)) )
    {
        ERRWRAP2(retval = _self_->correct(measurement));
        return pyopencv_from(retval);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_measurement = NULL;
    Mat measurement;
    Mat retval;

    const char* keywords[] = { "measurement", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:KalmanFilter.correct", (char**)keywords, &pyobj_measurement) &&
        pyopencv_to(pyobj_measurement, measurement, ArgInfo("measurement", 0)) )
    {
        ERRWRAP2(retval = _self_->correct(measurement));
        return pyopencv_from(retval);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_KalmanFilter_predict(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_KalmanFilter_Type))
        return failmsgp("Incorrect type of self (must be 'KalmanFilter' or its derivative)");
    cv::KalmanFilter* _self_ = ((pyopencv_KalmanFilter_t*)self)->v.get();
    {
    PyObject* pyobj_control = NULL;
    Mat control;
    Mat retval;

    const char* keywords[] = { "control", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|O:KalmanFilter.predict", (char**)keywords, &pyobj_control) &&
        pyopencv_to(pyobj_control, control, ArgInfo("control", 0)) )
    {
        ERRWRAP2(retval = _self_->predict(control));
        return pyopencv_from(retval);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_control = NULL;
    Mat control;
    Mat retval;

    const char* keywords[] = { "control", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|O:KalmanFilter.predict", (char**)keywords, &pyobj_control) &&
        pyopencv_to(pyobj_control, control, ArgInfo("control", 0)) )
    {
        ERRWRAP2(retval = _self_->predict(control));
        return pyopencv_from(retval);
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_KalmanFilter_methods[] =
{
    {"correct", (PyCFunction)pyopencv_cv_KalmanFilter_correct, METH_VARARGS | METH_KEYWORDS, "correct(measurement) -> retval"},
    {"predict", (PyCFunction)pyopencv_cv_KalmanFilter_predict, METH_VARARGS | METH_KEYWORDS, "predict([, control]) -> retval"},

    {NULL,          NULL}
};

static void pyopencv_KalmanFilter_specials(void)
{
    pyopencv_KalmanFilter_Type.tp_base = NULL;
    pyopencv_KalmanFilter_Type.tp_dealloc = pyopencv_KalmanFilter_dealloc;
    pyopencv_KalmanFilter_Type.tp_repr = pyopencv_KalmanFilter_repr;
    pyopencv_KalmanFilter_Type.tp_getset = pyopencv_KalmanFilter_getseters;
    pyopencv_KalmanFilter_Type.tp_methods = pyopencv_KalmanFilter_methods;
}

static PyObject* pyopencv_DenseOpticalFlow_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<DenseOpticalFlow %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_DenseOpticalFlow_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_DenseOpticalFlow_calc(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_DenseOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'DenseOpticalFlow' or its derivative)");
    cv::DenseOpticalFlow* _self_ = dynamic_cast<cv::DenseOpticalFlow*>(((pyopencv_DenseOpticalFlow_t*)self)->v.get());
    {
    PyObject* pyobj_I0 = NULL;
    Mat I0;
    PyObject* pyobj_I1 = NULL;
    Mat I1;
    PyObject* pyobj_flow = NULL;
    Mat flow;

    const char* keywords[] = { "I0", "I1", "flow", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OOO:DenseOpticalFlow.calc", (char**)keywords, &pyobj_I0, &pyobj_I1, &pyobj_flow) &&
        pyopencv_to(pyobj_I0, I0, ArgInfo("I0", 0)) &&
        pyopencv_to(pyobj_I1, I1, ArgInfo("I1", 0)) &&
        pyopencv_to(pyobj_flow, flow, ArgInfo("flow", 1)) )
    {
        ERRWRAP2(_self_->calc(I0, I1, flow));
        return pyopencv_from(flow);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_I0 = NULL;
    UMat I0;
    PyObject* pyobj_I1 = NULL;
    UMat I1;
    PyObject* pyobj_flow = NULL;
    UMat flow;

    const char* keywords[] = { "I0", "I1", "flow", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OOO:DenseOpticalFlow.calc", (char**)keywords, &pyobj_I0, &pyobj_I1, &pyobj_flow) &&
        pyopencv_to(pyobj_I0, I0, ArgInfo("I0", 0)) &&
        pyopencv_to(pyobj_I1, I1, ArgInfo("I1", 0)) &&
        pyopencv_to(pyobj_flow, flow, ArgInfo("flow", 1)) )
    {
        ERRWRAP2(_self_->calc(I0, I1, flow));
        return pyopencv_from(flow);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_DenseOpticalFlow_collectGarbage(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_DenseOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'DenseOpticalFlow' or its derivative)");
    cv::DenseOpticalFlow* _self_ = dynamic_cast<cv::DenseOpticalFlow*>(((pyopencv_DenseOpticalFlow_t*)self)->v.get());

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(_self_->collectGarbage());
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_DenseOpticalFlow_methods[] =
{
    {"calc", (PyCFunction)pyopencv_cv_DenseOpticalFlow_calc, METH_VARARGS | METH_KEYWORDS, "calc(I0, I1, flow) -> flow"},
    {"collectGarbage", (PyCFunction)pyopencv_cv_DenseOpticalFlow_collectGarbage, METH_VARARGS | METH_KEYWORDS, "collectGarbage() -> None"},

    {NULL,          NULL}
};

static void pyopencv_DenseOpticalFlow_specials(void)
{
    pyopencv_DenseOpticalFlow_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_DenseOpticalFlow_Type.tp_dealloc = pyopencv_DenseOpticalFlow_dealloc;
    pyopencv_DenseOpticalFlow_Type.tp_repr = pyopencv_DenseOpticalFlow_repr;
    pyopencv_DenseOpticalFlow_Type.tp_getset = pyopencv_DenseOpticalFlow_getseters;
    pyopencv_DenseOpticalFlow_Type.tp_methods = pyopencv_DenseOpticalFlow_methods;
}

static PyObject* pyopencv_SparseOpticalFlow_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<SparseOpticalFlow %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_SparseOpticalFlow_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_SparseOpticalFlow_calc(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_SparseOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'SparseOpticalFlow' or its derivative)");
    cv::SparseOpticalFlow* _self_ = dynamic_cast<cv::SparseOpticalFlow*>(((pyopencv_SparseOpticalFlow_t*)self)->v.get());
    {
    PyObject* pyobj_prevImg = NULL;
    Mat prevImg;
    PyObject* pyobj_nextImg = NULL;
    Mat nextImg;
    PyObject* pyobj_prevPts = NULL;
    Mat prevPts;
    PyObject* pyobj_nextPts = NULL;
    Mat nextPts;
    PyObject* pyobj_status = NULL;
    Mat status;
    PyObject* pyobj_err = NULL;
    Mat err;

    const char* keywords[] = { "prevImg", "nextImg", "prevPts", "nextPts", "status", "err", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OOOO|OO:SparseOpticalFlow.calc", (char**)keywords, &pyobj_prevImg, &pyobj_nextImg, &pyobj_prevPts, &pyobj_nextPts, &pyobj_status, &pyobj_err) &&
        pyopencv_to(pyobj_prevImg, prevImg, ArgInfo("prevImg", 0)) &&
        pyopencv_to(pyobj_nextImg, nextImg, ArgInfo("nextImg", 0)) &&
        pyopencv_to(pyobj_prevPts, prevPts, ArgInfo("prevPts", 0)) &&
        pyopencv_to(pyobj_nextPts, nextPts, ArgInfo("nextPts", 1)) &&
        pyopencv_to(pyobj_status, status, ArgInfo("status", 1)) &&
        pyopencv_to(pyobj_err, err, ArgInfo("err", 1)) )
    {
        ERRWRAP2(_self_->calc(prevImg, nextImg, prevPts, nextPts, status, err));
        return Py_BuildValue("(NNN)", pyopencv_from(nextPts), pyopencv_from(status), pyopencv_from(err));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_prevImg = NULL;
    UMat prevImg;
    PyObject* pyobj_nextImg = NULL;
    UMat nextImg;
    PyObject* pyobj_prevPts = NULL;
    UMat prevPts;
    PyObject* pyobj_nextPts = NULL;
    UMat nextPts;
    PyObject* pyobj_status = NULL;
    UMat status;
    PyObject* pyobj_err = NULL;
    UMat err;

    const char* keywords[] = { "prevImg", "nextImg", "prevPts", "nextPts", "status", "err", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OOOO|OO:SparseOpticalFlow.calc", (char**)keywords, &pyobj_prevImg, &pyobj_nextImg, &pyobj_prevPts, &pyobj_nextPts, &pyobj_status, &pyobj_err) &&
        pyopencv_to(pyobj_prevImg, prevImg, ArgInfo("prevImg", 0)) &&
        pyopencv_to(pyobj_nextImg, nextImg, ArgInfo("nextImg", 0)) &&
        pyopencv_to(pyobj_prevPts, prevPts, ArgInfo("prevPts", 0)) &&
        pyopencv_to(pyobj_nextPts, nextPts, ArgInfo("nextPts", 1)) &&
        pyopencv_to(pyobj_status, status, ArgInfo("status", 1)) &&
        pyopencv_to(pyobj_err, err, ArgInfo("err", 1)) )
    {
        ERRWRAP2(_self_->calc(prevImg, nextImg, prevPts, nextPts, status, err));
        return Py_BuildValue("(NNN)", pyopencv_from(nextPts), pyopencv_from(status), pyopencv_from(err));
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_SparseOpticalFlow_methods[] =
{
    {"calc", (PyCFunction)pyopencv_cv_SparseOpticalFlow_calc, METH_VARARGS | METH_KEYWORDS, "calc(prevImg, nextImg, prevPts, nextPts[, status[, err]]) -> nextPts, status, err"},

    {NULL,          NULL}
};

static void pyopencv_SparseOpticalFlow_specials(void)
{
    pyopencv_SparseOpticalFlow_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_SparseOpticalFlow_Type.tp_dealloc = pyopencv_SparseOpticalFlow_dealloc;
    pyopencv_SparseOpticalFlow_Type.tp_repr = pyopencv_SparseOpticalFlow_repr;
    pyopencv_SparseOpticalFlow_Type.tp_getset = pyopencv_SparseOpticalFlow_getseters;
    pyopencv_SparseOpticalFlow_Type.tp_methods = pyopencv_SparseOpticalFlow_methods;
}

static PyObject* pyopencv_DualTVL1OpticalFlow_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<DualTVL1OpticalFlow %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_DualTVL1OpticalFlow_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_DualTVL1OpticalFlow_getEpsilon(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_DualTVL1OpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'DualTVL1OpticalFlow' or its derivative)");
    cv::DualTVL1OpticalFlow* _self_ = dynamic_cast<cv::DualTVL1OpticalFlow*>(((pyopencv_DualTVL1OpticalFlow_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getEpsilon());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_DualTVL1OpticalFlow_getGamma(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_DualTVL1OpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'DualTVL1OpticalFlow' or its derivative)");
    cv::DualTVL1OpticalFlow* _self_ = dynamic_cast<cv::DualTVL1OpticalFlow*>(((pyopencv_DualTVL1OpticalFlow_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getGamma());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_DualTVL1OpticalFlow_getInnerIterations(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_DualTVL1OpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'DualTVL1OpticalFlow' or its derivative)");
    cv::DualTVL1OpticalFlow* _self_ = dynamic_cast<cv::DualTVL1OpticalFlow*>(((pyopencv_DualTVL1OpticalFlow_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getInnerIterations());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_DualTVL1OpticalFlow_getLambda(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_DualTVL1OpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'DualTVL1OpticalFlow' or its derivative)");
    cv::DualTVL1OpticalFlow* _self_ = dynamic_cast<cv::DualTVL1OpticalFlow*>(((pyopencv_DualTVL1OpticalFlow_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getLambda());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_DualTVL1OpticalFlow_getMedianFiltering(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_DualTVL1OpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'DualTVL1OpticalFlow' or its derivative)");
    cv::DualTVL1OpticalFlow* _self_ = dynamic_cast<cv::DualTVL1OpticalFlow*>(((pyopencv_DualTVL1OpticalFlow_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getMedianFiltering());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_DualTVL1OpticalFlow_getOuterIterations(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_DualTVL1OpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'DualTVL1OpticalFlow' or its derivative)");
    cv::DualTVL1OpticalFlow* _self_ = dynamic_cast<cv::DualTVL1OpticalFlow*>(((pyopencv_DualTVL1OpticalFlow_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getOuterIterations());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_DualTVL1OpticalFlow_getScaleStep(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_DualTVL1OpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'DualTVL1OpticalFlow' or its derivative)");
    cv::DualTVL1OpticalFlow* _self_ = dynamic_cast<cv::DualTVL1OpticalFlow*>(((pyopencv_DualTVL1OpticalFlow_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getScaleStep());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_DualTVL1OpticalFlow_getScalesNumber(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_DualTVL1OpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'DualTVL1OpticalFlow' or its derivative)");
    cv::DualTVL1OpticalFlow* _self_ = dynamic_cast<cv::DualTVL1OpticalFlow*>(((pyopencv_DualTVL1OpticalFlow_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getScalesNumber());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_DualTVL1OpticalFlow_getTau(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_DualTVL1OpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'DualTVL1OpticalFlow' or its derivative)");
    cv::DualTVL1OpticalFlow* _self_ = dynamic_cast<cv::DualTVL1OpticalFlow*>(((pyopencv_DualTVL1OpticalFlow_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getTau());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_DualTVL1OpticalFlow_getTheta(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_DualTVL1OpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'DualTVL1OpticalFlow' or its derivative)");
    cv::DualTVL1OpticalFlow* _self_ = dynamic_cast<cv::DualTVL1OpticalFlow*>(((pyopencv_DualTVL1OpticalFlow_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getTheta());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_DualTVL1OpticalFlow_getUseInitialFlow(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_DualTVL1OpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'DualTVL1OpticalFlow' or its derivative)");
    cv::DualTVL1OpticalFlow* _self_ = dynamic_cast<cv::DualTVL1OpticalFlow*>(((pyopencv_DualTVL1OpticalFlow_t*)self)->v.get());
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getUseInitialFlow());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_DualTVL1OpticalFlow_getWarpingsNumber(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_DualTVL1OpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'DualTVL1OpticalFlow' or its derivative)");
    cv::DualTVL1OpticalFlow* _self_ = dynamic_cast<cv::DualTVL1OpticalFlow*>(((pyopencv_DualTVL1OpticalFlow_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getWarpingsNumber());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_DualTVL1OpticalFlow_setEpsilon(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_DualTVL1OpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'DualTVL1OpticalFlow' or its derivative)");
    cv::DualTVL1OpticalFlow* _self_ = dynamic_cast<cv::DualTVL1OpticalFlow*>(((pyopencv_DualTVL1OpticalFlow_t*)self)->v.get());
    double val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:DualTVL1OpticalFlow.setEpsilon", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setEpsilon(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_DualTVL1OpticalFlow_setGamma(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_DualTVL1OpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'DualTVL1OpticalFlow' or its derivative)");
    cv::DualTVL1OpticalFlow* _self_ = dynamic_cast<cv::DualTVL1OpticalFlow*>(((pyopencv_DualTVL1OpticalFlow_t*)self)->v.get());
    double val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:DualTVL1OpticalFlow.setGamma", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setGamma(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_DualTVL1OpticalFlow_setInnerIterations(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_DualTVL1OpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'DualTVL1OpticalFlow' or its derivative)");
    cv::DualTVL1OpticalFlow* _self_ = dynamic_cast<cv::DualTVL1OpticalFlow*>(((pyopencv_DualTVL1OpticalFlow_t*)self)->v.get());
    int val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:DualTVL1OpticalFlow.setInnerIterations", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setInnerIterations(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_DualTVL1OpticalFlow_setLambda(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_DualTVL1OpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'DualTVL1OpticalFlow' or its derivative)");
    cv::DualTVL1OpticalFlow* _self_ = dynamic_cast<cv::DualTVL1OpticalFlow*>(((pyopencv_DualTVL1OpticalFlow_t*)self)->v.get());
    double val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:DualTVL1OpticalFlow.setLambda", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setLambda(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_DualTVL1OpticalFlow_setMedianFiltering(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_DualTVL1OpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'DualTVL1OpticalFlow' or its derivative)");
    cv::DualTVL1OpticalFlow* _self_ = dynamic_cast<cv::DualTVL1OpticalFlow*>(((pyopencv_DualTVL1OpticalFlow_t*)self)->v.get());
    int val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:DualTVL1OpticalFlow.setMedianFiltering", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setMedianFiltering(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_DualTVL1OpticalFlow_setOuterIterations(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_DualTVL1OpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'DualTVL1OpticalFlow' or its derivative)");
    cv::DualTVL1OpticalFlow* _self_ = dynamic_cast<cv::DualTVL1OpticalFlow*>(((pyopencv_DualTVL1OpticalFlow_t*)self)->v.get());
    int val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:DualTVL1OpticalFlow.setOuterIterations", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setOuterIterations(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_DualTVL1OpticalFlow_setScaleStep(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_DualTVL1OpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'DualTVL1OpticalFlow' or its derivative)");
    cv::DualTVL1OpticalFlow* _self_ = dynamic_cast<cv::DualTVL1OpticalFlow*>(((pyopencv_DualTVL1OpticalFlow_t*)self)->v.get());
    double val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:DualTVL1OpticalFlow.setScaleStep", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setScaleStep(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_DualTVL1OpticalFlow_setScalesNumber(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_DualTVL1OpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'DualTVL1OpticalFlow' or its derivative)");
    cv::DualTVL1OpticalFlow* _self_ = dynamic_cast<cv::DualTVL1OpticalFlow*>(((pyopencv_DualTVL1OpticalFlow_t*)self)->v.get());
    int val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:DualTVL1OpticalFlow.setScalesNumber", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setScalesNumber(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_DualTVL1OpticalFlow_setTau(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_DualTVL1OpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'DualTVL1OpticalFlow' or its derivative)");
    cv::DualTVL1OpticalFlow* _self_ = dynamic_cast<cv::DualTVL1OpticalFlow*>(((pyopencv_DualTVL1OpticalFlow_t*)self)->v.get());
    double val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:DualTVL1OpticalFlow.setTau", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setTau(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_DualTVL1OpticalFlow_setTheta(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_DualTVL1OpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'DualTVL1OpticalFlow' or its derivative)");
    cv::DualTVL1OpticalFlow* _self_ = dynamic_cast<cv::DualTVL1OpticalFlow*>(((pyopencv_DualTVL1OpticalFlow_t*)self)->v.get());
    double val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:DualTVL1OpticalFlow.setTheta", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setTheta(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_DualTVL1OpticalFlow_setUseInitialFlow(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_DualTVL1OpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'DualTVL1OpticalFlow' or its derivative)");
    cv::DualTVL1OpticalFlow* _self_ = dynamic_cast<cv::DualTVL1OpticalFlow*>(((pyopencv_DualTVL1OpticalFlow_t*)self)->v.get());
    bool val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "b:DualTVL1OpticalFlow.setUseInitialFlow", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setUseInitialFlow(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_DualTVL1OpticalFlow_setWarpingsNumber(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_DualTVL1OpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'DualTVL1OpticalFlow' or its derivative)");
    cv::DualTVL1OpticalFlow* _self_ = dynamic_cast<cv::DualTVL1OpticalFlow*>(((pyopencv_DualTVL1OpticalFlow_t*)self)->v.get());
    int val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:DualTVL1OpticalFlow.setWarpingsNumber", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setWarpingsNumber(val));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_DualTVL1OpticalFlow_methods[] =
{
    {"getEpsilon", (PyCFunction)pyopencv_cv_DualTVL1OpticalFlow_getEpsilon, METH_VARARGS | METH_KEYWORDS, "getEpsilon() -> retval"},
    {"getGamma", (PyCFunction)pyopencv_cv_DualTVL1OpticalFlow_getGamma, METH_VARARGS | METH_KEYWORDS, "getGamma() -> retval"},
    {"getInnerIterations", (PyCFunction)pyopencv_cv_DualTVL1OpticalFlow_getInnerIterations, METH_VARARGS | METH_KEYWORDS, "getInnerIterations() -> retval"},
    {"getLambda", (PyCFunction)pyopencv_cv_DualTVL1OpticalFlow_getLambda, METH_VARARGS | METH_KEYWORDS, "getLambda() -> retval"},
    {"getMedianFiltering", (PyCFunction)pyopencv_cv_DualTVL1OpticalFlow_getMedianFiltering, METH_VARARGS | METH_KEYWORDS, "getMedianFiltering() -> retval"},
    {"getOuterIterations", (PyCFunction)pyopencv_cv_DualTVL1OpticalFlow_getOuterIterations, METH_VARARGS | METH_KEYWORDS, "getOuterIterations() -> retval"},
    {"getScaleStep", (PyCFunction)pyopencv_cv_DualTVL1OpticalFlow_getScaleStep, METH_VARARGS | METH_KEYWORDS, "getScaleStep() -> retval"},
    {"getScalesNumber", (PyCFunction)pyopencv_cv_DualTVL1OpticalFlow_getScalesNumber, METH_VARARGS | METH_KEYWORDS, "getScalesNumber() -> retval"},
    {"getTau", (PyCFunction)pyopencv_cv_DualTVL1OpticalFlow_getTau, METH_VARARGS | METH_KEYWORDS, "getTau() -> retval"},
    {"getTheta", (PyCFunction)pyopencv_cv_DualTVL1OpticalFlow_getTheta, METH_VARARGS | METH_KEYWORDS, "getTheta() -> retval"},
    {"getUseInitialFlow", (PyCFunction)pyopencv_cv_DualTVL1OpticalFlow_getUseInitialFlow, METH_VARARGS | METH_KEYWORDS, "getUseInitialFlow() -> retval"},
    {"getWarpingsNumber", (PyCFunction)pyopencv_cv_DualTVL1OpticalFlow_getWarpingsNumber, METH_VARARGS | METH_KEYWORDS, "getWarpingsNumber() -> retval"},
    {"setEpsilon", (PyCFunction)pyopencv_cv_DualTVL1OpticalFlow_setEpsilon, METH_VARARGS | METH_KEYWORDS, "setEpsilon(val) -> None"},
    {"setGamma", (PyCFunction)pyopencv_cv_DualTVL1OpticalFlow_setGamma, METH_VARARGS | METH_KEYWORDS, "setGamma(val) -> None"},
    {"setInnerIterations", (PyCFunction)pyopencv_cv_DualTVL1OpticalFlow_setInnerIterations, METH_VARARGS | METH_KEYWORDS, "setInnerIterations(val) -> None"},
    {"setLambda", (PyCFunction)pyopencv_cv_DualTVL1OpticalFlow_setLambda, METH_VARARGS | METH_KEYWORDS, "setLambda(val) -> None"},
    {"setMedianFiltering", (PyCFunction)pyopencv_cv_DualTVL1OpticalFlow_setMedianFiltering, METH_VARARGS | METH_KEYWORDS, "setMedianFiltering(val) -> None"},
    {"setOuterIterations", (PyCFunction)pyopencv_cv_DualTVL1OpticalFlow_setOuterIterations, METH_VARARGS | METH_KEYWORDS, "setOuterIterations(val) -> None"},
    {"setScaleStep", (PyCFunction)pyopencv_cv_DualTVL1OpticalFlow_setScaleStep, METH_VARARGS | METH_KEYWORDS, "setScaleStep(val) -> None"},
    {"setScalesNumber", (PyCFunction)pyopencv_cv_DualTVL1OpticalFlow_setScalesNumber, METH_VARARGS | METH_KEYWORDS, "setScalesNumber(val) -> None"},
    {"setTau", (PyCFunction)pyopencv_cv_DualTVL1OpticalFlow_setTau, METH_VARARGS | METH_KEYWORDS, "setTau(val) -> None"},
    {"setTheta", (PyCFunction)pyopencv_cv_DualTVL1OpticalFlow_setTheta, METH_VARARGS | METH_KEYWORDS, "setTheta(val) -> None"},
    {"setUseInitialFlow", (PyCFunction)pyopencv_cv_DualTVL1OpticalFlow_setUseInitialFlow, METH_VARARGS | METH_KEYWORDS, "setUseInitialFlow(val) -> None"},
    {"setWarpingsNumber", (PyCFunction)pyopencv_cv_DualTVL1OpticalFlow_setWarpingsNumber, METH_VARARGS | METH_KEYWORDS, "setWarpingsNumber(val) -> None"},

    {NULL,          NULL}
};

static void pyopencv_DualTVL1OpticalFlow_specials(void)
{
    pyopencv_DualTVL1OpticalFlow_Type.tp_base = &pyopencv_DenseOpticalFlow_Type;
    pyopencv_DualTVL1OpticalFlow_Type.tp_dealloc = pyopencv_DualTVL1OpticalFlow_dealloc;
    pyopencv_DualTVL1OpticalFlow_Type.tp_repr = pyopencv_DualTVL1OpticalFlow_repr;
    pyopencv_DualTVL1OpticalFlow_Type.tp_getset = pyopencv_DualTVL1OpticalFlow_getseters;
    pyopencv_DualTVL1OpticalFlow_Type.tp_methods = pyopencv_DualTVL1OpticalFlow_methods;
}

static PyObject* pyopencv_FarnebackOpticalFlow_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<FarnebackOpticalFlow %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_FarnebackOpticalFlow_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_FarnebackOpticalFlow_getFastPyramids(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FarnebackOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'FarnebackOpticalFlow' or its derivative)");
    cv::FarnebackOpticalFlow* _self_ = dynamic_cast<cv::FarnebackOpticalFlow*>(((pyopencv_FarnebackOpticalFlow_t*)self)->v.get());
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getFastPyramids());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_FarnebackOpticalFlow_getFlags(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FarnebackOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'FarnebackOpticalFlow' or its derivative)");
    cv::FarnebackOpticalFlow* _self_ = dynamic_cast<cv::FarnebackOpticalFlow*>(((pyopencv_FarnebackOpticalFlow_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getFlags());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_FarnebackOpticalFlow_getNumIters(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FarnebackOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'FarnebackOpticalFlow' or its derivative)");
    cv::FarnebackOpticalFlow* _self_ = dynamic_cast<cv::FarnebackOpticalFlow*>(((pyopencv_FarnebackOpticalFlow_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getNumIters());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_FarnebackOpticalFlow_getNumLevels(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FarnebackOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'FarnebackOpticalFlow' or its derivative)");
    cv::FarnebackOpticalFlow* _self_ = dynamic_cast<cv::FarnebackOpticalFlow*>(((pyopencv_FarnebackOpticalFlow_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getNumLevels());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_FarnebackOpticalFlow_getPolyN(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FarnebackOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'FarnebackOpticalFlow' or its derivative)");
    cv::FarnebackOpticalFlow* _self_ = dynamic_cast<cv::FarnebackOpticalFlow*>(((pyopencv_FarnebackOpticalFlow_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getPolyN());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_FarnebackOpticalFlow_getPolySigma(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FarnebackOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'FarnebackOpticalFlow' or its derivative)");
    cv::FarnebackOpticalFlow* _self_ = dynamic_cast<cv::FarnebackOpticalFlow*>(((pyopencv_FarnebackOpticalFlow_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getPolySigma());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_FarnebackOpticalFlow_getPyrScale(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FarnebackOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'FarnebackOpticalFlow' or its derivative)");
    cv::FarnebackOpticalFlow* _self_ = dynamic_cast<cv::FarnebackOpticalFlow*>(((pyopencv_FarnebackOpticalFlow_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getPyrScale());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_FarnebackOpticalFlow_getWinSize(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FarnebackOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'FarnebackOpticalFlow' or its derivative)");
    cv::FarnebackOpticalFlow* _self_ = dynamic_cast<cv::FarnebackOpticalFlow*>(((pyopencv_FarnebackOpticalFlow_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getWinSize());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_FarnebackOpticalFlow_setFastPyramids(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FarnebackOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'FarnebackOpticalFlow' or its derivative)");
    cv::FarnebackOpticalFlow* _self_ = dynamic_cast<cv::FarnebackOpticalFlow*>(((pyopencv_FarnebackOpticalFlow_t*)self)->v.get());
    bool fastPyramids=0;

    const char* keywords[] = { "fastPyramids", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "b:FarnebackOpticalFlow.setFastPyramids", (char**)keywords, &fastPyramids) )
    {
        ERRWRAP2(_self_->setFastPyramids(fastPyramids));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_FarnebackOpticalFlow_setFlags(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FarnebackOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'FarnebackOpticalFlow' or its derivative)");
    cv::FarnebackOpticalFlow* _self_ = dynamic_cast<cv::FarnebackOpticalFlow*>(((pyopencv_FarnebackOpticalFlow_t*)self)->v.get());
    int flags=0;

    const char* keywords[] = { "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:FarnebackOpticalFlow.setFlags", (char**)keywords, &flags) )
    {
        ERRWRAP2(_self_->setFlags(flags));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_FarnebackOpticalFlow_setNumIters(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FarnebackOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'FarnebackOpticalFlow' or its derivative)");
    cv::FarnebackOpticalFlow* _self_ = dynamic_cast<cv::FarnebackOpticalFlow*>(((pyopencv_FarnebackOpticalFlow_t*)self)->v.get());
    int numIters=0;

    const char* keywords[] = { "numIters", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:FarnebackOpticalFlow.setNumIters", (char**)keywords, &numIters) )
    {
        ERRWRAP2(_self_->setNumIters(numIters));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_FarnebackOpticalFlow_setNumLevels(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FarnebackOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'FarnebackOpticalFlow' or its derivative)");
    cv::FarnebackOpticalFlow* _self_ = dynamic_cast<cv::FarnebackOpticalFlow*>(((pyopencv_FarnebackOpticalFlow_t*)self)->v.get());
    int numLevels=0;

    const char* keywords[] = { "numLevels", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:FarnebackOpticalFlow.setNumLevels", (char**)keywords, &numLevels) )
    {
        ERRWRAP2(_self_->setNumLevels(numLevels));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_FarnebackOpticalFlow_setPolyN(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FarnebackOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'FarnebackOpticalFlow' or its derivative)");
    cv::FarnebackOpticalFlow* _self_ = dynamic_cast<cv::FarnebackOpticalFlow*>(((pyopencv_FarnebackOpticalFlow_t*)self)->v.get());
    int polyN=0;

    const char* keywords[] = { "polyN", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:FarnebackOpticalFlow.setPolyN", (char**)keywords, &polyN) )
    {
        ERRWRAP2(_self_->setPolyN(polyN));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_FarnebackOpticalFlow_setPolySigma(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FarnebackOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'FarnebackOpticalFlow' or its derivative)");
    cv::FarnebackOpticalFlow* _self_ = dynamic_cast<cv::FarnebackOpticalFlow*>(((pyopencv_FarnebackOpticalFlow_t*)self)->v.get());
    double polySigma=0;

    const char* keywords[] = { "polySigma", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:FarnebackOpticalFlow.setPolySigma", (char**)keywords, &polySigma) )
    {
        ERRWRAP2(_self_->setPolySigma(polySigma));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_FarnebackOpticalFlow_setPyrScale(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FarnebackOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'FarnebackOpticalFlow' or its derivative)");
    cv::FarnebackOpticalFlow* _self_ = dynamic_cast<cv::FarnebackOpticalFlow*>(((pyopencv_FarnebackOpticalFlow_t*)self)->v.get());
    double pyrScale=0;

    const char* keywords[] = { "pyrScale", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:FarnebackOpticalFlow.setPyrScale", (char**)keywords, &pyrScale) )
    {
        ERRWRAP2(_self_->setPyrScale(pyrScale));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_FarnebackOpticalFlow_setWinSize(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FarnebackOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'FarnebackOpticalFlow' or its derivative)");
    cv::FarnebackOpticalFlow* _self_ = dynamic_cast<cv::FarnebackOpticalFlow*>(((pyopencv_FarnebackOpticalFlow_t*)self)->v.get());
    int winSize=0;

    const char* keywords[] = { "winSize", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:FarnebackOpticalFlow.setWinSize", (char**)keywords, &winSize) )
    {
        ERRWRAP2(_self_->setWinSize(winSize));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_FarnebackOpticalFlow_methods[] =
{
    {"getFastPyramids", (PyCFunction)pyopencv_cv_FarnebackOpticalFlow_getFastPyramids, METH_VARARGS | METH_KEYWORDS, "getFastPyramids() -> retval"},
    {"getFlags", (PyCFunction)pyopencv_cv_FarnebackOpticalFlow_getFlags, METH_VARARGS | METH_KEYWORDS, "getFlags() -> retval"},
    {"getNumIters", (PyCFunction)pyopencv_cv_FarnebackOpticalFlow_getNumIters, METH_VARARGS | METH_KEYWORDS, "getNumIters() -> retval"},
    {"getNumLevels", (PyCFunction)pyopencv_cv_FarnebackOpticalFlow_getNumLevels, METH_VARARGS | METH_KEYWORDS, "getNumLevels() -> retval"},
    {"getPolyN", (PyCFunction)pyopencv_cv_FarnebackOpticalFlow_getPolyN, METH_VARARGS | METH_KEYWORDS, "getPolyN() -> retval"},
    {"getPolySigma", (PyCFunction)pyopencv_cv_FarnebackOpticalFlow_getPolySigma, METH_VARARGS | METH_KEYWORDS, "getPolySigma() -> retval"},
    {"getPyrScale", (PyCFunction)pyopencv_cv_FarnebackOpticalFlow_getPyrScale, METH_VARARGS | METH_KEYWORDS, "getPyrScale() -> retval"},
    {"getWinSize", (PyCFunction)pyopencv_cv_FarnebackOpticalFlow_getWinSize, METH_VARARGS | METH_KEYWORDS, "getWinSize() -> retval"},
    {"setFastPyramids", (PyCFunction)pyopencv_cv_FarnebackOpticalFlow_setFastPyramids, METH_VARARGS | METH_KEYWORDS, "setFastPyramids(fastPyramids) -> None"},
    {"setFlags", (PyCFunction)pyopencv_cv_FarnebackOpticalFlow_setFlags, METH_VARARGS | METH_KEYWORDS, "setFlags(flags) -> None"},
    {"setNumIters", (PyCFunction)pyopencv_cv_FarnebackOpticalFlow_setNumIters, METH_VARARGS | METH_KEYWORDS, "setNumIters(numIters) -> None"},
    {"setNumLevels", (PyCFunction)pyopencv_cv_FarnebackOpticalFlow_setNumLevels, METH_VARARGS | METH_KEYWORDS, "setNumLevels(numLevels) -> None"},
    {"setPolyN", (PyCFunction)pyopencv_cv_FarnebackOpticalFlow_setPolyN, METH_VARARGS | METH_KEYWORDS, "setPolyN(polyN) -> None"},
    {"setPolySigma", (PyCFunction)pyopencv_cv_FarnebackOpticalFlow_setPolySigma, METH_VARARGS | METH_KEYWORDS, "setPolySigma(polySigma) -> None"},
    {"setPyrScale", (PyCFunction)pyopencv_cv_FarnebackOpticalFlow_setPyrScale, METH_VARARGS | METH_KEYWORDS, "setPyrScale(pyrScale) -> None"},
    {"setWinSize", (PyCFunction)pyopencv_cv_FarnebackOpticalFlow_setWinSize, METH_VARARGS | METH_KEYWORDS, "setWinSize(winSize) -> None"},

    {NULL,          NULL}
};

static void pyopencv_FarnebackOpticalFlow_specials(void)
{
    pyopencv_FarnebackOpticalFlow_Type.tp_base = &pyopencv_DenseOpticalFlow_Type;
    pyopencv_FarnebackOpticalFlow_Type.tp_dealloc = pyopencv_FarnebackOpticalFlow_dealloc;
    pyopencv_FarnebackOpticalFlow_Type.tp_repr = pyopencv_FarnebackOpticalFlow_repr;
    pyopencv_FarnebackOpticalFlow_Type.tp_getset = pyopencv_FarnebackOpticalFlow_getseters;
    pyopencv_FarnebackOpticalFlow_Type.tp_methods = pyopencv_FarnebackOpticalFlow_methods;
}

static PyObject* pyopencv_SparsePyrLKOpticalFlow_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<SparsePyrLKOpticalFlow %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_SparsePyrLKOpticalFlow_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_SparsePyrLKOpticalFlow_getFlags(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_SparsePyrLKOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'SparsePyrLKOpticalFlow' or its derivative)");
    cv::SparsePyrLKOpticalFlow* _self_ = dynamic_cast<cv::SparsePyrLKOpticalFlow*>(((pyopencv_SparsePyrLKOpticalFlow_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getFlags());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_SparsePyrLKOpticalFlow_getMaxLevel(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_SparsePyrLKOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'SparsePyrLKOpticalFlow' or its derivative)");
    cv::SparsePyrLKOpticalFlow* _self_ = dynamic_cast<cv::SparsePyrLKOpticalFlow*>(((pyopencv_SparsePyrLKOpticalFlow_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getMaxLevel());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_SparsePyrLKOpticalFlow_getMinEigThreshold(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_SparsePyrLKOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'SparsePyrLKOpticalFlow' or its derivative)");
    cv::SparsePyrLKOpticalFlow* _self_ = dynamic_cast<cv::SparsePyrLKOpticalFlow*>(((pyopencv_SparsePyrLKOpticalFlow_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getMinEigThreshold());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_SparsePyrLKOpticalFlow_getTermCriteria(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_SparsePyrLKOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'SparsePyrLKOpticalFlow' or its derivative)");
    cv::SparsePyrLKOpticalFlow* _self_ = dynamic_cast<cv::SparsePyrLKOpticalFlow*>(((pyopencv_SparsePyrLKOpticalFlow_t*)self)->v.get());
    TermCriteria retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getTermCriteria());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_SparsePyrLKOpticalFlow_getWinSize(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_SparsePyrLKOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'SparsePyrLKOpticalFlow' or its derivative)");
    cv::SparsePyrLKOpticalFlow* _self_ = dynamic_cast<cv::SparsePyrLKOpticalFlow*>(((pyopencv_SparsePyrLKOpticalFlow_t*)self)->v.get());
    Size retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getWinSize());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_SparsePyrLKOpticalFlow_setFlags(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_SparsePyrLKOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'SparsePyrLKOpticalFlow' or its derivative)");
    cv::SparsePyrLKOpticalFlow* _self_ = dynamic_cast<cv::SparsePyrLKOpticalFlow*>(((pyopencv_SparsePyrLKOpticalFlow_t*)self)->v.get());
    int flags=0;

    const char* keywords[] = { "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:SparsePyrLKOpticalFlow.setFlags", (char**)keywords, &flags) )
    {
        ERRWRAP2(_self_->setFlags(flags));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_SparsePyrLKOpticalFlow_setMaxLevel(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_SparsePyrLKOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'SparsePyrLKOpticalFlow' or its derivative)");
    cv::SparsePyrLKOpticalFlow* _self_ = dynamic_cast<cv::SparsePyrLKOpticalFlow*>(((pyopencv_SparsePyrLKOpticalFlow_t*)self)->v.get());
    int maxLevel=0;

    const char* keywords[] = { "maxLevel", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:SparsePyrLKOpticalFlow.setMaxLevel", (char**)keywords, &maxLevel) )
    {
        ERRWRAP2(_self_->setMaxLevel(maxLevel));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_SparsePyrLKOpticalFlow_setMinEigThreshold(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_SparsePyrLKOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'SparsePyrLKOpticalFlow' or its derivative)");
    cv::SparsePyrLKOpticalFlow* _self_ = dynamic_cast<cv::SparsePyrLKOpticalFlow*>(((pyopencv_SparsePyrLKOpticalFlow_t*)self)->v.get());
    double minEigThreshold=0;

    const char* keywords[] = { "minEigThreshold", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:SparsePyrLKOpticalFlow.setMinEigThreshold", (char**)keywords, &minEigThreshold) )
    {
        ERRWRAP2(_self_->setMinEigThreshold(minEigThreshold));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_SparsePyrLKOpticalFlow_setTermCriteria(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_SparsePyrLKOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'SparsePyrLKOpticalFlow' or its derivative)");
    cv::SparsePyrLKOpticalFlow* _self_ = dynamic_cast<cv::SparsePyrLKOpticalFlow*>(((pyopencv_SparsePyrLKOpticalFlow_t*)self)->v.get());
    PyObject* pyobj_crit = NULL;
    TermCriteria crit;

    const char* keywords[] = { "crit", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:SparsePyrLKOpticalFlow.setTermCriteria", (char**)keywords, &pyobj_crit) &&
        pyopencv_to(pyobj_crit, crit, ArgInfo("crit", 0)) )
    {
        ERRWRAP2(_self_->setTermCriteria(crit));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_SparsePyrLKOpticalFlow_setWinSize(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_SparsePyrLKOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'SparsePyrLKOpticalFlow' or its derivative)");
    cv::SparsePyrLKOpticalFlow* _self_ = dynamic_cast<cv::SparsePyrLKOpticalFlow*>(((pyopencv_SparsePyrLKOpticalFlow_t*)self)->v.get());
    PyObject* pyobj_winSize = NULL;
    Size winSize;

    const char* keywords[] = { "winSize", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:SparsePyrLKOpticalFlow.setWinSize", (char**)keywords, &pyobj_winSize) &&
        pyopencv_to(pyobj_winSize, winSize, ArgInfo("winSize", 0)) )
    {
        ERRWRAP2(_self_->setWinSize(winSize));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_SparsePyrLKOpticalFlow_methods[] =
{
    {"getFlags", (PyCFunction)pyopencv_cv_SparsePyrLKOpticalFlow_getFlags, METH_VARARGS | METH_KEYWORDS, "getFlags() -> retval"},
    {"getMaxLevel", (PyCFunction)pyopencv_cv_SparsePyrLKOpticalFlow_getMaxLevel, METH_VARARGS | METH_KEYWORDS, "getMaxLevel() -> retval"},
    {"getMinEigThreshold", (PyCFunction)pyopencv_cv_SparsePyrLKOpticalFlow_getMinEigThreshold, METH_VARARGS | METH_KEYWORDS, "getMinEigThreshold() -> retval"},
    {"getTermCriteria", (PyCFunction)pyopencv_cv_SparsePyrLKOpticalFlow_getTermCriteria, METH_VARARGS | METH_KEYWORDS, "getTermCriteria() -> retval"},
    {"getWinSize", (PyCFunction)pyopencv_cv_SparsePyrLKOpticalFlow_getWinSize, METH_VARARGS | METH_KEYWORDS, "getWinSize() -> retval"},
    {"setFlags", (PyCFunction)pyopencv_cv_SparsePyrLKOpticalFlow_setFlags, METH_VARARGS | METH_KEYWORDS, "setFlags(flags) -> None"},
    {"setMaxLevel", (PyCFunction)pyopencv_cv_SparsePyrLKOpticalFlow_setMaxLevel, METH_VARARGS | METH_KEYWORDS, "setMaxLevel(maxLevel) -> None"},
    {"setMinEigThreshold", (PyCFunction)pyopencv_cv_SparsePyrLKOpticalFlow_setMinEigThreshold, METH_VARARGS | METH_KEYWORDS, "setMinEigThreshold(minEigThreshold) -> None"},
    {"setTermCriteria", (PyCFunction)pyopencv_cv_SparsePyrLKOpticalFlow_setTermCriteria, METH_VARARGS | METH_KEYWORDS, "setTermCriteria(crit) -> None"},
    {"setWinSize", (PyCFunction)pyopencv_cv_SparsePyrLKOpticalFlow_setWinSize, METH_VARARGS | METH_KEYWORDS, "setWinSize(winSize) -> None"},

    {NULL,          NULL}
};

static void pyopencv_SparsePyrLKOpticalFlow_specials(void)
{
    pyopencv_SparsePyrLKOpticalFlow_Type.tp_base = &pyopencv_SparseOpticalFlow_Type;
    pyopencv_SparsePyrLKOpticalFlow_Type.tp_dealloc = pyopencv_SparsePyrLKOpticalFlow_dealloc;
    pyopencv_SparsePyrLKOpticalFlow_Type.tp_repr = pyopencv_SparsePyrLKOpticalFlow_repr;
    pyopencv_SparsePyrLKOpticalFlow_Type.tp_getset = pyopencv_SparsePyrLKOpticalFlow_getseters;
    pyopencv_SparsePyrLKOpticalFlow_Type.tp_methods = pyopencv_SparsePyrLKOpticalFlow_methods;
}

static PyObject* pyopencv_dnn_LSTMLayer_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<dnn_LSTMLayer %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_dnn_LSTMLayer_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_dnn_dnn_LSTMLayer_getC(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::dnn;

    if(!PyObject_TypeCheck(self, &pyopencv_dnn_LSTMLayer_Type))
        return failmsgp("Incorrect type of self (must be 'dnn_LSTMLayer' or its derivative)");
    cv::dnn::LSTMLayer* _self_ = ((pyopencv_dnn_LSTMLayer_t*)self)->v.get();
    Blob retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getC());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_dnn_dnn_LSTMLayer_getH(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::dnn;

    if(!PyObject_TypeCheck(self, &pyopencv_dnn_LSTMLayer_Type))
        return failmsgp("Incorrect type of self (must be 'dnn_LSTMLayer' or its derivative)");
    cv::dnn::LSTMLayer* _self_ = ((pyopencv_dnn_LSTMLayer_t*)self)->v.get();
    Blob retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getH());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_dnn_dnn_LSTMLayer_setC(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::dnn;

    if(!PyObject_TypeCheck(self, &pyopencv_dnn_LSTMLayer_Type))
        return failmsgp("Incorrect type of self (must be 'dnn_LSTMLayer' or its derivative)");
    cv::dnn::LSTMLayer* _self_ = ((pyopencv_dnn_LSTMLayer_t*)self)->v.get();
    PyObject* pyobj_C = NULL;
    Blob C;

    const char* keywords[] = { "C", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:dnn_LSTMLayer.setC", (char**)keywords, &pyobj_C) &&
        pyopencv_to(pyobj_C, C, ArgInfo("C", 0)) )
    {
        ERRWRAP2(_self_->setC(C));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_dnn_dnn_LSTMLayer_setH(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::dnn;

    if(!PyObject_TypeCheck(self, &pyopencv_dnn_LSTMLayer_Type))
        return failmsgp("Incorrect type of self (must be 'dnn_LSTMLayer' or its derivative)");
    cv::dnn::LSTMLayer* _self_ = ((pyopencv_dnn_LSTMLayer_t*)self)->v.get();
    PyObject* pyobj_H = NULL;
    Blob H;

    const char* keywords[] = { "H", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:dnn_LSTMLayer.setH", (char**)keywords, &pyobj_H) &&
        pyopencv_to(pyobj_H, H, ArgInfo("H", 0)) )
    {
        ERRWRAP2(_self_->setH(H));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_dnn_dnn_LSTMLayer_setOutShape(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::dnn;

    if(!PyObject_TypeCheck(self, &pyopencv_dnn_LSTMLayer_Type))
        return failmsgp("Incorrect type of self (must be 'dnn_LSTMLayer' or its derivative)");
    cv::dnn::LSTMLayer* _self_ = ((pyopencv_dnn_LSTMLayer_t*)self)->v.get();
    PyObject* pyobj_outTailShape = NULL;
    BlobShape outTailShape=BlobShape::empty();

    const char* keywords[] = { "outTailShape", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|O:dnn_LSTMLayer.setOutShape", (char**)keywords, &pyobj_outTailShape) &&
        pyopencv_to(pyobj_outTailShape, outTailShape, ArgInfo("outTailShape", 0)) )
    {
        ERRWRAP2(_self_->setOutShape(outTailShape));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_dnn_dnn_LSTMLayer_setProduceCellOutput(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::dnn;

    if(!PyObject_TypeCheck(self, &pyopencv_dnn_LSTMLayer_Type))
        return failmsgp("Incorrect type of self (must be 'dnn_LSTMLayer' or its derivative)");
    cv::dnn::LSTMLayer* _self_ = ((pyopencv_dnn_LSTMLayer_t*)self)->v.get();
    bool produce=false;

    const char* keywords[] = { "produce", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|b:dnn_LSTMLayer.setProduceCellOutput", (char**)keywords, &produce) )
    {
        ERRWRAP2(_self_->setProduceCellOutput(produce));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_dnn_dnn_LSTMLayer_setUseTimstampsDim(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::dnn;

    if(!PyObject_TypeCheck(self, &pyopencv_dnn_LSTMLayer_Type))
        return failmsgp("Incorrect type of self (must be 'dnn_LSTMLayer' or its derivative)");
    cv::dnn::LSTMLayer* _self_ = ((pyopencv_dnn_LSTMLayer_t*)self)->v.get();
    bool use=true;

    const char* keywords[] = { "use", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|b:dnn_LSTMLayer.setUseTimstampsDim", (char**)keywords, &use) )
    {
        ERRWRAP2(_self_->setUseTimstampsDim(use));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_dnn_dnn_LSTMLayer_setWeights(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::dnn;

    if(!PyObject_TypeCheck(self, &pyopencv_dnn_LSTMLayer_Type))
        return failmsgp("Incorrect type of self (must be 'dnn_LSTMLayer' or its derivative)");
    cv::dnn::LSTMLayer* _self_ = ((pyopencv_dnn_LSTMLayer_t*)self)->v.get();
    PyObject* pyobj_Wh = NULL;
    Blob Wh;
    PyObject* pyobj_Wx = NULL;
    Blob Wx;
    PyObject* pyobj_b = NULL;
    Blob b;

    const char* keywords[] = { "Wh", "Wx", "b", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OOO:dnn_LSTMLayer.setWeights", (char**)keywords, &pyobj_Wh, &pyobj_Wx, &pyobj_b) &&
        pyopencv_to(pyobj_Wh, Wh, ArgInfo("Wh", 0)) &&
        pyopencv_to(pyobj_Wx, Wx, ArgInfo("Wx", 0)) &&
        pyopencv_to(pyobj_b, b, ArgInfo("b", 0)) )
    {
        ERRWRAP2(_self_->setWeights(Wh, Wx, b));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_dnn_LSTMLayer_methods[] =
{
    {"getC", (PyCFunction)pyopencv_cv_dnn_dnn_LSTMLayer_getC, METH_VARARGS | METH_KEYWORDS, "getC() -> retval"},
    {"getH", (PyCFunction)pyopencv_cv_dnn_dnn_LSTMLayer_getH, METH_VARARGS | METH_KEYWORDS, "getH() -> retval"},
    {"setC", (PyCFunction)pyopencv_cv_dnn_dnn_LSTMLayer_setC, METH_VARARGS | METH_KEYWORDS, "setC(C) -> None"},
    {"setH", (PyCFunction)pyopencv_cv_dnn_dnn_LSTMLayer_setH, METH_VARARGS | METH_KEYWORDS, "setH(H) -> None"},
    {"setOutShape", (PyCFunction)pyopencv_cv_dnn_dnn_LSTMLayer_setOutShape, METH_VARARGS | METH_KEYWORDS, "setOutShape([, outTailShape]) -> None"},
    {"setProduceCellOutput", (PyCFunction)pyopencv_cv_dnn_dnn_LSTMLayer_setProduceCellOutput, METH_VARARGS | METH_KEYWORDS, "setProduceCellOutput([, produce]) -> None"},
    {"setUseTimstampsDim", (PyCFunction)pyopencv_cv_dnn_dnn_LSTMLayer_setUseTimstampsDim, METH_VARARGS | METH_KEYWORDS, "setUseTimstampsDim([, use]) -> None"},
    {"setWeights", (PyCFunction)pyopencv_cv_dnn_dnn_LSTMLayer_setWeights, METH_VARARGS | METH_KEYWORDS, "setWeights(Wh, Wx, b) -> None"},

    {NULL,          NULL}
};

static void pyopencv_dnn_LSTMLayer_specials(void)
{
    pyopencv_dnn_LSTMLayer_Type.tp_base = &pyopencv_dnn_Layer_Type;
    pyopencv_dnn_LSTMLayer_Type.tp_dealloc = pyopencv_dnn_LSTMLayer_dealloc;
    pyopencv_dnn_LSTMLayer_Type.tp_repr = pyopencv_dnn_LSTMLayer_repr;
    pyopencv_dnn_LSTMLayer_Type.tp_getset = pyopencv_dnn_LSTMLayer_getseters;
    pyopencv_dnn_LSTMLayer_Type.tp_methods = pyopencv_dnn_LSTMLayer_methods;
}

static PyObject* pyopencv_dnn_RNNLayer_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<dnn_RNNLayer %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_dnn_RNNLayer_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_dnn_dnn_RNNLayer_setProduceHiddenOutput(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::dnn;

    if(!PyObject_TypeCheck(self, &pyopencv_dnn_RNNLayer_Type))
        return failmsgp("Incorrect type of self (must be 'dnn_RNNLayer' or its derivative)");
    cv::dnn::RNNLayer* _self_ = ((pyopencv_dnn_RNNLayer_t*)self)->v.get();
    bool produce=false;

    const char* keywords[] = { "produce", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|b:dnn_RNNLayer.setProduceHiddenOutput", (char**)keywords, &produce) )
    {
        ERRWRAP2(_self_->setProduceHiddenOutput(produce));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_dnn_dnn_RNNLayer_setWeights(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::dnn;

    if(!PyObject_TypeCheck(self, &pyopencv_dnn_RNNLayer_Type))
        return failmsgp("Incorrect type of self (must be 'dnn_RNNLayer' or its derivative)");
    cv::dnn::RNNLayer* _self_ = ((pyopencv_dnn_RNNLayer_t*)self)->v.get();
    PyObject* pyobj_Wxh = NULL;
    Blob Wxh;
    PyObject* pyobj_bh = NULL;
    Blob bh;
    PyObject* pyobj_Whh = NULL;
    Blob Whh;
    PyObject* pyobj_Who = NULL;
    Blob Who;
    PyObject* pyobj_bo = NULL;
    Blob bo;

    const char* keywords[] = { "Wxh", "bh", "Whh", "Who", "bo", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OOOOO:dnn_RNNLayer.setWeights", (char**)keywords, &pyobj_Wxh, &pyobj_bh, &pyobj_Whh, &pyobj_Who, &pyobj_bo) &&
        pyopencv_to(pyobj_Wxh, Wxh, ArgInfo("Wxh", 0)) &&
        pyopencv_to(pyobj_bh, bh, ArgInfo("bh", 0)) &&
        pyopencv_to(pyobj_Whh, Whh, ArgInfo("Whh", 0)) &&
        pyopencv_to(pyobj_Who, Who, ArgInfo("Who", 0)) &&
        pyopencv_to(pyobj_bo, bo, ArgInfo("bo", 0)) )
    {
        ERRWRAP2(_self_->setWeights(Wxh, bh, Whh, Who, bo));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_dnn_RNNLayer_methods[] =
{
    {"setProduceHiddenOutput", (PyCFunction)pyopencv_cv_dnn_dnn_RNNLayer_setProduceHiddenOutput, METH_VARARGS | METH_KEYWORDS, "setProduceHiddenOutput([, produce]) -> None"},
    {"setWeights", (PyCFunction)pyopencv_cv_dnn_dnn_RNNLayer_setWeights, METH_VARARGS | METH_KEYWORDS, "setWeights(Wxh, bh, Whh, Who, bo) -> None"},

    {NULL,          NULL}
};

static void pyopencv_dnn_RNNLayer_specials(void)
{
    pyopencv_dnn_RNNLayer_Type.tp_base = &pyopencv_dnn_Layer_Type;
    pyopencv_dnn_RNNLayer_Type.tp_dealloc = pyopencv_dnn_RNNLayer_dealloc;
    pyopencv_dnn_RNNLayer_Type.tp_repr = pyopencv_dnn_RNNLayer_repr;
    pyopencv_dnn_RNNLayer_Type.tp_getset = pyopencv_dnn_RNNLayer_getseters;
    pyopencv_dnn_RNNLayer_Type.tp_methods = pyopencv_dnn_RNNLayer_methods;
}

static PyObject* pyopencv_dnn_BaseConvolutionLayer_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<dnn_BaseConvolutionLayer %p>", self);
    return PyString_FromString(str);
}


static PyObject* pyopencv_dnn_BaseConvolutionLayer_get_adjustPad(pyopencv_dnn_BaseConvolutionLayer_t* p, void *closure)
{
    return pyopencv_from(p->v->adjustPad);
}

static int pyopencv_dnn_BaseConvolutionLayer_set_adjustPad(pyopencv_dnn_BaseConvolutionLayer_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the adjustPad attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->adjustPad) ? 0 : -1;
}

static PyObject* pyopencv_dnn_BaseConvolutionLayer_get_dilation(pyopencv_dnn_BaseConvolutionLayer_t* p, void *closure)
{
    return pyopencv_from(p->v->dilation);
}

static int pyopencv_dnn_BaseConvolutionLayer_set_dilation(pyopencv_dnn_BaseConvolutionLayer_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the dilation attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->dilation) ? 0 : -1;
}

static PyObject* pyopencv_dnn_BaseConvolutionLayer_get_kernel(pyopencv_dnn_BaseConvolutionLayer_t* p, void *closure)
{
    return pyopencv_from(p->v->kernel);
}

static int pyopencv_dnn_BaseConvolutionLayer_set_kernel(pyopencv_dnn_BaseConvolutionLayer_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the kernel attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->kernel) ? 0 : -1;
}

static PyObject* pyopencv_dnn_BaseConvolutionLayer_get_pad(pyopencv_dnn_BaseConvolutionLayer_t* p, void *closure)
{
    return pyopencv_from(p->v->pad);
}

static int pyopencv_dnn_BaseConvolutionLayer_set_pad(pyopencv_dnn_BaseConvolutionLayer_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the pad attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->pad) ? 0 : -1;
}

static PyObject* pyopencv_dnn_BaseConvolutionLayer_get_padMode(pyopencv_dnn_BaseConvolutionLayer_t* p, void *closure)
{
    return pyopencv_from(p->v->padMode);
}

static int pyopencv_dnn_BaseConvolutionLayer_set_padMode(pyopencv_dnn_BaseConvolutionLayer_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the padMode attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->padMode) ? 0 : -1;
}

static PyObject* pyopencv_dnn_BaseConvolutionLayer_get_stride(pyopencv_dnn_BaseConvolutionLayer_t* p, void *closure)
{
    return pyopencv_from(p->v->stride);
}

static int pyopencv_dnn_BaseConvolutionLayer_set_stride(pyopencv_dnn_BaseConvolutionLayer_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the stride attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->stride) ? 0 : -1;
}


static PyGetSetDef pyopencv_dnn_BaseConvolutionLayer_getseters[] =
{
    {(char*)"adjustPad", (getter)pyopencv_dnn_BaseConvolutionLayer_get_adjustPad, (setter)pyopencv_dnn_BaseConvolutionLayer_set_adjustPad, (char*)"adjustPad", NULL},
    {(char*)"dilation", (getter)pyopencv_dnn_BaseConvolutionLayer_get_dilation, (setter)pyopencv_dnn_BaseConvolutionLayer_set_dilation, (char*)"dilation", NULL},
    {(char*)"kernel", (getter)pyopencv_dnn_BaseConvolutionLayer_get_kernel, (setter)pyopencv_dnn_BaseConvolutionLayer_set_kernel, (char*)"kernel", NULL},
    {(char*)"pad", (getter)pyopencv_dnn_BaseConvolutionLayer_get_pad, (setter)pyopencv_dnn_BaseConvolutionLayer_set_pad, (char*)"pad", NULL},
    {(char*)"padMode", (getter)pyopencv_dnn_BaseConvolutionLayer_get_padMode, (setter)pyopencv_dnn_BaseConvolutionLayer_set_padMode, (char*)"padMode", NULL},
    {(char*)"stride", (getter)pyopencv_dnn_BaseConvolutionLayer_get_stride, (setter)pyopencv_dnn_BaseConvolutionLayer_set_stride, (char*)"stride", NULL},
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_dnn_BaseConvolutionLayer_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_dnn_BaseConvolutionLayer_specials(void)
{
    pyopencv_dnn_BaseConvolutionLayer_Type.tp_base = &pyopencv_dnn_Layer_Type;
    pyopencv_dnn_BaseConvolutionLayer_Type.tp_dealloc = pyopencv_dnn_BaseConvolutionLayer_dealloc;
    pyopencv_dnn_BaseConvolutionLayer_Type.tp_repr = pyopencv_dnn_BaseConvolutionLayer_repr;
    pyopencv_dnn_BaseConvolutionLayer_Type.tp_getset = pyopencv_dnn_BaseConvolutionLayer_getseters;
    pyopencv_dnn_BaseConvolutionLayer_Type.tp_methods = pyopencv_dnn_BaseConvolutionLayer_methods;
}

static PyObject* pyopencv_dnn_ConvolutionLayer_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<dnn_ConvolutionLayer %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_dnn_ConvolutionLayer_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_dnn_ConvolutionLayer_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_dnn_ConvolutionLayer_specials(void)
{
    pyopencv_dnn_ConvolutionLayer_Type.tp_base = &pyopencv_dnn_BaseConvolutionLayer_Type;
    pyopencv_dnn_ConvolutionLayer_Type.tp_dealloc = pyopencv_dnn_ConvolutionLayer_dealloc;
    pyopencv_dnn_ConvolutionLayer_Type.tp_repr = pyopencv_dnn_ConvolutionLayer_repr;
    pyopencv_dnn_ConvolutionLayer_Type.tp_getset = pyopencv_dnn_ConvolutionLayer_getseters;
    pyopencv_dnn_ConvolutionLayer_Type.tp_methods = pyopencv_dnn_ConvolutionLayer_methods;
}

static PyObject* pyopencv_dnn_DeconvolutionLayer_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<dnn_DeconvolutionLayer %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_dnn_DeconvolutionLayer_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_dnn_DeconvolutionLayer_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_dnn_DeconvolutionLayer_specials(void)
{
    pyopencv_dnn_DeconvolutionLayer_Type.tp_base = &pyopencv_dnn_BaseConvolutionLayer_Type;
    pyopencv_dnn_DeconvolutionLayer_Type.tp_dealloc = pyopencv_dnn_DeconvolutionLayer_dealloc;
    pyopencv_dnn_DeconvolutionLayer_Type.tp_repr = pyopencv_dnn_DeconvolutionLayer_repr;
    pyopencv_dnn_DeconvolutionLayer_Type.tp_getset = pyopencv_dnn_DeconvolutionLayer_getseters;
    pyopencv_dnn_DeconvolutionLayer_Type.tp_methods = pyopencv_dnn_DeconvolutionLayer_methods;
}

static PyObject* pyopencv_dnn_LRNLayer_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<dnn_LRNLayer %p>", self);
    return PyString_FromString(str);
}


static PyObject* pyopencv_dnn_LRNLayer_get_alpha(pyopencv_dnn_LRNLayer_t* p, void *closure)
{
    return pyopencv_from(p->v->alpha);
}

static int pyopencv_dnn_LRNLayer_set_alpha(pyopencv_dnn_LRNLayer_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the alpha attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->alpha) ? 0 : -1;
}

static PyObject* pyopencv_dnn_LRNLayer_get_beta(pyopencv_dnn_LRNLayer_t* p, void *closure)
{
    return pyopencv_from(p->v->beta);
}

static int pyopencv_dnn_LRNLayer_set_beta(pyopencv_dnn_LRNLayer_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the beta attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->beta) ? 0 : -1;
}

static PyObject* pyopencv_dnn_LRNLayer_get_bias(pyopencv_dnn_LRNLayer_t* p, void *closure)
{
    return pyopencv_from(p->v->bias);
}

static int pyopencv_dnn_LRNLayer_set_bias(pyopencv_dnn_LRNLayer_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the bias attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->bias) ? 0 : -1;
}

static PyObject* pyopencv_dnn_LRNLayer_get_normBySize(pyopencv_dnn_LRNLayer_t* p, void *closure)
{
    return pyopencv_from(p->v->normBySize);
}

static int pyopencv_dnn_LRNLayer_set_normBySize(pyopencv_dnn_LRNLayer_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the normBySize attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->normBySize) ? 0 : -1;
}

static PyObject* pyopencv_dnn_LRNLayer_get_size(pyopencv_dnn_LRNLayer_t* p, void *closure)
{
    return pyopencv_from(p->v->size);
}

static int pyopencv_dnn_LRNLayer_set_size(pyopencv_dnn_LRNLayer_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the size attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->size) ? 0 : -1;
}

static PyObject* pyopencv_dnn_LRNLayer_get_type(pyopencv_dnn_LRNLayer_t* p, void *closure)
{
    return pyopencv_from(p->v->type);
}

static int pyopencv_dnn_LRNLayer_set_type(pyopencv_dnn_LRNLayer_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the type attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->type) ? 0 : -1;
}


static PyGetSetDef pyopencv_dnn_LRNLayer_getseters[] =
{
    {(char*)"alpha", (getter)pyopencv_dnn_LRNLayer_get_alpha, (setter)pyopencv_dnn_LRNLayer_set_alpha, (char*)"alpha", NULL},
    {(char*)"beta", (getter)pyopencv_dnn_LRNLayer_get_beta, (setter)pyopencv_dnn_LRNLayer_set_beta, (char*)"beta", NULL},
    {(char*)"bias", (getter)pyopencv_dnn_LRNLayer_get_bias, (setter)pyopencv_dnn_LRNLayer_set_bias, (char*)"bias", NULL},
    {(char*)"normBySize", (getter)pyopencv_dnn_LRNLayer_get_normBySize, (setter)pyopencv_dnn_LRNLayer_set_normBySize, (char*)"normBySize", NULL},
    {(char*)"size", (getter)pyopencv_dnn_LRNLayer_get_size, (setter)pyopencv_dnn_LRNLayer_set_size, (char*)"size", NULL},
    {(char*)"type", (getter)pyopencv_dnn_LRNLayer_get_type, (setter)pyopencv_dnn_LRNLayer_set_type, (char*)"type", NULL},
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_dnn_LRNLayer_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_dnn_LRNLayer_specials(void)
{
    pyopencv_dnn_LRNLayer_Type.tp_base = &pyopencv_dnn_Layer_Type;
    pyopencv_dnn_LRNLayer_Type.tp_dealloc = pyopencv_dnn_LRNLayer_dealloc;
    pyopencv_dnn_LRNLayer_Type.tp_repr = pyopencv_dnn_LRNLayer_repr;
    pyopencv_dnn_LRNLayer_Type.tp_getset = pyopencv_dnn_LRNLayer_getseters;
    pyopencv_dnn_LRNLayer_Type.tp_methods = pyopencv_dnn_LRNLayer_methods;
}

static PyObject* pyopencv_dnn_PoolingLayer_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<dnn_PoolingLayer %p>", self);
    return PyString_FromString(str);
}


static PyObject* pyopencv_dnn_PoolingLayer_get_globalPooling(pyopencv_dnn_PoolingLayer_t* p, void *closure)
{
    return pyopencv_from(p->v->globalPooling);
}

static int pyopencv_dnn_PoolingLayer_set_globalPooling(pyopencv_dnn_PoolingLayer_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the globalPooling attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->globalPooling) ? 0 : -1;
}

static PyObject* pyopencv_dnn_PoolingLayer_get_kernel(pyopencv_dnn_PoolingLayer_t* p, void *closure)
{
    return pyopencv_from(p->v->kernel);
}

static int pyopencv_dnn_PoolingLayer_set_kernel(pyopencv_dnn_PoolingLayer_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the kernel attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->kernel) ? 0 : -1;
}

static PyObject* pyopencv_dnn_PoolingLayer_get_pad(pyopencv_dnn_PoolingLayer_t* p, void *closure)
{
    return pyopencv_from(p->v->pad);
}

static int pyopencv_dnn_PoolingLayer_set_pad(pyopencv_dnn_PoolingLayer_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the pad attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->pad) ? 0 : -1;
}

static PyObject* pyopencv_dnn_PoolingLayer_get_padMode(pyopencv_dnn_PoolingLayer_t* p, void *closure)
{
    return pyopencv_from(p->v->padMode);
}

static int pyopencv_dnn_PoolingLayer_set_padMode(pyopencv_dnn_PoolingLayer_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the padMode attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->padMode) ? 0 : -1;
}

static PyObject* pyopencv_dnn_PoolingLayer_get_stride(pyopencv_dnn_PoolingLayer_t* p, void *closure)
{
    return pyopencv_from(p->v->stride);
}

static int pyopencv_dnn_PoolingLayer_set_stride(pyopencv_dnn_PoolingLayer_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the stride attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->stride) ? 0 : -1;
}

static PyObject* pyopencv_dnn_PoolingLayer_get_type(pyopencv_dnn_PoolingLayer_t* p, void *closure)
{
    return pyopencv_from(p->v->type);
}

static int pyopencv_dnn_PoolingLayer_set_type(pyopencv_dnn_PoolingLayer_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the type attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->type) ? 0 : -1;
}


static PyGetSetDef pyopencv_dnn_PoolingLayer_getseters[] =
{
    {(char*)"globalPooling", (getter)pyopencv_dnn_PoolingLayer_get_globalPooling, (setter)pyopencv_dnn_PoolingLayer_set_globalPooling, (char*)"globalPooling", NULL},
    {(char*)"kernel", (getter)pyopencv_dnn_PoolingLayer_get_kernel, (setter)pyopencv_dnn_PoolingLayer_set_kernel, (char*)"kernel", NULL},
    {(char*)"pad", (getter)pyopencv_dnn_PoolingLayer_get_pad, (setter)pyopencv_dnn_PoolingLayer_set_pad, (char*)"pad", NULL},
    {(char*)"padMode", (getter)pyopencv_dnn_PoolingLayer_get_padMode, (setter)pyopencv_dnn_PoolingLayer_set_padMode, (char*)"padMode", NULL},
    {(char*)"stride", (getter)pyopencv_dnn_PoolingLayer_get_stride, (setter)pyopencv_dnn_PoolingLayer_set_stride, (char*)"stride", NULL},
    {(char*)"type", (getter)pyopencv_dnn_PoolingLayer_get_type, (setter)pyopencv_dnn_PoolingLayer_set_type, (char*)"type", NULL},
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_dnn_PoolingLayer_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_dnn_PoolingLayer_specials(void)
{
    pyopencv_dnn_PoolingLayer_Type.tp_base = &pyopencv_dnn_Layer_Type;
    pyopencv_dnn_PoolingLayer_Type.tp_dealloc = pyopencv_dnn_PoolingLayer_dealloc;
    pyopencv_dnn_PoolingLayer_Type.tp_repr = pyopencv_dnn_PoolingLayer_repr;
    pyopencv_dnn_PoolingLayer_Type.tp_getset = pyopencv_dnn_PoolingLayer_getseters;
    pyopencv_dnn_PoolingLayer_Type.tp_methods = pyopencv_dnn_PoolingLayer_methods;
}

static PyObject* pyopencv_dnn_SoftmaxLayer_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<dnn_SoftmaxLayer %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_dnn_SoftmaxLayer_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_dnn_SoftmaxLayer_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_dnn_SoftmaxLayer_specials(void)
{
    pyopencv_dnn_SoftmaxLayer_Type.tp_base = &pyopencv_dnn_Layer_Type;
    pyopencv_dnn_SoftmaxLayer_Type.tp_dealloc = pyopencv_dnn_SoftmaxLayer_dealloc;
    pyopencv_dnn_SoftmaxLayer_Type.tp_repr = pyopencv_dnn_SoftmaxLayer_repr;
    pyopencv_dnn_SoftmaxLayer_Type.tp_getset = pyopencv_dnn_SoftmaxLayer_getseters;
    pyopencv_dnn_SoftmaxLayer_Type.tp_methods = pyopencv_dnn_SoftmaxLayer_methods;
}

static PyObject* pyopencv_dnn_InnerProductLayer_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<dnn_InnerProductLayer %p>", self);
    return PyString_FromString(str);
}


static PyObject* pyopencv_dnn_InnerProductLayer_get_axis(pyopencv_dnn_InnerProductLayer_t* p, void *closure)
{
    return pyopencv_from(p->v->axis);
}

static int pyopencv_dnn_InnerProductLayer_set_axis(pyopencv_dnn_InnerProductLayer_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the axis attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->axis) ? 0 : -1;
}


static PyGetSetDef pyopencv_dnn_InnerProductLayer_getseters[] =
{
    {(char*)"axis", (getter)pyopencv_dnn_InnerProductLayer_get_axis, (setter)pyopencv_dnn_InnerProductLayer_set_axis, (char*)"axis", NULL},
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_dnn_InnerProductLayer_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_dnn_InnerProductLayer_specials(void)
{
    pyopencv_dnn_InnerProductLayer_Type.tp_base = &pyopencv_dnn_Layer_Type;
    pyopencv_dnn_InnerProductLayer_Type.tp_dealloc = pyopencv_dnn_InnerProductLayer_dealloc;
    pyopencv_dnn_InnerProductLayer_Type.tp_repr = pyopencv_dnn_InnerProductLayer_repr;
    pyopencv_dnn_InnerProductLayer_Type.tp_getset = pyopencv_dnn_InnerProductLayer_getseters;
    pyopencv_dnn_InnerProductLayer_Type.tp_methods = pyopencv_dnn_InnerProductLayer_methods;
}

static PyObject* pyopencv_dnn_MVNLayer_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<dnn_MVNLayer %p>", self);
    return PyString_FromString(str);
}


static PyObject* pyopencv_dnn_MVNLayer_get_acrossChannels(pyopencv_dnn_MVNLayer_t* p, void *closure)
{
    return pyopencv_from(p->v->acrossChannels);
}

static int pyopencv_dnn_MVNLayer_set_acrossChannels(pyopencv_dnn_MVNLayer_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the acrossChannels attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->acrossChannels) ? 0 : -1;
}

static PyObject* pyopencv_dnn_MVNLayer_get_eps(pyopencv_dnn_MVNLayer_t* p, void *closure)
{
    return pyopencv_from(p->v->eps);
}

static int pyopencv_dnn_MVNLayer_set_eps(pyopencv_dnn_MVNLayer_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the eps attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->eps) ? 0 : -1;
}

static PyObject* pyopencv_dnn_MVNLayer_get_normVariance(pyopencv_dnn_MVNLayer_t* p, void *closure)
{
    return pyopencv_from(p->v->normVariance);
}

static int pyopencv_dnn_MVNLayer_set_normVariance(pyopencv_dnn_MVNLayer_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the normVariance attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->normVariance) ? 0 : -1;
}


static PyGetSetDef pyopencv_dnn_MVNLayer_getseters[] =
{
    {(char*)"acrossChannels", (getter)pyopencv_dnn_MVNLayer_get_acrossChannels, (setter)pyopencv_dnn_MVNLayer_set_acrossChannels, (char*)"acrossChannels", NULL},
    {(char*)"eps", (getter)pyopencv_dnn_MVNLayer_get_eps, (setter)pyopencv_dnn_MVNLayer_set_eps, (char*)"eps", NULL},
    {(char*)"normVariance", (getter)pyopencv_dnn_MVNLayer_get_normVariance, (setter)pyopencv_dnn_MVNLayer_set_normVariance, (char*)"normVariance", NULL},
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_dnn_MVNLayer_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_dnn_MVNLayer_specials(void)
{
    pyopencv_dnn_MVNLayer_Type.tp_base = &pyopencv_dnn_Layer_Type;
    pyopencv_dnn_MVNLayer_Type.tp_dealloc = pyopencv_dnn_MVNLayer_dealloc;
    pyopencv_dnn_MVNLayer_Type.tp_repr = pyopencv_dnn_MVNLayer_repr;
    pyopencv_dnn_MVNLayer_Type.tp_getset = pyopencv_dnn_MVNLayer_getseters;
    pyopencv_dnn_MVNLayer_Type.tp_methods = pyopencv_dnn_MVNLayer_methods;
}

static PyObject* pyopencv_dnn_ReshapeLayer_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<dnn_ReshapeLayer %p>", self);
    return PyString_FromString(str);
}


static PyObject* pyopencv_dnn_ReshapeLayer_get_newShapeDesc(pyopencv_dnn_ReshapeLayer_t* p, void *closure)
{
    return pyopencv_from(p->v->newShapeDesc);
}

static int pyopencv_dnn_ReshapeLayer_set_newShapeDesc(pyopencv_dnn_ReshapeLayer_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the newShapeDesc attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->newShapeDesc) ? 0 : -1;
}

static PyObject* pyopencv_dnn_ReshapeLayer_get_newShapeRange(pyopencv_dnn_ReshapeLayer_t* p, void *closure)
{
    return pyopencv_from(p->v->newShapeRange);
}

static int pyopencv_dnn_ReshapeLayer_set_newShapeRange(pyopencv_dnn_ReshapeLayer_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the newShapeRange attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->newShapeRange) ? 0 : -1;
}


static PyGetSetDef pyopencv_dnn_ReshapeLayer_getseters[] =
{
    {(char*)"newShapeDesc", (getter)pyopencv_dnn_ReshapeLayer_get_newShapeDesc, (setter)pyopencv_dnn_ReshapeLayer_set_newShapeDesc, (char*)"newShapeDesc", NULL},
    {(char*)"newShapeRange", (getter)pyopencv_dnn_ReshapeLayer_get_newShapeRange, (setter)pyopencv_dnn_ReshapeLayer_set_newShapeRange, (char*)"newShapeRange", NULL},
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_dnn_ReshapeLayer_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_dnn_ReshapeLayer_specials(void)
{
    pyopencv_dnn_ReshapeLayer_Type.tp_base = &pyopencv_dnn_Layer_Type;
    pyopencv_dnn_ReshapeLayer_Type.tp_dealloc = pyopencv_dnn_ReshapeLayer_dealloc;
    pyopencv_dnn_ReshapeLayer_Type.tp_repr = pyopencv_dnn_ReshapeLayer_repr;
    pyopencv_dnn_ReshapeLayer_Type.tp_getset = pyopencv_dnn_ReshapeLayer_getseters;
    pyopencv_dnn_ReshapeLayer_Type.tp_methods = pyopencv_dnn_ReshapeLayer_methods;
}

static PyObject* pyopencv_dnn_ConcatLayer_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<dnn_ConcatLayer %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_dnn_ConcatLayer_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_dnn_ConcatLayer_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_dnn_ConcatLayer_specials(void)
{
    pyopencv_dnn_ConcatLayer_Type.tp_base = &pyopencv_dnn_Layer_Type;
    pyopencv_dnn_ConcatLayer_Type.tp_dealloc = pyopencv_dnn_ConcatLayer_dealloc;
    pyopencv_dnn_ConcatLayer_Type.tp_repr = pyopencv_dnn_ConcatLayer_repr;
    pyopencv_dnn_ConcatLayer_Type.tp_getset = pyopencv_dnn_ConcatLayer_getseters;
    pyopencv_dnn_ConcatLayer_Type.tp_methods = pyopencv_dnn_ConcatLayer_methods;
}

static PyObject* pyopencv_dnn_SplitLayer_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<dnn_SplitLayer %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_dnn_SplitLayer_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_dnn_SplitLayer_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_dnn_SplitLayer_specials(void)
{
    pyopencv_dnn_SplitLayer_Type.tp_base = &pyopencv_dnn_Layer_Type;
    pyopencv_dnn_SplitLayer_Type.tp_dealloc = pyopencv_dnn_SplitLayer_dealloc;
    pyopencv_dnn_SplitLayer_Type.tp_repr = pyopencv_dnn_SplitLayer_repr;
    pyopencv_dnn_SplitLayer_Type.tp_getset = pyopencv_dnn_SplitLayer_getseters;
    pyopencv_dnn_SplitLayer_Type.tp_methods = pyopencv_dnn_SplitLayer_methods;
}

static PyObject* pyopencv_dnn_SliceLayer_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<dnn_SliceLayer %p>", self);
    return PyString_FromString(str);
}


static PyObject* pyopencv_dnn_SliceLayer_get_axis(pyopencv_dnn_SliceLayer_t* p, void *closure)
{
    return pyopencv_from(p->v->axis);
}

static int pyopencv_dnn_SliceLayer_set_axis(pyopencv_dnn_SliceLayer_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the axis attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->axis) ? 0 : -1;
}

static PyObject* pyopencv_dnn_SliceLayer_get_sliceIndices(pyopencv_dnn_SliceLayer_t* p, void *closure)
{
    return pyopencv_from(p->v->sliceIndices);
}


static PyGetSetDef pyopencv_dnn_SliceLayer_getseters[] =
{
    {(char*)"axis", (getter)pyopencv_dnn_SliceLayer_get_axis, (setter)pyopencv_dnn_SliceLayer_set_axis, (char*)"axis", NULL},
    {(char*)"sliceIndices", (getter)pyopencv_dnn_SliceLayer_get_sliceIndices, NULL, (char*)"sliceIndices", NULL},
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_dnn_SliceLayer_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_dnn_SliceLayer_specials(void)
{
    pyopencv_dnn_SliceLayer_Type.tp_base = &pyopencv_dnn_Layer_Type;
    pyopencv_dnn_SliceLayer_Type.tp_dealloc = pyopencv_dnn_SliceLayer_dealloc;
    pyopencv_dnn_SliceLayer_Type.tp_repr = pyopencv_dnn_SliceLayer_repr;
    pyopencv_dnn_SliceLayer_Type.tp_getset = pyopencv_dnn_SliceLayer_getseters;
    pyopencv_dnn_SliceLayer_Type.tp_methods = pyopencv_dnn_SliceLayer_methods;
}

static PyObject* pyopencv_dnn_ReLULayer_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<dnn_ReLULayer %p>", self);
    return PyString_FromString(str);
}


static PyObject* pyopencv_dnn_ReLULayer_get_negativeSlope(pyopencv_dnn_ReLULayer_t* p, void *closure)
{
    return pyopencv_from(p->v->negativeSlope);
}

static int pyopencv_dnn_ReLULayer_set_negativeSlope(pyopencv_dnn_ReLULayer_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the negativeSlope attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->negativeSlope) ? 0 : -1;
}


static PyGetSetDef pyopencv_dnn_ReLULayer_getseters[] =
{
    {(char*)"negativeSlope", (getter)pyopencv_dnn_ReLULayer_get_negativeSlope, (setter)pyopencv_dnn_ReLULayer_set_negativeSlope, (char*)"negativeSlope", NULL},
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_dnn_ReLULayer_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_dnn_ReLULayer_specials(void)
{
    pyopencv_dnn_ReLULayer_Type.tp_base = &pyopencv_dnn_Layer_Type;
    pyopencv_dnn_ReLULayer_Type.tp_dealloc = pyopencv_dnn_ReLULayer_dealloc;
    pyopencv_dnn_ReLULayer_Type.tp_repr = pyopencv_dnn_ReLULayer_repr;
    pyopencv_dnn_ReLULayer_Type.tp_getset = pyopencv_dnn_ReLULayer_getseters;
    pyopencv_dnn_ReLULayer_Type.tp_methods = pyopencv_dnn_ReLULayer_methods;
}

static PyObject* pyopencv_dnn_ChannelsPReLULayer_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<dnn_ChannelsPReLULayer %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_dnn_ChannelsPReLULayer_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_dnn_ChannelsPReLULayer_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_dnn_ChannelsPReLULayer_specials(void)
{
    pyopencv_dnn_ChannelsPReLULayer_Type.tp_base = &pyopencv_dnn_Layer_Type;
    pyopencv_dnn_ChannelsPReLULayer_Type.tp_dealloc = pyopencv_dnn_ChannelsPReLULayer_dealloc;
    pyopencv_dnn_ChannelsPReLULayer_Type.tp_repr = pyopencv_dnn_ChannelsPReLULayer_repr;
    pyopencv_dnn_ChannelsPReLULayer_Type.tp_getset = pyopencv_dnn_ChannelsPReLULayer_getseters;
    pyopencv_dnn_ChannelsPReLULayer_Type.tp_methods = pyopencv_dnn_ChannelsPReLULayer_methods;
}

static PyObject* pyopencv_dnn_TanHLayer_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<dnn_TanHLayer %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_dnn_TanHLayer_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_dnn_TanHLayer_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_dnn_TanHLayer_specials(void)
{
    pyopencv_dnn_TanHLayer_Type.tp_base = &pyopencv_dnn_Layer_Type;
    pyopencv_dnn_TanHLayer_Type.tp_dealloc = pyopencv_dnn_TanHLayer_dealloc;
    pyopencv_dnn_TanHLayer_Type.tp_repr = pyopencv_dnn_TanHLayer_repr;
    pyopencv_dnn_TanHLayer_Type.tp_getset = pyopencv_dnn_TanHLayer_getseters;
    pyopencv_dnn_TanHLayer_Type.tp_methods = pyopencv_dnn_TanHLayer_methods;
}

static PyObject* pyopencv_dnn_SigmoidLayer_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<dnn_SigmoidLayer %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_dnn_SigmoidLayer_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_dnn_SigmoidLayer_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_dnn_SigmoidLayer_specials(void)
{
    pyopencv_dnn_SigmoidLayer_Type.tp_base = &pyopencv_dnn_Layer_Type;
    pyopencv_dnn_SigmoidLayer_Type.tp_dealloc = pyopencv_dnn_SigmoidLayer_dealloc;
    pyopencv_dnn_SigmoidLayer_Type.tp_repr = pyopencv_dnn_SigmoidLayer_repr;
    pyopencv_dnn_SigmoidLayer_Type.tp_getset = pyopencv_dnn_SigmoidLayer_getseters;
    pyopencv_dnn_SigmoidLayer_Type.tp_methods = pyopencv_dnn_SigmoidLayer_methods;
}

static PyObject* pyopencv_dnn_BNLLLayer_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<dnn_BNLLLayer %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_dnn_BNLLLayer_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_dnn_BNLLLayer_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_dnn_BNLLLayer_specials(void)
{
    pyopencv_dnn_BNLLLayer_Type.tp_base = &pyopencv_dnn_Layer_Type;
    pyopencv_dnn_BNLLLayer_Type.tp_dealloc = pyopencv_dnn_BNLLLayer_dealloc;
    pyopencv_dnn_BNLLLayer_Type.tp_repr = pyopencv_dnn_BNLLLayer_repr;
    pyopencv_dnn_BNLLLayer_Type.tp_getset = pyopencv_dnn_BNLLLayer_getseters;
    pyopencv_dnn_BNLLLayer_Type.tp_methods = pyopencv_dnn_BNLLLayer_methods;
}

static PyObject* pyopencv_dnn_AbsLayer_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<dnn_AbsLayer %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_dnn_AbsLayer_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_dnn_AbsLayer_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_dnn_AbsLayer_specials(void)
{
    pyopencv_dnn_AbsLayer_Type.tp_base = &pyopencv_dnn_Layer_Type;
    pyopencv_dnn_AbsLayer_Type.tp_dealloc = pyopencv_dnn_AbsLayer_dealloc;
    pyopencv_dnn_AbsLayer_Type.tp_repr = pyopencv_dnn_AbsLayer_repr;
    pyopencv_dnn_AbsLayer_Type.tp_getset = pyopencv_dnn_AbsLayer_getseters;
    pyopencv_dnn_AbsLayer_Type.tp_methods = pyopencv_dnn_AbsLayer_methods;
}

static PyObject* pyopencv_dnn_PowerLayer_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<dnn_PowerLayer %p>", self);
    return PyString_FromString(str);
}


static PyObject* pyopencv_dnn_PowerLayer_get_power(pyopencv_dnn_PowerLayer_t* p, void *closure)
{
    return pyopencv_from(p->v->power);
}

static int pyopencv_dnn_PowerLayer_set_power(pyopencv_dnn_PowerLayer_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the power attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->power) ? 0 : -1;
}

static PyObject* pyopencv_dnn_PowerLayer_get_scale(pyopencv_dnn_PowerLayer_t* p, void *closure)
{
    return pyopencv_from(p->v->scale);
}

static int pyopencv_dnn_PowerLayer_set_scale(pyopencv_dnn_PowerLayer_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the scale attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->scale) ? 0 : -1;
}

static PyObject* pyopencv_dnn_PowerLayer_get_shift(pyopencv_dnn_PowerLayer_t* p, void *closure)
{
    return pyopencv_from(p->v->shift);
}

static int pyopencv_dnn_PowerLayer_set_shift(pyopencv_dnn_PowerLayer_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the shift attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->shift) ? 0 : -1;
}


static PyGetSetDef pyopencv_dnn_PowerLayer_getseters[] =
{
    {(char*)"power", (getter)pyopencv_dnn_PowerLayer_get_power, (setter)pyopencv_dnn_PowerLayer_set_power, (char*)"power", NULL},
    {(char*)"scale", (getter)pyopencv_dnn_PowerLayer_get_scale, (setter)pyopencv_dnn_PowerLayer_set_scale, (char*)"scale", NULL},
    {(char*)"shift", (getter)pyopencv_dnn_PowerLayer_get_shift, (setter)pyopencv_dnn_PowerLayer_set_shift, (char*)"shift", NULL},
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_dnn_PowerLayer_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_dnn_PowerLayer_specials(void)
{
    pyopencv_dnn_PowerLayer_Type.tp_base = &pyopencv_dnn_Layer_Type;
    pyopencv_dnn_PowerLayer_Type.tp_dealloc = pyopencv_dnn_PowerLayer_dealloc;
    pyopencv_dnn_PowerLayer_Type.tp_repr = pyopencv_dnn_PowerLayer_repr;
    pyopencv_dnn_PowerLayer_Type.tp_getset = pyopencv_dnn_PowerLayer_getseters;
    pyopencv_dnn_PowerLayer_Type.tp_methods = pyopencv_dnn_PowerLayer_methods;
}

static PyObject* pyopencv_dnn_CropLayer_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<dnn_CropLayer %p>", self);
    return PyString_FromString(str);
}


static PyObject* pyopencv_dnn_CropLayer_get_offset(pyopencv_dnn_CropLayer_t* p, void *closure)
{
    return pyopencv_from(p->v->offset);
}

static PyObject* pyopencv_dnn_CropLayer_get_startAxis(pyopencv_dnn_CropLayer_t* p, void *closure)
{
    return pyopencv_from(p->v->startAxis);
}


static PyGetSetDef pyopencv_dnn_CropLayer_getseters[] =
{
    {(char*)"offset", (getter)pyopencv_dnn_CropLayer_get_offset, NULL, (char*)"offset", NULL},
    {(char*)"startAxis", (getter)pyopencv_dnn_CropLayer_get_startAxis, NULL, (char*)"startAxis", NULL},
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_dnn_CropLayer_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_dnn_CropLayer_specials(void)
{
    pyopencv_dnn_CropLayer_Type.tp_base = &pyopencv_dnn_Layer_Type;
    pyopencv_dnn_CropLayer_Type.tp_dealloc = pyopencv_dnn_CropLayer_dealloc;
    pyopencv_dnn_CropLayer_Type.tp_repr = pyopencv_dnn_CropLayer_repr;
    pyopencv_dnn_CropLayer_Type.tp_getset = pyopencv_dnn_CropLayer_getseters;
    pyopencv_dnn_CropLayer_Type.tp_methods = pyopencv_dnn_CropLayer_methods;
}

static PyObject* pyopencv_dnn_EltwiseLayer_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<dnn_EltwiseLayer %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_dnn_EltwiseLayer_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_dnn_EltwiseLayer_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_dnn_EltwiseLayer_specials(void)
{
    pyopencv_dnn_EltwiseLayer_Type.tp_base = &pyopencv_dnn_Layer_Type;
    pyopencv_dnn_EltwiseLayer_Type.tp_dealloc = pyopencv_dnn_EltwiseLayer_dealloc;
    pyopencv_dnn_EltwiseLayer_Type.tp_repr = pyopencv_dnn_EltwiseLayer_repr;
    pyopencv_dnn_EltwiseLayer_Type.tp_getset = pyopencv_dnn_EltwiseLayer_getseters;
    pyopencv_dnn_EltwiseLayer_Type.tp_methods = pyopencv_dnn_EltwiseLayer_methods;
}

static PyObject* pyopencv_dnn_BatchNormLayer_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<dnn_BatchNormLayer %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_dnn_BatchNormLayer_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_dnn_BatchNormLayer_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_dnn_BatchNormLayer_specials(void)
{
    pyopencv_dnn_BatchNormLayer_Type.tp_base = &pyopencv_dnn_Layer_Type;
    pyopencv_dnn_BatchNormLayer_Type.tp_dealloc = pyopencv_dnn_BatchNormLayer_dealloc;
    pyopencv_dnn_BatchNormLayer_Type.tp_repr = pyopencv_dnn_BatchNormLayer_repr;
    pyopencv_dnn_BatchNormLayer_Type.tp_getset = pyopencv_dnn_BatchNormLayer_getseters;
    pyopencv_dnn_BatchNormLayer_Type.tp_methods = pyopencv_dnn_BatchNormLayer_methods;
}

static PyObject* pyopencv_dnn_MaxUnpoolLayer_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<dnn_MaxUnpoolLayer %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_dnn_MaxUnpoolLayer_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_dnn_MaxUnpoolLayer_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_dnn_MaxUnpoolLayer_specials(void)
{
    pyopencv_dnn_MaxUnpoolLayer_Type.tp_base = &pyopencv_dnn_Layer_Type;
    pyopencv_dnn_MaxUnpoolLayer_Type.tp_dealloc = pyopencv_dnn_MaxUnpoolLayer_dealloc;
    pyopencv_dnn_MaxUnpoolLayer_Type.tp_repr = pyopencv_dnn_MaxUnpoolLayer_repr;
    pyopencv_dnn_MaxUnpoolLayer_Type.tp_getset = pyopencv_dnn_MaxUnpoolLayer_getseters;
    pyopencv_dnn_MaxUnpoolLayer_Type.tp_methods = pyopencv_dnn_MaxUnpoolLayer_methods;
}

static PyObject* pyopencv_dnn_ScaleLayer_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<dnn_ScaleLayer %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_dnn_ScaleLayer_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_dnn_ScaleLayer_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_dnn_ScaleLayer_specials(void)
{
    pyopencv_dnn_ScaleLayer_Type.tp_base = &pyopencv_dnn_Layer_Type;
    pyopencv_dnn_ScaleLayer_Type.tp_dealloc = pyopencv_dnn_ScaleLayer_dealloc;
    pyopencv_dnn_ScaleLayer_Type.tp_repr = pyopencv_dnn_ScaleLayer_repr;
    pyopencv_dnn_ScaleLayer_Type.tp_getset = pyopencv_dnn_ScaleLayer_getseters;
    pyopencv_dnn_ScaleLayer_Type.tp_methods = pyopencv_dnn_ScaleLayer_methods;
}

static PyObject* pyopencv_dnn_BlobShape_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<dnn_BlobShape %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_dnn_BlobShape_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_dnn_BlobShape_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_dnn_BlobShape_specials(void)
{
    pyopencv_dnn_BlobShape_Type.tp_base = NULL;
    pyopencv_dnn_BlobShape_Type.tp_dealloc = pyopencv_dnn_BlobShape_dealloc;
    pyopencv_dnn_BlobShape_Type.tp_repr = pyopencv_dnn_BlobShape_repr;
    pyopencv_dnn_BlobShape_Type.tp_getset = pyopencv_dnn_BlobShape_getseters;
    pyopencv_dnn_BlobShape_Type.tp_methods = pyopencv_dnn_BlobShape_methods;
}

static PyObject* pyopencv_dnn_Blob_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<dnn_Blob %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_dnn_Blob_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_dnn_Blob_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_dnn_Blob_specials(void)
{
    pyopencv_dnn_Blob_Type.tp_base = NULL;
    pyopencv_dnn_Blob_Type.tp_dealloc = pyopencv_dnn_Blob_dealloc;
    pyopencv_dnn_Blob_Type.tp_repr = pyopencv_dnn_Blob_repr;
    pyopencv_dnn_Blob_Type.tp_getset = pyopencv_dnn_Blob_getseters;
    pyopencv_dnn_Blob_Type.tp_methods = pyopencv_dnn_Blob_methods;
}

static PyObject* pyopencv_dnn_Layer_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<dnn_Layer %p>", self);
    return PyString_FromString(str);
}


static PyObject* pyopencv_dnn_Layer_get_blobs(pyopencv_dnn_Layer_t* p, void *closure)
{
    return pyopencv_from(p->v->blobs);
}

static int pyopencv_dnn_Layer_set_blobs(pyopencv_dnn_Layer_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the blobs attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->blobs) ? 0 : -1;
}

static PyObject* pyopencv_dnn_Layer_get_name(pyopencv_dnn_Layer_t* p, void *closure)
{
    return pyopencv_from(p->v->name);
}

static PyObject* pyopencv_dnn_Layer_get_type(pyopencv_dnn_Layer_t* p, void *closure)
{
    return pyopencv_from(p->v->type);
}


static PyGetSetDef pyopencv_dnn_Layer_getseters[] =
{
    {(char*)"blobs", (getter)pyopencv_dnn_Layer_get_blobs, (setter)pyopencv_dnn_Layer_set_blobs, (char*)"blobs", NULL},
    {(char*)"name", (getter)pyopencv_dnn_Layer_get_name, NULL, (char*)"name", NULL},
    {(char*)"type", (getter)pyopencv_dnn_Layer_get_type, NULL, (char*)"type", NULL},
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_dnn_dnn_Layer_allocate(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::dnn;

    if(!PyObject_TypeCheck(self, &pyopencv_dnn_Layer_Type))
        return failmsgp("Incorrect type of self (must be 'dnn_Layer' or its derivative)");
    cv::dnn::Layer* _self_ = ((pyopencv_dnn_Layer_t*)self)->v.get();
    {
    PyObject* pyobj_inputs = NULL;
    vector_Blob inputs;
    vector_Blob outputs;

    const char* keywords[] = { "inputs", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:dnn_Layer.allocate", (char**)keywords, &pyobj_inputs) &&
        pyopencv_to(pyobj_inputs, inputs, ArgInfo("inputs", 0)) )
    {
        ERRWRAP2(_self_->allocate(inputs, outputs));
        return pyopencv_from(outputs);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_inputs = NULL;
    vector_Blob inputs;
    std::vector<Blob> retval;

    const char* keywords[] = { "inputs", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:dnn_Layer.allocate", (char**)keywords, &pyobj_inputs) &&
        pyopencv_to(pyobj_inputs, inputs, ArgInfo("inputs", 0)) )
    {
        ERRWRAP2(retval = _self_->allocate(inputs));
        return pyopencv_from(retval);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_dnn_dnn_Layer_forward(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::dnn;

    if(!PyObject_TypeCheck(self, &pyopencv_dnn_Layer_Type))
        return failmsgp("Incorrect type of self (must be 'dnn_Layer' or its derivative)");
    cv::dnn::Layer* _self_ = ((pyopencv_dnn_Layer_t*)self)->v.get();
    PyObject* pyobj_inputs = NULL;
    vector_Blob inputs;
    PyObject* pyobj_outputs = NULL;
    vector_Blob outputs;

    const char* keywords[] = { "inputs", "outputs", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO:dnn_Layer.forward", (char**)keywords, &pyobj_inputs, &pyobj_outputs) &&
        pyopencv_to(pyobj_inputs, inputs, ArgInfo("inputs", 0)) &&
        pyopencv_to(pyobj_outputs, outputs, ArgInfo("outputs", 1)) )
    {
        ERRWRAP2(_self_->forward(inputs, outputs));
        return pyopencv_from(outputs);
    }

    return NULL;
}

static PyObject* pyopencv_cv_dnn_dnn_Layer_run(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::dnn;

    if(!PyObject_TypeCheck(self, &pyopencv_dnn_Layer_Type))
        return failmsgp("Incorrect type of self (must be 'dnn_Layer' or its derivative)");
    cv::dnn::Layer* _self_ = ((pyopencv_dnn_Layer_t*)self)->v.get();
    PyObject* pyobj_inputs = NULL;
    vector_Blob inputs;
    vector_Blob outputs;

    const char* keywords[] = { "inputs", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:dnn_Layer.run", (char**)keywords, &pyobj_inputs) &&
        pyopencv_to(pyobj_inputs, inputs, ArgInfo("inputs", 0)) )
    {
        ERRWRAP2(_self_->run(inputs, outputs));
        return pyopencv_from(outputs);
    }

    return NULL;
}



static PyMethodDef pyopencv_dnn_Layer_methods[] =
{
    {"allocate", (PyCFunction)pyopencv_cv_dnn_dnn_Layer_allocate, METH_VARARGS | METH_KEYWORDS, "allocate(inputs) -> outputs  or  allocate(inputs) -> retval"},
    {"forward", (PyCFunction)pyopencv_cv_dnn_dnn_Layer_forward, METH_VARARGS | METH_KEYWORDS, "forward(inputs, outputs) -> outputs"},
    {"run", (PyCFunction)pyopencv_cv_dnn_dnn_Layer_run, METH_VARARGS | METH_KEYWORDS, "run(inputs) -> outputs"},

    {NULL,          NULL}
};

static void pyopencv_dnn_Layer_specials(void)
{
    pyopencv_dnn_Layer_Type.tp_base = NULL;
    pyopencv_dnn_Layer_Type.tp_dealloc = pyopencv_dnn_Layer_dealloc;
    pyopencv_dnn_Layer_Type.tp_repr = pyopencv_dnn_Layer_repr;
    pyopencv_dnn_Layer_Type.tp_getset = pyopencv_dnn_Layer_getseters;
    pyopencv_dnn_Layer_Type.tp_methods = pyopencv_dnn_Layer_methods;
}

static PyObject* pyopencv_dnn_Net_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<dnn_Net %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_dnn_Net_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_dnn_dnn_Net_allocate(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::dnn;

    if(!PyObject_TypeCheck(self, &pyopencv_dnn_Net_Type))
        return failmsgp("Incorrect type of self (must be 'dnn_Net' or its derivative)");
    cv::dnn::Net* _self_ = &((pyopencv_dnn_Net_t*)self)->v;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(_self_->allocate());
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_dnn_dnn_Net_connect(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::dnn;

    if(!PyObject_TypeCheck(self, &pyopencv_dnn_Net_Type))
        return failmsgp("Incorrect type of self (must be 'dnn_Net' or its derivative)");
    cv::dnn::Net* _self_ = &((pyopencv_dnn_Net_t*)self)->v;
    PyObject* pyobj_outPin = NULL;
    String outPin;
    PyObject* pyobj_inpPin = NULL;
    String inpPin;

    const char* keywords[] = { "outPin", "inpPin", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO:dnn_Net.connect", (char**)keywords, &pyobj_outPin, &pyobj_inpPin) &&
        pyopencv_to(pyobj_outPin, outPin, ArgInfo("outPin", 0)) &&
        pyopencv_to(pyobj_inpPin, inpPin, ArgInfo("inpPin", 0)) )
    {
        ERRWRAP2(_self_->connect(outPin, inpPin));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_dnn_dnn_Net_deleteLayer(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::dnn;

    if(!PyObject_TypeCheck(self, &pyopencv_dnn_Net_Type))
        return failmsgp("Incorrect type of self (must be 'dnn_Net' or its derivative)");
    cv::dnn::Net* _self_ = &((pyopencv_dnn_Net_t*)self)->v;
    PyObject* pyobj_layer = NULL;
    LayerId layer;

    const char* keywords[] = { "layer", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:dnn_Net.deleteLayer", (char**)keywords, &pyobj_layer) &&
        pyopencv_to(pyobj_layer, layer, ArgInfo("layer", 0)) )
    {
        ERRWRAP2(_self_->deleteLayer(layer));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_dnn_dnn_Net_empty(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::dnn;

    if(!PyObject_TypeCheck(self, &pyopencv_dnn_Net_Type))
        return failmsgp("Incorrect type of self (must be 'dnn_Net' or its derivative)");
    cv::dnn::Net* _self_ = &((pyopencv_dnn_Net_t*)self)->v;
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->empty());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_dnn_dnn_Net_forward(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::dnn;

    if(!PyObject_TypeCheck(self, &pyopencv_dnn_Net_Type))
        return failmsgp("Incorrect type of self (must be 'dnn_Net' or its derivative)");
    cv::dnn::Net* _self_ = &((pyopencv_dnn_Net_t*)self)->v;
    PyObject* pyobj_toLayer = NULL;
    LayerId toLayer=String();

    const char* keywords[] = { "toLayer", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|O:dnn_Net.forward", (char**)keywords, &pyobj_toLayer) &&
        pyopencv_to(pyobj_toLayer, toLayer, ArgInfo("toLayer", 0)) )
    {
        ERRWRAP2(_self_->forward(toLayer));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_dnn_dnn_Net_getBlob(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::dnn;

    if(!PyObject_TypeCheck(self, &pyopencv_dnn_Net_Type))
        return failmsgp("Incorrect type of self (must be 'dnn_Net' or its derivative)");
    cv::dnn::Net* _self_ = &((pyopencv_dnn_Net_t*)self)->v;
    PyObject* pyobj_outputName = NULL;
    String outputName;
    Blob retval;

    const char* keywords[] = { "outputName", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:dnn_Net.getBlob", (char**)keywords, &pyobj_outputName) &&
        pyopencv_to(pyobj_outputName, outputName, ArgInfo("outputName", 0)) )
    {
        ERRWRAP2(retval = _self_->getBlob(outputName));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_dnn_dnn_Net_getLayer(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::dnn;

    if(!PyObject_TypeCheck(self, &pyopencv_dnn_Net_Type))
        return failmsgp("Incorrect type of self (must be 'dnn_Net' or its derivative)");
    cv::dnn::Net* _self_ = &((pyopencv_dnn_Net_t*)self)->v;
    PyObject* pyobj_layerId = NULL;
    LayerId layerId;
    Ptr<Layer> retval;

    const char* keywords[] = { "layerId", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:dnn_Net.getLayer", (char**)keywords, &pyobj_layerId) &&
        pyopencv_to(pyobj_layerId, layerId, ArgInfo("layerId", 0)) )
    {
        ERRWRAP2(retval = _self_->getLayer(layerId));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_dnn_dnn_Net_getLayerId(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::dnn;

    if(!PyObject_TypeCheck(self, &pyopencv_dnn_Net_Type))
        return failmsgp("Incorrect type of self (must be 'dnn_Net' or its derivative)");
    cv::dnn::Net* _self_ = &((pyopencv_dnn_Net_t*)self)->v;
    PyObject* pyobj_layer = NULL;
    String layer;
    int retval;

    const char* keywords[] = { "layer", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:dnn_Net.getLayerId", (char**)keywords, &pyobj_layer) &&
        pyopencv_to(pyobj_layer, layer, ArgInfo("layer", 0)) )
    {
        ERRWRAP2(retval = _self_->getLayerId(layer));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_dnn_dnn_Net_getLayerInputs(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::dnn;

    if(!PyObject_TypeCheck(self, &pyopencv_dnn_Net_Type))
        return failmsgp("Incorrect type of self (must be 'dnn_Net' or its derivative)");
    cv::dnn::Net* _self_ = &((pyopencv_dnn_Net_t*)self)->v;
    PyObject* pyobj_layerId = NULL;
    LayerId layerId;
    std::vector<Ptr<Layer> > retval;

    const char* keywords[] = { "layerId", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:dnn_Net.getLayerInputs", (char**)keywords, &pyobj_layerId) &&
        pyopencv_to(pyobj_layerId, layerId, ArgInfo("layerId", 0)) )
    {
        ERRWRAP2(retval = _self_->getLayerInputs(layerId));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_dnn_dnn_Net_getLayerNames(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::dnn;

    if(!PyObject_TypeCheck(self, &pyopencv_dnn_Net_Type))
        return failmsgp("Incorrect type of self (must be 'dnn_Net' or its derivative)");
    cv::dnn::Net* _self_ = &((pyopencv_dnn_Net_t*)self)->v;
    std::vector<String> retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getLayerNames());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_dnn_dnn_Net_getParam(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::dnn;

    if(!PyObject_TypeCheck(self, &pyopencv_dnn_Net_Type))
        return failmsgp("Incorrect type of self (must be 'dnn_Net' or its derivative)");
    cv::dnn::Net* _self_ = &((pyopencv_dnn_Net_t*)self)->v;
    PyObject* pyobj_layer = NULL;
    LayerId layer;
    int numParam=0;
    Blob retval;

    const char* keywords[] = { "layer", "numParam", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|i:dnn_Net.getParam", (char**)keywords, &pyobj_layer, &numParam) &&
        pyopencv_to(pyobj_layer, layer, ArgInfo("layer", 0)) )
    {
        ERRWRAP2(retval = _self_->getParam(layer, numParam));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_dnn_dnn_Net_getUnconnectedOutLayers(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::dnn;

    if(!PyObject_TypeCheck(self, &pyopencv_dnn_Net_Type))
        return failmsgp("Incorrect type of self (must be 'dnn_Net' or its derivative)");
    cv::dnn::Net* _self_ = &((pyopencv_dnn_Net_t*)self)->v;
    std::vector<int> retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getUnconnectedOutLayers());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_dnn_dnn_Net_setBlob(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::dnn;

    if(!PyObject_TypeCheck(self, &pyopencv_dnn_Net_Type))
        return failmsgp("Incorrect type of self (must be 'dnn_Net' or its derivative)");
    cv::dnn::Net* _self_ = &((pyopencv_dnn_Net_t*)self)->v;
    PyObject* pyobj_outputName = NULL;
    String outputName;
    PyObject* pyobj_blob = NULL;
    Blob blob;

    const char* keywords[] = { "outputName", "blob", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO:dnn_Net.setBlob", (char**)keywords, &pyobj_outputName, &pyobj_blob) &&
        pyopencv_to(pyobj_outputName, outputName, ArgInfo("outputName", 0)) &&
        pyopencv_to(pyobj_blob, blob, ArgInfo("blob", 0)) )
    {
        ERRWRAP2(_self_->setBlob(outputName, blob));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_dnn_dnn_Net_setNetInputs(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::dnn;

    if(!PyObject_TypeCheck(self, &pyopencv_dnn_Net_Type))
        return failmsgp("Incorrect type of self (must be 'dnn_Net' or its derivative)");
    cv::dnn::Net* _self_ = &((pyopencv_dnn_Net_t*)self)->v;
    PyObject* pyobj_inputBlobNames = NULL;
    vector_String inputBlobNames;

    const char* keywords[] = { "inputBlobNames", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:dnn_Net.setNetInputs", (char**)keywords, &pyobj_inputBlobNames) &&
        pyopencv_to(pyobj_inputBlobNames, inputBlobNames, ArgInfo("inputBlobNames", 0)) )
    {
        ERRWRAP2(_self_->setNetInputs(inputBlobNames));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_dnn_dnn_Net_setParam(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::dnn;

    if(!PyObject_TypeCheck(self, &pyopencv_dnn_Net_Type))
        return failmsgp("Incorrect type of self (must be 'dnn_Net' or its derivative)");
    cv::dnn::Net* _self_ = &((pyopencv_dnn_Net_t*)self)->v;
    PyObject* pyobj_layer = NULL;
    LayerId layer;
    int numParam=0;
    PyObject* pyobj_blob = NULL;
    Blob blob;

    const char* keywords[] = { "layer", "numParam", "blob", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OiO:dnn_Net.setParam", (char**)keywords, &pyobj_layer, &numParam, &pyobj_blob) &&
        pyopencv_to(pyobj_layer, layer, ArgInfo("layer", 0)) &&
        pyopencv_to(pyobj_blob, blob, ArgInfo("blob", 0)) )
    {
        ERRWRAP2(_self_->setParam(layer, numParam, blob));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_dnn_Net_methods[] =
{
    {"allocate", (PyCFunction)pyopencv_cv_dnn_dnn_Net_allocate, METH_VARARGS | METH_KEYWORDS, "allocate() -> None"},
    {"connect", (PyCFunction)pyopencv_cv_dnn_dnn_Net_connect, METH_VARARGS | METH_KEYWORDS, "connect(outPin, inpPin) -> None"},
    {"deleteLayer", (PyCFunction)pyopencv_cv_dnn_dnn_Net_deleteLayer, METH_VARARGS | METH_KEYWORDS, "deleteLayer(layer) -> None"},
    {"empty", (PyCFunction)pyopencv_cv_dnn_dnn_Net_empty, METH_VARARGS | METH_KEYWORDS, "empty() -> retval"},
    {"forward", (PyCFunction)pyopencv_cv_dnn_dnn_Net_forward, METH_VARARGS | METH_KEYWORDS, "forward([, toLayer]) -> None"},
    {"getBlob", (PyCFunction)pyopencv_cv_dnn_dnn_Net_getBlob, METH_VARARGS | METH_KEYWORDS, "getBlob(outputName) -> retval"},
    {"getLayer", (PyCFunction)pyopencv_cv_dnn_dnn_Net_getLayer, METH_VARARGS | METH_KEYWORDS, "getLayer(layerId) -> retval"},
    {"getLayerId", (PyCFunction)pyopencv_cv_dnn_dnn_Net_getLayerId, METH_VARARGS | METH_KEYWORDS, "getLayerId(layer) -> retval"},
    {"getLayerInputs", (PyCFunction)pyopencv_cv_dnn_dnn_Net_getLayerInputs, METH_VARARGS | METH_KEYWORDS, "getLayerInputs(layerId) -> retval"},
    {"getLayerNames", (PyCFunction)pyopencv_cv_dnn_dnn_Net_getLayerNames, METH_VARARGS | METH_KEYWORDS, "getLayerNames() -> retval"},
    {"getParam", (PyCFunction)pyopencv_cv_dnn_dnn_Net_getParam, METH_VARARGS | METH_KEYWORDS, "getParam(layer[, numParam]) -> retval"},
    {"getUnconnectedOutLayers", (PyCFunction)pyopencv_cv_dnn_dnn_Net_getUnconnectedOutLayers, METH_VARARGS | METH_KEYWORDS, "getUnconnectedOutLayers() -> retval"},
    {"setBlob", (PyCFunction)pyopencv_cv_dnn_dnn_Net_setBlob, METH_VARARGS | METH_KEYWORDS, "setBlob(outputName, blob) -> None"},
    {"setNetInputs", (PyCFunction)pyopencv_cv_dnn_dnn_Net_setNetInputs, METH_VARARGS | METH_KEYWORDS, "setNetInputs(inputBlobNames) -> None"},
    {"setParam", (PyCFunction)pyopencv_cv_dnn_dnn_Net_setParam, METH_VARARGS | METH_KEYWORDS, "setParam(layer, numParam, blob) -> None"},

    {NULL,          NULL}
};

static void pyopencv_dnn_Net_specials(void)
{
    pyopencv_dnn_Net_Type.tp_base = NULL;
    pyopencv_dnn_Net_Type.tp_dealloc = pyopencv_dnn_Net_dealloc;
    pyopencv_dnn_Net_Type.tp_repr = pyopencv_dnn_Net_repr;
    pyopencv_dnn_Net_Type.tp_getset = pyopencv_dnn_Net_getseters;
    pyopencv_dnn_Net_Type.tp_methods = pyopencv_dnn_Net_methods;
}

static PyObject* pyopencv_dnn_Importer_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<dnn_Importer %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_dnn_Importer_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_dnn_dnn_Importer_populateNet(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::dnn;

    if(!PyObject_TypeCheck(self, &pyopencv_dnn_Importer_Type))
        return failmsgp("Incorrect type of self (must be 'dnn_Importer' or its derivative)");
    cv::dnn::Importer* _self_ = ((pyopencv_dnn_Importer_t*)self)->v.get();
    PyObject* pyobj_net = NULL;
    Net net;

    const char* keywords[] = { "net", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:dnn_Importer.populateNet", (char**)keywords, &pyobj_net) &&
        pyopencv_to(pyobj_net, net, ArgInfo("net", 0)) )
    {
        ERRWRAP2(_self_->populateNet(net));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_dnn_Importer_methods[] =
{
    {"populateNet", (PyCFunction)pyopencv_cv_dnn_dnn_Importer_populateNet, METH_VARARGS | METH_KEYWORDS, "populateNet(net) -> None"},

    {NULL,          NULL}
};

static void pyopencv_dnn_Importer_specials(void)
{
    pyopencv_dnn_Importer_Type.tp_base = NULL;
    pyopencv_dnn_Importer_Type.tp_dealloc = pyopencv_dnn_Importer_dealloc;
    pyopencv_dnn_Importer_Type.tp_repr = pyopencv_dnn_Importer_repr;
    pyopencv_dnn_Importer_Type.tp_getset = pyopencv_dnn_Importer_getseters;
    pyopencv_dnn_Importer_Type.tp_methods = pyopencv_dnn_Importer_methods;
}

static PyObject* pyopencv_HistogramCostExtractor_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<HistogramCostExtractor %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_HistogramCostExtractor_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_HistogramCostExtractor_buildCostMatrix(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_HistogramCostExtractor_Type))
        return failmsgp("Incorrect type of self (must be 'HistogramCostExtractor' or its derivative)");
    cv::HistogramCostExtractor* _self_ = dynamic_cast<cv::HistogramCostExtractor*>(((pyopencv_HistogramCostExtractor_t*)self)->v.get());
    {
    PyObject* pyobj_descriptors1 = NULL;
    Mat descriptors1;
    PyObject* pyobj_descriptors2 = NULL;
    Mat descriptors2;
    PyObject* pyobj_costMatrix = NULL;
    Mat costMatrix;

    const char* keywords[] = { "descriptors1", "descriptors2", "costMatrix", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|O:HistogramCostExtractor.buildCostMatrix", (char**)keywords, &pyobj_descriptors1, &pyobj_descriptors2, &pyobj_costMatrix) &&
        pyopencv_to(pyobj_descriptors1, descriptors1, ArgInfo("descriptors1", 0)) &&
        pyopencv_to(pyobj_descriptors2, descriptors2, ArgInfo("descriptors2", 0)) &&
        pyopencv_to(pyobj_costMatrix, costMatrix, ArgInfo("costMatrix", 1)) )
    {
        ERRWRAP2(_self_->buildCostMatrix(descriptors1, descriptors2, costMatrix));
        return pyopencv_from(costMatrix);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_descriptors1 = NULL;
    UMat descriptors1;
    PyObject* pyobj_descriptors2 = NULL;
    UMat descriptors2;
    PyObject* pyobj_costMatrix = NULL;
    UMat costMatrix;

    const char* keywords[] = { "descriptors1", "descriptors2", "costMatrix", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|O:HistogramCostExtractor.buildCostMatrix", (char**)keywords, &pyobj_descriptors1, &pyobj_descriptors2, &pyobj_costMatrix) &&
        pyopencv_to(pyobj_descriptors1, descriptors1, ArgInfo("descriptors1", 0)) &&
        pyopencv_to(pyobj_descriptors2, descriptors2, ArgInfo("descriptors2", 0)) &&
        pyopencv_to(pyobj_costMatrix, costMatrix, ArgInfo("costMatrix", 1)) )
    {
        ERRWRAP2(_self_->buildCostMatrix(descriptors1, descriptors2, costMatrix));
        return pyopencv_from(costMatrix);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_HistogramCostExtractor_getDefaultCost(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_HistogramCostExtractor_Type))
        return failmsgp("Incorrect type of self (must be 'HistogramCostExtractor' or its derivative)");
    cv::HistogramCostExtractor* _self_ = dynamic_cast<cv::HistogramCostExtractor*>(((pyopencv_HistogramCostExtractor_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getDefaultCost());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_HistogramCostExtractor_getNDummies(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_HistogramCostExtractor_Type))
        return failmsgp("Incorrect type of self (must be 'HistogramCostExtractor' or its derivative)");
    cv::HistogramCostExtractor* _self_ = dynamic_cast<cv::HistogramCostExtractor*>(((pyopencv_HistogramCostExtractor_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getNDummies());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_HistogramCostExtractor_setDefaultCost(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_HistogramCostExtractor_Type))
        return failmsgp("Incorrect type of self (must be 'HistogramCostExtractor' or its derivative)");
    cv::HistogramCostExtractor* _self_ = dynamic_cast<cv::HistogramCostExtractor*>(((pyopencv_HistogramCostExtractor_t*)self)->v.get());
    float defaultCost=0.f;

    const char* keywords[] = { "defaultCost", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:HistogramCostExtractor.setDefaultCost", (char**)keywords, &defaultCost) )
    {
        ERRWRAP2(_self_->setDefaultCost(defaultCost));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_HistogramCostExtractor_setNDummies(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_HistogramCostExtractor_Type))
        return failmsgp("Incorrect type of self (must be 'HistogramCostExtractor' or its derivative)");
    cv::HistogramCostExtractor* _self_ = dynamic_cast<cv::HistogramCostExtractor*>(((pyopencv_HistogramCostExtractor_t*)self)->v.get());
    int nDummies=0;

    const char* keywords[] = { "nDummies", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:HistogramCostExtractor.setNDummies", (char**)keywords, &nDummies) )
    {
        ERRWRAP2(_self_->setNDummies(nDummies));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_HistogramCostExtractor_methods[] =
{
    {"buildCostMatrix", (PyCFunction)pyopencv_cv_HistogramCostExtractor_buildCostMatrix, METH_VARARGS | METH_KEYWORDS, "buildCostMatrix(descriptors1, descriptors2[, costMatrix]) -> costMatrix"},
    {"getDefaultCost", (PyCFunction)pyopencv_cv_HistogramCostExtractor_getDefaultCost, METH_VARARGS | METH_KEYWORDS, "getDefaultCost() -> retval"},
    {"getNDummies", (PyCFunction)pyopencv_cv_HistogramCostExtractor_getNDummies, METH_VARARGS | METH_KEYWORDS, "getNDummies() -> retval"},
    {"setDefaultCost", (PyCFunction)pyopencv_cv_HistogramCostExtractor_setDefaultCost, METH_VARARGS | METH_KEYWORDS, "setDefaultCost(defaultCost) -> None"},
    {"setNDummies", (PyCFunction)pyopencv_cv_HistogramCostExtractor_setNDummies, METH_VARARGS | METH_KEYWORDS, "setNDummies(nDummies) -> None"},

    {NULL,          NULL}
};

static void pyopencv_HistogramCostExtractor_specials(void)
{
    pyopencv_HistogramCostExtractor_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_HistogramCostExtractor_Type.tp_dealloc = pyopencv_HistogramCostExtractor_dealloc;
    pyopencv_HistogramCostExtractor_Type.tp_repr = pyopencv_HistogramCostExtractor_repr;
    pyopencv_HistogramCostExtractor_Type.tp_getset = pyopencv_HistogramCostExtractor_getseters;
    pyopencv_HistogramCostExtractor_Type.tp_methods = pyopencv_HistogramCostExtractor_methods;
}

static PyObject* pyopencv_NormHistogramCostExtractor_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<NormHistogramCostExtractor %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_NormHistogramCostExtractor_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_NormHistogramCostExtractor_getNormFlag(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_NormHistogramCostExtractor_Type))
        return failmsgp("Incorrect type of self (must be 'NormHistogramCostExtractor' or its derivative)");
    cv::NormHistogramCostExtractor* _self_ = dynamic_cast<cv::NormHistogramCostExtractor*>(((pyopencv_NormHistogramCostExtractor_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getNormFlag());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_NormHistogramCostExtractor_setNormFlag(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_NormHistogramCostExtractor_Type))
        return failmsgp("Incorrect type of self (must be 'NormHistogramCostExtractor' or its derivative)");
    cv::NormHistogramCostExtractor* _self_ = dynamic_cast<cv::NormHistogramCostExtractor*>(((pyopencv_NormHistogramCostExtractor_t*)self)->v.get());
    int flag=0;

    const char* keywords[] = { "flag", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:NormHistogramCostExtractor.setNormFlag", (char**)keywords, &flag) )
    {
        ERRWRAP2(_self_->setNormFlag(flag));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_NormHistogramCostExtractor_methods[] =
{
    {"getNormFlag", (PyCFunction)pyopencv_cv_NormHistogramCostExtractor_getNormFlag, METH_VARARGS | METH_KEYWORDS, "getNormFlag() -> retval"},
    {"setNormFlag", (PyCFunction)pyopencv_cv_NormHistogramCostExtractor_setNormFlag, METH_VARARGS | METH_KEYWORDS, "setNormFlag(flag) -> None"},

    {NULL,          NULL}
};

static void pyopencv_NormHistogramCostExtractor_specials(void)
{
    pyopencv_NormHistogramCostExtractor_Type.tp_base = &pyopencv_HistogramCostExtractor_Type;
    pyopencv_NormHistogramCostExtractor_Type.tp_dealloc = pyopencv_NormHistogramCostExtractor_dealloc;
    pyopencv_NormHistogramCostExtractor_Type.tp_repr = pyopencv_NormHistogramCostExtractor_repr;
    pyopencv_NormHistogramCostExtractor_Type.tp_getset = pyopencv_NormHistogramCostExtractor_getseters;
    pyopencv_NormHistogramCostExtractor_Type.tp_methods = pyopencv_NormHistogramCostExtractor_methods;
}

static PyObject* pyopencv_EMDHistogramCostExtractor_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<EMDHistogramCostExtractor %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_EMDHistogramCostExtractor_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_EMDHistogramCostExtractor_getNormFlag(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_EMDHistogramCostExtractor_Type))
        return failmsgp("Incorrect type of self (must be 'EMDHistogramCostExtractor' or its derivative)");
    cv::EMDHistogramCostExtractor* _self_ = dynamic_cast<cv::EMDHistogramCostExtractor*>(((pyopencv_EMDHistogramCostExtractor_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getNormFlag());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_EMDHistogramCostExtractor_setNormFlag(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_EMDHistogramCostExtractor_Type))
        return failmsgp("Incorrect type of self (must be 'EMDHistogramCostExtractor' or its derivative)");
    cv::EMDHistogramCostExtractor* _self_ = dynamic_cast<cv::EMDHistogramCostExtractor*>(((pyopencv_EMDHistogramCostExtractor_t*)self)->v.get());
    int flag=0;

    const char* keywords[] = { "flag", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:EMDHistogramCostExtractor.setNormFlag", (char**)keywords, &flag) )
    {
        ERRWRAP2(_self_->setNormFlag(flag));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_EMDHistogramCostExtractor_methods[] =
{
    {"getNormFlag", (PyCFunction)pyopencv_cv_EMDHistogramCostExtractor_getNormFlag, METH_VARARGS | METH_KEYWORDS, "getNormFlag() -> retval"},
    {"setNormFlag", (PyCFunction)pyopencv_cv_EMDHistogramCostExtractor_setNormFlag, METH_VARARGS | METH_KEYWORDS, "setNormFlag(flag) -> None"},

    {NULL,          NULL}
};

static void pyopencv_EMDHistogramCostExtractor_specials(void)
{
    pyopencv_EMDHistogramCostExtractor_Type.tp_base = &pyopencv_HistogramCostExtractor_Type;
    pyopencv_EMDHistogramCostExtractor_Type.tp_dealloc = pyopencv_EMDHistogramCostExtractor_dealloc;
    pyopencv_EMDHistogramCostExtractor_Type.tp_repr = pyopencv_EMDHistogramCostExtractor_repr;
    pyopencv_EMDHistogramCostExtractor_Type.tp_getset = pyopencv_EMDHistogramCostExtractor_getseters;
    pyopencv_EMDHistogramCostExtractor_Type.tp_methods = pyopencv_EMDHistogramCostExtractor_methods;
}

static PyObject* pyopencv_ChiHistogramCostExtractor_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<ChiHistogramCostExtractor %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_ChiHistogramCostExtractor_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_ChiHistogramCostExtractor_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_ChiHistogramCostExtractor_specials(void)
{
    pyopencv_ChiHistogramCostExtractor_Type.tp_base = &pyopencv_HistogramCostExtractor_Type;
    pyopencv_ChiHistogramCostExtractor_Type.tp_dealloc = pyopencv_ChiHistogramCostExtractor_dealloc;
    pyopencv_ChiHistogramCostExtractor_Type.tp_repr = pyopencv_ChiHistogramCostExtractor_repr;
    pyopencv_ChiHistogramCostExtractor_Type.tp_getset = pyopencv_ChiHistogramCostExtractor_getseters;
    pyopencv_ChiHistogramCostExtractor_Type.tp_methods = pyopencv_ChiHistogramCostExtractor_methods;
}

static PyObject* pyopencv_EMDL1HistogramCostExtractor_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<EMDL1HistogramCostExtractor %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_EMDL1HistogramCostExtractor_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_EMDL1HistogramCostExtractor_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_EMDL1HistogramCostExtractor_specials(void)
{
    pyopencv_EMDL1HistogramCostExtractor_Type.tp_base = &pyopencv_HistogramCostExtractor_Type;
    pyopencv_EMDL1HistogramCostExtractor_Type.tp_dealloc = pyopencv_EMDL1HistogramCostExtractor_dealloc;
    pyopencv_EMDL1HistogramCostExtractor_Type.tp_repr = pyopencv_EMDL1HistogramCostExtractor_repr;
    pyopencv_EMDL1HistogramCostExtractor_Type.tp_getset = pyopencv_EMDL1HistogramCostExtractor_getseters;
    pyopencv_EMDL1HistogramCostExtractor_Type.tp_methods = pyopencv_EMDL1HistogramCostExtractor_methods;
}

static PyObject* pyopencv_ShapeDistanceExtractor_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<ShapeDistanceExtractor %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_ShapeDistanceExtractor_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_ShapeDistanceExtractor_computeDistance(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ShapeDistanceExtractor_Type))
        return failmsgp("Incorrect type of self (must be 'ShapeDistanceExtractor' or its derivative)");
    cv::ShapeDistanceExtractor* _self_ = dynamic_cast<cv::ShapeDistanceExtractor*>(((pyopencv_ShapeDistanceExtractor_t*)self)->v.get());
    {
    PyObject* pyobj_contour1 = NULL;
    Mat contour1;
    PyObject* pyobj_contour2 = NULL;
    Mat contour2;
    float retval;

    const char* keywords[] = { "contour1", "contour2", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO:ShapeDistanceExtractor.computeDistance", (char**)keywords, &pyobj_contour1, &pyobj_contour2) &&
        pyopencv_to(pyobj_contour1, contour1, ArgInfo("contour1", 0)) &&
        pyopencv_to(pyobj_contour2, contour2, ArgInfo("contour2", 0)) )
    {
        ERRWRAP2(retval = _self_->computeDistance(contour1, contour2));
        return pyopencv_from(retval);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_contour1 = NULL;
    UMat contour1;
    PyObject* pyobj_contour2 = NULL;
    UMat contour2;
    float retval;

    const char* keywords[] = { "contour1", "contour2", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO:ShapeDistanceExtractor.computeDistance", (char**)keywords, &pyobj_contour1, &pyobj_contour2) &&
        pyopencv_to(pyobj_contour1, contour1, ArgInfo("contour1", 0)) &&
        pyopencv_to(pyobj_contour2, contour2, ArgInfo("contour2", 0)) )
    {
        ERRWRAP2(retval = _self_->computeDistance(contour1, contour2));
        return pyopencv_from(retval);
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_ShapeDistanceExtractor_methods[] =
{
    {"computeDistance", (PyCFunction)pyopencv_cv_ShapeDistanceExtractor_computeDistance, METH_VARARGS | METH_KEYWORDS, "computeDistance(contour1, contour2) -> retval"},

    {NULL,          NULL}
};

static void pyopencv_ShapeDistanceExtractor_specials(void)
{
    pyopencv_ShapeDistanceExtractor_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_ShapeDistanceExtractor_Type.tp_dealloc = pyopencv_ShapeDistanceExtractor_dealloc;
    pyopencv_ShapeDistanceExtractor_Type.tp_repr = pyopencv_ShapeDistanceExtractor_repr;
    pyopencv_ShapeDistanceExtractor_Type.tp_getset = pyopencv_ShapeDistanceExtractor_getseters;
    pyopencv_ShapeDistanceExtractor_Type.tp_methods = pyopencv_ShapeDistanceExtractor_methods;
}

static PyObject* pyopencv_ShapeContextDistanceExtractor_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<ShapeContextDistanceExtractor %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_ShapeContextDistanceExtractor_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_ShapeContextDistanceExtractor_getAngularBins(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ShapeContextDistanceExtractor_Type))
        return failmsgp("Incorrect type of self (must be 'ShapeContextDistanceExtractor' or its derivative)");
    cv::ShapeContextDistanceExtractor* _self_ = dynamic_cast<cv::ShapeContextDistanceExtractor*>(((pyopencv_ShapeContextDistanceExtractor_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getAngularBins());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ShapeContextDistanceExtractor_getBendingEnergyWeight(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ShapeContextDistanceExtractor_Type))
        return failmsgp("Incorrect type of self (must be 'ShapeContextDistanceExtractor' or its derivative)");
    cv::ShapeContextDistanceExtractor* _self_ = dynamic_cast<cv::ShapeContextDistanceExtractor*>(((pyopencv_ShapeContextDistanceExtractor_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getBendingEnergyWeight());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ShapeContextDistanceExtractor_getCostExtractor(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ShapeContextDistanceExtractor_Type))
        return failmsgp("Incorrect type of self (must be 'ShapeContextDistanceExtractor' or its derivative)");
    cv::ShapeContextDistanceExtractor* _self_ = dynamic_cast<cv::ShapeContextDistanceExtractor*>(((pyopencv_ShapeContextDistanceExtractor_t*)self)->v.get());
    Ptr<HistogramCostExtractor> retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getCostExtractor());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ShapeContextDistanceExtractor_getImageAppearanceWeight(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ShapeContextDistanceExtractor_Type))
        return failmsgp("Incorrect type of self (must be 'ShapeContextDistanceExtractor' or its derivative)");
    cv::ShapeContextDistanceExtractor* _self_ = dynamic_cast<cv::ShapeContextDistanceExtractor*>(((pyopencv_ShapeContextDistanceExtractor_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getImageAppearanceWeight());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ShapeContextDistanceExtractor_getImages(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ShapeContextDistanceExtractor_Type))
        return failmsgp("Incorrect type of self (must be 'ShapeContextDistanceExtractor' or its derivative)");
    cv::ShapeContextDistanceExtractor* _self_ = dynamic_cast<cv::ShapeContextDistanceExtractor*>(((pyopencv_ShapeContextDistanceExtractor_t*)self)->v.get());
    {
    PyObject* pyobj_image1 = NULL;
    Mat image1;
    PyObject* pyobj_image2 = NULL;
    Mat image2;

    const char* keywords[] = { "image1", "image2", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|OO:ShapeContextDistanceExtractor.getImages", (char**)keywords, &pyobj_image1, &pyobj_image2) &&
        pyopencv_to(pyobj_image1, image1, ArgInfo("image1", 1)) &&
        pyopencv_to(pyobj_image2, image2, ArgInfo("image2", 1)) )
    {
        ERRWRAP2(_self_->getImages(image1, image2));
        return Py_BuildValue("(NN)", pyopencv_from(image1), pyopencv_from(image2));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_image1 = NULL;
    UMat image1;
    PyObject* pyobj_image2 = NULL;
    UMat image2;

    const char* keywords[] = { "image1", "image2", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|OO:ShapeContextDistanceExtractor.getImages", (char**)keywords, &pyobj_image1, &pyobj_image2) &&
        pyopencv_to(pyobj_image1, image1, ArgInfo("image1", 1)) &&
        pyopencv_to(pyobj_image2, image2, ArgInfo("image2", 1)) )
    {
        ERRWRAP2(_self_->getImages(image1, image2));
        return Py_BuildValue("(NN)", pyopencv_from(image1), pyopencv_from(image2));
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_ShapeContextDistanceExtractor_getInnerRadius(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ShapeContextDistanceExtractor_Type))
        return failmsgp("Incorrect type of self (must be 'ShapeContextDistanceExtractor' or its derivative)");
    cv::ShapeContextDistanceExtractor* _self_ = dynamic_cast<cv::ShapeContextDistanceExtractor*>(((pyopencv_ShapeContextDistanceExtractor_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getInnerRadius());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ShapeContextDistanceExtractor_getIterations(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ShapeContextDistanceExtractor_Type))
        return failmsgp("Incorrect type of self (must be 'ShapeContextDistanceExtractor' or its derivative)");
    cv::ShapeContextDistanceExtractor* _self_ = dynamic_cast<cv::ShapeContextDistanceExtractor*>(((pyopencv_ShapeContextDistanceExtractor_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getIterations());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ShapeContextDistanceExtractor_getOuterRadius(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ShapeContextDistanceExtractor_Type))
        return failmsgp("Incorrect type of self (must be 'ShapeContextDistanceExtractor' or its derivative)");
    cv::ShapeContextDistanceExtractor* _self_ = dynamic_cast<cv::ShapeContextDistanceExtractor*>(((pyopencv_ShapeContextDistanceExtractor_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getOuterRadius());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ShapeContextDistanceExtractor_getRadialBins(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ShapeContextDistanceExtractor_Type))
        return failmsgp("Incorrect type of self (must be 'ShapeContextDistanceExtractor' or its derivative)");
    cv::ShapeContextDistanceExtractor* _self_ = dynamic_cast<cv::ShapeContextDistanceExtractor*>(((pyopencv_ShapeContextDistanceExtractor_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getRadialBins());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ShapeContextDistanceExtractor_getRotationInvariant(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ShapeContextDistanceExtractor_Type))
        return failmsgp("Incorrect type of self (must be 'ShapeContextDistanceExtractor' or its derivative)");
    cv::ShapeContextDistanceExtractor* _self_ = dynamic_cast<cv::ShapeContextDistanceExtractor*>(((pyopencv_ShapeContextDistanceExtractor_t*)self)->v.get());
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getRotationInvariant());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ShapeContextDistanceExtractor_getShapeContextWeight(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ShapeContextDistanceExtractor_Type))
        return failmsgp("Incorrect type of self (must be 'ShapeContextDistanceExtractor' or its derivative)");
    cv::ShapeContextDistanceExtractor* _self_ = dynamic_cast<cv::ShapeContextDistanceExtractor*>(((pyopencv_ShapeContextDistanceExtractor_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getShapeContextWeight());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ShapeContextDistanceExtractor_getStdDev(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ShapeContextDistanceExtractor_Type))
        return failmsgp("Incorrect type of self (must be 'ShapeContextDistanceExtractor' or its derivative)");
    cv::ShapeContextDistanceExtractor* _self_ = dynamic_cast<cv::ShapeContextDistanceExtractor*>(((pyopencv_ShapeContextDistanceExtractor_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getStdDev());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ShapeContextDistanceExtractor_getTransformAlgorithm(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ShapeContextDistanceExtractor_Type))
        return failmsgp("Incorrect type of self (must be 'ShapeContextDistanceExtractor' or its derivative)");
    cv::ShapeContextDistanceExtractor* _self_ = dynamic_cast<cv::ShapeContextDistanceExtractor*>(((pyopencv_ShapeContextDistanceExtractor_t*)self)->v.get());
    Ptr<ShapeTransformer> retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getTransformAlgorithm());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ShapeContextDistanceExtractor_setAngularBins(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ShapeContextDistanceExtractor_Type))
        return failmsgp("Incorrect type of self (must be 'ShapeContextDistanceExtractor' or its derivative)");
    cv::ShapeContextDistanceExtractor* _self_ = dynamic_cast<cv::ShapeContextDistanceExtractor*>(((pyopencv_ShapeContextDistanceExtractor_t*)self)->v.get());
    int nAngularBins=0;

    const char* keywords[] = { "nAngularBins", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:ShapeContextDistanceExtractor.setAngularBins", (char**)keywords, &nAngularBins) )
    {
        ERRWRAP2(_self_->setAngularBins(nAngularBins));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ShapeContextDistanceExtractor_setBendingEnergyWeight(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ShapeContextDistanceExtractor_Type))
        return failmsgp("Incorrect type of self (must be 'ShapeContextDistanceExtractor' or its derivative)");
    cv::ShapeContextDistanceExtractor* _self_ = dynamic_cast<cv::ShapeContextDistanceExtractor*>(((pyopencv_ShapeContextDistanceExtractor_t*)self)->v.get());
    float bendingEnergyWeight=0.f;

    const char* keywords[] = { "bendingEnergyWeight", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:ShapeContextDistanceExtractor.setBendingEnergyWeight", (char**)keywords, &bendingEnergyWeight) )
    {
        ERRWRAP2(_self_->setBendingEnergyWeight(bendingEnergyWeight));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ShapeContextDistanceExtractor_setCostExtractor(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ShapeContextDistanceExtractor_Type))
        return failmsgp("Incorrect type of self (must be 'ShapeContextDistanceExtractor' or its derivative)");
    cv::ShapeContextDistanceExtractor* _self_ = dynamic_cast<cv::ShapeContextDistanceExtractor*>(((pyopencv_ShapeContextDistanceExtractor_t*)self)->v.get());
    PyObject* pyobj_comparer = NULL;
    Ptr<HistogramCostExtractor> comparer;

    const char* keywords[] = { "comparer", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:ShapeContextDistanceExtractor.setCostExtractor", (char**)keywords, &pyobj_comparer) &&
        pyopencv_to(pyobj_comparer, comparer, ArgInfo("comparer", 0)) )
    {
        ERRWRAP2(_self_->setCostExtractor(comparer));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ShapeContextDistanceExtractor_setImageAppearanceWeight(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ShapeContextDistanceExtractor_Type))
        return failmsgp("Incorrect type of self (must be 'ShapeContextDistanceExtractor' or its derivative)");
    cv::ShapeContextDistanceExtractor* _self_ = dynamic_cast<cv::ShapeContextDistanceExtractor*>(((pyopencv_ShapeContextDistanceExtractor_t*)self)->v.get());
    float imageAppearanceWeight=0.f;

    const char* keywords[] = { "imageAppearanceWeight", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:ShapeContextDistanceExtractor.setImageAppearanceWeight", (char**)keywords, &imageAppearanceWeight) )
    {
        ERRWRAP2(_self_->setImageAppearanceWeight(imageAppearanceWeight));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ShapeContextDistanceExtractor_setImages(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ShapeContextDistanceExtractor_Type))
        return failmsgp("Incorrect type of self (must be 'ShapeContextDistanceExtractor' or its derivative)");
    cv::ShapeContextDistanceExtractor* _self_ = dynamic_cast<cv::ShapeContextDistanceExtractor*>(((pyopencv_ShapeContextDistanceExtractor_t*)self)->v.get());
    {
    PyObject* pyobj_image1 = NULL;
    Mat image1;
    PyObject* pyobj_image2 = NULL;
    Mat image2;

    const char* keywords[] = { "image1", "image2", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO:ShapeContextDistanceExtractor.setImages", (char**)keywords, &pyobj_image1, &pyobj_image2) &&
        pyopencv_to(pyobj_image1, image1, ArgInfo("image1", 0)) &&
        pyopencv_to(pyobj_image2, image2, ArgInfo("image2", 0)) )
    {
        ERRWRAP2(_self_->setImages(image1, image2));
        Py_RETURN_NONE;
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_image1 = NULL;
    UMat image1;
    PyObject* pyobj_image2 = NULL;
    UMat image2;

    const char* keywords[] = { "image1", "image2", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO:ShapeContextDistanceExtractor.setImages", (char**)keywords, &pyobj_image1, &pyobj_image2) &&
        pyopencv_to(pyobj_image1, image1, ArgInfo("image1", 0)) &&
        pyopencv_to(pyobj_image2, image2, ArgInfo("image2", 0)) )
    {
        ERRWRAP2(_self_->setImages(image1, image2));
        Py_RETURN_NONE;
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_ShapeContextDistanceExtractor_setInnerRadius(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ShapeContextDistanceExtractor_Type))
        return failmsgp("Incorrect type of self (must be 'ShapeContextDistanceExtractor' or its derivative)");
    cv::ShapeContextDistanceExtractor* _self_ = dynamic_cast<cv::ShapeContextDistanceExtractor*>(((pyopencv_ShapeContextDistanceExtractor_t*)self)->v.get());
    float innerRadius=0.f;

    const char* keywords[] = { "innerRadius", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:ShapeContextDistanceExtractor.setInnerRadius", (char**)keywords, &innerRadius) )
    {
        ERRWRAP2(_self_->setInnerRadius(innerRadius));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ShapeContextDistanceExtractor_setIterations(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ShapeContextDistanceExtractor_Type))
        return failmsgp("Incorrect type of self (must be 'ShapeContextDistanceExtractor' or its derivative)");
    cv::ShapeContextDistanceExtractor* _self_ = dynamic_cast<cv::ShapeContextDistanceExtractor*>(((pyopencv_ShapeContextDistanceExtractor_t*)self)->v.get());
    int iterations=0;

    const char* keywords[] = { "iterations", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:ShapeContextDistanceExtractor.setIterations", (char**)keywords, &iterations) )
    {
        ERRWRAP2(_self_->setIterations(iterations));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ShapeContextDistanceExtractor_setOuterRadius(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ShapeContextDistanceExtractor_Type))
        return failmsgp("Incorrect type of self (must be 'ShapeContextDistanceExtractor' or its derivative)");
    cv::ShapeContextDistanceExtractor* _self_ = dynamic_cast<cv::ShapeContextDistanceExtractor*>(((pyopencv_ShapeContextDistanceExtractor_t*)self)->v.get());
    float outerRadius=0.f;

    const char* keywords[] = { "outerRadius", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:ShapeContextDistanceExtractor.setOuterRadius", (char**)keywords, &outerRadius) )
    {
        ERRWRAP2(_self_->setOuterRadius(outerRadius));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ShapeContextDistanceExtractor_setRadialBins(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ShapeContextDistanceExtractor_Type))
        return failmsgp("Incorrect type of self (must be 'ShapeContextDistanceExtractor' or its derivative)");
    cv::ShapeContextDistanceExtractor* _self_ = dynamic_cast<cv::ShapeContextDistanceExtractor*>(((pyopencv_ShapeContextDistanceExtractor_t*)self)->v.get());
    int nRadialBins=0;

    const char* keywords[] = { "nRadialBins", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:ShapeContextDistanceExtractor.setRadialBins", (char**)keywords, &nRadialBins) )
    {
        ERRWRAP2(_self_->setRadialBins(nRadialBins));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ShapeContextDistanceExtractor_setRotationInvariant(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ShapeContextDistanceExtractor_Type))
        return failmsgp("Incorrect type of self (must be 'ShapeContextDistanceExtractor' or its derivative)");
    cv::ShapeContextDistanceExtractor* _self_ = dynamic_cast<cv::ShapeContextDistanceExtractor*>(((pyopencv_ShapeContextDistanceExtractor_t*)self)->v.get());
    bool rotationInvariant=0;

    const char* keywords[] = { "rotationInvariant", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "b:ShapeContextDistanceExtractor.setRotationInvariant", (char**)keywords, &rotationInvariant) )
    {
        ERRWRAP2(_self_->setRotationInvariant(rotationInvariant));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ShapeContextDistanceExtractor_setShapeContextWeight(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ShapeContextDistanceExtractor_Type))
        return failmsgp("Incorrect type of self (must be 'ShapeContextDistanceExtractor' or its derivative)");
    cv::ShapeContextDistanceExtractor* _self_ = dynamic_cast<cv::ShapeContextDistanceExtractor*>(((pyopencv_ShapeContextDistanceExtractor_t*)self)->v.get());
    float shapeContextWeight=0.f;

    const char* keywords[] = { "shapeContextWeight", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:ShapeContextDistanceExtractor.setShapeContextWeight", (char**)keywords, &shapeContextWeight) )
    {
        ERRWRAP2(_self_->setShapeContextWeight(shapeContextWeight));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ShapeContextDistanceExtractor_setStdDev(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ShapeContextDistanceExtractor_Type))
        return failmsgp("Incorrect type of self (must be 'ShapeContextDistanceExtractor' or its derivative)");
    cv::ShapeContextDistanceExtractor* _self_ = dynamic_cast<cv::ShapeContextDistanceExtractor*>(((pyopencv_ShapeContextDistanceExtractor_t*)self)->v.get());
    float sigma=0.f;

    const char* keywords[] = { "sigma", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:ShapeContextDistanceExtractor.setStdDev", (char**)keywords, &sigma) )
    {
        ERRWRAP2(_self_->setStdDev(sigma));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ShapeContextDistanceExtractor_setTransformAlgorithm(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ShapeContextDistanceExtractor_Type))
        return failmsgp("Incorrect type of self (must be 'ShapeContextDistanceExtractor' or its derivative)");
    cv::ShapeContextDistanceExtractor* _self_ = dynamic_cast<cv::ShapeContextDistanceExtractor*>(((pyopencv_ShapeContextDistanceExtractor_t*)self)->v.get());
    PyObject* pyobj_transformer = NULL;
    Ptr<ShapeTransformer> transformer;

    const char* keywords[] = { "transformer", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:ShapeContextDistanceExtractor.setTransformAlgorithm", (char**)keywords, &pyobj_transformer) &&
        pyopencv_to(pyobj_transformer, transformer, ArgInfo("transformer", 0)) )
    {
        ERRWRAP2(_self_->setTransformAlgorithm(transformer));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_ShapeContextDistanceExtractor_methods[] =
{
    {"getAngularBins", (PyCFunction)pyopencv_cv_ShapeContextDistanceExtractor_getAngularBins, METH_VARARGS | METH_KEYWORDS, "getAngularBins() -> retval"},
    {"getBendingEnergyWeight", (PyCFunction)pyopencv_cv_ShapeContextDistanceExtractor_getBendingEnergyWeight, METH_VARARGS | METH_KEYWORDS, "getBendingEnergyWeight() -> retval"},
    {"getCostExtractor", (PyCFunction)pyopencv_cv_ShapeContextDistanceExtractor_getCostExtractor, METH_VARARGS | METH_KEYWORDS, "getCostExtractor() -> retval"},
    {"getImageAppearanceWeight", (PyCFunction)pyopencv_cv_ShapeContextDistanceExtractor_getImageAppearanceWeight, METH_VARARGS | METH_KEYWORDS, "getImageAppearanceWeight() -> retval"},
    {"getImages", (PyCFunction)pyopencv_cv_ShapeContextDistanceExtractor_getImages, METH_VARARGS | METH_KEYWORDS, "getImages([, image1[, image2]]) -> image1, image2"},
    {"getInnerRadius", (PyCFunction)pyopencv_cv_ShapeContextDistanceExtractor_getInnerRadius, METH_VARARGS | METH_KEYWORDS, "getInnerRadius() -> retval"},
    {"getIterations", (PyCFunction)pyopencv_cv_ShapeContextDistanceExtractor_getIterations, METH_VARARGS | METH_KEYWORDS, "getIterations() -> retval"},
    {"getOuterRadius", (PyCFunction)pyopencv_cv_ShapeContextDistanceExtractor_getOuterRadius, METH_VARARGS | METH_KEYWORDS, "getOuterRadius() -> retval"},
    {"getRadialBins", (PyCFunction)pyopencv_cv_ShapeContextDistanceExtractor_getRadialBins, METH_VARARGS | METH_KEYWORDS, "getRadialBins() -> retval"},
    {"getRotationInvariant", (PyCFunction)pyopencv_cv_ShapeContextDistanceExtractor_getRotationInvariant, METH_VARARGS | METH_KEYWORDS, "getRotationInvariant() -> retval"},
    {"getShapeContextWeight", (PyCFunction)pyopencv_cv_ShapeContextDistanceExtractor_getShapeContextWeight, METH_VARARGS | METH_KEYWORDS, "getShapeContextWeight() -> retval"},
    {"getStdDev", (PyCFunction)pyopencv_cv_ShapeContextDistanceExtractor_getStdDev, METH_VARARGS | METH_KEYWORDS, "getStdDev() -> retval"},
    {"getTransformAlgorithm", (PyCFunction)pyopencv_cv_ShapeContextDistanceExtractor_getTransformAlgorithm, METH_VARARGS | METH_KEYWORDS, "getTransformAlgorithm() -> retval"},
    {"setAngularBins", (PyCFunction)pyopencv_cv_ShapeContextDistanceExtractor_setAngularBins, METH_VARARGS | METH_KEYWORDS, "setAngularBins(nAngularBins) -> None"},
    {"setBendingEnergyWeight", (PyCFunction)pyopencv_cv_ShapeContextDistanceExtractor_setBendingEnergyWeight, METH_VARARGS | METH_KEYWORDS, "setBendingEnergyWeight(bendingEnergyWeight) -> None"},
    {"setCostExtractor", (PyCFunction)pyopencv_cv_ShapeContextDistanceExtractor_setCostExtractor, METH_VARARGS | METH_KEYWORDS, "setCostExtractor(comparer) -> None"},
    {"setImageAppearanceWeight", (PyCFunction)pyopencv_cv_ShapeContextDistanceExtractor_setImageAppearanceWeight, METH_VARARGS | METH_KEYWORDS, "setImageAppearanceWeight(imageAppearanceWeight) -> None"},
    {"setImages", (PyCFunction)pyopencv_cv_ShapeContextDistanceExtractor_setImages, METH_VARARGS | METH_KEYWORDS, "setImages(image1, image2) -> None"},
    {"setInnerRadius", (PyCFunction)pyopencv_cv_ShapeContextDistanceExtractor_setInnerRadius, METH_VARARGS | METH_KEYWORDS, "setInnerRadius(innerRadius) -> None"},
    {"setIterations", (PyCFunction)pyopencv_cv_ShapeContextDistanceExtractor_setIterations, METH_VARARGS | METH_KEYWORDS, "setIterations(iterations) -> None"},
    {"setOuterRadius", (PyCFunction)pyopencv_cv_ShapeContextDistanceExtractor_setOuterRadius, METH_VARARGS | METH_KEYWORDS, "setOuterRadius(outerRadius) -> None"},
    {"setRadialBins", (PyCFunction)pyopencv_cv_ShapeContextDistanceExtractor_setRadialBins, METH_VARARGS | METH_KEYWORDS, "setRadialBins(nRadialBins) -> None"},
    {"setRotationInvariant", (PyCFunction)pyopencv_cv_ShapeContextDistanceExtractor_setRotationInvariant, METH_VARARGS | METH_KEYWORDS, "setRotationInvariant(rotationInvariant) -> None"},
    {"setShapeContextWeight", (PyCFunction)pyopencv_cv_ShapeContextDistanceExtractor_setShapeContextWeight, METH_VARARGS | METH_KEYWORDS, "setShapeContextWeight(shapeContextWeight) -> None"},
    {"setStdDev", (PyCFunction)pyopencv_cv_ShapeContextDistanceExtractor_setStdDev, METH_VARARGS | METH_KEYWORDS, "setStdDev(sigma) -> None"},
    {"setTransformAlgorithm", (PyCFunction)pyopencv_cv_ShapeContextDistanceExtractor_setTransformAlgorithm, METH_VARARGS | METH_KEYWORDS, "setTransformAlgorithm(transformer) -> None"},

    {NULL,          NULL}
};

static void pyopencv_ShapeContextDistanceExtractor_specials(void)
{
    pyopencv_ShapeContextDistanceExtractor_Type.tp_base = &pyopencv_ShapeDistanceExtractor_Type;
    pyopencv_ShapeContextDistanceExtractor_Type.tp_dealloc = pyopencv_ShapeContextDistanceExtractor_dealloc;
    pyopencv_ShapeContextDistanceExtractor_Type.tp_repr = pyopencv_ShapeContextDistanceExtractor_repr;
    pyopencv_ShapeContextDistanceExtractor_Type.tp_getset = pyopencv_ShapeContextDistanceExtractor_getseters;
    pyopencv_ShapeContextDistanceExtractor_Type.tp_methods = pyopencv_ShapeContextDistanceExtractor_methods;
}

static PyObject* pyopencv_HausdorffDistanceExtractor_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<HausdorffDistanceExtractor %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_HausdorffDistanceExtractor_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_HausdorffDistanceExtractor_getDistanceFlag(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_HausdorffDistanceExtractor_Type))
        return failmsgp("Incorrect type of self (must be 'HausdorffDistanceExtractor' or its derivative)");
    cv::HausdorffDistanceExtractor* _self_ = dynamic_cast<cv::HausdorffDistanceExtractor*>(((pyopencv_HausdorffDistanceExtractor_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getDistanceFlag());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_HausdorffDistanceExtractor_getRankProportion(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_HausdorffDistanceExtractor_Type))
        return failmsgp("Incorrect type of self (must be 'HausdorffDistanceExtractor' or its derivative)");
    cv::HausdorffDistanceExtractor* _self_ = dynamic_cast<cv::HausdorffDistanceExtractor*>(((pyopencv_HausdorffDistanceExtractor_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getRankProportion());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_HausdorffDistanceExtractor_setDistanceFlag(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_HausdorffDistanceExtractor_Type))
        return failmsgp("Incorrect type of self (must be 'HausdorffDistanceExtractor' or its derivative)");
    cv::HausdorffDistanceExtractor* _self_ = dynamic_cast<cv::HausdorffDistanceExtractor*>(((pyopencv_HausdorffDistanceExtractor_t*)self)->v.get());
    int distanceFlag=0;

    const char* keywords[] = { "distanceFlag", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:HausdorffDistanceExtractor.setDistanceFlag", (char**)keywords, &distanceFlag) )
    {
        ERRWRAP2(_self_->setDistanceFlag(distanceFlag));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_HausdorffDistanceExtractor_setRankProportion(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_HausdorffDistanceExtractor_Type))
        return failmsgp("Incorrect type of self (must be 'HausdorffDistanceExtractor' or its derivative)");
    cv::HausdorffDistanceExtractor* _self_ = dynamic_cast<cv::HausdorffDistanceExtractor*>(((pyopencv_HausdorffDistanceExtractor_t*)self)->v.get());
    float rankProportion=0.f;

    const char* keywords[] = { "rankProportion", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:HausdorffDistanceExtractor.setRankProportion", (char**)keywords, &rankProportion) )
    {
        ERRWRAP2(_self_->setRankProportion(rankProportion));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_HausdorffDistanceExtractor_methods[] =
{
    {"getDistanceFlag", (PyCFunction)pyopencv_cv_HausdorffDistanceExtractor_getDistanceFlag, METH_VARARGS | METH_KEYWORDS, "getDistanceFlag() -> retval"},
    {"getRankProportion", (PyCFunction)pyopencv_cv_HausdorffDistanceExtractor_getRankProportion, METH_VARARGS | METH_KEYWORDS, "getRankProportion() -> retval"},
    {"setDistanceFlag", (PyCFunction)pyopencv_cv_HausdorffDistanceExtractor_setDistanceFlag, METH_VARARGS | METH_KEYWORDS, "setDistanceFlag(distanceFlag) -> None"},
    {"setRankProportion", (PyCFunction)pyopencv_cv_HausdorffDistanceExtractor_setRankProportion, METH_VARARGS | METH_KEYWORDS, "setRankProportion(rankProportion) -> None"},

    {NULL,          NULL}
};

static void pyopencv_HausdorffDistanceExtractor_specials(void)
{
    pyopencv_HausdorffDistanceExtractor_Type.tp_base = &pyopencv_ShapeDistanceExtractor_Type;
    pyopencv_HausdorffDistanceExtractor_Type.tp_dealloc = pyopencv_HausdorffDistanceExtractor_dealloc;
    pyopencv_HausdorffDistanceExtractor_Type.tp_repr = pyopencv_HausdorffDistanceExtractor_repr;
    pyopencv_HausdorffDistanceExtractor_Type.tp_getset = pyopencv_HausdorffDistanceExtractor_getseters;
    pyopencv_HausdorffDistanceExtractor_Type.tp_methods = pyopencv_HausdorffDistanceExtractor_methods;
}

static PyObject* pyopencv_ShapeTransformer_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<ShapeTransformer %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_ShapeTransformer_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_ShapeTransformer_applyTransformation(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ShapeTransformer_Type))
        return failmsgp("Incorrect type of self (must be 'ShapeTransformer' or its derivative)");
    cv::ShapeTransformer* _self_ = dynamic_cast<cv::ShapeTransformer*>(((pyopencv_ShapeTransformer_t*)self)->v.get());
    {
    PyObject* pyobj_input = NULL;
    Mat input;
    PyObject* pyobj_output = NULL;
    Mat output;
    float retval;

    const char* keywords[] = { "input", "output", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:ShapeTransformer.applyTransformation", (char**)keywords, &pyobj_input, &pyobj_output) &&
        pyopencv_to(pyobj_input, input, ArgInfo("input", 0)) &&
        pyopencv_to(pyobj_output, output, ArgInfo("output", 1)) )
    {
        ERRWRAP2(retval = _self_->applyTransformation(input, output));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(output));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_input = NULL;
    UMat input;
    PyObject* pyobj_output = NULL;
    UMat output;
    float retval;

    const char* keywords[] = { "input", "output", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:ShapeTransformer.applyTransformation", (char**)keywords, &pyobj_input, &pyobj_output) &&
        pyopencv_to(pyobj_input, input, ArgInfo("input", 0)) &&
        pyopencv_to(pyobj_output, output, ArgInfo("output", 1)) )
    {
        ERRWRAP2(retval = _self_->applyTransformation(input, output));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(output));
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_ShapeTransformer_estimateTransformation(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ShapeTransformer_Type))
        return failmsgp("Incorrect type of self (must be 'ShapeTransformer' or its derivative)");
    cv::ShapeTransformer* _self_ = dynamic_cast<cv::ShapeTransformer*>(((pyopencv_ShapeTransformer_t*)self)->v.get());
    {
    PyObject* pyobj_transformingShape = NULL;
    Mat transformingShape;
    PyObject* pyobj_targetShape = NULL;
    Mat targetShape;
    PyObject* pyobj_matches = NULL;
    vector_DMatch matches;

    const char* keywords[] = { "transformingShape", "targetShape", "matches", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OOO:ShapeTransformer.estimateTransformation", (char**)keywords, &pyobj_transformingShape, &pyobj_targetShape, &pyobj_matches) &&
        pyopencv_to(pyobj_transformingShape, transformingShape, ArgInfo("transformingShape", 0)) &&
        pyopencv_to(pyobj_targetShape, targetShape, ArgInfo("targetShape", 0)) &&
        pyopencv_to(pyobj_matches, matches, ArgInfo("matches", 0)) )
    {
        ERRWRAP2(_self_->estimateTransformation(transformingShape, targetShape, matches));
        Py_RETURN_NONE;
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_transformingShape = NULL;
    UMat transformingShape;
    PyObject* pyobj_targetShape = NULL;
    UMat targetShape;
    PyObject* pyobj_matches = NULL;
    vector_DMatch matches;

    const char* keywords[] = { "transformingShape", "targetShape", "matches", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OOO:ShapeTransformer.estimateTransformation", (char**)keywords, &pyobj_transformingShape, &pyobj_targetShape, &pyobj_matches) &&
        pyopencv_to(pyobj_transformingShape, transformingShape, ArgInfo("transformingShape", 0)) &&
        pyopencv_to(pyobj_targetShape, targetShape, ArgInfo("targetShape", 0)) &&
        pyopencv_to(pyobj_matches, matches, ArgInfo("matches", 0)) )
    {
        ERRWRAP2(_self_->estimateTransformation(transformingShape, targetShape, matches));
        Py_RETURN_NONE;
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_ShapeTransformer_warpImage(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ShapeTransformer_Type))
        return failmsgp("Incorrect type of self (must be 'ShapeTransformer' or its derivative)");
    cv::ShapeTransformer* _self_ = dynamic_cast<cv::ShapeTransformer*>(((pyopencv_ShapeTransformer_t*)self)->v.get());
    {
    PyObject* pyobj_transformingImage = NULL;
    Mat transformingImage;
    PyObject* pyobj_output = NULL;
    Mat output;
    int flags=INTER_LINEAR;
    int borderMode=BORDER_CONSTANT;
    PyObject* pyobj_borderValue = NULL;
    Scalar borderValue;

    const char* keywords[] = { "transformingImage", "output", "flags", "borderMode", "borderValue", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|OiiO:ShapeTransformer.warpImage", (char**)keywords, &pyobj_transformingImage, &pyobj_output, &flags, &borderMode, &pyobj_borderValue) &&
        pyopencv_to(pyobj_transformingImage, transformingImage, ArgInfo("transformingImage", 0)) &&
        pyopencv_to(pyobj_output, output, ArgInfo("output", 1)) &&
        pyopencv_to(pyobj_borderValue, borderValue, ArgInfo("borderValue", 0)) )
    {
        ERRWRAP2(_self_->warpImage(transformingImage, output, flags, borderMode, borderValue));
        return pyopencv_from(output);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_transformingImage = NULL;
    UMat transformingImage;
    PyObject* pyobj_output = NULL;
    UMat output;
    int flags=INTER_LINEAR;
    int borderMode=BORDER_CONSTANT;
    PyObject* pyobj_borderValue = NULL;
    Scalar borderValue;

    const char* keywords[] = { "transformingImage", "output", "flags", "borderMode", "borderValue", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|OiiO:ShapeTransformer.warpImage", (char**)keywords, &pyobj_transformingImage, &pyobj_output, &flags, &borderMode, &pyobj_borderValue) &&
        pyopencv_to(pyobj_transformingImage, transformingImage, ArgInfo("transformingImage", 0)) &&
        pyopencv_to(pyobj_output, output, ArgInfo("output", 1)) &&
        pyopencv_to(pyobj_borderValue, borderValue, ArgInfo("borderValue", 0)) )
    {
        ERRWRAP2(_self_->warpImage(transformingImage, output, flags, borderMode, borderValue));
        return pyopencv_from(output);
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_ShapeTransformer_methods[] =
{
    {"applyTransformation", (PyCFunction)pyopencv_cv_ShapeTransformer_applyTransformation, METH_VARARGS | METH_KEYWORDS, "applyTransformation(input[, output]) -> retval, output"},
    {"estimateTransformation", (PyCFunction)pyopencv_cv_ShapeTransformer_estimateTransformation, METH_VARARGS | METH_KEYWORDS, "estimateTransformation(transformingShape, targetShape, matches) -> None"},
    {"warpImage", (PyCFunction)pyopencv_cv_ShapeTransformer_warpImage, METH_VARARGS | METH_KEYWORDS, "warpImage(transformingImage[, output[, flags[, borderMode[, borderValue]]]]) -> output"},

    {NULL,          NULL}
};

static void pyopencv_ShapeTransformer_specials(void)
{
    pyopencv_ShapeTransformer_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_ShapeTransformer_Type.tp_dealloc = pyopencv_ShapeTransformer_dealloc;
    pyopencv_ShapeTransformer_Type.tp_repr = pyopencv_ShapeTransformer_repr;
    pyopencv_ShapeTransformer_Type.tp_getset = pyopencv_ShapeTransformer_getseters;
    pyopencv_ShapeTransformer_Type.tp_methods = pyopencv_ShapeTransformer_methods;
}

static PyObject* pyopencv_ThinPlateSplineShapeTransformer_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<ThinPlateSplineShapeTransformer %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_ThinPlateSplineShapeTransformer_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_ThinPlateSplineShapeTransformer_getRegularizationParameter(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ThinPlateSplineShapeTransformer_Type))
        return failmsgp("Incorrect type of self (must be 'ThinPlateSplineShapeTransformer' or its derivative)");
    cv::ThinPlateSplineShapeTransformer* _self_ = dynamic_cast<cv::ThinPlateSplineShapeTransformer*>(((pyopencv_ThinPlateSplineShapeTransformer_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getRegularizationParameter());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ThinPlateSplineShapeTransformer_setRegularizationParameter(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ThinPlateSplineShapeTransformer_Type))
        return failmsgp("Incorrect type of self (must be 'ThinPlateSplineShapeTransformer' or its derivative)");
    cv::ThinPlateSplineShapeTransformer* _self_ = dynamic_cast<cv::ThinPlateSplineShapeTransformer*>(((pyopencv_ThinPlateSplineShapeTransformer_t*)self)->v.get());
    double beta=0;

    const char* keywords[] = { "beta", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:ThinPlateSplineShapeTransformer.setRegularizationParameter", (char**)keywords, &beta) )
    {
        ERRWRAP2(_self_->setRegularizationParameter(beta));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_ThinPlateSplineShapeTransformer_methods[] =
{
    {"getRegularizationParameter", (PyCFunction)pyopencv_cv_ThinPlateSplineShapeTransformer_getRegularizationParameter, METH_VARARGS | METH_KEYWORDS, "getRegularizationParameter() -> retval"},
    {"setRegularizationParameter", (PyCFunction)pyopencv_cv_ThinPlateSplineShapeTransformer_setRegularizationParameter, METH_VARARGS | METH_KEYWORDS, "setRegularizationParameter(beta) -> None"},

    {NULL,          NULL}
};

static void pyopencv_ThinPlateSplineShapeTransformer_specials(void)
{
    pyopencv_ThinPlateSplineShapeTransformer_Type.tp_base = &pyopencv_ShapeTransformer_Type;
    pyopencv_ThinPlateSplineShapeTransformer_Type.tp_dealloc = pyopencv_ThinPlateSplineShapeTransformer_dealloc;
    pyopencv_ThinPlateSplineShapeTransformer_Type.tp_repr = pyopencv_ThinPlateSplineShapeTransformer_repr;
    pyopencv_ThinPlateSplineShapeTransformer_Type.tp_getset = pyopencv_ThinPlateSplineShapeTransformer_getseters;
    pyopencv_ThinPlateSplineShapeTransformer_Type.tp_methods = pyopencv_ThinPlateSplineShapeTransformer_methods;
}

static PyObject* pyopencv_AffineTransformer_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<AffineTransformer %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_AffineTransformer_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_AffineTransformer_getFullAffine(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_AffineTransformer_Type))
        return failmsgp("Incorrect type of self (must be 'AffineTransformer' or its derivative)");
    cv::AffineTransformer* _self_ = dynamic_cast<cv::AffineTransformer*>(((pyopencv_AffineTransformer_t*)self)->v.get());
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getFullAffine());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_AffineTransformer_setFullAffine(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_AffineTransformer_Type))
        return failmsgp("Incorrect type of self (must be 'AffineTransformer' or its derivative)");
    cv::AffineTransformer* _self_ = dynamic_cast<cv::AffineTransformer*>(((pyopencv_AffineTransformer_t*)self)->v.get());
    bool fullAffine=0;

    const char* keywords[] = { "fullAffine", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "b:AffineTransformer.setFullAffine", (char**)keywords, &fullAffine) )
    {
        ERRWRAP2(_self_->setFullAffine(fullAffine));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_AffineTransformer_methods[] =
{
    {"getFullAffine", (PyCFunction)pyopencv_cv_AffineTransformer_getFullAffine, METH_VARARGS | METH_KEYWORDS, "getFullAffine() -> retval"},
    {"setFullAffine", (PyCFunction)pyopencv_cv_AffineTransformer_setFullAffine, METH_VARARGS | METH_KEYWORDS, "setFullAffine(fullAffine) -> None"},

    {NULL,          NULL}
};

static void pyopencv_AffineTransformer_specials(void)
{
    pyopencv_AffineTransformer_Type.tp_base = &pyopencv_ShapeTransformer_Type;
    pyopencv_AffineTransformer_Type.tp_dealloc = pyopencv_AffineTransformer_dealloc;
    pyopencv_AffineTransformer_Type.tp_repr = pyopencv_AffineTransformer_repr;
    pyopencv_AffineTransformer_Type.tp_getset = pyopencv_AffineTransformer_getseters;
    pyopencv_AffineTransformer_Type.tp_methods = pyopencv_AffineTransformer_methods;
}

static PyObject* pyopencv_VideoCapture_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<VideoCapture %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_VideoCapture_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_VideoCapture_get(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_VideoCapture_Type))
        return failmsgp("Incorrect type of self (must be 'VideoCapture' or its derivative)");
    cv::VideoCapture* _self_ = ((pyopencv_VideoCapture_t*)self)->v.get();
    int propId=0;
    double retval;

    const char* keywords[] = { "propId", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:VideoCapture.get", (char**)keywords, &propId) )
    {
        ERRWRAP2(retval = _self_->get(propId));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_VideoCapture_grab(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_VideoCapture_Type))
        return failmsgp("Incorrect type of self (must be 'VideoCapture' or its derivative)");
    cv::VideoCapture* _self_ = ((pyopencv_VideoCapture_t*)self)->v.get();
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->grab());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_VideoCapture_isOpened(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_VideoCapture_Type))
        return failmsgp("Incorrect type of self (must be 'VideoCapture' or its derivative)");
    cv::VideoCapture* _self_ = ((pyopencv_VideoCapture_t*)self)->v.get();
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->isOpened());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_VideoCapture_open(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_VideoCapture_Type))
        return failmsgp("Incorrect type of self (must be 'VideoCapture' or its derivative)");
    cv::VideoCapture* _self_ = ((pyopencv_VideoCapture_t*)self)->v.get();
    {
    PyObject* pyobj_filename = NULL;
    String filename;
    bool retval;

    const char* keywords[] = { "filename", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:VideoCapture.open", (char**)keywords, &pyobj_filename) &&
        pyopencv_to(pyobj_filename, filename, ArgInfo("filename", 0)) )
    {
        ERRWRAP2(retval = _self_->open(filename));
        return pyopencv_from(retval);
    }
    }
    PyErr_Clear();

    {
    int index=0;
    bool retval;

    const char* keywords[] = { "index", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:VideoCapture.open", (char**)keywords, &index) )
    {
        ERRWRAP2(retval = _self_->open(index));
        return pyopencv_from(retval);
    }
    }
    PyErr_Clear();

    {
    int cameraNum=0;
    int apiPreference=0;
    bool retval;

    const char* keywords[] = { "cameraNum", "apiPreference", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "ii:VideoCapture.open", (char**)keywords, &cameraNum, &apiPreference) )
    {
        ERRWRAP2(retval = _self_->open(cameraNum, apiPreference));
        return pyopencv_from(retval);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_filename = NULL;
    String filename;
    int apiPreference=0;
    bool retval;

    const char* keywords[] = { "filename", "apiPreference", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "Oi:VideoCapture.open", (char**)keywords, &pyobj_filename, &apiPreference) &&
        pyopencv_to(pyobj_filename, filename, ArgInfo("filename", 0)) )
    {
        ERRWRAP2(retval = _self_->open(filename, apiPreference));
        return pyopencv_from(retval);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_VideoCapture_read(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_VideoCapture_Type))
        return failmsgp("Incorrect type of self (must be 'VideoCapture' or its derivative)");
    cv::VideoCapture* _self_ = ((pyopencv_VideoCapture_t*)self)->v.get();
    {
    PyObject* pyobj_image = NULL;
    Mat image;
    bool retval;

    const char* keywords[] = { "image", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|O:VideoCapture.read", (char**)keywords, &pyobj_image) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 1)) )
    {
        ERRWRAP2(retval = _self_->read(image));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(image));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    bool retval;

    const char* keywords[] = { "image", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|O:VideoCapture.read", (char**)keywords, &pyobj_image) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 1)) )
    {
        ERRWRAP2(retval = _self_->read(image));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(image));
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_VideoCapture_release(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_VideoCapture_Type))
        return failmsgp("Incorrect type of self (must be 'VideoCapture' or its derivative)");
    cv::VideoCapture* _self_ = ((pyopencv_VideoCapture_t*)self)->v.get();

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(_self_->release());
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_VideoCapture_retrieve(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_VideoCapture_Type))
        return failmsgp("Incorrect type of self (must be 'VideoCapture' or its derivative)");
    cv::VideoCapture* _self_ = ((pyopencv_VideoCapture_t*)self)->v.get();
    {
    PyObject* pyobj_image = NULL;
    Mat image;
    int flag=0;
    bool retval;

    const char* keywords[] = { "image", "flag", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|Oi:VideoCapture.retrieve", (char**)keywords, &pyobj_image, &flag) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 1)) )
    {
        ERRWRAP2(retval = _self_->retrieve(image, flag));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(image));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    int flag=0;
    bool retval;

    const char* keywords[] = { "image", "flag", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|Oi:VideoCapture.retrieve", (char**)keywords, &pyobj_image, &flag) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 1)) )
    {
        ERRWRAP2(retval = _self_->retrieve(image, flag));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(image));
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_VideoCapture_set(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_VideoCapture_Type))
        return failmsgp("Incorrect type of self (must be 'VideoCapture' or its derivative)");
    cv::VideoCapture* _self_ = ((pyopencv_VideoCapture_t*)self)->v.get();
    int propId=0;
    double value=0;
    bool retval;

    const char* keywords[] = { "propId", "value", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "id:VideoCapture.set", (char**)keywords, &propId, &value) )
    {
        ERRWRAP2(retval = _self_->set(propId, value));
        return pyopencv_from(retval);
    }

    return NULL;
}



static PyMethodDef pyopencv_VideoCapture_methods[] =
{
    {"get", (PyCFunction)pyopencv_cv_VideoCapture_get, METH_VARARGS | METH_KEYWORDS, "get(propId) -> retval"},
    {"grab", (PyCFunction)pyopencv_cv_VideoCapture_grab, METH_VARARGS | METH_KEYWORDS, "grab() -> retval"},
    {"isOpened", (PyCFunction)pyopencv_cv_VideoCapture_isOpened, METH_VARARGS | METH_KEYWORDS, "isOpened() -> retval"},
    {"open", (PyCFunction)pyopencv_cv_VideoCapture_open, METH_VARARGS | METH_KEYWORDS, "open(filename) -> retval  or  open(index) -> retval  or  open(cameraNum, apiPreference) -> retval  or  open(filename, apiPreference) -> retval"},
    {"read", (PyCFunction)pyopencv_cv_VideoCapture_read, METH_VARARGS | METH_KEYWORDS, "read([, image]) -> retval, image"},
    {"release", (PyCFunction)pyopencv_cv_VideoCapture_release, METH_VARARGS | METH_KEYWORDS, "release() -> None"},
    {"retrieve", (PyCFunction)pyopencv_cv_VideoCapture_retrieve, METH_VARARGS | METH_KEYWORDS, "retrieve([, image[, flag]]) -> retval, image"},
    {"set", (PyCFunction)pyopencv_cv_VideoCapture_set, METH_VARARGS | METH_KEYWORDS, "set(propId, value) -> retval"},

    {NULL,          NULL}
};

static void pyopencv_VideoCapture_specials(void)
{
    pyopencv_VideoCapture_Type.tp_base = NULL;
    pyopencv_VideoCapture_Type.tp_dealloc = pyopencv_VideoCapture_dealloc;
    pyopencv_VideoCapture_Type.tp_repr = pyopencv_VideoCapture_repr;
    pyopencv_VideoCapture_Type.tp_getset = pyopencv_VideoCapture_getseters;
    pyopencv_VideoCapture_Type.tp_methods = pyopencv_VideoCapture_methods;
}

static PyObject* pyopencv_VideoWriter_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<VideoWriter %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_VideoWriter_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_VideoWriter_get(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_VideoWriter_Type))
        return failmsgp("Incorrect type of self (must be 'VideoWriter' or its derivative)");
    cv::VideoWriter* _self_ = ((pyopencv_VideoWriter_t*)self)->v.get();
    int propId=0;
    double retval;

    const char* keywords[] = { "propId", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:VideoWriter.get", (char**)keywords, &propId) )
    {
        ERRWRAP2(retval = _self_->get(propId));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_VideoWriter_isOpened(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_VideoWriter_Type))
        return failmsgp("Incorrect type of self (must be 'VideoWriter' or its derivative)");
    cv::VideoWriter* _self_ = ((pyopencv_VideoWriter_t*)self)->v.get();
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->isOpened());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_VideoWriter_open(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_VideoWriter_Type))
        return failmsgp("Incorrect type of self (must be 'VideoWriter' or its derivative)");
    cv::VideoWriter* _self_ = ((pyopencv_VideoWriter_t*)self)->v.get();
    PyObject* pyobj_filename = NULL;
    String filename;
    int fourcc=0;
    double fps=0;
    PyObject* pyobj_frameSize = NULL;
    Size frameSize;
    bool isColor=true;
    bool retval;

    const char* keywords[] = { "filename", "fourcc", "fps", "frameSize", "isColor", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OidO|b:VideoWriter.open", (char**)keywords, &pyobj_filename, &fourcc, &fps, &pyobj_frameSize, &isColor) &&
        pyopencv_to(pyobj_filename, filename, ArgInfo("filename", 0)) &&
        pyopencv_to(pyobj_frameSize, frameSize, ArgInfo("frameSize", 0)) )
    {
        ERRWRAP2(retval = _self_->open(filename, fourcc, fps, frameSize, isColor));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_VideoWriter_release(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_VideoWriter_Type))
        return failmsgp("Incorrect type of self (must be 'VideoWriter' or its derivative)");
    cv::VideoWriter* _self_ = ((pyopencv_VideoWriter_t*)self)->v.get();

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(_self_->release());
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_VideoWriter_set(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_VideoWriter_Type))
        return failmsgp("Incorrect type of self (must be 'VideoWriter' or its derivative)");
    cv::VideoWriter* _self_ = ((pyopencv_VideoWriter_t*)self)->v.get();
    int propId=0;
    double value=0;
    bool retval;

    const char* keywords[] = { "propId", "value", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "id:VideoWriter.set", (char**)keywords, &propId, &value) )
    {
        ERRWRAP2(retval = _self_->set(propId, value));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_VideoWriter_write(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_VideoWriter_Type))
        return failmsgp("Incorrect type of self (must be 'VideoWriter' or its derivative)");
    cv::VideoWriter* _self_ = ((pyopencv_VideoWriter_t*)self)->v.get();
    {
    PyObject* pyobj_image = NULL;
    Mat image;

    const char* keywords[] = { "image", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:VideoWriter.write", (char**)keywords, &pyobj_image) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) )
    {
        ERRWRAP2(_self_->write(image));
        Py_RETURN_NONE;
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_image = NULL;
    Mat image;

    const char* keywords[] = { "image", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:VideoWriter.write", (char**)keywords, &pyobj_image) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) )
    {
        ERRWRAP2(_self_->write(image));
        Py_RETURN_NONE;
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_VideoWriter_methods[] =
{
    {"get", (PyCFunction)pyopencv_cv_VideoWriter_get, METH_VARARGS | METH_KEYWORDS, "get(propId) -> retval"},
    {"isOpened", (PyCFunction)pyopencv_cv_VideoWriter_isOpened, METH_VARARGS | METH_KEYWORDS, "isOpened() -> retval"},
    {"open", (PyCFunction)pyopencv_cv_VideoWriter_open, METH_VARARGS | METH_KEYWORDS, "open(filename, fourcc, fps, frameSize[, isColor]) -> retval"},
    {"release", (PyCFunction)pyopencv_cv_VideoWriter_release, METH_VARARGS | METH_KEYWORDS, "release() -> None"},
    {"set", (PyCFunction)pyopencv_cv_VideoWriter_set, METH_VARARGS | METH_KEYWORDS, "set(propId, value) -> retval"},
    {"write", (PyCFunction)pyopencv_cv_VideoWriter_write, METH_VARARGS | METH_KEYWORDS, "write(image) -> None"},

    {NULL,          NULL}
};

static void pyopencv_VideoWriter_specials(void)
{
    pyopencv_VideoWriter_Type.tp_base = NULL;
    pyopencv_VideoWriter_Type.tp_dealloc = pyopencv_VideoWriter_dealloc;
    pyopencv_VideoWriter_Type.tp_repr = pyopencv_VideoWriter_repr;
    pyopencv_VideoWriter_Type.tp_getset = pyopencv_VideoWriter_getseters;
    pyopencv_VideoWriter_Type.tp_methods = pyopencv_VideoWriter_methods;
}

static PyObject* pyopencv_BaseCascadeClassifier_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<BaseCascadeClassifier %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_BaseCascadeClassifier_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_BaseCascadeClassifier_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_BaseCascadeClassifier_specials(void)
{
    pyopencv_BaseCascadeClassifier_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_BaseCascadeClassifier_Type.tp_dealloc = pyopencv_BaseCascadeClassifier_dealloc;
    pyopencv_BaseCascadeClassifier_Type.tp_repr = pyopencv_BaseCascadeClassifier_repr;
    pyopencv_BaseCascadeClassifier_Type.tp_getset = pyopencv_BaseCascadeClassifier_getseters;
    pyopencv_BaseCascadeClassifier_Type.tp_methods = pyopencv_BaseCascadeClassifier_methods;
}

static PyObject* pyopencv_CascadeClassifier_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<CascadeClassifier %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_CascadeClassifier_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_CascadeClassifier_detectMultiScale(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_CascadeClassifier_Type))
        return failmsgp("Incorrect type of self (must be 'CascadeClassifier' or its derivative)");
    cv::CascadeClassifier* _self_ = ((pyopencv_CascadeClassifier_t*)self)->v.get();
    {
    PyObject* pyobj_image = NULL;
    Mat image;
    vector_Rect objects;
    double scaleFactor=1.1;
    int minNeighbors=3;
    int flags=0;
    PyObject* pyobj_minSize = NULL;
    Size minSize;
    PyObject* pyobj_maxSize = NULL;
    Size maxSize;

    const char* keywords[] = { "image", "scaleFactor", "minNeighbors", "flags", "minSize", "maxSize", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|diiOO:CascadeClassifier.detectMultiScale", (char**)keywords, &pyobj_image, &scaleFactor, &minNeighbors, &flags, &pyobj_minSize, &pyobj_maxSize) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_minSize, minSize, ArgInfo("minSize", 0)) &&
        pyopencv_to(pyobj_maxSize, maxSize, ArgInfo("maxSize", 0)) )
    {
        ERRWRAP2(_self_->detectMultiScale(image, objects, scaleFactor, minNeighbors, flags, minSize, maxSize));
        return pyopencv_from(objects);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    vector_Rect objects;
    double scaleFactor=1.1;
    int minNeighbors=3;
    int flags=0;
    PyObject* pyobj_minSize = NULL;
    Size minSize;
    PyObject* pyobj_maxSize = NULL;
    Size maxSize;

    const char* keywords[] = { "image", "scaleFactor", "minNeighbors", "flags", "minSize", "maxSize", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|diiOO:CascadeClassifier.detectMultiScale", (char**)keywords, &pyobj_image, &scaleFactor, &minNeighbors, &flags, &pyobj_minSize, &pyobj_maxSize) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_minSize, minSize, ArgInfo("minSize", 0)) &&
        pyopencv_to(pyobj_maxSize, maxSize, ArgInfo("maxSize", 0)) )
    {
        ERRWRAP2(_self_->detectMultiScale(image, objects, scaleFactor, minNeighbors, flags, minSize, maxSize));
        return pyopencv_from(objects);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_CascadeClassifier_detectMultiScale2(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_CascadeClassifier_Type))
        return failmsgp("Incorrect type of self (must be 'CascadeClassifier' or its derivative)");
    cv::CascadeClassifier* _self_ = ((pyopencv_CascadeClassifier_t*)self)->v.get();
    {
    PyObject* pyobj_image = NULL;
    Mat image;
    vector_Rect objects;
    vector_int numDetections;
    double scaleFactor=1.1;
    int minNeighbors=3;
    int flags=0;
    PyObject* pyobj_minSize = NULL;
    Size minSize;
    PyObject* pyobj_maxSize = NULL;
    Size maxSize;

    const char* keywords[] = { "image", "scaleFactor", "minNeighbors", "flags", "minSize", "maxSize", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|diiOO:CascadeClassifier.detectMultiScale2", (char**)keywords, &pyobj_image, &scaleFactor, &minNeighbors, &flags, &pyobj_minSize, &pyobj_maxSize) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_minSize, minSize, ArgInfo("minSize", 0)) &&
        pyopencv_to(pyobj_maxSize, maxSize, ArgInfo("maxSize", 0)) )
    {
        ERRWRAP2(_self_->detectMultiScale(image, objects, numDetections, scaleFactor, minNeighbors, flags, minSize, maxSize));
        return Py_BuildValue("(NN)", pyopencv_from(objects), pyopencv_from(numDetections));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    vector_Rect objects;
    vector_int numDetections;
    double scaleFactor=1.1;
    int minNeighbors=3;
    int flags=0;
    PyObject* pyobj_minSize = NULL;
    Size minSize;
    PyObject* pyobj_maxSize = NULL;
    Size maxSize;

    const char* keywords[] = { "image", "scaleFactor", "minNeighbors", "flags", "minSize", "maxSize", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|diiOO:CascadeClassifier.detectMultiScale2", (char**)keywords, &pyobj_image, &scaleFactor, &minNeighbors, &flags, &pyobj_minSize, &pyobj_maxSize) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_minSize, minSize, ArgInfo("minSize", 0)) &&
        pyopencv_to(pyobj_maxSize, maxSize, ArgInfo("maxSize", 0)) )
    {
        ERRWRAP2(_self_->detectMultiScale(image, objects, numDetections, scaleFactor, minNeighbors, flags, minSize, maxSize));
        return Py_BuildValue("(NN)", pyopencv_from(objects), pyopencv_from(numDetections));
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_CascadeClassifier_detectMultiScale3(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_CascadeClassifier_Type))
        return failmsgp("Incorrect type of self (must be 'CascadeClassifier' or its derivative)");
    cv::CascadeClassifier* _self_ = ((pyopencv_CascadeClassifier_t*)self)->v.get();
    {
    PyObject* pyobj_image = NULL;
    Mat image;
    vector_Rect objects;
    vector_int rejectLevels;
    vector_double levelWeights;
    double scaleFactor=1.1;
    int minNeighbors=3;
    int flags=0;
    PyObject* pyobj_minSize = NULL;
    Size minSize;
    PyObject* pyobj_maxSize = NULL;
    Size maxSize;
    bool outputRejectLevels=false;

    const char* keywords[] = { "image", "scaleFactor", "minNeighbors", "flags", "minSize", "maxSize", "outputRejectLevels", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|diiOOb:CascadeClassifier.detectMultiScale3", (char**)keywords, &pyobj_image, &scaleFactor, &minNeighbors, &flags, &pyobj_minSize, &pyobj_maxSize, &outputRejectLevels) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_minSize, minSize, ArgInfo("minSize", 0)) &&
        pyopencv_to(pyobj_maxSize, maxSize, ArgInfo("maxSize", 0)) )
    {
        ERRWRAP2(_self_->detectMultiScale(image, objects, rejectLevels, levelWeights, scaleFactor, minNeighbors, flags, minSize, maxSize, outputRejectLevels));
        return Py_BuildValue("(NNN)", pyopencv_from(objects), pyopencv_from(rejectLevels), pyopencv_from(levelWeights));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    vector_Rect objects;
    vector_int rejectLevels;
    vector_double levelWeights;
    double scaleFactor=1.1;
    int minNeighbors=3;
    int flags=0;
    PyObject* pyobj_minSize = NULL;
    Size minSize;
    PyObject* pyobj_maxSize = NULL;
    Size maxSize;
    bool outputRejectLevels=false;

    const char* keywords[] = { "image", "scaleFactor", "minNeighbors", "flags", "minSize", "maxSize", "outputRejectLevels", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|diiOOb:CascadeClassifier.detectMultiScale3", (char**)keywords, &pyobj_image, &scaleFactor, &minNeighbors, &flags, &pyobj_minSize, &pyobj_maxSize, &outputRejectLevels) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_minSize, minSize, ArgInfo("minSize", 0)) &&
        pyopencv_to(pyobj_maxSize, maxSize, ArgInfo("maxSize", 0)) )
    {
        ERRWRAP2(_self_->detectMultiScale(image, objects, rejectLevels, levelWeights, scaleFactor, minNeighbors, flags, minSize, maxSize, outputRejectLevels));
        return Py_BuildValue("(NNN)", pyopencv_from(objects), pyopencv_from(rejectLevels), pyopencv_from(levelWeights));
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_CascadeClassifier_empty(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_CascadeClassifier_Type))
        return failmsgp("Incorrect type of self (must be 'CascadeClassifier' or its derivative)");
    cv::CascadeClassifier* _self_ = ((pyopencv_CascadeClassifier_t*)self)->v.get();
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->empty());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_CascadeClassifier_getFeatureType(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_CascadeClassifier_Type))
        return failmsgp("Incorrect type of self (must be 'CascadeClassifier' or its derivative)");
    cv::CascadeClassifier* _self_ = ((pyopencv_CascadeClassifier_t*)self)->v.get();
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getFeatureType());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_CascadeClassifier_getOriginalWindowSize(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_CascadeClassifier_Type))
        return failmsgp("Incorrect type of self (must be 'CascadeClassifier' or its derivative)");
    cv::CascadeClassifier* _self_ = ((pyopencv_CascadeClassifier_t*)self)->v.get();
    Size retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getOriginalWindowSize());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_CascadeClassifier_isOldFormatCascade(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_CascadeClassifier_Type))
        return failmsgp("Incorrect type of self (must be 'CascadeClassifier' or its derivative)");
    cv::CascadeClassifier* _self_ = ((pyopencv_CascadeClassifier_t*)self)->v.get();
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->isOldFormatCascade());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_CascadeClassifier_load(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_CascadeClassifier_Type))
        return failmsgp("Incorrect type of self (must be 'CascadeClassifier' or its derivative)");
    cv::CascadeClassifier* _self_ = ((pyopencv_CascadeClassifier_t*)self)->v.get();
    PyObject* pyobj_filename = NULL;
    String filename;
    bool retval;

    const char* keywords[] = { "filename", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:CascadeClassifier.load", (char**)keywords, &pyobj_filename) &&
        pyopencv_to(pyobj_filename, filename, ArgInfo("filename", 0)) )
    {
        ERRWRAP2(retval = _self_->load(filename));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_CascadeClassifier_read(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_CascadeClassifier_Type))
        return failmsgp("Incorrect type of self (must be 'CascadeClassifier' or its derivative)");
    cv::CascadeClassifier* _self_ = ((pyopencv_CascadeClassifier_t*)self)->v.get();
    PyObject* pyobj_node = NULL;
    FileNode node;
    bool retval;

    const char* keywords[] = { "node", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:CascadeClassifier.read", (char**)keywords, &pyobj_node) &&
        pyopencv_to(pyobj_node, node, ArgInfo("node", 0)) )
    {
        ERRWRAP2(retval = _self_->read(node));
        return pyopencv_from(retval);
    }

    return NULL;
}



static PyMethodDef pyopencv_CascadeClassifier_methods[] =
{
    {"detectMultiScale", (PyCFunction)pyopencv_cv_CascadeClassifier_detectMultiScale, METH_VARARGS | METH_KEYWORDS, "detectMultiScale(image[, scaleFactor[, minNeighbors[, flags[, minSize[, maxSize]]]]]) -> objects"},
    {"detectMultiScale2", (PyCFunction)pyopencv_cv_CascadeClassifier_detectMultiScale2, METH_VARARGS | METH_KEYWORDS, "detectMultiScale2(image[, scaleFactor[, minNeighbors[, flags[, minSize[, maxSize]]]]]) -> objects, numDetections"},
    {"detectMultiScale3", (PyCFunction)pyopencv_cv_CascadeClassifier_detectMultiScale3, METH_VARARGS | METH_KEYWORDS, "detectMultiScale3(image[, scaleFactor[, minNeighbors[, flags[, minSize[, maxSize[, outputRejectLevels]]]]]]) -> objects, rejectLevels, levelWeights"},
    {"empty", (PyCFunction)pyopencv_cv_CascadeClassifier_empty, METH_VARARGS | METH_KEYWORDS, "empty() -> retval"},
    {"getFeatureType", (PyCFunction)pyopencv_cv_CascadeClassifier_getFeatureType, METH_VARARGS | METH_KEYWORDS, "getFeatureType() -> retval"},
    {"getOriginalWindowSize", (PyCFunction)pyopencv_cv_CascadeClassifier_getOriginalWindowSize, METH_VARARGS | METH_KEYWORDS, "getOriginalWindowSize() -> retval"},
    {"isOldFormatCascade", (PyCFunction)pyopencv_cv_CascadeClassifier_isOldFormatCascade, METH_VARARGS | METH_KEYWORDS, "isOldFormatCascade() -> retval"},
    {"load", (PyCFunction)pyopencv_cv_CascadeClassifier_load, METH_VARARGS | METH_KEYWORDS, "load(filename) -> retval"},
    {"read", (PyCFunction)pyopencv_cv_CascadeClassifier_read, METH_VARARGS | METH_KEYWORDS, "read(node) -> retval"},

    {NULL,          NULL}
};

static void pyopencv_CascadeClassifier_specials(void)
{
    pyopencv_CascadeClassifier_Type.tp_base = NULL;
    pyopencv_CascadeClassifier_Type.tp_dealloc = pyopencv_CascadeClassifier_dealloc;
    pyopencv_CascadeClassifier_Type.tp_repr = pyopencv_CascadeClassifier_repr;
    pyopencv_CascadeClassifier_Type.tp_getset = pyopencv_CascadeClassifier_getseters;
    pyopencv_CascadeClassifier_Type.tp_methods = pyopencv_CascadeClassifier_methods;
}

static PyObject* pyopencv_HOGDescriptor_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<HOGDescriptor %p>", self);
    return PyString_FromString(str);
}


static PyObject* pyopencv_HOGDescriptor_get_L2HysThreshold(pyopencv_HOGDescriptor_t* p, void *closure)
{
    return pyopencv_from(p->v->L2HysThreshold);
}

static PyObject* pyopencv_HOGDescriptor_get_blockSize(pyopencv_HOGDescriptor_t* p, void *closure)
{
    return pyopencv_from(p->v->blockSize);
}

static PyObject* pyopencv_HOGDescriptor_get_blockStride(pyopencv_HOGDescriptor_t* p, void *closure)
{
    return pyopencv_from(p->v->blockStride);
}

static PyObject* pyopencv_HOGDescriptor_get_cellSize(pyopencv_HOGDescriptor_t* p, void *closure)
{
    return pyopencv_from(p->v->cellSize);
}

static PyObject* pyopencv_HOGDescriptor_get_derivAperture(pyopencv_HOGDescriptor_t* p, void *closure)
{
    return pyopencv_from(p->v->derivAperture);
}

static PyObject* pyopencv_HOGDescriptor_get_gammaCorrection(pyopencv_HOGDescriptor_t* p, void *closure)
{
    return pyopencv_from(p->v->gammaCorrection);
}

static PyObject* pyopencv_HOGDescriptor_get_histogramNormType(pyopencv_HOGDescriptor_t* p, void *closure)
{
    return pyopencv_from(p->v->histogramNormType);
}

static PyObject* pyopencv_HOGDescriptor_get_nbins(pyopencv_HOGDescriptor_t* p, void *closure)
{
    return pyopencv_from(p->v->nbins);
}

static PyObject* pyopencv_HOGDescriptor_get_nlevels(pyopencv_HOGDescriptor_t* p, void *closure)
{
    return pyopencv_from(p->v->nlevels);
}

static PyObject* pyopencv_HOGDescriptor_get_signedGradient(pyopencv_HOGDescriptor_t* p, void *closure)
{
    return pyopencv_from(p->v->signedGradient);
}

static PyObject* pyopencv_HOGDescriptor_get_svmDetector(pyopencv_HOGDescriptor_t* p, void *closure)
{
    return pyopencv_from(p->v->svmDetector);
}

static PyObject* pyopencv_HOGDescriptor_get_winSigma(pyopencv_HOGDescriptor_t* p, void *closure)
{
    return pyopencv_from(p->v->winSigma);
}

static PyObject* pyopencv_HOGDescriptor_get_winSize(pyopencv_HOGDescriptor_t* p, void *closure)
{
    return pyopencv_from(p->v->winSize);
}


static PyGetSetDef pyopencv_HOGDescriptor_getseters[] =
{
    {(char*)"L2HysThreshold", (getter)pyopencv_HOGDescriptor_get_L2HysThreshold, NULL, (char*)"L2HysThreshold", NULL},
    {(char*)"blockSize", (getter)pyopencv_HOGDescriptor_get_blockSize, NULL, (char*)"blockSize", NULL},
    {(char*)"blockStride", (getter)pyopencv_HOGDescriptor_get_blockStride, NULL, (char*)"blockStride", NULL},
    {(char*)"cellSize", (getter)pyopencv_HOGDescriptor_get_cellSize, NULL, (char*)"cellSize", NULL},
    {(char*)"derivAperture", (getter)pyopencv_HOGDescriptor_get_derivAperture, NULL, (char*)"derivAperture", NULL},
    {(char*)"gammaCorrection", (getter)pyopencv_HOGDescriptor_get_gammaCorrection, NULL, (char*)"gammaCorrection", NULL},
    {(char*)"histogramNormType", (getter)pyopencv_HOGDescriptor_get_histogramNormType, NULL, (char*)"histogramNormType", NULL},
    {(char*)"nbins", (getter)pyopencv_HOGDescriptor_get_nbins, NULL, (char*)"nbins", NULL},
    {(char*)"nlevels", (getter)pyopencv_HOGDescriptor_get_nlevels, NULL, (char*)"nlevels", NULL},
    {(char*)"signedGradient", (getter)pyopencv_HOGDescriptor_get_signedGradient, NULL, (char*)"signedGradient", NULL},
    {(char*)"svmDetector", (getter)pyopencv_HOGDescriptor_get_svmDetector, NULL, (char*)"svmDetector", NULL},
    {(char*)"winSigma", (getter)pyopencv_HOGDescriptor_get_winSigma, NULL, (char*)"winSigma", NULL},
    {(char*)"winSize", (getter)pyopencv_HOGDescriptor_get_winSize, NULL, (char*)"winSize", NULL},
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_HOGDescriptor_checkDetectorSize(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_HOGDescriptor_Type))
        return failmsgp("Incorrect type of self (must be 'HOGDescriptor' or its derivative)");
    cv::HOGDescriptor* _self_ = ((pyopencv_HOGDescriptor_t*)self)->v.get();
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->checkDetectorSize());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_HOGDescriptor_compute(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_HOGDescriptor_Type))
        return failmsgp("Incorrect type of self (must be 'HOGDescriptor' or its derivative)");
    cv::HOGDescriptor* _self_ = ((pyopencv_HOGDescriptor_t*)self)->v.get();
    {
    PyObject* pyobj_img = NULL;
    Mat img;
    vector_float descriptors;
    PyObject* pyobj_winStride = NULL;
    Size winStride;
    PyObject* pyobj_padding = NULL;
    Size padding;
    PyObject* pyobj_locations = NULL;
    vector_Point locations=std::vector<Point>();

    const char* keywords[] = { "img", "winStride", "padding", "locations", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|OOO:HOGDescriptor.compute", (char**)keywords, &pyobj_img, &pyobj_winStride, &pyobj_padding, &pyobj_locations) &&
        pyopencv_to(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to(pyobj_winStride, winStride, ArgInfo("winStride", 0)) &&
        pyopencv_to(pyobj_padding, padding, ArgInfo("padding", 0)) &&
        pyopencv_to(pyobj_locations, locations, ArgInfo("locations", 0)) )
    {
        ERRWRAP2(_self_->compute(img, descriptors, winStride, padding, locations));
        return pyopencv_from(descriptors);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_img = NULL;
    UMat img;
    vector_float descriptors;
    PyObject* pyobj_winStride = NULL;
    Size winStride;
    PyObject* pyobj_padding = NULL;
    Size padding;
    PyObject* pyobj_locations = NULL;
    vector_Point locations=std::vector<Point>();

    const char* keywords[] = { "img", "winStride", "padding", "locations", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|OOO:HOGDescriptor.compute", (char**)keywords, &pyobj_img, &pyobj_winStride, &pyobj_padding, &pyobj_locations) &&
        pyopencv_to(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to(pyobj_winStride, winStride, ArgInfo("winStride", 0)) &&
        pyopencv_to(pyobj_padding, padding, ArgInfo("padding", 0)) &&
        pyopencv_to(pyobj_locations, locations, ArgInfo("locations", 0)) )
    {
        ERRWRAP2(_self_->compute(img, descriptors, winStride, padding, locations));
        return pyopencv_from(descriptors);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_HOGDescriptor_computeGradient(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_HOGDescriptor_Type))
        return failmsgp("Incorrect type of self (must be 'HOGDescriptor' or its derivative)");
    cv::HOGDescriptor* _self_ = ((pyopencv_HOGDescriptor_t*)self)->v.get();
    {
    PyObject* pyobj_img = NULL;
    Mat img;
    PyObject* pyobj_grad = NULL;
    Mat grad;
    PyObject* pyobj_angleOfs = NULL;
    Mat angleOfs;
    PyObject* pyobj_paddingTL = NULL;
    Size paddingTL;
    PyObject* pyobj_paddingBR = NULL;
    Size paddingBR;

    const char* keywords[] = { "img", "grad", "angleOfs", "paddingTL", "paddingBR", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|OOOO:HOGDescriptor.computeGradient", (char**)keywords, &pyobj_img, &pyobj_grad, &pyobj_angleOfs, &pyobj_paddingTL, &pyobj_paddingBR) &&
        pyopencv_to(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to(pyobj_grad, grad, ArgInfo("grad", 1)) &&
        pyopencv_to(pyobj_angleOfs, angleOfs, ArgInfo("angleOfs", 1)) &&
        pyopencv_to(pyobj_paddingTL, paddingTL, ArgInfo("paddingTL", 0)) &&
        pyopencv_to(pyobj_paddingBR, paddingBR, ArgInfo("paddingBR", 0)) )
    {
        ERRWRAP2(_self_->computeGradient(img, grad, angleOfs, paddingTL, paddingBR));
        return Py_BuildValue("(NN)", pyopencv_from(grad), pyopencv_from(angleOfs));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_img = NULL;
    Mat img;
    PyObject* pyobj_grad = NULL;
    Mat grad;
    PyObject* pyobj_angleOfs = NULL;
    Mat angleOfs;
    PyObject* pyobj_paddingTL = NULL;
    Size paddingTL;
    PyObject* pyobj_paddingBR = NULL;
    Size paddingBR;

    const char* keywords[] = { "img", "grad", "angleOfs", "paddingTL", "paddingBR", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|OOOO:HOGDescriptor.computeGradient", (char**)keywords, &pyobj_img, &pyobj_grad, &pyobj_angleOfs, &pyobj_paddingTL, &pyobj_paddingBR) &&
        pyopencv_to(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to(pyobj_grad, grad, ArgInfo("grad", 1)) &&
        pyopencv_to(pyobj_angleOfs, angleOfs, ArgInfo("angleOfs", 1)) &&
        pyopencv_to(pyobj_paddingTL, paddingTL, ArgInfo("paddingTL", 0)) &&
        pyopencv_to(pyobj_paddingBR, paddingBR, ArgInfo("paddingBR", 0)) )
    {
        ERRWRAP2(_self_->computeGradient(img, grad, angleOfs, paddingTL, paddingBR));
        return Py_BuildValue("(NN)", pyopencv_from(grad), pyopencv_from(angleOfs));
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_HOGDescriptor_detect(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_HOGDescriptor_Type))
        return failmsgp("Incorrect type of self (must be 'HOGDescriptor' or its derivative)");
    cv::HOGDescriptor* _self_ = ((pyopencv_HOGDescriptor_t*)self)->v.get();
    {
    PyObject* pyobj_img = NULL;
    Mat img;
    vector_Point foundLocations;
    vector_double weights;
    double hitThreshold=0;
    PyObject* pyobj_winStride = NULL;
    Size winStride;
    PyObject* pyobj_padding = NULL;
    Size padding;
    PyObject* pyobj_searchLocations = NULL;
    vector_Point searchLocations=std::vector<Point>();

    const char* keywords[] = { "img", "hitThreshold", "winStride", "padding", "searchLocations", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|dOOO:HOGDescriptor.detect", (char**)keywords, &pyobj_img, &hitThreshold, &pyobj_winStride, &pyobj_padding, &pyobj_searchLocations) &&
        pyopencv_to(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to(pyobj_winStride, winStride, ArgInfo("winStride", 0)) &&
        pyopencv_to(pyobj_padding, padding, ArgInfo("padding", 0)) &&
        pyopencv_to(pyobj_searchLocations, searchLocations, ArgInfo("searchLocations", 0)) )
    {
        ERRWRAP2(_self_->detect(img, foundLocations, weights, hitThreshold, winStride, padding, searchLocations));
        return Py_BuildValue("(NN)", pyopencv_from(foundLocations), pyopencv_from(weights));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_img = NULL;
    Mat img;
    vector_Point foundLocations;
    vector_double weights;
    double hitThreshold=0;
    PyObject* pyobj_winStride = NULL;
    Size winStride;
    PyObject* pyobj_padding = NULL;
    Size padding;
    PyObject* pyobj_searchLocations = NULL;
    vector_Point searchLocations=std::vector<Point>();

    const char* keywords[] = { "img", "hitThreshold", "winStride", "padding", "searchLocations", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|dOOO:HOGDescriptor.detect", (char**)keywords, &pyobj_img, &hitThreshold, &pyobj_winStride, &pyobj_padding, &pyobj_searchLocations) &&
        pyopencv_to(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to(pyobj_winStride, winStride, ArgInfo("winStride", 0)) &&
        pyopencv_to(pyobj_padding, padding, ArgInfo("padding", 0)) &&
        pyopencv_to(pyobj_searchLocations, searchLocations, ArgInfo("searchLocations", 0)) )
    {
        ERRWRAP2(_self_->detect(img, foundLocations, weights, hitThreshold, winStride, padding, searchLocations));
        return Py_BuildValue("(NN)", pyopencv_from(foundLocations), pyopencv_from(weights));
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_HOGDescriptor_detectMultiScale(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_HOGDescriptor_Type))
        return failmsgp("Incorrect type of self (must be 'HOGDescriptor' or its derivative)");
    cv::HOGDescriptor* _self_ = ((pyopencv_HOGDescriptor_t*)self)->v.get();
    {
    PyObject* pyobj_img = NULL;
    Mat img;
    vector_Rect foundLocations;
    vector_double foundWeights;
    double hitThreshold=0;
    PyObject* pyobj_winStride = NULL;
    Size winStride;
    PyObject* pyobj_padding = NULL;
    Size padding;
    double scale=1.05;
    double finalThreshold=2.0;
    bool useMeanshiftGrouping=false;

    const char* keywords[] = { "img", "hitThreshold", "winStride", "padding", "scale", "finalThreshold", "useMeanshiftGrouping", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|dOOddb:HOGDescriptor.detectMultiScale", (char**)keywords, &pyobj_img, &hitThreshold, &pyobj_winStride, &pyobj_padding, &scale, &finalThreshold, &useMeanshiftGrouping) &&
        pyopencv_to(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to(pyobj_winStride, winStride, ArgInfo("winStride", 0)) &&
        pyopencv_to(pyobj_padding, padding, ArgInfo("padding", 0)) )
    {
        ERRWRAP2(_self_->detectMultiScale(img, foundLocations, foundWeights, hitThreshold, winStride, padding, scale, finalThreshold, useMeanshiftGrouping));
        return Py_BuildValue("(NN)", pyopencv_from(foundLocations), pyopencv_from(foundWeights));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_img = NULL;
    UMat img;
    vector_Rect foundLocations;
    vector_double foundWeights;
    double hitThreshold=0;
    PyObject* pyobj_winStride = NULL;
    Size winStride;
    PyObject* pyobj_padding = NULL;
    Size padding;
    double scale=1.05;
    double finalThreshold=2.0;
    bool useMeanshiftGrouping=false;

    const char* keywords[] = { "img", "hitThreshold", "winStride", "padding", "scale", "finalThreshold", "useMeanshiftGrouping", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|dOOddb:HOGDescriptor.detectMultiScale", (char**)keywords, &pyobj_img, &hitThreshold, &pyobj_winStride, &pyobj_padding, &scale, &finalThreshold, &useMeanshiftGrouping) &&
        pyopencv_to(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to(pyobj_winStride, winStride, ArgInfo("winStride", 0)) &&
        pyopencv_to(pyobj_padding, padding, ArgInfo("padding", 0)) )
    {
        ERRWRAP2(_self_->detectMultiScale(img, foundLocations, foundWeights, hitThreshold, winStride, padding, scale, finalThreshold, useMeanshiftGrouping));
        return Py_BuildValue("(NN)", pyopencv_from(foundLocations), pyopencv_from(foundWeights));
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_HOGDescriptor_getDescriptorSize(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_HOGDescriptor_Type))
        return failmsgp("Incorrect type of self (must be 'HOGDescriptor' or its derivative)");
    cv::HOGDescriptor* _self_ = ((pyopencv_HOGDescriptor_t*)self)->v.get();
    size_t retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getDescriptorSize());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_HOGDescriptor_getWinSigma(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_HOGDescriptor_Type))
        return failmsgp("Incorrect type of self (must be 'HOGDescriptor' or its derivative)");
    cv::HOGDescriptor* _self_ = ((pyopencv_HOGDescriptor_t*)self)->v.get();
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getWinSigma());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_HOGDescriptor_load(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_HOGDescriptor_Type))
        return failmsgp("Incorrect type of self (must be 'HOGDescriptor' or its derivative)");
    cv::HOGDescriptor* _self_ = ((pyopencv_HOGDescriptor_t*)self)->v.get();
    PyObject* pyobj_filename = NULL;
    String filename;
    PyObject* pyobj_objname = NULL;
    String objname;
    bool retval;

    const char* keywords[] = { "filename", "objname", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:HOGDescriptor.load", (char**)keywords, &pyobj_filename, &pyobj_objname) &&
        pyopencv_to(pyobj_filename, filename, ArgInfo("filename", 0)) &&
        pyopencv_to(pyobj_objname, objname, ArgInfo("objname", 0)) )
    {
        ERRWRAP2(retval = _self_->load(filename, objname));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_HOGDescriptor_save(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_HOGDescriptor_Type))
        return failmsgp("Incorrect type of self (must be 'HOGDescriptor' or its derivative)");
    cv::HOGDescriptor* _self_ = ((pyopencv_HOGDescriptor_t*)self)->v.get();
    PyObject* pyobj_filename = NULL;
    String filename;
    PyObject* pyobj_objname = NULL;
    String objname;

    const char* keywords[] = { "filename", "objname", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:HOGDescriptor.save", (char**)keywords, &pyobj_filename, &pyobj_objname) &&
        pyopencv_to(pyobj_filename, filename, ArgInfo("filename", 0)) &&
        pyopencv_to(pyobj_objname, objname, ArgInfo("objname", 0)) )
    {
        ERRWRAP2(_self_->save(filename, objname));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_HOGDescriptor_setSVMDetector(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_HOGDescriptor_Type))
        return failmsgp("Incorrect type of self (must be 'HOGDescriptor' or its derivative)");
    cv::HOGDescriptor* _self_ = ((pyopencv_HOGDescriptor_t*)self)->v.get();
    {
    PyObject* pyobj__svmdetector = NULL;
    Mat _svmdetector;

    const char* keywords[] = { "_svmdetector", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:HOGDescriptor.setSVMDetector", (char**)keywords, &pyobj__svmdetector) &&
        pyopencv_to(pyobj__svmdetector, _svmdetector, ArgInfo("_svmdetector", 0)) )
    {
        ERRWRAP2(_self_->setSVMDetector(_svmdetector));
        Py_RETURN_NONE;
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj__svmdetector = NULL;
    UMat _svmdetector;

    const char* keywords[] = { "_svmdetector", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:HOGDescriptor.setSVMDetector", (char**)keywords, &pyobj__svmdetector) &&
        pyopencv_to(pyobj__svmdetector, _svmdetector, ArgInfo("_svmdetector", 0)) )
    {
        ERRWRAP2(_self_->setSVMDetector(_svmdetector));
        Py_RETURN_NONE;
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_HOGDescriptor_methods[] =
{
    {"checkDetectorSize", (PyCFunction)pyopencv_cv_HOGDescriptor_checkDetectorSize, METH_VARARGS | METH_KEYWORDS, "checkDetectorSize() -> retval"},
    {"compute", (PyCFunction)pyopencv_cv_HOGDescriptor_compute, METH_VARARGS | METH_KEYWORDS, "compute(img[, winStride[, padding[, locations]]]) -> descriptors"},
    {"computeGradient", (PyCFunction)pyopencv_cv_HOGDescriptor_computeGradient, METH_VARARGS | METH_KEYWORDS, "computeGradient(img[, grad[, angleOfs[, paddingTL[, paddingBR]]]]) -> grad, angleOfs"},
    {"detect", (PyCFunction)pyopencv_cv_HOGDescriptor_detect, METH_VARARGS | METH_KEYWORDS, "detect(img[, hitThreshold[, winStride[, padding[, searchLocations]]]]) -> foundLocations, weights"},
    {"detectMultiScale", (PyCFunction)pyopencv_cv_HOGDescriptor_detectMultiScale, METH_VARARGS | METH_KEYWORDS, "detectMultiScale(img[, hitThreshold[, winStride[, padding[, scale[, finalThreshold[, useMeanshiftGrouping]]]]]]) -> foundLocations, foundWeights"},
    {"getDescriptorSize", (PyCFunction)pyopencv_cv_HOGDescriptor_getDescriptorSize, METH_VARARGS | METH_KEYWORDS, "getDescriptorSize() -> retval"},
    {"getWinSigma", (PyCFunction)pyopencv_cv_HOGDescriptor_getWinSigma, METH_VARARGS | METH_KEYWORDS, "getWinSigma() -> retval"},
    {"load", (PyCFunction)pyopencv_cv_HOGDescriptor_load, METH_VARARGS | METH_KEYWORDS, "load(filename[, objname]) -> retval"},
    {"save", (PyCFunction)pyopencv_cv_HOGDescriptor_save, METH_VARARGS | METH_KEYWORDS, "save(filename[, objname]) -> None"},
    {"setSVMDetector", (PyCFunction)pyopencv_cv_HOGDescriptor_setSVMDetector, METH_VARARGS | METH_KEYWORDS, "setSVMDetector(_svmdetector) -> None"},

    {NULL,          NULL}
};

static void pyopencv_HOGDescriptor_specials(void)
{
    pyopencv_HOGDescriptor_Type.tp_base = NULL;
    pyopencv_HOGDescriptor_Type.tp_dealloc = pyopencv_HOGDescriptor_dealloc;
    pyopencv_HOGDescriptor_Type.tp_repr = pyopencv_HOGDescriptor_repr;
    pyopencv_HOGDescriptor_Type.tp_getset = pyopencv_HOGDescriptor_getseters;
    pyopencv_HOGDescriptor_Type.tp_methods = pyopencv_HOGDescriptor_methods;
}

static PyObject* pyopencv_plot_Plot2d_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<plot_Plot2d %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_plot_Plot2d_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_plot_plot_Plot2d_render(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::plot;

    if(!PyObject_TypeCheck(self, &pyopencv_plot_Plot2d_Type))
        return failmsgp("Incorrect type of self (must be 'plot_Plot2d' or its derivative)");
    cv::plot::Plot2d* _self_ = dynamic_cast<cv::plot::Plot2d*>(((pyopencv_plot_Plot2d_t*)self)->v.get());
    {
    PyObject* pyobj__plotResult = NULL;
    Mat _plotResult;

    const char* keywords[] = { "_plotResult", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|O:plot_Plot2d.render", (char**)keywords, &pyobj__plotResult) &&
        pyopencv_to(pyobj__plotResult, _plotResult, ArgInfo("_plotResult", 1)) )
    {
        ERRWRAP2(_self_->render(_plotResult));
        return pyopencv_from(_plotResult);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj__plotResult = NULL;
    UMat _plotResult;

    const char* keywords[] = { "_plotResult", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|O:plot_Plot2d.render", (char**)keywords, &pyobj__plotResult) &&
        pyopencv_to(pyobj__plotResult, _plotResult, ArgInfo("_plotResult", 1)) )
    {
        ERRWRAP2(_self_->render(_plotResult));
        return pyopencv_from(_plotResult);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_plot_plot_Plot2d_setMaxX(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::plot;

    if(!PyObject_TypeCheck(self, &pyopencv_plot_Plot2d_Type))
        return failmsgp("Incorrect type of self (must be 'plot_Plot2d' or its derivative)");
    cv::plot::Plot2d* _self_ = dynamic_cast<cv::plot::Plot2d*>(((pyopencv_plot_Plot2d_t*)self)->v.get());
    double _plotMaxX=0;

    const char* keywords[] = { "_plotMaxX", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:plot_Plot2d.setMaxX", (char**)keywords, &_plotMaxX) )
    {
        ERRWRAP2(_self_->setMaxX(_plotMaxX));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_plot_plot_Plot2d_setMaxY(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::plot;

    if(!PyObject_TypeCheck(self, &pyopencv_plot_Plot2d_Type))
        return failmsgp("Incorrect type of self (must be 'plot_Plot2d' or its derivative)");
    cv::plot::Plot2d* _self_ = dynamic_cast<cv::plot::Plot2d*>(((pyopencv_plot_Plot2d_t*)self)->v.get());
    double _plotMaxY=0;

    const char* keywords[] = { "_plotMaxY", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:plot_Plot2d.setMaxY", (char**)keywords, &_plotMaxY) )
    {
        ERRWRAP2(_self_->setMaxY(_plotMaxY));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_plot_plot_Plot2d_setMinX(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::plot;

    if(!PyObject_TypeCheck(self, &pyopencv_plot_Plot2d_Type))
        return failmsgp("Incorrect type of self (must be 'plot_Plot2d' or its derivative)");
    cv::plot::Plot2d* _self_ = dynamic_cast<cv::plot::Plot2d*>(((pyopencv_plot_Plot2d_t*)self)->v.get());
    double _plotMinX=0;

    const char* keywords[] = { "_plotMinX", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:plot_Plot2d.setMinX", (char**)keywords, &_plotMinX) )
    {
        ERRWRAP2(_self_->setMinX(_plotMinX));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_plot_plot_Plot2d_setMinY(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::plot;

    if(!PyObject_TypeCheck(self, &pyopencv_plot_Plot2d_Type))
        return failmsgp("Incorrect type of self (must be 'plot_Plot2d' or its derivative)");
    cv::plot::Plot2d* _self_ = dynamic_cast<cv::plot::Plot2d*>(((pyopencv_plot_Plot2d_t*)self)->v.get());
    double _plotMinY=0;

    const char* keywords[] = { "_plotMinY", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:plot_Plot2d.setMinY", (char**)keywords, &_plotMinY) )
    {
        ERRWRAP2(_self_->setMinY(_plotMinY));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_plot_plot_Plot2d_setNeedPlotLine(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::plot;

    if(!PyObject_TypeCheck(self, &pyopencv_plot_Plot2d_Type))
        return failmsgp("Incorrect type of self (must be 'plot_Plot2d' or its derivative)");
    cv::plot::Plot2d* _self_ = dynamic_cast<cv::plot::Plot2d*>(((pyopencv_plot_Plot2d_t*)self)->v.get());
    bool _needPlotLine=0;

    const char* keywords[] = { "_needPlotLine", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "b:plot_Plot2d.setNeedPlotLine", (char**)keywords, &_needPlotLine) )
    {
        ERRWRAP2(_self_->setNeedPlotLine(_needPlotLine));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_plot_plot_Plot2d_setPlotAxisColor(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::plot;

    if(!PyObject_TypeCheck(self, &pyopencv_plot_Plot2d_Type))
        return failmsgp("Incorrect type of self (must be 'plot_Plot2d' or its derivative)");
    cv::plot::Plot2d* _self_ = dynamic_cast<cv::plot::Plot2d*>(((pyopencv_plot_Plot2d_t*)self)->v.get());
    PyObject* pyobj__plotAxisColor = NULL;
    Scalar _plotAxisColor;

    const char* keywords[] = { "_plotAxisColor", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:plot_Plot2d.setPlotAxisColor", (char**)keywords, &pyobj__plotAxisColor) &&
        pyopencv_to(pyobj__plotAxisColor, _plotAxisColor, ArgInfo("_plotAxisColor", 0)) )
    {
        ERRWRAP2(_self_->setPlotAxisColor(_plotAxisColor));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_plot_plot_Plot2d_setPlotBackgroundColor(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::plot;

    if(!PyObject_TypeCheck(self, &pyopencv_plot_Plot2d_Type))
        return failmsgp("Incorrect type of self (must be 'plot_Plot2d' or its derivative)");
    cv::plot::Plot2d* _self_ = dynamic_cast<cv::plot::Plot2d*>(((pyopencv_plot_Plot2d_t*)self)->v.get());
    PyObject* pyobj__plotBackgroundColor = NULL;
    Scalar _plotBackgroundColor;

    const char* keywords[] = { "_plotBackgroundColor", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:plot_Plot2d.setPlotBackgroundColor", (char**)keywords, &pyobj__plotBackgroundColor) &&
        pyopencv_to(pyobj__plotBackgroundColor, _plotBackgroundColor, ArgInfo("_plotBackgroundColor", 0)) )
    {
        ERRWRAP2(_self_->setPlotBackgroundColor(_plotBackgroundColor));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_plot_plot_Plot2d_setPlotGridColor(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::plot;

    if(!PyObject_TypeCheck(self, &pyopencv_plot_Plot2d_Type))
        return failmsgp("Incorrect type of self (must be 'plot_Plot2d' or its derivative)");
    cv::plot::Plot2d* _self_ = dynamic_cast<cv::plot::Plot2d*>(((pyopencv_plot_Plot2d_t*)self)->v.get());
    PyObject* pyobj__plotGridColor = NULL;
    Scalar _plotGridColor;

    const char* keywords[] = { "_plotGridColor", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:plot_Plot2d.setPlotGridColor", (char**)keywords, &pyobj__plotGridColor) &&
        pyopencv_to(pyobj__plotGridColor, _plotGridColor, ArgInfo("_plotGridColor", 0)) )
    {
        ERRWRAP2(_self_->setPlotGridColor(_plotGridColor));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_plot_plot_Plot2d_setPlotLineColor(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::plot;

    if(!PyObject_TypeCheck(self, &pyopencv_plot_Plot2d_Type))
        return failmsgp("Incorrect type of self (must be 'plot_Plot2d' or its derivative)");
    cv::plot::Plot2d* _self_ = dynamic_cast<cv::plot::Plot2d*>(((pyopencv_plot_Plot2d_t*)self)->v.get());
    PyObject* pyobj__plotLineColor = NULL;
    Scalar _plotLineColor;

    const char* keywords[] = { "_plotLineColor", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:plot_Plot2d.setPlotLineColor", (char**)keywords, &pyobj__plotLineColor) &&
        pyopencv_to(pyobj__plotLineColor, _plotLineColor, ArgInfo("_plotLineColor", 0)) )
    {
        ERRWRAP2(_self_->setPlotLineColor(_plotLineColor));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_plot_plot_Plot2d_setPlotLineWidth(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::plot;

    if(!PyObject_TypeCheck(self, &pyopencv_plot_Plot2d_Type))
        return failmsgp("Incorrect type of self (must be 'plot_Plot2d' or its derivative)");
    cv::plot::Plot2d* _self_ = dynamic_cast<cv::plot::Plot2d*>(((pyopencv_plot_Plot2d_t*)self)->v.get());
    int _plotLineWidth=0;

    const char* keywords[] = { "_plotLineWidth", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:plot_Plot2d.setPlotLineWidth", (char**)keywords, &_plotLineWidth) )
    {
        ERRWRAP2(_self_->setPlotLineWidth(_plotLineWidth));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_plot_plot_Plot2d_setPlotSize(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::plot;

    if(!PyObject_TypeCheck(self, &pyopencv_plot_Plot2d_Type))
        return failmsgp("Incorrect type of self (must be 'plot_Plot2d' or its derivative)");
    cv::plot::Plot2d* _self_ = dynamic_cast<cv::plot::Plot2d*>(((pyopencv_plot_Plot2d_t*)self)->v.get());
    int _plotSizeWidth=0;
    int _plotSizeHeight=0;

    const char* keywords[] = { "_plotSizeWidth", "_plotSizeHeight", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "ii:plot_Plot2d.setPlotSize", (char**)keywords, &_plotSizeWidth, &_plotSizeHeight) )
    {
        ERRWRAP2(_self_->setPlotSize(_plotSizeWidth, _plotSizeHeight));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_plot_plot_Plot2d_setPlotTextColor(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::plot;

    if(!PyObject_TypeCheck(self, &pyopencv_plot_Plot2d_Type))
        return failmsgp("Incorrect type of self (must be 'plot_Plot2d' or its derivative)");
    cv::plot::Plot2d* _self_ = dynamic_cast<cv::plot::Plot2d*>(((pyopencv_plot_Plot2d_t*)self)->v.get());
    PyObject* pyobj__plotTextColor = NULL;
    Scalar _plotTextColor;

    const char* keywords[] = { "_plotTextColor", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:plot_Plot2d.setPlotTextColor", (char**)keywords, &pyobj__plotTextColor) &&
        pyopencv_to(pyobj__plotTextColor, _plotTextColor, ArgInfo("_plotTextColor", 0)) )
    {
        ERRWRAP2(_self_->setPlotTextColor(_plotTextColor));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_plot_Plot2d_methods[] =
{
    {"render", (PyCFunction)pyopencv_cv_plot_plot_Plot2d_render, METH_VARARGS | METH_KEYWORDS, "render([, _plotResult]) -> _plotResult"},
    {"setMaxX", (PyCFunction)pyopencv_cv_plot_plot_Plot2d_setMaxX, METH_VARARGS | METH_KEYWORDS, "setMaxX(_plotMaxX) -> None"},
    {"setMaxY", (PyCFunction)pyopencv_cv_plot_plot_Plot2d_setMaxY, METH_VARARGS | METH_KEYWORDS, "setMaxY(_plotMaxY) -> None"},
    {"setMinX", (PyCFunction)pyopencv_cv_plot_plot_Plot2d_setMinX, METH_VARARGS | METH_KEYWORDS, "setMinX(_plotMinX) -> None"},
    {"setMinY", (PyCFunction)pyopencv_cv_plot_plot_Plot2d_setMinY, METH_VARARGS | METH_KEYWORDS, "setMinY(_plotMinY) -> None"},
    {"setNeedPlotLine", (PyCFunction)pyopencv_cv_plot_plot_Plot2d_setNeedPlotLine, METH_VARARGS | METH_KEYWORDS, "setNeedPlotLine(_needPlotLine) -> None"},
    {"setPlotAxisColor", (PyCFunction)pyopencv_cv_plot_plot_Plot2d_setPlotAxisColor, METH_VARARGS | METH_KEYWORDS, "setPlotAxisColor(_plotAxisColor) -> None"},
    {"setPlotBackgroundColor", (PyCFunction)pyopencv_cv_plot_plot_Plot2d_setPlotBackgroundColor, METH_VARARGS | METH_KEYWORDS, "setPlotBackgroundColor(_plotBackgroundColor) -> None"},
    {"setPlotGridColor", (PyCFunction)pyopencv_cv_plot_plot_Plot2d_setPlotGridColor, METH_VARARGS | METH_KEYWORDS, "setPlotGridColor(_plotGridColor) -> None"},
    {"setPlotLineColor", (PyCFunction)pyopencv_cv_plot_plot_Plot2d_setPlotLineColor, METH_VARARGS | METH_KEYWORDS, "setPlotLineColor(_plotLineColor) -> None"},
    {"setPlotLineWidth", (PyCFunction)pyopencv_cv_plot_plot_Plot2d_setPlotLineWidth, METH_VARARGS | METH_KEYWORDS, "setPlotLineWidth(_plotLineWidth) -> None"},
    {"setPlotSize", (PyCFunction)pyopencv_cv_plot_plot_Plot2d_setPlotSize, METH_VARARGS | METH_KEYWORDS, "setPlotSize(_plotSizeWidth, _plotSizeHeight) -> None"},
    {"setPlotTextColor", (PyCFunction)pyopencv_cv_plot_plot_Plot2d_setPlotTextColor, METH_VARARGS | METH_KEYWORDS, "setPlotTextColor(_plotTextColor) -> None"},

    {NULL,          NULL}
};

static void pyopencv_plot_Plot2d_specials(void)
{
    pyopencv_plot_Plot2d_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_plot_Plot2d_Type.tp_dealloc = pyopencv_plot_Plot2d_dealloc;
    pyopencv_plot_Plot2d_Type.tp_repr = pyopencv_plot_Plot2d_repr;
    pyopencv_plot_Plot2d_Type.tp_getset = pyopencv_plot_Plot2d_getseters;
    pyopencv_plot_Plot2d_Type.tp_methods = pyopencv_plot_Plot2d_methods;
}

static PyObject* pyopencv_xphoto_WhiteBalancer_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<xphoto_WhiteBalancer %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_xphoto_WhiteBalancer_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_xphoto_xphoto_WhiteBalancer_balanceWhite(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xphoto;

    if(!PyObject_TypeCheck(self, &pyopencv_xphoto_WhiteBalancer_Type))
        return failmsgp("Incorrect type of self (must be 'xphoto_WhiteBalancer' or its derivative)");
    cv::xphoto::WhiteBalancer* _self_ = dynamic_cast<cv::xphoto::WhiteBalancer*>(((pyopencv_xphoto_WhiteBalancer_t*)self)->v.get());
    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;

    const char* keywords[] = { "src", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:xphoto_WhiteBalancer.balanceWhite", (char**)keywords, &pyobj_src, &pyobj_dst) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(_self_->balanceWhite(src, dst));
        return pyopencv_from(dst);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;

    const char* keywords[] = { "src", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:xphoto_WhiteBalancer.balanceWhite", (char**)keywords, &pyobj_src, &pyobj_dst) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(_self_->balanceWhite(src, dst));
        return pyopencv_from(dst);
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_xphoto_WhiteBalancer_methods[] =
{
    {"balanceWhite", (PyCFunction)pyopencv_cv_xphoto_xphoto_WhiteBalancer_balanceWhite, METH_VARARGS | METH_KEYWORDS, "balanceWhite(src[, dst]) -> dst"},

    {NULL,          NULL}
};

static void pyopencv_xphoto_WhiteBalancer_specials(void)
{
    pyopencv_xphoto_WhiteBalancer_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_xphoto_WhiteBalancer_Type.tp_dealloc = pyopencv_xphoto_WhiteBalancer_dealloc;
    pyopencv_xphoto_WhiteBalancer_Type.tp_repr = pyopencv_xphoto_WhiteBalancer_repr;
    pyopencv_xphoto_WhiteBalancer_Type.tp_getset = pyopencv_xphoto_WhiteBalancer_getseters;
    pyopencv_xphoto_WhiteBalancer_Type.tp_methods = pyopencv_xphoto_WhiteBalancer_methods;
}

static PyObject* pyopencv_xphoto_SimpleWB_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<xphoto_SimpleWB %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_xphoto_SimpleWB_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_xphoto_xphoto_SimpleWB_getInputMax(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xphoto;

    if(!PyObject_TypeCheck(self, &pyopencv_xphoto_SimpleWB_Type))
        return failmsgp("Incorrect type of self (must be 'xphoto_SimpleWB' or its derivative)");
    cv::xphoto::SimpleWB* _self_ = dynamic_cast<cv::xphoto::SimpleWB*>(((pyopencv_xphoto_SimpleWB_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getInputMax());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xphoto_xphoto_SimpleWB_getInputMin(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xphoto;

    if(!PyObject_TypeCheck(self, &pyopencv_xphoto_SimpleWB_Type))
        return failmsgp("Incorrect type of self (must be 'xphoto_SimpleWB' or its derivative)");
    cv::xphoto::SimpleWB* _self_ = dynamic_cast<cv::xphoto::SimpleWB*>(((pyopencv_xphoto_SimpleWB_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getInputMin());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xphoto_xphoto_SimpleWB_getOutputMax(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xphoto;

    if(!PyObject_TypeCheck(self, &pyopencv_xphoto_SimpleWB_Type))
        return failmsgp("Incorrect type of self (must be 'xphoto_SimpleWB' or its derivative)");
    cv::xphoto::SimpleWB* _self_ = dynamic_cast<cv::xphoto::SimpleWB*>(((pyopencv_xphoto_SimpleWB_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getOutputMax());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xphoto_xphoto_SimpleWB_getOutputMin(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xphoto;

    if(!PyObject_TypeCheck(self, &pyopencv_xphoto_SimpleWB_Type))
        return failmsgp("Incorrect type of self (must be 'xphoto_SimpleWB' or its derivative)");
    cv::xphoto::SimpleWB* _self_ = dynamic_cast<cv::xphoto::SimpleWB*>(((pyopencv_xphoto_SimpleWB_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getOutputMin());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xphoto_xphoto_SimpleWB_getP(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xphoto;

    if(!PyObject_TypeCheck(self, &pyopencv_xphoto_SimpleWB_Type))
        return failmsgp("Incorrect type of self (must be 'xphoto_SimpleWB' or its derivative)");
    cv::xphoto::SimpleWB* _self_ = dynamic_cast<cv::xphoto::SimpleWB*>(((pyopencv_xphoto_SimpleWB_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getP());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xphoto_xphoto_SimpleWB_setInputMax(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xphoto;

    if(!PyObject_TypeCheck(self, &pyopencv_xphoto_SimpleWB_Type))
        return failmsgp("Incorrect type of self (must be 'xphoto_SimpleWB' or its derivative)");
    cv::xphoto::SimpleWB* _self_ = dynamic_cast<cv::xphoto::SimpleWB*>(((pyopencv_xphoto_SimpleWB_t*)self)->v.get());
    float val=0.f;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:xphoto_SimpleWB.setInputMax", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setInputMax(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_xphoto_xphoto_SimpleWB_setInputMin(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xphoto;

    if(!PyObject_TypeCheck(self, &pyopencv_xphoto_SimpleWB_Type))
        return failmsgp("Incorrect type of self (must be 'xphoto_SimpleWB' or its derivative)");
    cv::xphoto::SimpleWB* _self_ = dynamic_cast<cv::xphoto::SimpleWB*>(((pyopencv_xphoto_SimpleWB_t*)self)->v.get());
    float val=0.f;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:xphoto_SimpleWB.setInputMin", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setInputMin(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_xphoto_xphoto_SimpleWB_setOutputMax(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xphoto;

    if(!PyObject_TypeCheck(self, &pyopencv_xphoto_SimpleWB_Type))
        return failmsgp("Incorrect type of self (must be 'xphoto_SimpleWB' or its derivative)");
    cv::xphoto::SimpleWB* _self_ = dynamic_cast<cv::xphoto::SimpleWB*>(((pyopencv_xphoto_SimpleWB_t*)self)->v.get());
    float val=0.f;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:xphoto_SimpleWB.setOutputMax", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setOutputMax(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_xphoto_xphoto_SimpleWB_setOutputMin(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xphoto;

    if(!PyObject_TypeCheck(self, &pyopencv_xphoto_SimpleWB_Type))
        return failmsgp("Incorrect type of self (must be 'xphoto_SimpleWB' or its derivative)");
    cv::xphoto::SimpleWB* _self_ = dynamic_cast<cv::xphoto::SimpleWB*>(((pyopencv_xphoto_SimpleWB_t*)self)->v.get());
    float val=0.f;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:xphoto_SimpleWB.setOutputMin", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setOutputMin(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_xphoto_xphoto_SimpleWB_setP(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xphoto;

    if(!PyObject_TypeCheck(self, &pyopencv_xphoto_SimpleWB_Type))
        return failmsgp("Incorrect type of self (must be 'xphoto_SimpleWB' or its derivative)");
    cv::xphoto::SimpleWB* _self_ = dynamic_cast<cv::xphoto::SimpleWB*>(((pyopencv_xphoto_SimpleWB_t*)self)->v.get());
    float val=0.f;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:xphoto_SimpleWB.setP", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setP(val));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_xphoto_SimpleWB_methods[] =
{
    {"getInputMax", (PyCFunction)pyopencv_cv_xphoto_xphoto_SimpleWB_getInputMax, METH_VARARGS | METH_KEYWORDS, "getInputMax() -> retval"},
    {"getInputMin", (PyCFunction)pyopencv_cv_xphoto_xphoto_SimpleWB_getInputMin, METH_VARARGS | METH_KEYWORDS, "getInputMin() -> retval"},
    {"getOutputMax", (PyCFunction)pyopencv_cv_xphoto_xphoto_SimpleWB_getOutputMax, METH_VARARGS | METH_KEYWORDS, "getOutputMax() -> retval"},
    {"getOutputMin", (PyCFunction)pyopencv_cv_xphoto_xphoto_SimpleWB_getOutputMin, METH_VARARGS | METH_KEYWORDS, "getOutputMin() -> retval"},
    {"getP", (PyCFunction)pyopencv_cv_xphoto_xphoto_SimpleWB_getP, METH_VARARGS | METH_KEYWORDS, "getP() -> retval"},
    {"setInputMax", (PyCFunction)pyopencv_cv_xphoto_xphoto_SimpleWB_setInputMax, METH_VARARGS | METH_KEYWORDS, "setInputMax(val) -> None"},
    {"setInputMin", (PyCFunction)pyopencv_cv_xphoto_xphoto_SimpleWB_setInputMin, METH_VARARGS | METH_KEYWORDS, "setInputMin(val) -> None"},
    {"setOutputMax", (PyCFunction)pyopencv_cv_xphoto_xphoto_SimpleWB_setOutputMax, METH_VARARGS | METH_KEYWORDS, "setOutputMax(val) -> None"},
    {"setOutputMin", (PyCFunction)pyopencv_cv_xphoto_xphoto_SimpleWB_setOutputMin, METH_VARARGS | METH_KEYWORDS, "setOutputMin(val) -> None"},
    {"setP", (PyCFunction)pyopencv_cv_xphoto_xphoto_SimpleWB_setP, METH_VARARGS | METH_KEYWORDS, "setP(val) -> None"},

    {NULL,          NULL}
};

static void pyopencv_xphoto_SimpleWB_specials(void)
{
    pyopencv_xphoto_SimpleWB_Type.tp_base = &pyopencv_xphoto_WhiteBalancer_Type;
    pyopencv_xphoto_SimpleWB_Type.tp_dealloc = pyopencv_xphoto_SimpleWB_dealloc;
    pyopencv_xphoto_SimpleWB_Type.tp_repr = pyopencv_xphoto_SimpleWB_repr;
    pyopencv_xphoto_SimpleWB_Type.tp_getset = pyopencv_xphoto_SimpleWB_getseters;
    pyopencv_xphoto_SimpleWB_Type.tp_methods = pyopencv_xphoto_SimpleWB_methods;
}

static PyObject* pyopencv_xphoto_GrayworldWB_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<xphoto_GrayworldWB %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_xphoto_GrayworldWB_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_xphoto_xphoto_GrayworldWB_getSaturationThreshold(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xphoto;

    if(!PyObject_TypeCheck(self, &pyopencv_xphoto_GrayworldWB_Type))
        return failmsgp("Incorrect type of self (must be 'xphoto_GrayworldWB' or its derivative)");
    cv::xphoto::GrayworldWB* _self_ = dynamic_cast<cv::xphoto::GrayworldWB*>(((pyopencv_xphoto_GrayworldWB_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getSaturationThreshold());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xphoto_xphoto_GrayworldWB_setSaturationThreshold(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xphoto;

    if(!PyObject_TypeCheck(self, &pyopencv_xphoto_GrayworldWB_Type))
        return failmsgp("Incorrect type of self (must be 'xphoto_GrayworldWB' or its derivative)");
    cv::xphoto::GrayworldWB* _self_ = dynamic_cast<cv::xphoto::GrayworldWB*>(((pyopencv_xphoto_GrayworldWB_t*)self)->v.get());
    float val=0.f;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:xphoto_GrayworldWB.setSaturationThreshold", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setSaturationThreshold(val));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_xphoto_GrayworldWB_methods[] =
{
    {"getSaturationThreshold", (PyCFunction)pyopencv_cv_xphoto_xphoto_GrayworldWB_getSaturationThreshold, METH_VARARGS | METH_KEYWORDS, "getSaturationThreshold() -> retval"},
    {"setSaturationThreshold", (PyCFunction)pyopencv_cv_xphoto_xphoto_GrayworldWB_setSaturationThreshold, METH_VARARGS | METH_KEYWORDS, "setSaturationThreshold(val) -> None"},

    {NULL,          NULL}
};

static void pyopencv_xphoto_GrayworldWB_specials(void)
{
    pyopencv_xphoto_GrayworldWB_Type.tp_base = &pyopencv_xphoto_WhiteBalancer_Type;
    pyopencv_xphoto_GrayworldWB_Type.tp_dealloc = pyopencv_xphoto_GrayworldWB_dealloc;
    pyopencv_xphoto_GrayworldWB_Type.tp_repr = pyopencv_xphoto_GrayworldWB_repr;
    pyopencv_xphoto_GrayworldWB_Type.tp_getset = pyopencv_xphoto_GrayworldWB_getseters;
    pyopencv_xphoto_GrayworldWB_Type.tp_methods = pyopencv_xphoto_GrayworldWB_methods;
}

static PyObject* pyopencv_xphoto_LearningBasedWB_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<xphoto_LearningBasedWB %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_xphoto_LearningBasedWB_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_xphoto_xphoto_LearningBasedWB_extractSimpleFeatures(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xphoto;

    if(!PyObject_TypeCheck(self, &pyopencv_xphoto_LearningBasedWB_Type))
        return failmsgp("Incorrect type of self (must be 'xphoto_LearningBasedWB' or its derivative)");
    cv::xphoto::LearningBasedWB* _self_ = dynamic_cast<cv::xphoto::LearningBasedWB*>(((pyopencv_xphoto_LearningBasedWB_t*)self)->v.get());
    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;

    const char* keywords[] = { "src", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:xphoto_LearningBasedWB.extractSimpleFeatures", (char**)keywords, &pyobj_src, &pyobj_dst) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(_self_->extractSimpleFeatures(src, dst));
        return pyopencv_from(dst);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;

    const char* keywords[] = { "src", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:xphoto_LearningBasedWB.extractSimpleFeatures", (char**)keywords, &pyobj_src, &pyobj_dst) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(_self_->extractSimpleFeatures(src, dst));
        return pyopencv_from(dst);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_xphoto_xphoto_LearningBasedWB_getHistBinNum(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xphoto;

    if(!PyObject_TypeCheck(self, &pyopencv_xphoto_LearningBasedWB_Type))
        return failmsgp("Incorrect type of self (must be 'xphoto_LearningBasedWB' or its derivative)");
    cv::xphoto::LearningBasedWB* _self_ = dynamic_cast<cv::xphoto::LearningBasedWB*>(((pyopencv_xphoto_LearningBasedWB_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getHistBinNum());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xphoto_xphoto_LearningBasedWB_getRangeMaxVal(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xphoto;

    if(!PyObject_TypeCheck(self, &pyopencv_xphoto_LearningBasedWB_Type))
        return failmsgp("Incorrect type of self (must be 'xphoto_LearningBasedWB' or its derivative)");
    cv::xphoto::LearningBasedWB* _self_ = dynamic_cast<cv::xphoto::LearningBasedWB*>(((pyopencv_xphoto_LearningBasedWB_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getRangeMaxVal());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xphoto_xphoto_LearningBasedWB_getSaturationThreshold(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xphoto;

    if(!PyObject_TypeCheck(self, &pyopencv_xphoto_LearningBasedWB_Type))
        return failmsgp("Incorrect type of self (must be 'xphoto_LearningBasedWB' or its derivative)");
    cv::xphoto::LearningBasedWB* _self_ = dynamic_cast<cv::xphoto::LearningBasedWB*>(((pyopencv_xphoto_LearningBasedWB_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getSaturationThreshold());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xphoto_xphoto_LearningBasedWB_setHistBinNum(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xphoto;

    if(!PyObject_TypeCheck(self, &pyopencv_xphoto_LearningBasedWB_Type))
        return failmsgp("Incorrect type of self (must be 'xphoto_LearningBasedWB' or its derivative)");
    cv::xphoto::LearningBasedWB* _self_ = dynamic_cast<cv::xphoto::LearningBasedWB*>(((pyopencv_xphoto_LearningBasedWB_t*)self)->v.get());
    int val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:xphoto_LearningBasedWB.setHistBinNum", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setHistBinNum(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_xphoto_xphoto_LearningBasedWB_setRangeMaxVal(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xphoto;

    if(!PyObject_TypeCheck(self, &pyopencv_xphoto_LearningBasedWB_Type))
        return failmsgp("Incorrect type of self (must be 'xphoto_LearningBasedWB' or its derivative)");
    cv::xphoto::LearningBasedWB* _self_ = dynamic_cast<cv::xphoto::LearningBasedWB*>(((pyopencv_xphoto_LearningBasedWB_t*)self)->v.get());
    int val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:xphoto_LearningBasedWB.setRangeMaxVal", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setRangeMaxVal(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_xphoto_xphoto_LearningBasedWB_setSaturationThreshold(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xphoto;

    if(!PyObject_TypeCheck(self, &pyopencv_xphoto_LearningBasedWB_Type))
        return failmsgp("Incorrect type of self (must be 'xphoto_LearningBasedWB' or its derivative)");
    cv::xphoto::LearningBasedWB* _self_ = dynamic_cast<cv::xphoto::LearningBasedWB*>(((pyopencv_xphoto_LearningBasedWB_t*)self)->v.get());
    float val=0.f;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:xphoto_LearningBasedWB.setSaturationThreshold", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setSaturationThreshold(val));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_xphoto_LearningBasedWB_methods[] =
{
    {"extractSimpleFeatures", (PyCFunction)pyopencv_cv_xphoto_xphoto_LearningBasedWB_extractSimpleFeatures, METH_VARARGS | METH_KEYWORDS, "extractSimpleFeatures(src[, dst]) -> dst"},
    {"getHistBinNum", (PyCFunction)pyopencv_cv_xphoto_xphoto_LearningBasedWB_getHistBinNum, METH_VARARGS | METH_KEYWORDS, "getHistBinNum() -> retval"},
    {"getRangeMaxVal", (PyCFunction)pyopencv_cv_xphoto_xphoto_LearningBasedWB_getRangeMaxVal, METH_VARARGS | METH_KEYWORDS, "getRangeMaxVal() -> retval"},
    {"getSaturationThreshold", (PyCFunction)pyopencv_cv_xphoto_xphoto_LearningBasedWB_getSaturationThreshold, METH_VARARGS | METH_KEYWORDS, "getSaturationThreshold() -> retval"},
    {"setHistBinNum", (PyCFunction)pyopencv_cv_xphoto_xphoto_LearningBasedWB_setHistBinNum, METH_VARARGS | METH_KEYWORDS, "setHistBinNum(val) -> None"},
    {"setRangeMaxVal", (PyCFunction)pyopencv_cv_xphoto_xphoto_LearningBasedWB_setRangeMaxVal, METH_VARARGS | METH_KEYWORDS, "setRangeMaxVal(val) -> None"},
    {"setSaturationThreshold", (PyCFunction)pyopencv_cv_xphoto_xphoto_LearningBasedWB_setSaturationThreshold, METH_VARARGS | METH_KEYWORDS, "setSaturationThreshold(val) -> None"},

    {NULL,          NULL}
};

static void pyopencv_xphoto_LearningBasedWB_specials(void)
{
    pyopencv_xphoto_LearningBasedWB_Type.tp_base = &pyopencv_xphoto_WhiteBalancer_Type;
    pyopencv_xphoto_LearningBasedWB_Type.tp_dealloc = pyopencv_xphoto_LearningBasedWB_dealloc;
    pyopencv_xphoto_LearningBasedWB_Type.tp_repr = pyopencv_xphoto_LearningBasedWB_repr;
    pyopencv_xphoto_LearningBasedWB_Type.tp_getset = pyopencv_xphoto_LearningBasedWB_getseters;
    pyopencv_xphoto_LearningBasedWB_Type.tp_methods = pyopencv_xphoto_LearningBasedWB_methods;
}

static PyObject* pyopencv_bgsegm_BackgroundSubtractorMOG_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<bgsegm_BackgroundSubtractorMOG %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_bgsegm_BackgroundSubtractorMOG_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorMOG_getBackgroundRatio(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bgsegm;

    if(!PyObject_TypeCheck(self, &pyopencv_bgsegm_BackgroundSubtractorMOG_Type))
        return failmsgp("Incorrect type of self (must be 'bgsegm_BackgroundSubtractorMOG' or its derivative)");
    cv::bgsegm::BackgroundSubtractorMOG* _self_ = dynamic_cast<cv::bgsegm::BackgroundSubtractorMOG*>(((pyopencv_bgsegm_BackgroundSubtractorMOG_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getBackgroundRatio());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorMOG_getHistory(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bgsegm;

    if(!PyObject_TypeCheck(self, &pyopencv_bgsegm_BackgroundSubtractorMOG_Type))
        return failmsgp("Incorrect type of self (must be 'bgsegm_BackgroundSubtractorMOG' or its derivative)");
    cv::bgsegm::BackgroundSubtractorMOG* _self_ = dynamic_cast<cv::bgsegm::BackgroundSubtractorMOG*>(((pyopencv_bgsegm_BackgroundSubtractorMOG_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getHistory());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorMOG_getNMixtures(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bgsegm;

    if(!PyObject_TypeCheck(self, &pyopencv_bgsegm_BackgroundSubtractorMOG_Type))
        return failmsgp("Incorrect type of self (must be 'bgsegm_BackgroundSubtractorMOG' or its derivative)");
    cv::bgsegm::BackgroundSubtractorMOG* _self_ = dynamic_cast<cv::bgsegm::BackgroundSubtractorMOG*>(((pyopencv_bgsegm_BackgroundSubtractorMOG_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getNMixtures());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorMOG_getNoiseSigma(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bgsegm;

    if(!PyObject_TypeCheck(self, &pyopencv_bgsegm_BackgroundSubtractorMOG_Type))
        return failmsgp("Incorrect type of self (must be 'bgsegm_BackgroundSubtractorMOG' or its derivative)");
    cv::bgsegm::BackgroundSubtractorMOG* _self_ = dynamic_cast<cv::bgsegm::BackgroundSubtractorMOG*>(((pyopencv_bgsegm_BackgroundSubtractorMOG_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getNoiseSigma());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorMOG_setBackgroundRatio(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bgsegm;

    if(!PyObject_TypeCheck(self, &pyopencv_bgsegm_BackgroundSubtractorMOG_Type))
        return failmsgp("Incorrect type of self (must be 'bgsegm_BackgroundSubtractorMOG' or its derivative)");
    cv::bgsegm::BackgroundSubtractorMOG* _self_ = dynamic_cast<cv::bgsegm::BackgroundSubtractorMOG*>(((pyopencv_bgsegm_BackgroundSubtractorMOG_t*)self)->v.get());
    double backgroundRatio=0;

    const char* keywords[] = { "backgroundRatio", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:bgsegm_BackgroundSubtractorMOG.setBackgroundRatio", (char**)keywords, &backgroundRatio) )
    {
        ERRWRAP2(_self_->setBackgroundRatio(backgroundRatio));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorMOG_setHistory(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bgsegm;

    if(!PyObject_TypeCheck(self, &pyopencv_bgsegm_BackgroundSubtractorMOG_Type))
        return failmsgp("Incorrect type of self (must be 'bgsegm_BackgroundSubtractorMOG' or its derivative)");
    cv::bgsegm::BackgroundSubtractorMOG* _self_ = dynamic_cast<cv::bgsegm::BackgroundSubtractorMOG*>(((pyopencv_bgsegm_BackgroundSubtractorMOG_t*)self)->v.get());
    int nframes=0;

    const char* keywords[] = { "nframes", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:bgsegm_BackgroundSubtractorMOG.setHistory", (char**)keywords, &nframes) )
    {
        ERRWRAP2(_self_->setHistory(nframes));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorMOG_setNMixtures(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bgsegm;

    if(!PyObject_TypeCheck(self, &pyopencv_bgsegm_BackgroundSubtractorMOG_Type))
        return failmsgp("Incorrect type of self (must be 'bgsegm_BackgroundSubtractorMOG' or its derivative)");
    cv::bgsegm::BackgroundSubtractorMOG* _self_ = dynamic_cast<cv::bgsegm::BackgroundSubtractorMOG*>(((pyopencv_bgsegm_BackgroundSubtractorMOG_t*)self)->v.get());
    int nmix=0;

    const char* keywords[] = { "nmix", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:bgsegm_BackgroundSubtractorMOG.setNMixtures", (char**)keywords, &nmix) )
    {
        ERRWRAP2(_self_->setNMixtures(nmix));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorMOG_setNoiseSigma(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bgsegm;

    if(!PyObject_TypeCheck(self, &pyopencv_bgsegm_BackgroundSubtractorMOG_Type))
        return failmsgp("Incorrect type of self (must be 'bgsegm_BackgroundSubtractorMOG' or its derivative)");
    cv::bgsegm::BackgroundSubtractorMOG* _self_ = dynamic_cast<cv::bgsegm::BackgroundSubtractorMOG*>(((pyopencv_bgsegm_BackgroundSubtractorMOG_t*)self)->v.get());
    double noiseSigma=0;

    const char* keywords[] = { "noiseSigma", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:bgsegm_BackgroundSubtractorMOG.setNoiseSigma", (char**)keywords, &noiseSigma) )
    {
        ERRWRAP2(_self_->setNoiseSigma(noiseSigma));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_bgsegm_BackgroundSubtractorMOG_methods[] =
{
    {"getBackgroundRatio", (PyCFunction)pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorMOG_getBackgroundRatio, METH_VARARGS | METH_KEYWORDS, "getBackgroundRatio() -> retval"},
    {"getHistory", (PyCFunction)pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorMOG_getHistory, METH_VARARGS | METH_KEYWORDS, "getHistory() -> retval"},
    {"getNMixtures", (PyCFunction)pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorMOG_getNMixtures, METH_VARARGS | METH_KEYWORDS, "getNMixtures() -> retval"},
    {"getNoiseSigma", (PyCFunction)pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorMOG_getNoiseSigma, METH_VARARGS | METH_KEYWORDS, "getNoiseSigma() -> retval"},
    {"setBackgroundRatio", (PyCFunction)pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorMOG_setBackgroundRatio, METH_VARARGS | METH_KEYWORDS, "setBackgroundRatio(backgroundRatio) -> None"},
    {"setHistory", (PyCFunction)pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorMOG_setHistory, METH_VARARGS | METH_KEYWORDS, "setHistory(nframes) -> None"},
    {"setNMixtures", (PyCFunction)pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorMOG_setNMixtures, METH_VARARGS | METH_KEYWORDS, "setNMixtures(nmix) -> None"},
    {"setNoiseSigma", (PyCFunction)pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorMOG_setNoiseSigma, METH_VARARGS | METH_KEYWORDS, "setNoiseSigma(noiseSigma) -> None"},

    {NULL,          NULL}
};

static void pyopencv_bgsegm_BackgroundSubtractorMOG_specials(void)
{
    pyopencv_bgsegm_BackgroundSubtractorMOG_Type.tp_base = &pyopencv_BackgroundSubtractor_Type;
    pyopencv_bgsegm_BackgroundSubtractorMOG_Type.tp_dealloc = pyopencv_bgsegm_BackgroundSubtractorMOG_dealloc;
    pyopencv_bgsegm_BackgroundSubtractorMOG_Type.tp_repr = pyopencv_bgsegm_BackgroundSubtractorMOG_repr;
    pyopencv_bgsegm_BackgroundSubtractorMOG_Type.tp_getset = pyopencv_bgsegm_BackgroundSubtractorMOG_getseters;
    pyopencv_bgsegm_BackgroundSubtractorMOG_Type.tp_methods = pyopencv_bgsegm_BackgroundSubtractorMOG_methods;
}

static PyObject* pyopencv_bgsegm_BackgroundSubtractorGMG_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<bgsegm_BackgroundSubtractorGMG %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_bgsegm_BackgroundSubtractorGMG_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorGMG_getBackgroundPrior(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bgsegm;

    if(!PyObject_TypeCheck(self, &pyopencv_bgsegm_BackgroundSubtractorGMG_Type))
        return failmsgp("Incorrect type of self (must be 'bgsegm_BackgroundSubtractorGMG' or its derivative)");
    cv::bgsegm::BackgroundSubtractorGMG* _self_ = dynamic_cast<cv::bgsegm::BackgroundSubtractorGMG*>(((pyopencv_bgsegm_BackgroundSubtractorGMG_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getBackgroundPrior());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorGMG_getDecisionThreshold(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bgsegm;

    if(!PyObject_TypeCheck(self, &pyopencv_bgsegm_BackgroundSubtractorGMG_Type))
        return failmsgp("Incorrect type of self (must be 'bgsegm_BackgroundSubtractorGMG' or its derivative)");
    cv::bgsegm::BackgroundSubtractorGMG* _self_ = dynamic_cast<cv::bgsegm::BackgroundSubtractorGMG*>(((pyopencv_bgsegm_BackgroundSubtractorGMG_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getDecisionThreshold());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorGMG_getDefaultLearningRate(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bgsegm;

    if(!PyObject_TypeCheck(self, &pyopencv_bgsegm_BackgroundSubtractorGMG_Type))
        return failmsgp("Incorrect type of self (must be 'bgsegm_BackgroundSubtractorGMG' or its derivative)");
    cv::bgsegm::BackgroundSubtractorGMG* _self_ = dynamic_cast<cv::bgsegm::BackgroundSubtractorGMG*>(((pyopencv_bgsegm_BackgroundSubtractorGMG_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getDefaultLearningRate());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorGMG_getMaxFeatures(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bgsegm;

    if(!PyObject_TypeCheck(self, &pyopencv_bgsegm_BackgroundSubtractorGMG_Type))
        return failmsgp("Incorrect type of self (must be 'bgsegm_BackgroundSubtractorGMG' or its derivative)");
    cv::bgsegm::BackgroundSubtractorGMG* _self_ = dynamic_cast<cv::bgsegm::BackgroundSubtractorGMG*>(((pyopencv_bgsegm_BackgroundSubtractorGMG_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getMaxFeatures());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorGMG_getMaxVal(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bgsegm;

    if(!PyObject_TypeCheck(self, &pyopencv_bgsegm_BackgroundSubtractorGMG_Type))
        return failmsgp("Incorrect type of self (must be 'bgsegm_BackgroundSubtractorGMG' or its derivative)");
    cv::bgsegm::BackgroundSubtractorGMG* _self_ = dynamic_cast<cv::bgsegm::BackgroundSubtractorGMG*>(((pyopencv_bgsegm_BackgroundSubtractorGMG_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getMaxVal());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorGMG_getMinVal(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bgsegm;

    if(!PyObject_TypeCheck(self, &pyopencv_bgsegm_BackgroundSubtractorGMG_Type))
        return failmsgp("Incorrect type of self (must be 'bgsegm_BackgroundSubtractorGMG' or its derivative)");
    cv::bgsegm::BackgroundSubtractorGMG* _self_ = dynamic_cast<cv::bgsegm::BackgroundSubtractorGMG*>(((pyopencv_bgsegm_BackgroundSubtractorGMG_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getMinVal());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorGMG_getNumFrames(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bgsegm;

    if(!PyObject_TypeCheck(self, &pyopencv_bgsegm_BackgroundSubtractorGMG_Type))
        return failmsgp("Incorrect type of self (must be 'bgsegm_BackgroundSubtractorGMG' or its derivative)");
    cv::bgsegm::BackgroundSubtractorGMG* _self_ = dynamic_cast<cv::bgsegm::BackgroundSubtractorGMG*>(((pyopencv_bgsegm_BackgroundSubtractorGMG_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getNumFrames());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorGMG_getQuantizationLevels(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bgsegm;

    if(!PyObject_TypeCheck(self, &pyopencv_bgsegm_BackgroundSubtractorGMG_Type))
        return failmsgp("Incorrect type of self (must be 'bgsegm_BackgroundSubtractorGMG' or its derivative)");
    cv::bgsegm::BackgroundSubtractorGMG* _self_ = dynamic_cast<cv::bgsegm::BackgroundSubtractorGMG*>(((pyopencv_bgsegm_BackgroundSubtractorGMG_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getQuantizationLevels());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorGMG_getSmoothingRadius(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bgsegm;

    if(!PyObject_TypeCheck(self, &pyopencv_bgsegm_BackgroundSubtractorGMG_Type))
        return failmsgp("Incorrect type of self (must be 'bgsegm_BackgroundSubtractorGMG' or its derivative)");
    cv::bgsegm::BackgroundSubtractorGMG* _self_ = dynamic_cast<cv::bgsegm::BackgroundSubtractorGMG*>(((pyopencv_bgsegm_BackgroundSubtractorGMG_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getSmoothingRadius());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorGMG_getUpdateBackgroundModel(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bgsegm;

    if(!PyObject_TypeCheck(self, &pyopencv_bgsegm_BackgroundSubtractorGMG_Type))
        return failmsgp("Incorrect type of self (must be 'bgsegm_BackgroundSubtractorGMG' or its derivative)");
    cv::bgsegm::BackgroundSubtractorGMG* _self_ = dynamic_cast<cv::bgsegm::BackgroundSubtractorGMG*>(((pyopencv_bgsegm_BackgroundSubtractorGMG_t*)self)->v.get());
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getUpdateBackgroundModel());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorGMG_setBackgroundPrior(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bgsegm;

    if(!PyObject_TypeCheck(self, &pyopencv_bgsegm_BackgroundSubtractorGMG_Type))
        return failmsgp("Incorrect type of self (must be 'bgsegm_BackgroundSubtractorGMG' or its derivative)");
    cv::bgsegm::BackgroundSubtractorGMG* _self_ = dynamic_cast<cv::bgsegm::BackgroundSubtractorGMG*>(((pyopencv_bgsegm_BackgroundSubtractorGMG_t*)self)->v.get());
    double bgprior=0;

    const char* keywords[] = { "bgprior", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:bgsegm_BackgroundSubtractorGMG.setBackgroundPrior", (char**)keywords, &bgprior) )
    {
        ERRWRAP2(_self_->setBackgroundPrior(bgprior));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorGMG_setDecisionThreshold(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bgsegm;

    if(!PyObject_TypeCheck(self, &pyopencv_bgsegm_BackgroundSubtractorGMG_Type))
        return failmsgp("Incorrect type of self (must be 'bgsegm_BackgroundSubtractorGMG' or its derivative)");
    cv::bgsegm::BackgroundSubtractorGMG* _self_ = dynamic_cast<cv::bgsegm::BackgroundSubtractorGMG*>(((pyopencv_bgsegm_BackgroundSubtractorGMG_t*)self)->v.get());
    double thresh=0;

    const char* keywords[] = { "thresh", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:bgsegm_BackgroundSubtractorGMG.setDecisionThreshold", (char**)keywords, &thresh) )
    {
        ERRWRAP2(_self_->setDecisionThreshold(thresh));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorGMG_setDefaultLearningRate(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bgsegm;

    if(!PyObject_TypeCheck(self, &pyopencv_bgsegm_BackgroundSubtractorGMG_Type))
        return failmsgp("Incorrect type of self (must be 'bgsegm_BackgroundSubtractorGMG' or its derivative)");
    cv::bgsegm::BackgroundSubtractorGMG* _self_ = dynamic_cast<cv::bgsegm::BackgroundSubtractorGMG*>(((pyopencv_bgsegm_BackgroundSubtractorGMG_t*)self)->v.get());
    double lr=0;

    const char* keywords[] = { "lr", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:bgsegm_BackgroundSubtractorGMG.setDefaultLearningRate", (char**)keywords, &lr) )
    {
        ERRWRAP2(_self_->setDefaultLearningRate(lr));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorGMG_setMaxFeatures(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bgsegm;

    if(!PyObject_TypeCheck(self, &pyopencv_bgsegm_BackgroundSubtractorGMG_Type))
        return failmsgp("Incorrect type of self (must be 'bgsegm_BackgroundSubtractorGMG' or its derivative)");
    cv::bgsegm::BackgroundSubtractorGMG* _self_ = dynamic_cast<cv::bgsegm::BackgroundSubtractorGMG*>(((pyopencv_bgsegm_BackgroundSubtractorGMG_t*)self)->v.get());
    int maxFeatures=0;

    const char* keywords[] = { "maxFeatures", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:bgsegm_BackgroundSubtractorGMG.setMaxFeatures", (char**)keywords, &maxFeatures) )
    {
        ERRWRAP2(_self_->setMaxFeatures(maxFeatures));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorGMG_setMaxVal(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bgsegm;

    if(!PyObject_TypeCheck(self, &pyopencv_bgsegm_BackgroundSubtractorGMG_Type))
        return failmsgp("Incorrect type of self (must be 'bgsegm_BackgroundSubtractorGMG' or its derivative)");
    cv::bgsegm::BackgroundSubtractorGMG* _self_ = dynamic_cast<cv::bgsegm::BackgroundSubtractorGMG*>(((pyopencv_bgsegm_BackgroundSubtractorGMG_t*)self)->v.get());
    double val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:bgsegm_BackgroundSubtractorGMG.setMaxVal", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setMaxVal(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorGMG_setMinVal(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bgsegm;

    if(!PyObject_TypeCheck(self, &pyopencv_bgsegm_BackgroundSubtractorGMG_Type))
        return failmsgp("Incorrect type of self (must be 'bgsegm_BackgroundSubtractorGMG' or its derivative)");
    cv::bgsegm::BackgroundSubtractorGMG* _self_ = dynamic_cast<cv::bgsegm::BackgroundSubtractorGMG*>(((pyopencv_bgsegm_BackgroundSubtractorGMG_t*)self)->v.get());
    double val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:bgsegm_BackgroundSubtractorGMG.setMinVal", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setMinVal(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorGMG_setNumFrames(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bgsegm;

    if(!PyObject_TypeCheck(self, &pyopencv_bgsegm_BackgroundSubtractorGMG_Type))
        return failmsgp("Incorrect type of self (must be 'bgsegm_BackgroundSubtractorGMG' or its derivative)");
    cv::bgsegm::BackgroundSubtractorGMG* _self_ = dynamic_cast<cv::bgsegm::BackgroundSubtractorGMG*>(((pyopencv_bgsegm_BackgroundSubtractorGMG_t*)self)->v.get());
    int nframes=0;

    const char* keywords[] = { "nframes", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:bgsegm_BackgroundSubtractorGMG.setNumFrames", (char**)keywords, &nframes) )
    {
        ERRWRAP2(_self_->setNumFrames(nframes));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorGMG_setQuantizationLevels(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bgsegm;

    if(!PyObject_TypeCheck(self, &pyopencv_bgsegm_BackgroundSubtractorGMG_Type))
        return failmsgp("Incorrect type of self (must be 'bgsegm_BackgroundSubtractorGMG' or its derivative)");
    cv::bgsegm::BackgroundSubtractorGMG* _self_ = dynamic_cast<cv::bgsegm::BackgroundSubtractorGMG*>(((pyopencv_bgsegm_BackgroundSubtractorGMG_t*)self)->v.get());
    int nlevels=0;

    const char* keywords[] = { "nlevels", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:bgsegm_BackgroundSubtractorGMG.setQuantizationLevels", (char**)keywords, &nlevels) )
    {
        ERRWRAP2(_self_->setQuantizationLevels(nlevels));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorGMG_setSmoothingRadius(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bgsegm;

    if(!PyObject_TypeCheck(self, &pyopencv_bgsegm_BackgroundSubtractorGMG_Type))
        return failmsgp("Incorrect type of self (must be 'bgsegm_BackgroundSubtractorGMG' or its derivative)");
    cv::bgsegm::BackgroundSubtractorGMG* _self_ = dynamic_cast<cv::bgsegm::BackgroundSubtractorGMG*>(((pyopencv_bgsegm_BackgroundSubtractorGMG_t*)self)->v.get());
    int radius=0;

    const char* keywords[] = { "radius", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:bgsegm_BackgroundSubtractorGMG.setSmoothingRadius", (char**)keywords, &radius) )
    {
        ERRWRAP2(_self_->setSmoothingRadius(radius));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorGMG_setUpdateBackgroundModel(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bgsegm;

    if(!PyObject_TypeCheck(self, &pyopencv_bgsegm_BackgroundSubtractorGMG_Type))
        return failmsgp("Incorrect type of self (must be 'bgsegm_BackgroundSubtractorGMG' or its derivative)");
    cv::bgsegm::BackgroundSubtractorGMG* _self_ = dynamic_cast<cv::bgsegm::BackgroundSubtractorGMG*>(((pyopencv_bgsegm_BackgroundSubtractorGMG_t*)self)->v.get());
    bool update=0;

    const char* keywords[] = { "update", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "b:bgsegm_BackgroundSubtractorGMG.setUpdateBackgroundModel", (char**)keywords, &update) )
    {
        ERRWRAP2(_self_->setUpdateBackgroundModel(update));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_bgsegm_BackgroundSubtractorGMG_methods[] =
{
    {"getBackgroundPrior", (PyCFunction)pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorGMG_getBackgroundPrior, METH_VARARGS | METH_KEYWORDS, "getBackgroundPrior() -> retval"},
    {"getDecisionThreshold", (PyCFunction)pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorGMG_getDecisionThreshold, METH_VARARGS | METH_KEYWORDS, "getDecisionThreshold() -> retval"},
    {"getDefaultLearningRate", (PyCFunction)pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorGMG_getDefaultLearningRate, METH_VARARGS | METH_KEYWORDS, "getDefaultLearningRate() -> retval"},
    {"getMaxFeatures", (PyCFunction)pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorGMG_getMaxFeatures, METH_VARARGS | METH_KEYWORDS, "getMaxFeatures() -> retval"},
    {"getMaxVal", (PyCFunction)pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorGMG_getMaxVal, METH_VARARGS | METH_KEYWORDS, "getMaxVal() -> retval"},
    {"getMinVal", (PyCFunction)pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorGMG_getMinVal, METH_VARARGS | METH_KEYWORDS, "getMinVal() -> retval"},
    {"getNumFrames", (PyCFunction)pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorGMG_getNumFrames, METH_VARARGS | METH_KEYWORDS, "getNumFrames() -> retval"},
    {"getQuantizationLevels", (PyCFunction)pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorGMG_getQuantizationLevels, METH_VARARGS | METH_KEYWORDS, "getQuantizationLevels() -> retval"},
    {"getSmoothingRadius", (PyCFunction)pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorGMG_getSmoothingRadius, METH_VARARGS | METH_KEYWORDS, "getSmoothingRadius() -> retval"},
    {"getUpdateBackgroundModel", (PyCFunction)pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorGMG_getUpdateBackgroundModel, METH_VARARGS | METH_KEYWORDS, "getUpdateBackgroundModel() -> retval"},
    {"setBackgroundPrior", (PyCFunction)pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorGMG_setBackgroundPrior, METH_VARARGS | METH_KEYWORDS, "setBackgroundPrior(bgprior) -> None"},
    {"setDecisionThreshold", (PyCFunction)pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorGMG_setDecisionThreshold, METH_VARARGS | METH_KEYWORDS, "setDecisionThreshold(thresh) -> None"},
    {"setDefaultLearningRate", (PyCFunction)pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorGMG_setDefaultLearningRate, METH_VARARGS | METH_KEYWORDS, "setDefaultLearningRate(lr) -> None"},
    {"setMaxFeatures", (PyCFunction)pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorGMG_setMaxFeatures, METH_VARARGS | METH_KEYWORDS, "setMaxFeatures(maxFeatures) -> None"},
    {"setMaxVal", (PyCFunction)pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorGMG_setMaxVal, METH_VARARGS | METH_KEYWORDS, "setMaxVal(val) -> None"},
    {"setMinVal", (PyCFunction)pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorGMG_setMinVal, METH_VARARGS | METH_KEYWORDS, "setMinVal(val) -> None"},
    {"setNumFrames", (PyCFunction)pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorGMG_setNumFrames, METH_VARARGS | METH_KEYWORDS, "setNumFrames(nframes) -> None"},
    {"setQuantizationLevels", (PyCFunction)pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorGMG_setQuantizationLevels, METH_VARARGS | METH_KEYWORDS, "setQuantizationLevels(nlevels) -> None"},
    {"setSmoothingRadius", (PyCFunction)pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorGMG_setSmoothingRadius, METH_VARARGS | METH_KEYWORDS, "setSmoothingRadius(radius) -> None"},
    {"setUpdateBackgroundModel", (PyCFunction)pyopencv_cv_bgsegm_bgsegm_BackgroundSubtractorGMG_setUpdateBackgroundModel, METH_VARARGS | METH_KEYWORDS, "setUpdateBackgroundModel(update) -> None"},

    {NULL,          NULL}
};

static void pyopencv_bgsegm_BackgroundSubtractorGMG_specials(void)
{
    pyopencv_bgsegm_BackgroundSubtractorGMG_Type.tp_base = &pyopencv_BackgroundSubtractor_Type;
    pyopencv_bgsegm_BackgroundSubtractorGMG_Type.tp_dealloc = pyopencv_bgsegm_BackgroundSubtractorGMG_dealloc;
    pyopencv_bgsegm_BackgroundSubtractorGMG_Type.tp_repr = pyopencv_bgsegm_BackgroundSubtractorGMG_repr;
    pyopencv_bgsegm_BackgroundSubtractorGMG_Type.tp_getset = pyopencv_bgsegm_BackgroundSubtractorGMG_getseters;
    pyopencv_bgsegm_BackgroundSubtractorGMG_Type.tp_methods = pyopencv_bgsegm_BackgroundSubtractorGMG_methods;
}

static PyObject* pyopencv_bioinspired_Retina_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<bioinspired_Retina %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_bioinspired_Retina_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_bioinspired_bioinspired_Retina_activateContoursProcessing(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bioinspired;

    if(!PyObject_TypeCheck(self, &pyopencv_bioinspired_Retina_Type))
        return failmsgp("Incorrect type of self (must be 'bioinspired_Retina' or its derivative)");
    cv::bioinspired::Retina* _self_ = dynamic_cast<cv::bioinspired::Retina*>(((pyopencv_bioinspired_Retina_t*)self)->v.get());
    bool activate=0;

    const char* keywords[] = { "activate", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "b:bioinspired_Retina.activateContoursProcessing", (char**)keywords, &activate) )
    {
        ERRWRAP2(_self_->activateContoursProcessing(activate));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_bioinspired_bioinspired_Retina_activateMovingContoursProcessing(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bioinspired;

    if(!PyObject_TypeCheck(self, &pyopencv_bioinspired_Retina_Type))
        return failmsgp("Incorrect type of self (must be 'bioinspired_Retina' or its derivative)");
    cv::bioinspired::Retina* _self_ = dynamic_cast<cv::bioinspired::Retina*>(((pyopencv_bioinspired_Retina_t*)self)->v.get());
    bool activate=0;

    const char* keywords[] = { "activate", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "b:bioinspired_Retina.activateMovingContoursProcessing", (char**)keywords, &activate) )
    {
        ERRWRAP2(_self_->activateMovingContoursProcessing(activate));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_bioinspired_bioinspired_Retina_applyFastToneMapping(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bioinspired;

    if(!PyObject_TypeCheck(self, &pyopencv_bioinspired_Retina_Type))
        return failmsgp("Incorrect type of self (must be 'bioinspired_Retina' or its derivative)");
    cv::bioinspired::Retina* _self_ = dynamic_cast<cv::bioinspired::Retina*>(((pyopencv_bioinspired_Retina_t*)self)->v.get());
    {
    PyObject* pyobj_inputImage = NULL;
    Mat inputImage;
    PyObject* pyobj_outputToneMappedImage = NULL;
    Mat outputToneMappedImage;

    const char* keywords[] = { "inputImage", "outputToneMappedImage", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:bioinspired_Retina.applyFastToneMapping", (char**)keywords, &pyobj_inputImage, &pyobj_outputToneMappedImage) &&
        pyopencv_to(pyobj_inputImage, inputImage, ArgInfo("inputImage", 0)) &&
        pyopencv_to(pyobj_outputToneMappedImage, outputToneMappedImage, ArgInfo("outputToneMappedImage", 1)) )
    {
        ERRWRAP2(_self_->applyFastToneMapping(inputImage, outputToneMappedImage));
        return pyopencv_from(outputToneMappedImage);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_inputImage = NULL;
    UMat inputImage;
    PyObject* pyobj_outputToneMappedImage = NULL;
    UMat outputToneMappedImage;

    const char* keywords[] = { "inputImage", "outputToneMappedImage", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:bioinspired_Retina.applyFastToneMapping", (char**)keywords, &pyobj_inputImage, &pyobj_outputToneMappedImage) &&
        pyopencv_to(pyobj_inputImage, inputImage, ArgInfo("inputImage", 0)) &&
        pyopencv_to(pyobj_outputToneMappedImage, outputToneMappedImage, ArgInfo("outputToneMappedImage", 1)) )
    {
        ERRWRAP2(_self_->applyFastToneMapping(inputImage, outputToneMappedImage));
        return pyopencv_from(outputToneMappedImage);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_bioinspired_bioinspired_Retina_clearBuffers(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bioinspired;

    if(!PyObject_TypeCheck(self, &pyopencv_bioinspired_Retina_Type))
        return failmsgp("Incorrect type of self (must be 'bioinspired_Retina' or its derivative)");
    cv::bioinspired::Retina* _self_ = dynamic_cast<cv::bioinspired::Retina*>(((pyopencv_bioinspired_Retina_t*)self)->v.get());

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(_self_->clearBuffers());
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_bioinspired_bioinspired_Retina_getInputSize(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bioinspired;

    if(!PyObject_TypeCheck(self, &pyopencv_bioinspired_Retina_Type))
        return failmsgp("Incorrect type of self (must be 'bioinspired_Retina' or its derivative)");
    cv::bioinspired::Retina* _self_ = dynamic_cast<cv::bioinspired::Retina*>(((pyopencv_bioinspired_Retina_t*)self)->v.get());
    Size retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getInputSize());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_bioinspired_bioinspired_Retina_getMagno(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bioinspired;

    if(!PyObject_TypeCheck(self, &pyopencv_bioinspired_Retina_Type))
        return failmsgp("Incorrect type of self (must be 'bioinspired_Retina' or its derivative)");
    cv::bioinspired::Retina* _self_ = dynamic_cast<cv::bioinspired::Retina*>(((pyopencv_bioinspired_Retina_t*)self)->v.get());
    {
    PyObject* pyobj_retinaOutput_magno = NULL;
    Mat retinaOutput_magno;

    const char* keywords[] = { "retinaOutput_magno", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|O:bioinspired_Retina.getMagno", (char**)keywords, &pyobj_retinaOutput_magno) &&
        pyopencv_to(pyobj_retinaOutput_magno, retinaOutput_magno, ArgInfo("retinaOutput_magno", 1)) )
    {
        ERRWRAP2(_self_->getMagno(retinaOutput_magno));
        return pyopencv_from(retinaOutput_magno);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_retinaOutput_magno = NULL;
    UMat retinaOutput_magno;

    const char* keywords[] = { "retinaOutput_magno", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|O:bioinspired_Retina.getMagno", (char**)keywords, &pyobj_retinaOutput_magno) &&
        pyopencv_to(pyobj_retinaOutput_magno, retinaOutput_magno, ArgInfo("retinaOutput_magno", 1)) )
    {
        ERRWRAP2(_self_->getMagno(retinaOutput_magno));
        return pyopencv_from(retinaOutput_magno);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_bioinspired_bioinspired_Retina_getMagnoRAW(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bioinspired;

    if(!PyObject_TypeCheck(self, &pyopencv_bioinspired_Retina_Type))
        return failmsgp("Incorrect type of self (must be 'bioinspired_Retina' or its derivative)");
    cv::bioinspired::Retina* _self_ = dynamic_cast<cv::bioinspired::Retina*>(((pyopencv_bioinspired_Retina_t*)self)->v.get());
    {
    PyObject* pyobj_retinaOutput_magno = NULL;
    Mat retinaOutput_magno;

    const char* keywords[] = { "retinaOutput_magno", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|O:bioinspired_Retina.getMagnoRAW", (char**)keywords, &pyobj_retinaOutput_magno) &&
        pyopencv_to(pyobj_retinaOutput_magno, retinaOutput_magno, ArgInfo("retinaOutput_magno", 1)) )
    {
        ERRWRAP2(_self_->getMagnoRAW(retinaOutput_magno));
        return pyopencv_from(retinaOutput_magno);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_retinaOutput_magno = NULL;
    UMat retinaOutput_magno;

    const char* keywords[] = { "retinaOutput_magno", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|O:bioinspired_Retina.getMagnoRAW", (char**)keywords, &pyobj_retinaOutput_magno) &&
        pyopencv_to(pyobj_retinaOutput_magno, retinaOutput_magno, ArgInfo("retinaOutput_magno", 1)) )
    {
        ERRWRAP2(_self_->getMagnoRAW(retinaOutput_magno));
        return pyopencv_from(retinaOutput_magno);
    }
    }
    PyErr_Clear();

    {
    Mat retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getMagnoRAW());
        return pyopencv_from(retval);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_bioinspired_bioinspired_Retina_getOutputSize(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bioinspired;

    if(!PyObject_TypeCheck(self, &pyopencv_bioinspired_Retina_Type))
        return failmsgp("Incorrect type of self (must be 'bioinspired_Retina' or its derivative)");
    cv::bioinspired::Retina* _self_ = dynamic_cast<cv::bioinspired::Retina*>(((pyopencv_bioinspired_Retina_t*)self)->v.get());
    Size retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getOutputSize());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_bioinspired_bioinspired_Retina_getParvo(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bioinspired;

    if(!PyObject_TypeCheck(self, &pyopencv_bioinspired_Retina_Type))
        return failmsgp("Incorrect type of self (must be 'bioinspired_Retina' or its derivative)");
    cv::bioinspired::Retina* _self_ = dynamic_cast<cv::bioinspired::Retina*>(((pyopencv_bioinspired_Retina_t*)self)->v.get());
    {
    PyObject* pyobj_retinaOutput_parvo = NULL;
    Mat retinaOutput_parvo;

    const char* keywords[] = { "retinaOutput_parvo", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|O:bioinspired_Retina.getParvo", (char**)keywords, &pyobj_retinaOutput_parvo) &&
        pyopencv_to(pyobj_retinaOutput_parvo, retinaOutput_parvo, ArgInfo("retinaOutput_parvo", 1)) )
    {
        ERRWRAP2(_self_->getParvo(retinaOutput_parvo));
        return pyopencv_from(retinaOutput_parvo);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_retinaOutput_parvo = NULL;
    UMat retinaOutput_parvo;

    const char* keywords[] = { "retinaOutput_parvo", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|O:bioinspired_Retina.getParvo", (char**)keywords, &pyobj_retinaOutput_parvo) &&
        pyopencv_to(pyobj_retinaOutput_parvo, retinaOutput_parvo, ArgInfo("retinaOutput_parvo", 1)) )
    {
        ERRWRAP2(_self_->getParvo(retinaOutput_parvo));
        return pyopencv_from(retinaOutput_parvo);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_bioinspired_bioinspired_Retina_getParvoRAW(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bioinspired;

    if(!PyObject_TypeCheck(self, &pyopencv_bioinspired_Retina_Type))
        return failmsgp("Incorrect type of self (must be 'bioinspired_Retina' or its derivative)");
    cv::bioinspired::Retina* _self_ = dynamic_cast<cv::bioinspired::Retina*>(((pyopencv_bioinspired_Retina_t*)self)->v.get());
    {
    PyObject* pyobj_retinaOutput_parvo = NULL;
    Mat retinaOutput_parvo;

    const char* keywords[] = { "retinaOutput_parvo", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|O:bioinspired_Retina.getParvoRAW", (char**)keywords, &pyobj_retinaOutput_parvo) &&
        pyopencv_to(pyobj_retinaOutput_parvo, retinaOutput_parvo, ArgInfo("retinaOutput_parvo", 1)) )
    {
        ERRWRAP2(_self_->getParvoRAW(retinaOutput_parvo));
        return pyopencv_from(retinaOutput_parvo);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_retinaOutput_parvo = NULL;
    UMat retinaOutput_parvo;

    const char* keywords[] = { "retinaOutput_parvo", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|O:bioinspired_Retina.getParvoRAW", (char**)keywords, &pyobj_retinaOutput_parvo) &&
        pyopencv_to(pyobj_retinaOutput_parvo, retinaOutput_parvo, ArgInfo("retinaOutput_parvo", 1)) )
    {
        ERRWRAP2(_self_->getParvoRAW(retinaOutput_parvo));
        return pyopencv_from(retinaOutput_parvo);
    }
    }
    PyErr_Clear();

    {
    Mat retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getParvoRAW());
        return pyopencv_from(retval);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_bioinspired_bioinspired_Retina_printSetup(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bioinspired;

    if(!PyObject_TypeCheck(self, &pyopencv_bioinspired_Retina_Type))
        return failmsgp("Incorrect type of self (must be 'bioinspired_Retina' or its derivative)");
    cv::bioinspired::Retina* _self_ = dynamic_cast<cv::bioinspired::Retina*>(((pyopencv_bioinspired_Retina_t*)self)->v.get());
    String retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->printSetup());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_bioinspired_bioinspired_Retina_run(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bioinspired;

    if(!PyObject_TypeCheck(self, &pyopencv_bioinspired_Retina_Type))
        return failmsgp("Incorrect type of self (must be 'bioinspired_Retina' or its derivative)");
    cv::bioinspired::Retina* _self_ = dynamic_cast<cv::bioinspired::Retina*>(((pyopencv_bioinspired_Retina_t*)self)->v.get());
    {
    PyObject* pyobj_inputImage = NULL;
    Mat inputImage;

    const char* keywords[] = { "inputImage", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:bioinspired_Retina.run", (char**)keywords, &pyobj_inputImage) &&
        pyopencv_to(pyobj_inputImage, inputImage, ArgInfo("inputImage", 0)) )
    {
        ERRWRAP2(_self_->run(inputImage));
        Py_RETURN_NONE;
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_inputImage = NULL;
    UMat inputImage;

    const char* keywords[] = { "inputImage", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:bioinspired_Retina.run", (char**)keywords, &pyobj_inputImage) &&
        pyopencv_to(pyobj_inputImage, inputImage, ArgInfo("inputImage", 0)) )
    {
        ERRWRAP2(_self_->run(inputImage));
        Py_RETURN_NONE;
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_bioinspired_bioinspired_Retina_setColorSaturation(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bioinspired;

    if(!PyObject_TypeCheck(self, &pyopencv_bioinspired_Retina_Type))
        return failmsgp("Incorrect type of self (must be 'bioinspired_Retina' or its derivative)");
    cv::bioinspired::Retina* _self_ = dynamic_cast<cv::bioinspired::Retina*>(((pyopencv_bioinspired_Retina_t*)self)->v.get());
    bool saturateColors=true;
    float colorSaturationValue=4.0f;

    const char* keywords[] = { "saturateColors", "colorSaturationValue", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|bf:bioinspired_Retina.setColorSaturation", (char**)keywords, &saturateColors, &colorSaturationValue) )
    {
        ERRWRAP2(_self_->setColorSaturation(saturateColors, colorSaturationValue));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_bioinspired_bioinspired_Retina_setup(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bioinspired;

    if(!PyObject_TypeCheck(self, &pyopencv_bioinspired_Retina_Type))
        return failmsgp("Incorrect type of self (must be 'bioinspired_Retina' or its derivative)");
    cv::bioinspired::Retina* _self_ = dynamic_cast<cv::bioinspired::Retina*>(((pyopencv_bioinspired_Retina_t*)self)->v.get());
    PyObject* pyobj_retinaParameterFile = NULL;
    String retinaParameterFile="";
    bool applyDefaultSetupOnFailure=true;

    const char* keywords[] = { "retinaParameterFile", "applyDefaultSetupOnFailure", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|Ob:bioinspired_Retina.setup", (char**)keywords, &pyobj_retinaParameterFile, &applyDefaultSetupOnFailure) &&
        pyopencv_to(pyobj_retinaParameterFile, retinaParameterFile, ArgInfo("retinaParameterFile", 0)) )
    {
        ERRWRAP2(_self_->setup(retinaParameterFile, applyDefaultSetupOnFailure));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_bioinspired_bioinspired_Retina_setupIPLMagnoChannel(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bioinspired;

    if(!PyObject_TypeCheck(self, &pyopencv_bioinspired_Retina_Type))
        return failmsgp("Incorrect type of self (must be 'bioinspired_Retina' or its derivative)");
    cv::bioinspired::Retina* _self_ = dynamic_cast<cv::bioinspired::Retina*>(((pyopencv_bioinspired_Retina_t*)self)->v.get());
    bool normaliseOutput=true;
    float parasolCells_beta=0.f;
    float parasolCells_tau=0.f;
    float parasolCells_k=7.f;
    float amacrinCellsTemporalCutFrequency=1.2f;
    float V0CompressionParameter=0.95f;
    float localAdaptintegration_tau=0.f;
    float localAdaptintegration_k=7.f;

    const char* keywords[] = { "normaliseOutput", "parasolCells_beta", "parasolCells_tau", "parasolCells_k", "amacrinCellsTemporalCutFrequency", "V0CompressionParameter", "localAdaptintegration_tau", "localAdaptintegration_k", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|bfffffff:bioinspired_Retina.setupIPLMagnoChannel", (char**)keywords, &normaliseOutput, &parasolCells_beta, &parasolCells_tau, &parasolCells_k, &amacrinCellsTemporalCutFrequency, &V0CompressionParameter, &localAdaptintegration_tau, &localAdaptintegration_k) )
    {
        ERRWRAP2(_self_->setupIPLMagnoChannel(normaliseOutput, parasolCells_beta, parasolCells_tau, parasolCells_k, amacrinCellsTemporalCutFrequency, V0CompressionParameter, localAdaptintegration_tau, localAdaptintegration_k));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_bioinspired_bioinspired_Retina_setupOPLandIPLParvoChannel(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bioinspired;

    if(!PyObject_TypeCheck(self, &pyopencv_bioinspired_Retina_Type))
        return failmsgp("Incorrect type of self (must be 'bioinspired_Retina' or its derivative)");
    cv::bioinspired::Retina* _self_ = dynamic_cast<cv::bioinspired::Retina*>(((pyopencv_bioinspired_Retina_t*)self)->v.get());
    bool colorMode=true;
    bool normaliseOutput=true;
    float photoreceptorsLocalAdaptationSensitivity=0.7f;
    float photoreceptorsTemporalConstant=0.5f;
    float photoreceptorsSpatialConstant=0.53f;
    float horizontalCellsGain=0.f;
    float HcellsTemporalConstant=1.f;
    float HcellsSpatialConstant=7.f;
    float ganglionCellsSensitivity=0.7f;

    const char* keywords[] = { "colorMode", "normaliseOutput", "photoreceptorsLocalAdaptationSensitivity", "photoreceptorsTemporalConstant", "photoreceptorsSpatialConstant", "horizontalCellsGain", "HcellsTemporalConstant", "HcellsSpatialConstant", "ganglionCellsSensitivity", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|bbfffffff:bioinspired_Retina.setupOPLandIPLParvoChannel", (char**)keywords, &colorMode, &normaliseOutput, &photoreceptorsLocalAdaptationSensitivity, &photoreceptorsTemporalConstant, &photoreceptorsSpatialConstant, &horizontalCellsGain, &HcellsTemporalConstant, &HcellsSpatialConstant, &ganglionCellsSensitivity) )
    {
        ERRWRAP2(_self_->setupOPLandIPLParvoChannel(colorMode, normaliseOutput, photoreceptorsLocalAdaptationSensitivity, photoreceptorsTemporalConstant, photoreceptorsSpatialConstant, horizontalCellsGain, HcellsTemporalConstant, HcellsSpatialConstant, ganglionCellsSensitivity));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_bioinspired_bioinspired_Retina_write(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bioinspired;

    if(!PyObject_TypeCheck(self, &pyopencv_bioinspired_Retina_Type))
        return failmsgp("Incorrect type of self (must be 'bioinspired_Retina' or its derivative)");
    cv::bioinspired::Retina* _self_ = dynamic_cast<cv::bioinspired::Retina*>(((pyopencv_bioinspired_Retina_t*)self)->v.get());
    PyObject* pyobj_fs = NULL;
    String fs;

    const char* keywords[] = { "fs", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:bioinspired_Retina.write", (char**)keywords, &pyobj_fs) &&
        pyopencv_to(pyobj_fs, fs, ArgInfo("fs", 0)) )
    {
        ERRWRAP2(_self_->write(fs));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_bioinspired_Retina_methods[] =
{
    {"activateContoursProcessing", (PyCFunction)pyopencv_cv_bioinspired_bioinspired_Retina_activateContoursProcessing, METH_VARARGS | METH_KEYWORDS, "activateContoursProcessing(activate) -> None"},
    {"activateMovingContoursProcessing", (PyCFunction)pyopencv_cv_bioinspired_bioinspired_Retina_activateMovingContoursProcessing, METH_VARARGS | METH_KEYWORDS, "activateMovingContoursProcessing(activate) -> None"},
    {"applyFastToneMapping", (PyCFunction)pyopencv_cv_bioinspired_bioinspired_Retina_applyFastToneMapping, METH_VARARGS | METH_KEYWORDS, "applyFastToneMapping(inputImage[, outputToneMappedImage]) -> outputToneMappedImage"},
    {"clearBuffers", (PyCFunction)pyopencv_cv_bioinspired_bioinspired_Retina_clearBuffers, METH_VARARGS | METH_KEYWORDS, "clearBuffers() -> None"},
    {"getInputSize", (PyCFunction)pyopencv_cv_bioinspired_bioinspired_Retina_getInputSize, METH_VARARGS | METH_KEYWORDS, "getInputSize() -> retval"},
    {"getMagno", (PyCFunction)pyopencv_cv_bioinspired_bioinspired_Retina_getMagno, METH_VARARGS | METH_KEYWORDS, "getMagno([, retinaOutput_magno]) -> retinaOutput_magno"},
    {"getMagnoRAW", (PyCFunction)pyopencv_cv_bioinspired_bioinspired_Retina_getMagnoRAW, METH_VARARGS | METH_KEYWORDS, "getMagnoRAW([, retinaOutput_magno]) -> retinaOutput_magno  or  getMagnoRAW() -> retval"},
    {"getOutputSize", (PyCFunction)pyopencv_cv_bioinspired_bioinspired_Retina_getOutputSize, METH_VARARGS | METH_KEYWORDS, "getOutputSize() -> retval"},
    {"getParvo", (PyCFunction)pyopencv_cv_bioinspired_bioinspired_Retina_getParvo, METH_VARARGS | METH_KEYWORDS, "getParvo([, retinaOutput_parvo]) -> retinaOutput_parvo"},
    {"getParvoRAW", (PyCFunction)pyopencv_cv_bioinspired_bioinspired_Retina_getParvoRAW, METH_VARARGS | METH_KEYWORDS, "getParvoRAW([, retinaOutput_parvo]) -> retinaOutput_parvo  or  getParvoRAW() -> retval"},
    {"printSetup", (PyCFunction)pyopencv_cv_bioinspired_bioinspired_Retina_printSetup, METH_VARARGS | METH_KEYWORDS, "printSetup() -> retval"},
    {"run", (PyCFunction)pyopencv_cv_bioinspired_bioinspired_Retina_run, METH_VARARGS | METH_KEYWORDS, "run(inputImage) -> None"},
    {"setColorSaturation", (PyCFunction)pyopencv_cv_bioinspired_bioinspired_Retina_setColorSaturation, METH_VARARGS | METH_KEYWORDS, "setColorSaturation([, saturateColors[, colorSaturationValue]]) -> None"},
    {"setup", (PyCFunction)pyopencv_cv_bioinspired_bioinspired_Retina_setup, METH_VARARGS | METH_KEYWORDS, "setup([, retinaParameterFile[, applyDefaultSetupOnFailure]]) -> None"},
    {"setupIPLMagnoChannel", (PyCFunction)pyopencv_cv_bioinspired_bioinspired_Retina_setupIPLMagnoChannel, METH_VARARGS | METH_KEYWORDS, "setupIPLMagnoChannel([, normaliseOutput[, parasolCells_beta[, parasolCells_tau[, parasolCells_k[, amacrinCellsTemporalCutFrequency[, V0CompressionParameter[, localAdaptintegration_tau[, localAdaptintegration_k]]]]]]]]) -> None"},
    {"setupOPLandIPLParvoChannel", (PyCFunction)pyopencv_cv_bioinspired_bioinspired_Retina_setupOPLandIPLParvoChannel, METH_VARARGS | METH_KEYWORDS, "setupOPLandIPLParvoChannel([, colorMode[, normaliseOutput[, photoreceptorsLocalAdaptationSensitivity[, photoreceptorsTemporalConstant[, photoreceptorsSpatialConstant[, horizontalCellsGain[, HcellsTemporalConstant[, HcellsSpatialConstant[, ganglionCellsSensitivity]]]]]]]]]) -> None"},
    {"write", (PyCFunction)pyopencv_cv_bioinspired_bioinspired_Retina_write, METH_VARARGS | METH_KEYWORDS, "write(fs) -> None"},

    {NULL,          NULL}
};

static void pyopencv_bioinspired_Retina_specials(void)
{
    pyopencv_bioinspired_Retina_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_bioinspired_Retina_Type.tp_dealloc = pyopencv_bioinspired_Retina_dealloc;
    pyopencv_bioinspired_Retina_Type.tp_repr = pyopencv_bioinspired_Retina_repr;
    pyopencv_bioinspired_Retina_Type.tp_getset = pyopencv_bioinspired_Retina_getseters;
    pyopencv_bioinspired_Retina_Type.tp_methods = pyopencv_bioinspired_Retina_methods;
}

static PyObject* pyopencv_bioinspired_RetinaFastToneMapping_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<bioinspired_RetinaFastToneMapping %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_bioinspired_RetinaFastToneMapping_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_bioinspired_bioinspired_RetinaFastToneMapping_applyFastToneMapping(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bioinspired;

    if(!PyObject_TypeCheck(self, &pyopencv_bioinspired_RetinaFastToneMapping_Type))
        return failmsgp("Incorrect type of self (must be 'bioinspired_RetinaFastToneMapping' or its derivative)");
    cv::bioinspired::RetinaFastToneMapping* _self_ = dynamic_cast<cv::bioinspired::RetinaFastToneMapping*>(((pyopencv_bioinspired_RetinaFastToneMapping_t*)self)->v.get());
    {
    PyObject* pyobj_inputImage = NULL;
    Mat inputImage;
    PyObject* pyobj_outputToneMappedImage = NULL;
    Mat outputToneMappedImage;

    const char* keywords[] = { "inputImage", "outputToneMappedImage", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:bioinspired_RetinaFastToneMapping.applyFastToneMapping", (char**)keywords, &pyobj_inputImage, &pyobj_outputToneMappedImage) &&
        pyopencv_to(pyobj_inputImage, inputImage, ArgInfo("inputImage", 0)) &&
        pyopencv_to(pyobj_outputToneMappedImage, outputToneMappedImage, ArgInfo("outputToneMappedImage", 1)) )
    {
        ERRWRAP2(_self_->applyFastToneMapping(inputImage, outputToneMappedImage));
        return pyopencv_from(outputToneMappedImage);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_inputImage = NULL;
    UMat inputImage;
    PyObject* pyobj_outputToneMappedImage = NULL;
    UMat outputToneMappedImage;

    const char* keywords[] = { "inputImage", "outputToneMappedImage", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:bioinspired_RetinaFastToneMapping.applyFastToneMapping", (char**)keywords, &pyobj_inputImage, &pyobj_outputToneMappedImage) &&
        pyopencv_to(pyobj_inputImage, inputImage, ArgInfo("inputImage", 0)) &&
        pyopencv_to(pyobj_outputToneMappedImage, outputToneMappedImage, ArgInfo("outputToneMappedImage", 1)) )
    {
        ERRWRAP2(_self_->applyFastToneMapping(inputImage, outputToneMappedImage));
        return pyopencv_from(outputToneMappedImage);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_bioinspired_bioinspired_RetinaFastToneMapping_setup(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bioinspired;

    if(!PyObject_TypeCheck(self, &pyopencv_bioinspired_RetinaFastToneMapping_Type))
        return failmsgp("Incorrect type of self (must be 'bioinspired_RetinaFastToneMapping' or its derivative)");
    cv::bioinspired::RetinaFastToneMapping* _self_ = dynamic_cast<cv::bioinspired::RetinaFastToneMapping*>(((pyopencv_bioinspired_RetinaFastToneMapping_t*)self)->v.get());
    float photoreceptorsNeighborhoodRadius=3.f;
    float ganglioncellsNeighborhoodRadius=1.f;
    float meanLuminanceModulatorK=1.f;

    const char* keywords[] = { "photoreceptorsNeighborhoodRadius", "ganglioncellsNeighborhoodRadius", "meanLuminanceModulatorK", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|fff:bioinspired_RetinaFastToneMapping.setup", (char**)keywords, &photoreceptorsNeighborhoodRadius, &ganglioncellsNeighborhoodRadius, &meanLuminanceModulatorK) )
    {
        ERRWRAP2(_self_->setup(photoreceptorsNeighborhoodRadius, ganglioncellsNeighborhoodRadius, meanLuminanceModulatorK));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_bioinspired_RetinaFastToneMapping_methods[] =
{
    {"applyFastToneMapping", (PyCFunction)pyopencv_cv_bioinspired_bioinspired_RetinaFastToneMapping_applyFastToneMapping, METH_VARARGS | METH_KEYWORDS, "applyFastToneMapping(inputImage[, outputToneMappedImage]) -> outputToneMappedImage"},
    {"setup", (PyCFunction)pyopencv_cv_bioinspired_bioinspired_RetinaFastToneMapping_setup, METH_VARARGS | METH_KEYWORDS, "setup([, photoreceptorsNeighborhoodRadius[, ganglioncellsNeighborhoodRadius[, meanLuminanceModulatorK]]]) -> None"},

    {NULL,          NULL}
};

static void pyopencv_bioinspired_RetinaFastToneMapping_specials(void)
{
    pyopencv_bioinspired_RetinaFastToneMapping_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_bioinspired_RetinaFastToneMapping_Type.tp_dealloc = pyopencv_bioinspired_RetinaFastToneMapping_dealloc;
    pyopencv_bioinspired_RetinaFastToneMapping_Type.tp_repr = pyopencv_bioinspired_RetinaFastToneMapping_repr;
    pyopencv_bioinspired_RetinaFastToneMapping_Type.tp_getset = pyopencv_bioinspired_RetinaFastToneMapping_getseters;
    pyopencv_bioinspired_RetinaFastToneMapping_Type.tp_methods = pyopencv_bioinspired_RetinaFastToneMapping_methods;
}

static PyObject* pyopencv_bioinspired_TransientAreasSegmentationModule_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<bioinspired_TransientAreasSegmentationModule %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_bioinspired_TransientAreasSegmentationModule_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_bioinspired_bioinspired_TransientAreasSegmentationModule_clearAllBuffers(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bioinspired;

    if(!PyObject_TypeCheck(self, &pyopencv_bioinspired_TransientAreasSegmentationModule_Type))
        return failmsgp("Incorrect type of self (must be 'bioinspired_TransientAreasSegmentationModule' or its derivative)");
    cv::bioinspired::TransientAreasSegmentationModule* _self_ = dynamic_cast<cv::bioinspired::TransientAreasSegmentationModule*>(((pyopencv_bioinspired_TransientAreasSegmentationModule_t*)self)->v.get());

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(_self_->clearAllBuffers());
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_bioinspired_bioinspired_TransientAreasSegmentationModule_getSegmentationPicture(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bioinspired;

    if(!PyObject_TypeCheck(self, &pyopencv_bioinspired_TransientAreasSegmentationModule_Type))
        return failmsgp("Incorrect type of self (must be 'bioinspired_TransientAreasSegmentationModule' or its derivative)");
    cv::bioinspired::TransientAreasSegmentationModule* _self_ = dynamic_cast<cv::bioinspired::TransientAreasSegmentationModule*>(((pyopencv_bioinspired_TransientAreasSegmentationModule_t*)self)->v.get());
    {
    PyObject* pyobj_transientAreas = NULL;
    Mat transientAreas;

    const char* keywords[] = { "transientAreas", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|O:bioinspired_TransientAreasSegmentationModule.getSegmentationPicture", (char**)keywords, &pyobj_transientAreas) &&
        pyopencv_to(pyobj_transientAreas, transientAreas, ArgInfo("transientAreas", 1)) )
    {
        ERRWRAP2(_self_->getSegmentationPicture(transientAreas));
        return pyopencv_from(transientAreas);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_transientAreas = NULL;
    UMat transientAreas;

    const char* keywords[] = { "transientAreas", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|O:bioinspired_TransientAreasSegmentationModule.getSegmentationPicture", (char**)keywords, &pyobj_transientAreas) &&
        pyopencv_to(pyobj_transientAreas, transientAreas, ArgInfo("transientAreas", 1)) )
    {
        ERRWRAP2(_self_->getSegmentationPicture(transientAreas));
        return pyopencv_from(transientAreas);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_bioinspired_bioinspired_TransientAreasSegmentationModule_getSize(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bioinspired;

    if(!PyObject_TypeCheck(self, &pyopencv_bioinspired_TransientAreasSegmentationModule_Type))
        return failmsgp("Incorrect type of self (must be 'bioinspired_TransientAreasSegmentationModule' or its derivative)");
    cv::bioinspired::TransientAreasSegmentationModule* _self_ = dynamic_cast<cv::bioinspired::TransientAreasSegmentationModule*>(((pyopencv_bioinspired_TransientAreasSegmentationModule_t*)self)->v.get());
    Size retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getSize());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_bioinspired_bioinspired_TransientAreasSegmentationModule_printSetup(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bioinspired;

    if(!PyObject_TypeCheck(self, &pyopencv_bioinspired_TransientAreasSegmentationModule_Type))
        return failmsgp("Incorrect type of self (must be 'bioinspired_TransientAreasSegmentationModule' or its derivative)");
    cv::bioinspired::TransientAreasSegmentationModule* _self_ = dynamic_cast<cv::bioinspired::TransientAreasSegmentationModule*>(((pyopencv_bioinspired_TransientAreasSegmentationModule_t*)self)->v.get());
    String retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->printSetup());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_bioinspired_bioinspired_TransientAreasSegmentationModule_run(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bioinspired;

    if(!PyObject_TypeCheck(self, &pyopencv_bioinspired_TransientAreasSegmentationModule_Type))
        return failmsgp("Incorrect type of self (must be 'bioinspired_TransientAreasSegmentationModule' or its derivative)");
    cv::bioinspired::TransientAreasSegmentationModule* _self_ = dynamic_cast<cv::bioinspired::TransientAreasSegmentationModule*>(((pyopencv_bioinspired_TransientAreasSegmentationModule_t*)self)->v.get());
    {
    PyObject* pyobj_inputToSegment = NULL;
    Mat inputToSegment;
    int channelIndex=0;

    const char* keywords[] = { "inputToSegment", "channelIndex", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|i:bioinspired_TransientAreasSegmentationModule.run", (char**)keywords, &pyobj_inputToSegment, &channelIndex) &&
        pyopencv_to(pyobj_inputToSegment, inputToSegment, ArgInfo("inputToSegment", 0)) )
    {
        ERRWRAP2(_self_->run(inputToSegment, channelIndex));
        Py_RETURN_NONE;
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_inputToSegment = NULL;
    UMat inputToSegment;
    int channelIndex=0;

    const char* keywords[] = { "inputToSegment", "channelIndex", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|i:bioinspired_TransientAreasSegmentationModule.run", (char**)keywords, &pyobj_inputToSegment, &channelIndex) &&
        pyopencv_to(pyobj_inputToSegment, inputToSegment, ArgInfo("inputToSegment", 0)) )
    {
        ERRWRAP2(_self_->run(inputToSegment, channelIndex));
        Py_RETURN_NONE;
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_bioinspired_bioinspired_TransientAreasSegmentationModule_setup(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bioinspired;

    if(!PyObject_TypeCheck(self, &pyopencv_bioinspired_TransientAreasSegmentationModule_Type))
        return failmsgp("Incorrect type of self (must be 'bioinspired_TransientAreasSegmentationModule' or its derivative)");
    cv::bioinspired::TransientAreasSegmentationModule* _self_ = dynamic_cast<cv::bioinspired::TransientAreasSegmentationModule*>(((pyopencv_bioinspired_TransientAreasSegmentationModule_t*)self)->v.get());
    PyObject* pyobj_segmentationParameterFile = NULL;
    String segmentationParameterFile="";
    bool applyDefaultSetupOnFailure=true;

    const char* keywords[] = { "segmentationParameterFile", "applyDefaultSetupOnFailure", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|Ob:bioinspired_TransientAreasSegmentationModule.setup", (char**)keywords, &pyobj_segmentationParameterFile, &applyDefaultSetupOnFailure) &&
        pyopencv_to(pyobj_segmentationParameterFile, segmentationParameterFile, ArgInfo("segmentationParameterFile", 0)) )
    {
        ERRWRAP2(_self_->setup(segmentationParameterFile, applyDefaultSetupOnFailure));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_bioinspired_bioinspired_TransientAreasSegmentationModule_write(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::bioinspired;

    if(!PyObject_TypeCheck(self, &pyopencv_bioinspired_TransientAreasSegmentationModule_Type))
        return failmsgp("Incorrect type of self (must be 'bioinspired_TransientAreasSegmentationModule' or its derivative)");
    cv::bioinspired::TransientAreasSegmentationModule* _self_ = dynamic_cast<cv::bioinspired::TransientAreasSegmentationModule*>(((pyopencv_bioinspired_TransientAreasSegmentationModule_t*)self)->v.get());
    PyObject* pyobj_fs = NULL;
    String fs;

    const char* keywords[] = { "fs", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:bioinspired_TransientAreasSegmentationModule.write", (char**)keywords, &pyobj_fs) &&
        pyopencv_to(pyobj_fs, fs, ArgInfo("fs", 0)) )
    {
        ERRWRAP2(_self_->write(fs));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_bioinspired_TransientAreasSegmentationModule_methods[] =
{
    {"clearAllBuffers", (PyCFunction)pyopencv_cv_bioinspired_bioinspired_TransientAreasSegmentationModule_clearAllBuffers, METH_VARARGS | METH_KEYWORDS, "clearAllBuffers() -> None"},
    {"getSegmentationPicture", (PyCFunction)pyopencv_cv_bioinspired_bioinspired_TransientAreasSegmentationModule_getSegmentationPicture, METH_VARARGS | METH_KEYWORDS, "getSegmentationPicture([, transientAreas]) -> transientAreas"},
    {"getSize", (PyCFunction)pyopencv_cv_bioinspired_bioinspired_TransientAreasSegmentationModule_getSize, METH_VARARGS | METH_KEYWORDS, "getSize() -> retval"},
    {"printSetup", (PyCFunction)pyopencv_cv_bioinspired_bioinspired_TransientAreasSegmentationModule_printSetup, METH_VARARGS | METH_KEYWORDS, "printSetup() -> retval"},
    {"run", (PyCFunction)pyopencv_cv_bioinspired_bioinspired_TransientAreasSegmentationModule_run, METH_VARARGS | METH_KEYWORDS, "run(inputToSegment[, channelIndex]) -> None"},
    {"setup", (PyCFunction)pyopencv_cv_bioinspired_bioinspired_TransientAreasSegmentationModule_setup, METH_VARARGS | METH_KEYWORDS, "setup([, segmentationParameterFile[, applyDefaultSetupOnFailure]]) -> None"},
    {"write", (PyCFunction)pyopencv_cv_bioinspired_bioinspired_TransientAreasSegmentationModule_write, METH_VARARGS | METH_KEYWORDS, "write(fs) -> None"},

    {NULL,          NULL}
};

static void pyopencv_bioinspired_TransientAreasSegmentationModule_specials(void)
{
    pyopencv_bioinspired_TransientAreasSegmentationModule_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_bioinspired_TransientAreasSegmentationModule_Type.tp_dealloc = pyopencv_bioinspired_TransientAreasSegmentationModule_dealloc;
    pyopencv_bioinspired_TransientAreasSegmentationModule_Type.tp_repr = pyopencv_bioinspired_TransientAreasSegmentationModule_repr;
    pyopencv_bioinspired_TransientAreasSegmentationModule_Type.tp_getset = pyopencv_bioinspired_TransientAreasSegmentationModule_getseters;
    pyopencv_bioinspired_TransientAreasSegmentationModule_Type.tp_methods = pyopencv_bioinspired_TransientAreasSegmentationModule_methods;
}

static PyObject* pyopencv_dpm_DPMDetector_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<dpm_DPMDetector %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_dpm_DPMDetector_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_dpm_DPMDetector_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_dpm_DPMDetector_specials(void)
{
    pyopencv_dpm_DPMDetector_Type.tp_base = NULL;
    pyopencv_dpm_DPMDetector_Type.tp_dealloc = pyopencv_dpm_DPMDetector_dealloc;
    pyopencv_dpm_DPMDetector_Type.tp_repr = pyopencv_dpm_DPMDetector_repr;
    pyopencv_dpm_DPMDetector_Type.tp_getset = pyopencv_dpm_DPMDetector_getseters;
    pyopencv_dpm_DPMDetector_Type.tp_methods = pyopencv_dpm_DPMDetector_methods;
}

static PyObject* pyopencv_dpm_DPMDetector_ObjectDetection_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<dpm_DPMDetector_ObjectDetection %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_dpm_DPMDetector_ObjectDetection_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_dpm_DPMDetector_ObjectDetection_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_dpm_DPMDetector_ObjectDetection_specials(void)
{
    pyopencv_dpm_DPMDetector_ObjectDetection_Type.tp_base = NULL;
    pyopencv_dpm_DPMDetector_ObjectDetection_Type.tp_dealloc = pyopencv_dpm_DPMDetector_ObjectDetection_dealloc;
    pyopencv_dpm_DPMDetector_ObjectDetection_Type.tp_repr = pyopencv_dpm_DPMDetector_ObjectDetection_repr;
    pyopencv_dpm_DPMDetector_ObjectDetection_Type.tp_getset = pyopencv_dpm_DPMDetector_ObjectDetection_getseters;
    pyopencv_dpm_DPMDetector_ObjectDetection_Type.tp_methods = pyopencv_dpm_DPMDetector_ObjectDetection_methods;
}

static PyObject* pyopencv_face_FaceRecognizer_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<face_FaceRecognizer %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_face_FaceRecognizer_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_face_face_FaceRecognizer_getLabelInfo(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::face;

    if(!PyObject_TypeCheck(self, &pyopencv_face_FaceRecognizer_Type))
        return failmsgp("Incorrect type of self (must be 'face_FaceRecognizer' or its derivative)");
    cv::face::FaceRecognizer* _self_ = dynamic_cast<cv::face::FaceRecognizer*>(((pyopencv_face_FaceRecognizer_t*)self)->v.get());
    int label=0;
    String retval;

    const char* keywords[] = { "label", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:face_FaceRecognizer.getLabelInfo", (char**)keywords, &label) )
    {
        ERRWRAP2(retval = _self_->getLabelInfo(label));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_face_face_FaceRecognizer_getLabelsByString(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::face;

    if(!PyObject_TypeCheck(self, &pyopencv_face_FaceRecognizer_Type))
        return failmsgp("Incorrect type of self (must be 'face_FaceRecognizer' or its derivative)");
    cv::face::FaceRecognizer* _self_ = dynamic_cast<cv::face::FaceRecognizer*>(((pyopencv_face_FaceRecognizer_t*)self)->v.get());
    PyObject* pyobj_str = NULL;
    String str;
    std::vector<int> retval;

    const char* keywords[] = { "str", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:face_FaceRecognizer.getLabelsByString", (char**)keywords, &pyobj_str) &&
        pyopencv_to(pyobj_str, str, ArgInfo("str", 0)) )
    {
        ERRWRAP2(retval = _self_->getLabelsByString(str));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_face_face_FaceRecognizer_load(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::face;

    if(!PyObject_TypeCheck(self, &pyopencv_face_FaceRecognizer_Type))
        return failmsgp("Incorrect type of self (must be 'face_FaceRecognizer' or its derivative)");
    cv::face::FaceRecognizer* _self_ = dynamic_cast<cv::face::FaceRecognizer*>(((pyopencv_face_FaceRecognizer_t*)self)->v.get());
    PyObject* pyobj_filename = NULL;
    String filename;

    const char* keywords[] = { "filename", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:face_FaceRecognizer.load", (char**)keywords, &pyobj_filename) &&
        pyopencv_to(pyobj_filename, filename, ArgInfo("filename", 0)) )
    {
        ERRWRAP2(_self_->load(filename));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_face_face_FaceRecognizer_predict(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::face;

    if(!PyObject_TypeCheck(self, &pyopencv_face_FaceRecognizer_Type))
        return failmsgp("Incorrect type of self (must be 'face_FaceRecognizer' or its derivative)");
    cv::face::FaceRecognizer* _self_ = dynamic_cast<cv::face::FaceRecognizer*>(((pyopencv_face_FaceRecognizer_t*)self)->v.get());
    {
    PyObject* pyobj_src = NULL;
    Mat src;
    int label;
    double confidence;

    const char* keywords[] = { "src", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:face_FaceRecognizer.predict", (char**)keywords, &pyobj_src) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) )
    {
        ERRWRAP2(_self_->predict(src, label, confidence));
        return Py_BuildValue("(NN)", pyopencv_from(label), pyopencv_from(confidence));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    int label;
    double confidence;

    const char* keywords[] = { "src", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:face_FaceRecognizer.predict", (char**)keywords, &pyobj_src) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) )
    {
        ERRWRAP2(_self_->predict(src, label, confidence));
        return Py_BuildValue("(NN)", pyopencv_from(label), pyopencv_from(confidence));
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_face_face_FaceRecognizer_predict_collect(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::face;

    if(!PyObject_TypeCheck(self, &pyopencv_face_FaceRecognizer_Type))
        return failmsgp("Incorrect type of self (must be 'face_FaceRecognizer' or its derivative)");
    cv::face::FaceRecognizer* _self_ = dynamic_cast<cv::face::FaceRecognizer*>(((pyopencv_face_FaceRecognizer_t*)self)->v.get());
    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_collector = NULL;
    Ptr<PredictCollector> collector;

    const char* keywords[] = { "src", "collector", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO:face_FaceRecognizer.predict_collect", (char**)keywords, &pyobj_src, &pyobj_collector) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_collector, collector, ArgInfo("collector", 0)) )
    {
        ERRWRAP2(_self_->predict(src, collector));
        Py_RETURN_NONE;
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_collector = NULL;
    Ptr<PredictCollector> collector;

    const char* keywords[] = { "src", "collector", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO:face_FaceRecognizer.predict_collect", (char**)keywords, &pyobj_src, &pyobj_collector) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_collector, collector, ArgInfo("collector", 0)) )
    {
        ERRWRAP2(_self_->predict(src, collector));
        Py_RETURN_NONE;
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_face_face_FaceRecognizer_predict_label(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::face;

    if(!PyObject_TypeCheck(self, &pyopencv_face_FaceRecognizer_Type))
        return failmsgp("Incorrect type of self (must be 'face_FaceRecognizer' or its derivative)");
    cv::face::FaceRecognizer* _self_ = dynamic_cast<cv::face::FaceRecognizer*>(((pyopencv_face_FaceRecognizer_t*)self)->v.get());
    {
    PyObject* pyobj_src = NULL;
    Mat src;
    int retval;

    const char* keywords[] = { "src", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:face_FaceRecognizer.predict_label", (char**)keywords, &pyobj_src) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) )
    {
        ERRWRAP2(retval = _self_->predict(src));
        return pyopencv_from(retval);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    int retval;

    const char* keywords[] = { "src", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:face_FaceRecognizer.predict_label", (char**)keywords, &pyobj_src) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) )
    {
        ERRWRAP2(retval = _self_->predict(src));
        return pyopencv_from(retval);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_face_face_FaceRecognizer_save(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::face;

    if(!PyObject_TypeCheck(self, &pyopencv_face_FaceRecognizer_Type))
        return failmsgp("Incorrect type of self (must be 'face_FaceRecognizer' or its derivative)");
    cv::face::FaceRecognizer* _self_ = dynamic_cast<cv::face::FaceRecognizer*>(((pyopencv_face_FaceRecognizer_t*)self)->v.get());
    PyObject* pyobj_filename = NULL;
    String filename;

    const char* keywords[] = { "filename", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:face_FaceRecognizer.save", (char**)keywords, &pyobj_filename) &&
        pyopencv_to(pyobj_filename, filename, ArgInfo("filename", 0)) )
    {
        ERRWRAP2(_self_->save(filename));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_face_face_FaceRecognizer_setLabelInfo(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::face;

    if(!PyObject_TypeCheck(self, &pyopencv_face_FaceRecognizer_Type))
        return failmsgp("Incorrect type of self (must be 'face_FaceRecognizer' or its derivative)");
    cv::face::FaceRecognizer* _self_ = dynamic_cast<cv::face::FaceRecognizer*>(((pyopencv_face_FaceRecognizer_t*)self)->v.get());
    int label=0;
    PyObject* pyobj_strInfo = NULL;
    String strInfo;

    const char* keywords[] = { "label", "strInfo", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "iO:face_FaceRecognizer.setLabelInfo", (char**)keywords, &label, &pyobj_strInfo) &&
        pyopencv_to(pyobj_strInfo, strInfo, ArgInfo("strInfo", 0)) )
    {
        ERRWRAP2(_self_->setLabelInfo(label, strInfo));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_face_face_FaceRecognizer_train(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::face;

    if(!PyObject_TypeCheck(self, &pyopencv_face_FaceRecognizer_Type))
        return failmsgp("Incorrect type of self (must be 'face_FaceRecognizer' or its derivative)");
    cv::face::FaceRecognizer* _self_ = dynamic_cast<cv::face::FaceRecognizer*>(((pyopencv_face_FaceRecognizer_t*)self)->v.get());
    {
    PyObject* pyobj_src = NULL;
    vector_Mat src;
    PyObject* pyobj_labels = NULL;
    Mat labels;

    const char* keywords[] = { "src", "labels", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO:face_FaceRecognizer.train", (char**)keywords, &pyobj_src, &pyobj_labels) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_labels, labels, ArgInfo("labels", 0)) )
    {
        ERRWRAP2(_self_->train(src, labels));
        Py_RETURN_NONE;
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_src = NULL;
    vector_Mat src;
    PyObject* pyobj_labels = NULL;
    UMat labels;

    const char* keywords[] = { "src", "labels", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO:face_FaceRecognizer.train", (char**)keywords, &pyobj_src, &pyobj_labels) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_labels, labels, ArgInfo("labels", 0)) )
    {
        ERRWRAP2(_self_->train(src, labels));
        Py_RETURN_NONE;
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_face_face_FaceRecognizer_update(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::face;

    if(!PyObject_TypeCheck(self, &pyopencv_face_FaceRecognizer_Type))
        return failmsgp("Incorrect type of self (must be 'face_FaceRecognizer' or its derivative)");
    cv::face::FaceRecognizer* _self_ = dynamic_cast<cv::face::FaceRecognizer*>(((pyopencv_face_FaceRecognizer_t*)self)->v.get());
    {
    PyObject* pyobj_src = NULL;
    vector_Mat src;
    PyObject* pyobj_labels = NULL;
    Mat labels;

    const char* keywords[] = { "src", "labels", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO:face_FaceRecognizer.update", (char**)keywords, &pyobj_src, &pyobj_labels) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_labels, labels, ArgInfo("labels", 0)) )
    {
        ERRWRAP2(_self_->update(src, labels));
        Py_RETURN_NONE;
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_src = NULL;
    vector_Mat src;
    PyObject* pyobj_labels = NULL;
    UMat labels;

    const char* keywords[] = { "src", "labels", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO:face_FaceRecognizer.update", (char**)keywords, &pyobj_src, &pyobj_labels) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_labels, labels, ArgInfo("labels", 0)) )
    {
        ERRWRAP2(_self_->update(src, labels));
        Py_RETURN_NONE;
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_face_FaceRecognizer_methods[] =
{
    {"getLabelInfo", (PyCFunction)pyopencv_cv_face_face_FaceRecognizer_getLabelInfo, METH_VARARGS | METH_KEYWORDS, "getLabelInfo(label) -> retval"},
    {"getLabelsByString", (PyCFunction)pyopencv_cv_face_face_FaceRecognizer_getLabelsByString, METH_VARARGS | METH_KEYWORDS, "getLabelsByString(str) -> retval"},
    {"load", (PyCFunction)pyopencv_cv_face_face_FaceRecognizer_load, METH_VARARGS | METH_KEYWORDS, "load(filename) -> None"},
    {"predict", (PyCFunction)pyopencv_cv_face_face_FaceRecognizer_predict, METH_VARARGS | METH_KEYWORDS, "predict(src) -> label, confidence"},
    {"predict_collect", (PyCFunction)pyopencv_cv_face_face_FaceRecognizer_predict_collect, METH_VARARGS | METH_KEYWORDS, "predict_collect(src, collector) -> None"},
    {"predict_label", (PyCFunction)pyopencv_cv_face_face_FaceRecognizer_predict_label, METH_VARARGS | METH_KEYWORDS, "predict_label(src) -> retval"},
    {"save", (PyCFunction)pyopencv_cv_face_face_FaceRecognizer_save, METH_VARARGS | METH_KEYWORDS, "save(filename) -> None"},
    {"setLabelInfo", (PyCFunction)pyopencv_cv_face_face_FaceRecognizer_setLabelInfo, METH_VARARGS | METH_KEYWORDS, "setLabelInfo(label, strInfo) -> None"},
    {"train", (PyCFunction)pyopencv_cv_face_face_FaceRecognizer_train, METH_VARARGS | METH_KEYWORDS, "train(src, labels) -> None"},
    {"update", (PyCFunction)pyopencv_cv_face_face_FaceRecognizer_update, METH_VARARGS | METH_KEYWORDS, "update(src, labels) -> None"},

    {NULL,          NULL}
};

static void pyopencv_face_FaceRecognizer_specials(void)
{
    pyopencv_face_FaceRecognizer_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_face_FaceRecognizer_Type.tp_dealloc = pyopencv_face_FaceRecognizer_dealloc;
    pyopencv_face_FaceRecognizer_Type.tp_repr = pyopencv_face_FaceRecognizer_repr;
    pyopencv_face_FaceRecognizer_Type.tp_getset = pyopencv_face_FaceRecognizer_getseters;
    pyopencv_face_FaceRecognizer_Type.tp_methods = pyopencv_face_FaceRecognizer_methods;
}

static PyObject* pyopencv_face_BIF_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<face_BIF %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_face_BIF_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_face_face_BIF_compute(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::face;

    if(!PyObject_TypeCheck(self, &pyopencv_face_BIF_Type))
        return failmsgp("Incorrect type of self (must be 'face_BIF' or its derivative)");
    cv::face::BIF* _self_ = dynamic_cast<cv::face::BIF*>(((pyopencv_face_BIF_t*)self)->v.get());
    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_features = NULL;
    Mat features;

    const char* keywords[] = { "image", "features", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:face_BIF.compute", (char**)keywords, &pyobj_image, &pyobj_features) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_features, features, ArgInfo("features", 1)) )
    {
        ERRWRAP2(_self_->compute(image, features));
        return pyopencv_from(features);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_features = NULL;
    UMat features;

    const char* keywords[] = { "image", "features", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:face_BIF.compute", (char**)keywords, &pyobj_image, &pyobj_features) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_features, features, ArgInfo("features", 1)) )
    {
        ERRWRAP2(_self_->compute(image, features));
        return pyopencv_from(features);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_face_face_BIF_getNumBands(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::face;

    if(!PyObject_TypeCheck(self, &pyopencv_face_BIF_Type))
        return failmsgp("Incorrect type of self (must be 'face_BIF' or its derivative)");
    cv::face::BIF* _self_ = dynamic_cast<cv::face::BIF*>(((pyopencv_face_BIF_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getNumBands());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_face_face_BIF_getNumRotations(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::face;

    if(!PyObject_TypeCheck(self, &pyopencv_face_BIF_Type))
        return failmsgp("Incorrect type of self (must be 'face_BIF' or its derivative)");
    cv::face::BIF* _self_ = dynamic_cast<cv::face::BIF*>(((pyopencv_face_BIF_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getNumRotations());
        return pyopencv_from(retval);
    }

    return NULL;
}



static PyMethodDef pyopencv_face_BIF_methods[] =
{
    {"compute", (PyCFunction)pyopencv_cv_face_face_BIF_compute, METH_VARARGS | METH_KEYWORDS, "compute(image[, features]) -> features"},
    {"getNumBands", (PyCFunction)pyopencv_cv_face_face_BIF_getNumBands, METH_VARARGS | METH_KEYWORDS, "getNumBands() -> retval"},
    {"getNumRotations", (PyCFunction)pyopencv_cv_face_face_BIF_getNumRotations, METH_VARARGS | METH_KEYWORDS, "getNumRotations() -> retval"},

    {NULL,          NULL}
};

static void pyopencv_face_BIF_specials(void)
{
    pyopencv_face_BIF_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_face_BIF_Type.tp_dealloc = pyopencv_face_BIF_dealloc;
    pyopencv_face_BIF_Type.tp_repr = pyopencv_face_BIF_repr;
    pyopencv_face_BIF_Type.tp_getset = pyopencv_face_BIF_getseters;
    pyopencv_face_BIF_Type.tp_methods = pyopencv_face_BIF_methods;
}

static PyObject* pyopencv_face_BasicFaceRecognizer_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<face_BasicFaceRecognizer %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_face_BasicFaceRecognizer_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_face_face_BasicFaceRecognizer_getEigenValues(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::face;

    if(!PyObject_TypeCheck(self, &pyopencv_face_BasicFaceRecognizer_Type))
        return failmsgp("Incorrect type of self (must be 'face_BasicFaceRecognizer' or its derivative)");
    cv::face::BasicFaceRecognizer* _self_ = dynamic_cast<cv::face::BasicFaceRecognizer*>(((pyopencv_face_BasicFaceRecognizer_t*)self)->v.get());
    cv::Mat retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getEigenValues());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_face_face_BasicFaceRecognizer_getEigenVectors(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::face;

    if(!PyObject_TypeCheck(self, &pyopencv_face_BasicFaceRecognizer_Type))
        return failmsgp("Incorrect type of self (must be 'face_BasicFaceRecognizer' or its derivative)");
    cv::face::BasicFaceRecognizer* _self_ = dynamic_cast<cv::face::BasicFaceRecognizer*>(((pyopencv_face_BasicFaceRecognizer_t*)self)->v.get());
    cv::Mat retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getEigenVectors());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_face_face_BasicFaceRecognizer_getLabels(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::face;

    if(!PyObject_TypeCheck(self, &pyopencv_face_BasicFaceRecognizer_Type))
        return failmsgp("Incorrect type of self (must be 'face_BasicFaceRecognizer' or its derivative)");
    cv::face::BasicFaceRecognizer* _self_ = dynamic_cast<cv::face::BasicFaceRecognizer*>(((pyopencv_face_BasicFaceRecognizer_t*)self)->v.get());
    cv::Mat retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getLabels());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_face_face_BasicFaceRecognizer_getMean(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::face;

    if(!PyObject_TypeCheck(self, &pyopencv_face_BasicFaceRecognizer_Type))
        return failmsgp("Incorrect type of self (must be 'face_BasicFaceRecognizer' or its derivative)");
    cv::face::BasicFaceRecognizer* _self_ = dynamic_cast<cv::face::BasicFaceRecognizer*>(((pyopencv_face_BasicFaceRecognizer_t*)self)->v.get());
    cv::Mat retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getMean());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_face_face_BasicFaceRecognizer_getNumComponents(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::face;

    if(!PyObject_TypeCheck(self, &pyopencv_face_BasicFaceRecognizer_Type))
        return failmsgp("Incorrect type of self (must be 'face_BasicFaceRecognizer' or its derivative)");
    cv::face::BasicFaceRecognizer* _self_ = dynamic_cast<cv::face::BasicFaceRecognizer*>(((pyopencv_face_BasicFaceRecognizer_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getNumComponents());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_face_face_BasicFaceRecognizer_getProjections(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::face;

    if(!PyObject_TypeCheck(self, &pyopencv_face_BasicFaceRecognizer_Type))
        return failmsgp("Incorrect type of self (must be 'face_BasicFaceRecognizer' or its derivative)");
    cv::face::BasicFaceRecognizer* _self_ = dynamic_cast<cv::face::BasicFaceRecognizer*>(((pyopencv_face_BasicFaceRecognizer_t*)self)->v.get());
    std::vector<cv::Mat> retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getProjections());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_face_face_BasicFaceRecognizer_getThreshold(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::face;

    if(!PyObject_TypeCheck(self, &pyopencv_face_BasicFaceRecognizer_Type))
        return failmsgp("Incorrect type of self (must be 'face_BasicFaceRecognizer' or its derivative)");
    cv::face::BasicFaceRecognizer* _self_ = dynamic_cast<cv::face::BasicFaceRecognizer*>(((pyopencv_face_BasicFaceRecognizer_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getThreshold());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_face_face_BasicFaceRecognizer_setNumComponents(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::face;

    if(!PyObject_TypeCheck(self, &pyopencv_face_BasicFaceRecognizer_Type))
        return failmsgp("Incorrect type of self (must be 'face_BasicFaceRecognizer' or its derivative)");
    cv::face::BasicFaceRecognizer* _self_ = dynamic_cast<cv::face::BasicFaceRecognizer*>(((pyopencv_face_BasicFaceRecognizer_t*)self)->v.get());
    int val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:face_BasicFaceRecognizer.setNumComponents", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setNumComponents(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_face_face_BasicFaceRecognizer_setThreshold(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::face;

    if(!PyObject_TypeCheck(self, &pyopencv_face_BasicFaceRecognizer_Type))
        return failmsgp("Incorrect type of self (must be 'face_BasicFaceRecognizer' or its derivative)");
    cv::face::BasicFaceRecognizer* _self_ = dynamic_cast<cv::face::BasicFaceRecognizer*>(((pyopencv_face_BasicFaceRecognizer_t*)self)->v.get());
    double val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:face_BasicFaceRecognizer.setThreshold", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setThreshold(val));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_face_BasicFaceRecognizer_methods[] =
{
    {"getEigenValues", (PyCFunction)pyopencv_cv_face_face_BasicFaceRecognizer_getEigenValues, METH_VARARGS | METH_KEYWORDS, "getEigenValues() -> retval"},
    {"getEigenVectors", (PyCFunction)pyopencv_cv_face_face_BasicFaceRecognizer_getEigenVectors, METH_VARARGS | METH_KEYWORDS, "getEigenVectors() -> retval"},
    {"getLabels", (PyCFunction)pyopencv_cv_face_face_BasicFaceRecognizer_getLabels, METH_VARARGS | METH_KEYWORDS, "getLabels() -> retval"},
    {"getMean", (PyCFunction)pyopencv_cv_face_face_BasicFaceRecognizer_getMean, METH_VARARGS | METH_KEYWORDS, "getMean() -> retval"},
    {"getNumComponents", (PyCFunction)pyopencv_cv_face_face_BasicFaceRecognizer_getNumComponents, METH_VARARGS | METH_KEYWORDS, "getNumComponents() -> retval"},
    {"getProjections", (PyCFunction)pyopencv_cv_face_face_BasicFaceRecognizer_getProjections, METH_VARARGS | METH_KEYWORDS, "getProjections() -> retval"},
    {"getThreshold", (PyCFunction)pyopencv_cv_face_face_BasicFaceRecognizer_getThreshold, METH_VARARGS | METH_KEYWORDS, "getThreshold() -> retval"},
    {"setNumComponents", (PyCFunction)pyopencv_cv_face_face_BasicFaceRecognizer_setNumComponents, METH_VARARGS | METH_KEYWORDS, "setNumComponents(val) -> None"},
    {"setThreshold", (PyCFunction)pyopencv_cv_face_face_BasicFaceRecognizer_setThreshold, METH_VARARGS | METH_KEYWORDS, "setThreshold(val) -> None"},

    {NULL,          NULL}
};

static void pyopencv_face_BasicFaceRecognizer_specials(void)
{
    pyopencv_face_BasicFaceRecognizer_Type.tp_base = &pyopencv_face_FaceRecognizer_Type;
    pyopencv_face_BasicFaceRecognizer_Type.tp_dealloc = pyopencv_face_BasicFaceRecognizer_dealloc;
    pyopencv_face_BasicFaceRecognizer_Type.tp_repr = pyopencv_face_BasicFaceRecognizer_repr;
    pyopencv_face_BasicFaceRecognizer_Type.tp_getset = pyopencv_face_BasicFaceRecognizer_getseters;
    pyopencv_face_BasicFaceRecognizer_Type.tp_methods = pyopencv_face_BasicFaceRecognizer_methods;
}

static PyObject* pyopencv_face_LBPHFaceRecognizer_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<face_LBPHFaceRecognizer %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_face_LBPHFaceRecognizer_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_face_face_LBPHFaceRecognizer_getGridX(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::face;

    if(!PyObject_TypeCheck(self, &pyopencv_face_LBPHFaceRecognizer_Type))
        return failmsgp("Incorrect type of self (must be 'face_LBPHFaceRecognizer' or its derivative)");
    cv::face::LBPHFaceRecognizer* _self_ = dynamic_cast<cv::face::LBPHFaceRecognizer*>(((pyopencv_face_LBPHFaceRecognizer_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getGridX());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_face_face_LBPHFaceRecognizer_getGridY(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::face;

    if(!PyObject_TypeCheck(self, &pyopencv_face_LBPHFaceRecognizer_Type))
        return failmsgp("Incorrect type of self (must be 'face_LBPHFaceRecognizer' or its derivative)");
    cv::face::LBPHFaceRecognizer* _self_ = dynamic_cast<cv::face::LBPHFaceRecognizer*>(((pyopencv_face_LBPHFaceRecognizer_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getGridY());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_face_face_LBPHFaceRecognizer_getHistograms(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::face;

    if(!PyObject_TypeCheck(self, &pyopencv_face_LBPHFaceRecognizer_Type))
        return failmsgp("Incorrect type of self (must be 'face_LBPHFaceRecognizer' or its derivative)");
    cv::face::LBPHFaceRecognizer* _self_ = dynamic_cast<cv::face::LBPHFaceRecognizer*>(((pyopencv_face_LBPHFaceRecognizer_t*)self)->v.get());
    std::vector<cv::Mat> retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getHistograms());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_face_face_LBPHFaceRecognizer_getLabels(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::face;

    if(!PyObject_TypeCheck(self, &pyopencv_face_LBPHFaceRecognizer_Type))
        return failmsgp("Incorrect type of self (must be 'face_LBPHFaceRecognizer' or its derivative)");
    cv::face::LBPHFaceRecognizer* _self_ = dynamic_cast<cv::face::LBPHFaceRecognizer*>(((pyopencv_face_LBPHFaceRecognizer_t*)self)->v.get());
    cv::Mat retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getLabels());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_face_face_LBPHFaceRecognizer_getNeighbors(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::face;

    if(!PyObject_TypeCheck(self, &pyopencv_face_LBPHFaceRecognizer_Type))
        return failmsgp("Incorrect type of self (must be 'face_LBPHFaceRecognizer' or its derivative)");
    cv::face::LBPHFaceRecognizer* _self_ = dynamic_cast<cv::face::LBPHFaceRecognizer*>(((pyopencv_face_LBPHFaceRecognizer_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getNeighbors());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_face_face_LBPHFaceRecognizer_getRadius(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::face;

    if(!PyObject_TypeCheck(self, &pyopencv_face_LBPHFaceRecognizer_Type))
        return failmsgp("Incorrect type of self (must be 'face_LBPHFaceRecognizer' or its derivative)");
    cv::face::LBPHFaceRecognizer* _self_ = dynamic_cast<cv::face::LBPHFaceRecognizer*>(((pyopencv_face_LBPHFaceRecognizer_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getRadius());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_face_face_LBPHFaceRecognizer_getThreshold(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::face;

    if(!PyObject_TypeCheck(self, &pyopencv_face_LBPHFaceRecognizer_Type))
        return failmsgp("Incorrect type of self (must be 'face_LBPHFaceRecognizer' or its derivative)");
    cv::face::LBPHFaceRecognizer* _self_ = dynamic_cast<cv::face::LBPHFaceRecognizer*>(((pyopencv_face_LBPHFaceRecognizer_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getThreshold());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_face_face_LBPHFaceRecognizer_setGridX(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::face;

    if(!PyObject_TypeCheck(self, &pyopencv_face_LBPHFaceRecognizer_Type))
        return failmsgp("Incorrect type of self (must be 'face_LBPHFaceRecognizer' or its derivative)");
    cv::face::LBPHFaceRecognizer* _self_ = dynamic_cast<cv::face::LBPHFaceRecognizer*>(((pyopencv_face_LBPHFaceRecognizer_t*)self)->v.get());
    int val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:face_LBPHFaceRecognizer.setGridX", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setGridX(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_face_face_LBPHFaceRecognizer_setGridY(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::face;

    if(!PyObject_TypeCheck(self, &pyopencv_face_LBPHFaceRecognizer_Type))
        return failmsgp("Incorrect type of self (must be 'face_LBPHFaceRecognizer' or its derivative)");
    cv::face::LBPHFaceRecognizer* _self_ = dynamic_cast<cv::face::LBPHFaceRecognizer*>(((pyopencv_face_LBPHFaceRecognizer_t*)self)->v.get());
    int val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:face_LBPHFaceRecognizer.setGridY", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setGridY(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_face_face_LBPHFaceRecognizer_setNeighbors(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::face;

    if(!PyObject_TypeCheck(self, &pyopencv_face_LBPHFaceRecognizer_Type))
        return failmsgp("Incorrect type of self (must be 'face_LBPHFaceRecognizer' or its derivative)");
    cv::face::LBPHFaceRecognizer* _self_ = dynamic_cast<cv::face::LBPHFaceRecognizer*>(((pyopencv_face_LBPHFaceRecognizer_t*)self)->v.get());
    int val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:face_LBPHFaceRecognizer.setNeighbors", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setNeighbors(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_face_face_LBPHFaceRecognizer_setRadius(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::face;

    if(!PyObject_TypeCheck(self, &pyopencv_face_LBPHFaceRecognizer_Type))
        return failmsgp("Incorrect type of self (must be 'face_LBPHFaceRecognizer' or its derivative)");
    cv::face::LBPHFaceRecognizer* _self_ = dynamic_cast<cv::face::LBPHFaceRecognizer*>(((pyopencv_face_LBPHFaceRecognizer_t*)self)->v.get());
    int val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:face_LBPHFaceRecognizer.setRadius", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setRadius(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_face_face_LBPHFaceRecognizer_setThreshold(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::face;

    if(!PyObject_TypeCheck(self, &pyopencv_face_LBPHFaceRecognizer_Type))
        return failmsgp("Incorrect type of self (must be 'face_LBPHFaceRecognizer' or its derivative)");
    cv::face::LBPHFaceRecognizer* _self_ = dynamic_cast<cv::face::LBPHFaceRecognizer*>(((pyopencv_face_LBPHFaceRecognizer_t*)self)->v.get());
    double val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:face_LBPHFaceRecognizer.setThreshold", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setThreshold(val));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_face_LBPHFaceRecognizer_methods[] =
{
    {"getGridX", (PyCFunction)pyopencv_cv_face_face_LBPHFaceRecognizer_getGridX, METH_VARARGS | METH_KEYWORDS, "getGridX() -> retval"},
    {"getGridY", (PyCFunction)pyopencv_cv_face_face_LBPHFaceRecognizer_getGridY, METH_VARARGS | METH_KEYWORDS, "getGridY() -> retval"},
    {"getHistograms", (PyCFunction)pyopencv_cv_face_face_LBPHFaceRecognizer_getHistograms, METH_VARARGS | METH_KEYWORDS, "getHistograms() -> retval"},
    {"getLabels", (PyCFunction)pyopencv_cv_face_face_LBPHFaceRecognizer_getLabels, METH_VARARGS | METH_KEYWORDS, "getLabels() -> retval"},
    {"getNeighbors", (PyCFunction)pyopencv_cv_face_face_LBPHFaceRecognizer_getNeighbors, METH_VARARGS | METH_KEYWORDS, "getNeighbors() -> retval"},
    {"getRadius", (PyCFunction)pyopencv_cv_face_face_LBPHFaceRecognizer_getRadius, METH_VARARGS | METH_KEYWORDS, "getRadius() -> retval"},
    {"getThreshold", (PyCFunction)pyopencv_cv_face_face_LBPHFaceRecognizer_getThreshold, METH_VARARGS | METH_KEYWORDS, "getThreshold() -> retval"},
    {"setGridX", (PyCFunction)pyopencv_cv_face_face_LBPHFaceRecognizer_setGridX, METH_VARARGS | METH_KEYWORDS, "setGridX(val) -> None"},
    {"setGridY", (PyCFunction)pyopencv_cv_face_face_LBPHFaceRecognizer_setGridY, METH_VARARGS | METH_KEYWORDS, "setGridY(val) -> None"},
    {"setNeighbors", (PyCFunction)pyopencv_cv_face_face_LBPHFaceRecognizer_setNeighbors, METH_VARARGS | METH_KEYWORDS, "setNeighbors(val) -> None"},
    {"setRadius", (PyCFunction)pyopencv_cv_face_face_LBPHFaceRecognizer_setRadius, METH_VARARGS | METH_KEYWORDS, "setRadius(val) -> None"},
    {"setThreshold", (PyCFunction)pyopencv_cv_face_face_LBPHFaceRecognizer_setThreshold, METH_VARARGS | METH_KEYWORDS, "setThreshold(val) -> None"},

    {NULL,          NULL}
};

static void pyopencv_face_LBPHFaceRecognizer_specials(void)
{
    pyopencv_face_LBPHFaceRecognizer_Type.tp_base = &pyopencv_face_FaceRecognizer_Type;
    pyopencv_face_LBPHFaceRecognizer_Type.tp_dealloc = pyopencv_face_LBPHFaceRecognizer_dealloc;
    pyopencv_face_LBPHFaceRecognizer_Type.tp_repr = pyopencv_face_LBPHFaceRecognizer_repr;
    pyopencv_face_LBPHFaceRecognizer_Type.tp_getset = pyopencv_face_LBPHFaceRecognizer_getseters;
    pyopencv_face_LBPHFaceRecognizer_Type.tp_methods = pyopencv_face_LBPHFaceRecognizer_methods;
}

static PyObject* pyopencv_face_PredictCollector_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<face_PredictCollector %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_face_PredictCollector_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_face_PredictCollector_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_face_PredictCollector_specials(void)
{
    pyopencv_face_PredictCollector_Type.tp_base = NULL;
    pyopencv_face_PredictCollector_Type.tp_dealloc = pyopencv_face_PredictCollector_dealloc;
    pyopencv_face_PredictCollector_Type.tp_repr = pyopencv_face_PredictCollector_repr;
    pyopencv_face_PredictCollector_Type.tp_getset = pyopencv_face_PredictCollector_getseters;
    pyopencv_face_PredictCollector_Type.tp_methods = pyopencv_face_PredictCollector_methods;
}

static PyObject* pyopencv_face_StandardCollector_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<face_StandardCollector %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_face_StandardCollector_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_face_face_StandardCollector_getMinDist(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::face;

    if(!PyObject_TypeCheck(self, &pyopencv_face_StandardCollector_Type))
        return failmsgp("Incorrect type of self (must be 'face_StandardCollector' or its derivative)");
    cv::face::StandardCollector* _self_ = ((pyopencv_face_StandardCollector_t*)self)->v.get();
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getMinDist());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_face_face_StandardCollector_getMinLabel(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::face;

    if(!PyObject_TypeCheck(self, &pyopencv_face_StandardCollector_Type))
        return failmsgp("Incorrect type of self (must be 'face_StandardCollector' or its derivative)");
    cv::face::StandardCollector* _self_ = ((pyopencv_face_StandardCollector_t*)self)->v.get();
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getMinLabel());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_face_face_StandardCollector_getResults(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::face;

    if(!PyObject_TypeCheck(self, &pyopencv_face_StandardCollector_Type))
        return failmsgp("Incorrect type of self (must be 'face_StandardCollector' or its derivative)");
    cv::face::StandardCollector* _self_ = ((pyopencv_face_StandardCollector_t*)self)->v.get();
    bool sorted=false;
    std::vector< std::pair<int, double> > retval;

    const char* keywords[] = { "sorted", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|b:face_StandardCollector.getResults", (char**)keywords, &sorted) )
    {
        ERRWRAP2(retval = _self_->getResults(sorted));
        return pyopencv_from(retval);
    }

    return NULL;
}



static PyMethodDef pyopencv_face_StandardCollector_methods[] =
{
    {"getMinDist", (PyCFunction)pyopencv_cv_face_face_StandardCollector_getMinDist, METH_VARARGS | METH_KEYWORDS, "getMinDist() -> retval"},
    {"getMinLabel", (PyCFunction)pyopencv_cv_face_face_StandardCollector_getMinLabel, METH_VARARGS | METH_KEYWORDS, "getMinLabel() -> retval"},
    {"getResults", (PyCFunction)pyopencv_cv_face_face_StandardCollector_getResults, METH_VARARGS | METH_KEYWORDS, "getResults([, sorted]) -> retval"},

    {NULL,          NULL}
};

static void pyopencv_face_StandardCollector_specials(void)
{
    pyopencv_face_StandardCollector_Type.tp_base = &pyopencv_face_PredictCollector_Type;
    pyopencv_face_StandardCollector_Type.tp_dealloc = pyopencv_face_StandardCollector_dealloc;
    pyopencv_face_StandardCollector_Type.tp_repr = pyopencv_face_StandardCollector_repr;
    pyopencv_face_StandardCollector_Type.tp_getset = pyopencv_face_StandardCollector_getseters;
    pyopencv_face_StandardCollector_Type.tp_methods = pyopencv_face_StandardCollector_methods;
}

static PyObject* pyopencv_Feature2D_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<Feature2D %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_Feature2D_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_Feature2D_compute(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_Feature2D_Type))
        return failmsgp("Incorrect type of self (must be 'Feature2D' or its derivative)");
    cv::Feature2D* _self_ = dynamic_cast<cv::Feature2D*>(((pyopencv_Feature2D_t*)self)->v.get());
    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_keypoints = NULL;
    vector_KeyPoint keypoints;
    PyObject* pyobj_descriptors = NULL;
    Mat descriptors;

    const char* keywords[] = { "image", "keypoints", "descriptors", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|O:Feature2D.compute", (char**)keywords, &pyobj_image, &pyobj_keypoints, &pyobj_descriptors) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_keypoints, keypoints, ArgInfo("keypoints", 1)) &&
        pyopencv_to(pyobj_descriptors, descriptors, ArgInfo("descriptors", 1)) )
    {
        ERRWRAP2(_self_->compute(image, keypoints, descriptors));
        return Py_BuildValue("(NN)", pyopencv_from(keypoints), pyopencv_from(descriptors));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_keypoints = NULL;
    vector_KeyPoint keypoints;
    PyObject* pyobj_descriptors = NULL;
    UMat descriptors;

    const char* keywords[] = { "image", "keypoints", "descriptors", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|O:Feature2D.compute", (char**)keywords, &pyobj_image, &pyobj_keypoints, &pyobj_descriptors) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_keypoints, keypoints, ArgInfo("keypoints", 1)) &&
        pyopencv_to(pyobj_descriptors, descriptors, ArgInfo("descriptors", 1)) )
    {
        ERRWRAP2(_self_->compute(image, keypoints, descriptors));
        return Py_BuildValue("(NN)", pyopencv_from(keypoints), pyopencv_from(descriptors));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_images = NULL;
    vector_Mat images;
    PyObject* pyobj_keypoints = NULL;
    vector_vector_KeyPoint keypoints;
    PyObject* pyobj_descriptors = NULL;
    vector_Mat descriptors;

    const char* keywords[] = { "images", "keypoints", "descriptors", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|O:Feature2D.compute", (char**)keywords, &pyobj_images, &pyobj_keypoints, &pyobj_descriptors) &&
        pyopencv_to(pyobj_images, images, ArgInfo("images", 0)) &&
        pyopencv_to(pyobj_keypoints, keypoints, ArgInfo("keypoints", 1)) &&
        pyopencv_to(pyobj_descriptors, descriptors, ArgInfo("descriptors", 1)) )
    {
        ERRWRAP2(_self_->compute(images, keypoints, descriptors));
        return Py_BuildValue("(NN)", pyopencv_from(keypoints), pyopencv_from(descriptors));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_images = NULL;
    vector_Mat images;
    PyObject* pyobj_keypoints = NULL;
    vector_vector_KeyPoint keypoints;
    PyObject* pyobj_descriptors = NULL;
    vector_Mat descriptors;

    const char* keywords[] = { "images", "keypoints", "descriptors", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|O:Feature2D.compute", (char**)keywords, &pyobj_images, &pyobj_keypoints, &pyobj_descriptors) &&
        pyopencv_to(pyobj_images, images, ArgInfo("images", 0)) &&
        pyopencv_to(pyobj_keypoints, keypoints, ArgInfo("keypoints", 1)) &&
        pyopencv_to(pyobj_descriptors, descriptors, ArgInfo("descriptors", 1)) )
    {
        ERRWRAP2(_self_->compute(images, keypoints, descriptors));
        return Py_BuildValue("(NN)", pyopencv_from(keypoints), pyopencv_from(descriptors));
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_Feature2D_defaultNorm(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_Feature2D_Type))
        return failmsgp("Incorrect type of self (must be 'Feature2D' or its derivative)");
    cv::Feature2D* _self_ = dynamic_cast<cv::Feature2D*>(((pyopencv_Feature2D_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->defaultNorm());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_Feature2D_descriptorSize(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_Feature2D_Type))
        return failmsgp("Incorrect type of self (must be 'Feature2D' or its derivative)");
    cv::Feature2D* _self_ = dynamic_cast<cv::Feature2D*>(((pyopencv_Feature2D_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->descriptorSize());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_Feature2D_descriptorType(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_Feature2D_Type))
        return failmsgp("Incorrect type of self (must be 'Feature2D' or its derivative)");
    cv::Feature2D* _self_ = dynamic_cast<cv::Feature2D*>(((pyopencv_Feature2D_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->descriptorType());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_Feature2D_detect(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_Feature2D_Type))
        return failmsgp("Incorrect type of self (must be 'Feature2D' or its derivative)");
    cv::Feature2D* _self_ = dynamic_cast<cv::Feature2D*>(((pyopencv_Feature2D_t*)self)->v.get());
    {
    PyObject* pyobj_image = NULL;
    Mat image;
    vector_KeyPoint keypoints;
    PyObject* pyobj_mask = NULL;
    Mat mask;

    const char* keywords[] = { "image", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:Feature2D.detect", (char**)keywords, &pyobj_image, &pyobj_mask) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(_self_->detect(image, keypoints, mask));
        return pyopencv_from(keypoints);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    vector_KeyPoint keypoints;
    PyObject* pyobj_mask = NULL;
    UMat mask;

    const char* keywords[] = { "image", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:Feature2D.detect", (char**)keywords, &pyobj_image, &pyobj_mask) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(_self_->detect(image, keypoints, mask));
        return pyopencv_from(keypoints);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_images = NULL;
    vector_Mat images;
    vector_vector_KeyPoint keypoints;
    PyObject* pyobj_masks = NULL;
    vector_Mat masks;

    const char* keywords[] = { "images", "masks", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:Feature2D.detect", (char**)keywords, &pyobj_images, &pyobj_masks) &&
        pyopencv_to(pyobj_images, images, ArgInfo("images", 0)) &&
        pyopencv_to(pyobj_masks, masks, ArgInfo("masks", 0)) )
    {
        ERRWRAP2(_self_->detect(images, keypoints, masks));
        return pyopencv_from(keypoints);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_images = NULL;
    vector_Mat images;
    vector_vector_KeyPoint keypoints;
    PyObject* pyobj_masks = NULL;
    vector_Mat masks;

    const char* keywords[] = { "images", "masks", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:Feature2D.detect", (char**)keywords, &pyobj_images, &pyobj_masks) &&
        pyopencv_to(pyobj_images, images, ArgInfo("images", 0)) &&
        pyopencv_to(pyobj_masks, masks, ArgInfo("masks", 0)) )
    {
        ERRWRAP2(_self_->detect(images, keypoints, masks));
        return pyopencv_from(keypoints);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_Feature2D_detectAndCompute(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_Feature2D_Type))
        return failmsgp("Incorrect type of self (must be 'Feature2D' or its derivative)");
    cv::Feature2D* _self_ = dynamic_cast<cv::Feature2D*>(((pyopencv_Feature2D_t*)self)->v.get());
    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    vector_KeyPoint keypoints;
    PyObject* pyobj_descriptors = NULL;
    Mat descriptors;
    bool useProvidedKeypoints=false;

    const char* keywords[] = { "image", "mask", "descriptors", "useProvidedKeypoints", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|Ob:Feature2D.detectAndCompute", (char**)keywords, &pyobj_image, &pyobj_mask, &pyobj_descriptors, &useProvidedKeypoints) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_mask, mask, ArgInfo("mask", 0)) &&
        pyopencv_to(pyobj_descriptors, descriptors, ArgInfo("descriptors", 1)) )
    {
        ERRWRAP2(_self_->detectAndCompute(image, mask, keypoints, descriptors, useProvidedKeypoints));
        return Py_BuildValue("(NN)", pyopencv_from(keypoints), pyopencv_from(descriptors));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_mask = NULL;
    UMat mask;
    vector_KeyPoint keypoints;
    PyObject* pyobj_descriptors = NULL;
    UMat descriptors;
    bool useProvidedKeypoints=false;

    const char* keywords[] = { "image", "mask", "descriptors", "useProvidedKeypoints", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|Ob:Feature2D.detectAndCompute", (char**)keywords, &pyobj_image, &pyobj_mask, &pyobj_descriptors, &useProvidedKeypoints) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_mask, mask, ArgInfo("mask", 0)) &&
        pyopencv_to(pyobj_descriptors, descriptors, ArgInfo("descriptors", 1)) )
    {
        ERRWRAP2(_self_->detectAndCompute(image, mask, keypoints, descriptors, useProvidedKeypoints));
        return Py_BuildValue("(NN)", pyopencv_from(keypoints), pyopencv_from(descriptors));
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_Feature2D_empty(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_Feature2D_Type))
        return failmsgp("Incorrect type of self (must be 'Feature2D' or its derivative)");
    cv::Feature2D* _self_ = dynamic_cast<cv::Feature2D*>(((pyopencv_Feature2D_t*)self)->v.get());
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->empty());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_Feature2D_read(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_Feature2D_Type))
        return failmsgp("Incorrect type of self (must be 'Feature2D' or its derivative)");
    cv::Feature2D* _self_ = dynamic_cast<cv::Feature2D*>(((pyopencv_Feature2D_t*)self)->v.get());
    PyObject* pyobj_fileName = NULL;
    String fileName;

    const char* keywords[] = { "fileName", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:Feature2D.read", (char**)keywords, &pyobj_fileName) &&
        pyopencv_to(pyobj_fileName, fileName, ArgInfo("fileName", 0)) )
    {
        ERRWRAP2(_self_->read(fileName));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_Feature2D_write(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_Feature2D_Type))
        return failmsgp("Incorrect type of self (must be 'Feature2D' or its derivative)");
    cv::Feature2D* _self_ = dynamic_cast<cv::Feature2D*>(((pyopencv_Feature2D_t*)self)->v.get());
    PyObject* pyobj_fileName = NULL;
    String fileName;

    const char* keywords[] = { "fileName", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:Feature2D.write", (char**)keywords, &pyobj_fileName) &&
        pyopencv_to(pyobj_fileName, fileName, ArgInfo("fileName", 0)) )
    {
        ERRWRAP2(_self_->write(fileName));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_Feature2D_methods[] =
{
    {"compute", (PyCFunction)pyopencv_cv_Feature2D_compute, METH_VARARGS | METH_KEYWORDS, "compute(image, keypoints[, descriptors]) -> keypoints, descriptors  or  compute(images, keypoints[, descriptors]) -> keypoints, descriptors"},
    {"defaultNorm", (PyCFunction)pyopencv_cv_Feature2D_defaultNorm, METH_VARARGS | METH_KEYWORDS, "defaultNorm() -> retval"},
    {"descriptorSize", (PyCFunction)pyopencv_cv_Feature2D_descriptorSize, METH_VARARGS | METH_KEYWORDS, "descriptorSize() -> retval"},
    {"descriptorType", (PyCFunction)pyopencv_cv_Feature2D_descriptorType, METH_VARARGS | METH_KEYWORDS, "descriptorType() -> retval"},
    {"detect", (PyCFunction)pyopencv_cv_Feature2D_detect, METH_VARARGS | METH_KEYWORDS, "detect(image[, mask]) -> keypoints  or  detect(images[, masks]) -> keypoints"},
    {"detectAndCompute", (PyCFunction)pyopencv_cv_Feature2D_detectAndCompute, METH_VARARGS | METH_KEYWORDS, "detectAndCompute(image, mask[, descriptors[, useProvidedKeypoints]]) -> keypoints, descriptors"},
    {"empty", (PyCFunction)pyopencv_cv_Feature2D_empty, METH_VARARGS | METH_KEYWORDS, "empty() -> retval"},
    {"read", (PyCFunction)pyopencv_cv_Feature2D_read, METH_VARARGS | METH_KEYWORDS, "read(fileName) -> None"},
    {"write", (PyCFunction)pyopencv_cv_Feature2D_write, METH_VARARGS | METH_KEYWORDS, "write(fileName) -> None"},

    {NULL,          NULL}
};

static void pyopencv_Feature2D_specials(void)
{
    pyopencv_Feature2D_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_Feature2D_Type.tp_dealloc = pyopencv_Feature2D_dealloc;
    pyopencv_Feature2D_Type.tp_repr = pyopencv_Feature2D_repr;
    pyopencv_Feature2D_Type.tp_getset = pyopencv_Feature2D_getseters;
    pyopencv_Feature2D_Type.tp_methods = pyopencv_Feature2D_methods;
}

static PyObject* pyopencv_BRISK_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<BRISK %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_BRISK_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_BRISK_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_BRISK_specials(void)
{
    pyopencv_BRISK_Type.tp_base = &pyopencv_Feature2D_Type;
    pyopencv_BRISK_Type.tp_dealloc = pyopencv_BRISK_dealloc;
    pyopencv_BRISK_Type.tp_repr = pyopencv_BRISK_repr;
    pyopencv_BRISK_Type.tp_getset = pyopencv_BRISK_getseters;
    pyopencv_BRISK_Type.tp_methods = pyopencv_BRISK_methods;
}

static PyObject* pyopencv_ORB_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<ORB %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_ORB_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_ORB_getEdgeThreshold(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ORB_Type))
        return failmsgp("Incorrect type of self (must be 'ORB' or its derivative)");
    cv::ORB* _self_ = dynamic_cast<cv::ORB*>(((pyopencv_ORB_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getEdgeThreshold());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ORB_getFastThreshold(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ORB_Type))
        return failmsgp("Incorrect type of self (must be 'ORB' or its derivative)");
    cv::ORB* _self_ = dynamic_cast<cv::ORB*>(((pyopencv_ORB_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getFastThreshold());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ORB_getFirstLevel(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ORB_Type))
        return failmsgp("Incorrect type of self (must be 'ORB' or its derivative)");
    cv::ORB* _self_ = dynamic_cast<cv::ORB*>(((pyopencv_ORB_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getFirstLevel());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ORB_getMaxFeatures(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ORB_Type))
        return failmsgp("Incorrect type of self (must be 'ORB' or its derivative)");
    cv::ORB* _self_ = dynamic_cast<cv::ORB*>(((pyopencv_ORB_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getMaxFeatures());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ORB_getNLevels(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ORB_Type))
        return failmsgp("Incorrect type of self (must be 'ORB' or its derivative)");
    cv::ORB* _self_ = dynamic_cast<cv::ORB*>(((pyopencv_ORB_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getNLevels());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ORB_getPatchSize(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ORB_Type))
        return failmsgp("Incorrect type of self (must be 'ORB' or its derivative)");
    cv::ORB* _self_ = dynamic_cast<cv::ORB*>(((pyopencv_ORB_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getPatchSize());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ORB_getScaleFactor(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ORB_Type))
        return failmsgp("Incorrect type of self (must be 'ORB' or its derivative)");
    cv::ORB* _self_ = dynamic_cast<cv::ORB*>(((pyopencv_ORB_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getScaleFactor());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ORB_getScoreType(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ORB_Type))
        return failmsgp("Incorrect type of self (must be 'ORB' or its derivative)");
    cv::ORB* _self_ = dynamic_cast<cv::ORB*>(((pyopencv_ORB_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getScoreType());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ORB_getWTA_K(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ORB_Type))
        return failmsgp("Incorrect type of self (must be 'ORB' or its derivative)");
    cv::ORB* _self_ = dynamic_cast<cv::ORB*>(((pyopencv_ORB_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getWTA_K());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ORB_setEdgeThreshold(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ORB_Type))
        return failmsgp("Incorrect type of self (must be 'ORB' or its derivative)");
    cv::ORB* _self_ = dynamic_cast<cv::ORB*>(((pyopencv_ORB_t*)self)->v.get());
    int edgeThreshold=0;

    const char* keywords[] = { "edgeThreshold", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:ORB.setEdgeThreshold", (char**)keywords, &edgeThreshold) )
    {
        ERRWRAP2(_self_->setEdgeThreshold(edgeThreshold));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ORB_setFastThreshold(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ORB_Type))
        return failmsgp("Incorrect type of self (must be 'ORB' or its derivative)");
    cv::ORB* _self_ = dynamic_cast<cv::ORB*>(((pyopencv_ORB_t*)self)->v.get());
    int fastThreshold=0;

    const char* keywords[] = { "fastThreshold", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:ORB.setFastThreshold", (char**)keywords, &fastThreshold) )
    {
        ERRWRAP2(_self_->setFastThreshold(fastThreshold));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ORB_setFirstLevel(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ORB_Type))
        return failmsgp("Incorrect type of self (must be 'ORB' or its derivative)");
    cv::ORB* _self_ = dynamic_cast<cv::ORB*>(((pyopencv_ORB_t*)self)->v.get());
    int firstLevel=0;

    const char* keywords[] = { "firstLevel", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:ORB.setFirstLevel", (char**)keywords, &firstLevel) )
    {
        ERRWRAP2(_self_->setFirstLevel(firstLevel));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ORB_setMaxFeatures(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ORB_Type))
        return failmsgp("Incorrect type of self (must be 'ORB' or its derivative)");
    cv::ORB* _self_ = dynamic_cast<cv::ORB*>(((pyopencv_ORB_t*)self)->v.get());
    int maxFeatures=0;

    const char* keywords[] = { "maxFeatures", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:ORB.setMaxFeatures", (char**)keywords, &maxFeatures) )
    {
        ERRWRAP2(_self_->setMaxFeatures(maxFeatures));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ORB_setNLevels(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ORB_Type))
        return failmsgp("Incorrect type of self (must be 'ORB' or its derivative)");
    cv::ORB* _self_ = dynamic_cast<cv::ORB*>(((pyopencv_ORB_t*)self)->v.get());
    int nlevels=0;

    const char* keywords[] = { "nlevels", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:ORB.setNLevels", (char**)keywords, &nlevels) )
    {
        ERRWRAP2(_self_->setNLevels(nlevels));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ORB_setPatchSize(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ORB_Type))
        return failmsgp("Incorrect type of self (must be 'ORB' or its derivative)");
    cv::ORB* _self_ = dynamic_cast<cv::ORB*>(((pyopencv_ORB_t*)self)->v.get());
    int patchSize=0;

    const char* keywords[] = { "patchSize", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:ORB.setPatchSize", (char**)keywords, &patchSize) )
    {
        ERRWRAP2(_self_->setPatchSize(patchSize));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ORB_setScaleFactor(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ORB_Type))
        return failmsgp("Incorrect type of self (must be 'ORB' or its derivative)");
    cv::ORB* _self_ = dynamic_cast<cv::ORB*>(((pyopencv_ORB_t*)self)->v.get());
    double scaleFactor=0;

    const char* keywords[] = { "scaleFactor", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:ORB.setScaleFactor", (char**)keywords, &scaleFactor) )
    {
        ERRWRAP2(_self_->setScaleFactor(scaleFactor));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ORB_setScoreType(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ORB_Type))
        return failmsgp("Incorrect type of self (must be 'ORB' or its derivative)");
    cv::ORB* _self_ = dynamic_cast<cv::ORB*>(((pyopencv_ORB_t*)self)->v.get());
    int scoreType=0;

    const char* keywords[] = { "scoreType", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:ORB.setScoreType", (char**)keywords, &scoreType) )
    {
        ERRWRAP2(_self_->setScoreType(scoreType));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ORB_setWTA_K(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_ORB_Type))
        return failmsgp("Incorrect type of self (must be 'ORB' or its derivative)");
    cv::ORB* _self_ = dynamic_cast<cv::ORB*>(((pyopencv_ORB_t*)self)->v.get());
    int wta_k=0;

    const char* keywords[] = { "wta_k", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:ORB.setWTA_K", (char**)keywords, &wta_k) )
    {
        ERRWRAP2(_self_->setWTA_K(wta_k));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_ORB_methods[] =
{
    {"getEdgeThreshold", (PyCFunction)pyopencv_cv_ORB_getEdgeThreshold, METH_VARARGS | METH_KEYWORDS, "getEdgeThreshold() -> retval"},
    {"getFastThreshold", (PyCFunction)pyopencv_cv_ORB_getFastThreshold, METH_VARARGS | METH_KEYWORDS, "getFastThreshold() -> retval"},
    {"getFirstLevel", (PyCFunction)pyopencv_cv_ORB_getFirstLevel, METH_VARARGS | METH_KEYWORDS, "getFirstLevel() -> retval"},
    {"getMaxFeatures", (PyCFunction)pyopencv_cv_ORB_getMaxFeatures, METH_VARARGS | METH_KEYWORDS, "getMaxFeatures() -> retval"},
    {"getNLevels", (PyCFunction)pyopencv_cv_ORB_getNLevels, METH_VARARGS | METH_KEYWORDS, "getNLevels() -> retval"},
    {"getPatchSize", (PyCFunction)pyopencv_cv_ORB_getPatchSize, METH_VARARGS | METH_KEYWORDS, "getPatchSize() -> retval"},
    {"getScaleFactor", (PyCFunction)pyopencv_cv_ORB_getScaleFactor, METH_VARARGS | METH_KEYWORDS, "getScaleFactor() -> retval"},
    {"getScoreType", (PyCFunction)pyopencv_cv_ORB_getScoreType, METH_VARARGS | METH_KEYWORDS, "getScoreType() -> retval"},
    {"getWTA_K", (PyCFunction)pyopencv_cv_ORB_getWTA_K, METH_VARARGS | METH_KEYWORDS, "getWTA_K() -> retval"},
    {"setEdgeThreshold", (PyCFunction)pyopencv_cv_ORB_setEdgeThreshold, METH_VARARGS | METH_KEYWORDS, "setEdgeThreshold(edgeThreshold) -> None"},
    {"setFastThreshold", (PyCFunction)pyopencv_cv_ORB_setFastThreshold, METH_VARARGS | METH_KEYWORDS, "setFastThreshold(fastThreshold) -> None"},
    {"setFirstLevel", (PyCFunction)pyopencv_cv_ORB_setFirstLevel, METH_VARARGS | METH_KEYWORDS, "setFirstLevel(firstLevel) -> None"},
    {"setMaxFeatures", (PyCFunction)pyopencv_cv_ORB_setMaxFeatures, METH_VARARGS | METH_KEYWORDS, "setMaxFeatures(maxFeatures) -> None"},
    {"setNLevels", (PyCFunction)pyopencv_cv_ORB_setNLevels, METH_VARARGS | METH_KEYWORDS, "setNLevels(nlevels) -> None"},
    {"setPatchSize", (PyCFunction)pyopencv_cv_ORB_setPatchSize, METH_VARARGS | METH_KEYWORDS, "setPatchSize(patchSize) -> None"},
    {"setScaleFactor", (PyCFunction)pyopencv_cv_ORB_setScaleFactor, METH_VARARGS | METH_KEYWORDS, "setScaleFactor(scaleFactor) -> None"},
    {"setScoreType", (PyCFunction)pyopencv_cv_ORB_setScoreType, METH_VARARGS | METH_KEYWORDS, "setScoreType(scoreType) -> None"},
    {"setWTA_K", (PyCFunction)pyopencv_cv_ORB_setWTA_K, METH_VARARGS | METH_KEYWORDS, "setWTA_K(wta_k) -> None"},

    {NULL,          NULL}
};

static void pyopencv_ORB_specials(void)
{
    pyopencv_ORB_Type.tp_base = &pyopencv_Feature2D_Type;
    pyopencv_ORB_Type.tp_dealloc = pyopencv_ORB_dealloc;
    pyopencv_ORB_Type.tp_repr = pyopencv_ORB_repr;
    pyopencv_ORB_Type.tp_getset = pyopencv_ORB_getseters;
    pyopencv_ORB_Type.tp_methods = pyopencv_ORB_methods;
}

static PyObject* pyopencv_MSER_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<MSER %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_MSER_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_MSER_detectRegions(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_MSER_Type))
        return failmsgp("Incorrect type of self (must be 'MSER' or its derivative)");
    cv::MSER* _self_ = dynamic_cast<cv::MSER*>(((pyopencv_MSER_t*)self)->v.get());
    {
    PyObject* pyobj_image = NULL;
    Mat image;
    vector_vector_Point msers;
    vector_Rect bboxes;

    const char* keywords[] = { "image", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:MSER.detectRegions", (char**)keywords, &pyobj_image) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) )
    {
        ERRWRAP2(_self_->detectRegions(image, msers, bboxes));
        return Py_BuildValue("(NN)", pyopencv_from(msers), pyopencv_from(bboxes));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    vector_vector_Point msers;
    vector_Rect bboxes;

    const char* keywords[] = { "image", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:MSER.detectRegions", (char**)keywords, &pyobj_image) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) )
    {
        ERRWRAP2(_self_->detectRegions(image, msers, bboxes));
        return Py_BuildValue("(NN)", pyopencv_from(msers), pyopencv_from(bboxes));
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_MSER_getDelta(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_MSER_Type))
        return failmsgp("Incorrect type of self (must be 'MSER' or its derivative)");
    cv::MSER* _self_ = dynamic_cast<cv::MSER*>(((pyopencv_MSER_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getDelta());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_MSER_getMaxArea(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_MSER_Type))
        return failmsgp("Incorrect type of self (must be 'MSER' or its derivative)");
    cv::MSER* _self_ = dynamic_cast<cv::MSER*>(((pyopencv_MSER_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getMaxArea());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_MSER_getMinArea(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_MSER_Type))
        return failmsgp("Incorrect type of self (must be 'MSER' or its derivative)");
    cv::MSER* _self_ = dynamic_cast<cv::MSER*>(((pyopencv_MSER_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getMinArea());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_MSER_getPass2Only(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_MSER_Type))
        return failmsgp("Incorrect type of self (must be 'MSER' or its derivative)");
    cv::MSER* _self_ = dynamic_cast<cv::MSER*>(((pyopencv_MSER_t*)self)->v.get());
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getPass2Only());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_MSER_setDelta(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_MSER_Type))
        return failmsgp("Incorrect type of self (must be 'MSER' or its derivative)");
    cv::MSER* _self_ = dynamic_cast<cv::MSER*>(((pyopencv_MSER_t*)self)->v.get());
    int delta=0;

    const char* keywords[] = { "delta", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:MSER.setDelta", (char**)keywords, &delta) )
    {
        ERRWRAP2(_self_->setDelta(delta));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_MSER_setMaxArea(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_MSER_Type))
        return failmsgp("Incorrect type of self (must be 'MSER' or its derivative)");
    cv::MSER* _self_ = dynamic_cast<cv::MSER*>(((pyopencv_MSER_t*)self)->v.get());
    int maxArea=0;

    const char* keywords[] = { "maxArea", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:MSER.setMaxArea", (char**)keywords, &maxArea) )
    {
        ERRWRAP2(_self_->setMaxArea(maxArea));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_MSER_setMinArea(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_MSER_Type))
        return failmsgp("Incorrect type of self (must be 'MSER' or its derivative)");
    cv::MSER* _self_ = dynamic_cast<cv::MSER*>(((pyopencv_MSER_t*)self)->v.get());
    int minArea=0;

    const char* keywords[] = { "minArea", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:MSER.setMinArea", (char**)keywords, &minArea) )
    {
        ERRWRAP2(_self_->setMinArea(minArea));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_MSER_setPass2Only(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_MSER_Type))
        return failmsgp("Incorrect type of self (must be 'MSER' or its derivative)");
    cv::MSER* _self_ = dynamic_cast<cv::MSER*>(((pyopencv_MSER_t*)self)->v.get());
    bool f=0;

    const char* keywords[] = { "f", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "b:MSER.setPass2Only", (char**)keywords, &f) )
    {
        ERRWRAP2(_self_->setPass2Only(f));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_MSER_methods[] =
{
    {"detectRegions", (PyCFunction)pyopencv_cv_MSER_detectRegions, METH_VARARGS | METH_KEYWORDS, "detectRegions(image) -> msers, bboxes"},
    {"getDelta", (PyCFunction)pyopencv_cv_MSER_getDelta, METH_VARARGS | METH_KEYWORDS, "getDelta() -> retval"},
    {"getMaxArea", (PyCFunction)pyopencv_cv_MSER_getMaxArea, METH_VARARGS | METH_KEYWORDS, "getMaxArea() -> retval"},
    {"getMinArea", (PyCFunction)pyopencv_cv_MSER_getMinArea, METH_VARARGS | METH_KEYWORDS, "getMinArea() -> retval"},
    {"getPass2Only", (PyCFunction)pyopencv_cv_MSER_getPass2Only, METH_VARARGS | METH_KEYWORDS, "getPass2Only() -> retval"},
    {"setDelta", (PyCFunction)pyopencv_cv_MSER_setDelta, METH_VARARGS | METH_KEYWORDS, "setDelta(delta) -> None"},
    {"setMaxArea", (PyCFunction)pyopencv_cv_MSER_setMaxArea, METH_VARARGS | METH_KEYWORDS, "setMaxArea(maxArea) -> None"},
    {"setMinArea", (PyCFunction)pyopencv_cv_MSER_setMinArea, METH_VARARGS | METH_KEYWORDS, "setMinArea(minArea) -> None"},
    {"setPass2Only", (PyCFunction)pyopencv_cv_MSER_setPass2Only, METH_VARARGS | METH_KEYWORDS, "setPass2Only(f) -> None"},

    {NULL,          NULL}
};

static void pyopencv_MSER_specials(void)
{
    pyopencv_MSER_Type.tp_base = &pyopencv_Feature2D_Type;
    pyopencv_MSER_Type.tp_dealloc = pyopencv_MSER_dealloc;
    pyopencv_MSER_Type.tp_repr = pyopencv_MSER_repr;
    pyopencv_MSER_Type.tp_getset = pyopencv_MSER_getseters;
    pyopencv_MSER_Type.tp_methods = pyopencv_MSER_methods;
}

static PyObject* pyopencv_FastFeatureDetector_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<FastFeatureDetector %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_FastFeatureDetector_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_FastFeatureDetector_getNonmaxSuppression(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FastFeatureDetector_Type))
        return failmsgp("Incorrect type of self (must be 'FastFeatureDetector' or its derivative)");
    cv::FastFeatureDetector* _self_ = dynamic_cast<cv::FastFeatureDetector*>(((pyopencv_FastFeatureDetector_t*)self)->v.get());
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getNonmaxSuppression());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_FastFeatureDetector_getThreshold(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FastFeatureDetector_Type))
        return failmsgp("Incorrect type of self (must be 'FastFeatureDetector' or its derivative)");
    cv::FastFeatureDetector* _self_ = dynamic_cast<cv::FastFeatureDetector*>(((pyopencv_FastFeatureDetector_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getThreshold());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_FastFeatureDetector_getType(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FastFeatureDetector_Type))
        return failmsgp("Incorrect type of self (must be 'FastFeatureDetector' or its derivative)");
    cv::FastFeatureDetector* _self_ = dynamic_cast<cv::FastFeatureDetector*>(((pyopencv_FastFeatureDetector_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getType());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_FastFeatureDetector_setNonmaxSuppression(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FastFeatureDetector_Type))
        return failmsgp("Incorrect type of self (must be 'FastFeatureDetector' or its derivative)");
    cv::FastFeatureDetector* _self_ = dynamic_cast<cv::FastFeatureDetector*>(((pyopencv_FastFeatureDetector_t*)self)->v.get());
    bool f=0;

    const char* keywords[] = { "f", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "b:FastFeatureDetector.setNonmaxSuppression", (char**)keywords, &f) )
    {
        ERRWRAP2(_self_->setNonmaxSuppression(f));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_FastFeatureDetector_setThreshold(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FastFeatureDetector_Type))
        return failmsgp("Incorrect type of self (must be 'FastFeatureDetector' or its derivative)");
    cv::FastFeatureDetector* _self_ = dynamic_cast<cv::FastFeatureDetector*>(((pyopencv_FastFeatureDetector_t*)self)->v.get());
    int threshold=0;

    const char* keywords[] = { "threshold", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:FastFeatureDetector.setThreshold", (char**)keywords, &threshold) )
    {
        ERRWRAP2(_self_->setThreshold(threshold));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_FastFeatureDetector_setType(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_FastFeatureDetector_Type))
        return failmsgp("Incorrect type of self (must be 'FastFeatureDetector' or its derivative)");
    cv::FastFeatureDetector* _self_ = dynamic_cast<cv::FastFeatureDetector*>(((pyopencv_FastFeatureDetector_t*)self)->v.get());
    int type=0;

    const char* keywords[] = { "type", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:FastFeatureDetector.setType", (char**)keywords, &type) )
    {
        ERRWRAP2(_self_->setType(type));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_FastFeatureDetector_methods[] =
{
    {"getNonmaxSuppression", (PyCFunction)pyopencv_cv_FastFeatureDetector_getNonmaxSuppression, METH_VARARGS | METH_KEYWORDS, "getNonmaxSuppression() -> retval"},
    {"getThreshold", (PyCFunction)pyopencv_cv_FastFeatureDetector_getThreshold, METH_VARARGS | METH_KEYWORDS, "getThreshold() -> retval"},
    {"getType", (PyCFunction)pyopencv_cv_FastFeatureDetector_getType, METH_VARARGS | METH_KEYWORDS, "getType() -> retval"},
    {"setNonmaxSuppression", (PyCFunction)pyopencv_cv_FastFeatureDetector_setNonmaxSuppression, METH_VARARGS | METH_KEYWORDS, "setNonmaxSuppression(f) -> None"},
    {"setThreshold", (PyCFunction)pyopencv_cv_FastFeatureDetector_setThreshold, METH_VARARGS | METH_KEYWORDS, "setThreshold(threshold) -> None"},
    {"setType", (PyCFunction)pyopencv_cv_FastFeatureDetector_setType, METH_VARARGS | METH_KEYWORDS, "setType(type) -> None"},

    {NULL,          NULL}
};

static void pyopencv_FastFeatureDetector_specials(void)
{
    pyopencv_FastFeatureDetector_Type.tp_base = &pyopencv_Feature2D_Type;
    pyopencv_FastFeatureDetector_Type.tp_dealloc = pyopencv_FastFeatureDetector_dealloc;
    pyopencv_FastFeatureDetector_Type.tp_repr = pyopencv_FastFeatureDetector_repr;
    pyopencv_FastFeatureDetector_Type.tp_getset = pyopencv_FastFeatureDetector_getseters;
    pyopencv_FastFeatureDetector_Type.tp_methods = pyopencv_FastFeatureDetector_methods;
}

static PyObject* pyopencv_AgastFeatureDetector_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<AgastFeatureDetector %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_AgastFeatureDetector_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_AgastFeatureDetector_getNonmaxSuppression(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_AgastFeatureDetector_Type))
        return failmsgp("Incorrect type of self (must be 'AgastFeatureDetector' or its derivative)");
    cv::AgastFeatureDetector* _self_ = dynamic_cast<cv::AgastFeatureDetector*>(((pyopencv_AgastFeatureDetector_t*)self)->v.get());
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getNonmaxSuppression());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_AgastFeatureDetector_getThreshold(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_AgastFeatureDetector_Type))
        return failmsgp("Incorrect type of self (must be 'AgastFeatureDetector' or its derivative)");
    cv::AgastFeatureDetector* _self_ = dynamic_cast<cv::AgastFeatureDetector*>(((pyopencv_AgastFeatureDetector_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getThreshold());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_AgastFeatureDetector_getType(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_AgastFeatureDetector_Type))
        return failmsgp("Incorrect type of self (must be 'AgastFeatureDetector' or its derivative)");
    cv::AgastFeatureDetector* _self_ = dynamic_cast<cv::AgastFeatureDetector*>(((pyopencv_AgastFeatureDetector_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getType());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_AgastFeatureDetector_setNonmaxSuppression(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_AgastFeatureDetector_Type))
        return failmsgp("Incorrect type of self (must be 'AgastFeatureDetector' or its derivative)");
    cv::AgastFeatureDetector* _self_ = dynamic_cast<cv::AgastFeatureDetector*>(((pyopencv_AgastFeatureDetector_t*)self)->v.get());
    bool f=0;

    const char* keywords[] = { "f", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "b:AgastFeatureDetector.setNonmaxSuppression", (char**)keywords, &f) )
    {
        ERRWRAP2(_self_->setNonmaxSuppression(f));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_AgastFeatureDetector_setThreshold(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_AgastFeatureDetector_Type))
        return failmsgp("Incorrect type of self (must be 'AgastFeatureDetector' or its derivative)");
    cv::AgastFeatureDetector* _self_ = dynamic_cast<cv::AgastFeatureDetector*>(((pyopencv_AgastFeatureDetector_t*)self)->v.get());
    int threshold=0;

    const char* keywords[] = { "threshold", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:AgastFeatureDetector.setThreshold", (char**)keywords, &threshold) )
    {
        ERRWRAP2(_self_->setThreshold(threshold));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_AgastFeatureDetector_setType(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_AgastFeatureDetector_Type))
        return failmsgp("Incorrect type of self (must be 'AgastFeatureDetector' or its derivative)");
    cv::AgastFeatureDetector* _self_ = dynamic_cast<cv::AgastFeatureDetector*>(((pyopencv_AgastFeatureDetector_t*)self)->v.get());
    int type=0;

    const char* keywords[] = { "type", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:AgastFeatureDetector.setType", (char**)keywords, &type) )
    {
        ERRWRAP2(_self_->setType(type));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_AgastFeatureDetector_methods[] =
{
    {"getNonmaxSuppression", (PyCFunction)pyopencv_cv_AgastFeatureDetector_getNonmaxSuppression, METH_VARARGS | METH_KEYWORDS, "getNonmaxSuppression() -> retval"},
    {"getThreshold", (PyCFunction)pyopencv_cv_AgastFeatureDetector_getThreshold, METH_VARARGS | METH_KEYWORDS, "getThreshold() -> retval"},
    {"getType", (PyCFunction)pyopencv_cv_AgastFeatureDetector_getType, METH_VARARGS | METH_KEYWORDS, "getType() -> retval"},
    {"setNonmaxSuppression", (PyCFunction)pyopencv_cv_AgastFeatureDetector_setNonmaxSuppression, METH_VARARGS | METH_KEYWORDS, "setNonmaxSuppression(f) -> None"},
    {"setThreshold", (PyCFunction)pyopencv_cv_AgastFeatureDetector_setThreshold, METH_VARARGS | METH_KEYWORDS, "setThreshold(threshold) -> None"},
    {"setType", (PyCFunction)pyopencv_cv_AgastFeatureDetector_setType, METH_VARARGS | METH_KEYWORDS, "setType(type) -> None"},

    {NULL,          NULL}
};

static void pyopencv_AgastFeatureDetector_specials(void)
{
    pyopencv_AgastFeatureDetector_Type.tp_base = &pyopencv_Feature2D_Type;
    pyopencv_AgastFeatureDetector_Type.tp_dealloc = pyopencv_AgastFeatureDetector_dealloc;
    pyopencv_AgastFeatureDetector_Type.tp_repr = pyopencv_AgastFeatureDetector_repr;
    pyopencv_AgastFeatureDetector_Type.tp_getset = pyopencv_AgastFeatureDetector_getseters;
    pyopencv_AgastFeatureDetector_Type.tp_methods = pyopencv_AgastFeatureDetector_methods;
}

static PyObject* pyopencv_GFTTDetector_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<GFTTDetector %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_GFTTDetector_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_GFTTDetector_getBlockSize(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_GFTTDetector_Type))
        return failmsgp("Incorrect type of self (must be 'GFTTDetector' or its derivative)");
    cv::GFTTDetector* _self_ = dynamic_cast<cv::GFTTDetector*>(((pyopencv_GFTTDetector_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getBlockSize());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_GFTTDetector_getHarrisDetector(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_GFTTDetector_Type))
        return failmsgp("Incorrect type of self (must be 'GFTTDetector' or its derivative)");
    cv::GFTTDetector* _self_ = dynamic_cast<cv::GFTTDetector*>(((pyopencv_GFTTDetector_t*)self)->v.get());
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getHarrisDetector());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_GFTTDetector_getK(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_GFTTDetector_Type))
        return failmsgp("Incorrect type of self (must be 'GFTTDetector' or its derivative)");
    cv::GFTTDetector* _self_ = dynamic_cast<cv::GFTTDetector*>(((pyopencv_GFTTDetector_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getK());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_GFTTDetector_getMaxFeatures(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_GFTTDetector_Type))
        return failmsgp("Incorrect type of self (must be 'GFTTDetector' or its derivative)");
    cv::GFTTDetector* _self_ = dynamic_cast<cv::GFTTDetector*>(((pyopencv_GFTTDetector_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getMaxFeatures());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_GFTTDetector_getMinDistance(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_GFTTDetector_Type))
        return failmsgp("Incorrect type of self (must be 'GFTTDetector' or its derivative)");
    cv::GFTTDetector* _self_ = dynamic_cast<cv::GFTTDetector*>(((pyopencv_GFTTDetector_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getMinDistance());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_GFTTDetector_getQualityLevel(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_GFTTDetector_Type))
        return failmsgp("Incorrect type of self (must be 'GFTTDetector' or its derivative)");
    cv::GFTTDetector* _self_ = dynamic_cast<cv::GFTTDetector*>(((pyopencv_GFTTDetector_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getQualityLevel());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_GFTTDetector_setBlockSize(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_GFTTDetector_Type))
        return failmsgp("Incorrect type of self (must be 'GFTTDetector' or its derivative)");
    cv::GFTTDetector* _self_ = dynamic_cast<cv::GFTTDetector*>(((pyopencv_GFTTDetector_t*)self)->v.get());
    int blockSize=0;

    const char* keywords[] = { "blockSize", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:GFTTDetector.setBlockSize", (char**)keywords, &blockSize) )
    {
        ERRWRAP2(_self_->setBlockSize(blockSize));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_GFTTDetector_setHarrisDetector(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_GFTTDetector_Type))
        return failmsgp("Incorrect type of self (must be 'GFTTDetector' or its derivative)");
    cv::GFTTDetector* _self_ = dynamic_cast<cv::GFTTDetector*>(((pyopencv_GFTTDetector_t*)self)->v.get());
    bool val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "b:GFTTDetector.setHarrisDetector", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setHarrisDetector(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_GFTTDetector_setK(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_GFTTDetector_Type))
        return failmsgp("Incorrect type of self (must be 'GFTTDetector' or its derivative)");
    cv::GFTTDetector* _self_ = dynamic_cast<cv::GFTTDetector*>(((pyopencv_GFTTDetector_t*)self)->v.get());
    double k=0;

    const char* keywords[] = { "k", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:GFTTDetector.setK", (char**)keywords, &k) )
    {
        ERRWRAP2(_self_->setK(k));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_GFTTDetector_setMaxFeatures(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_GFTTDetector_Type))
        return failmsgp("Incorrect type of self (must be 'GFTTDetector' or its derivative)");
    cv::GFTTDetector* _self_ = dynamic_cast<cv::GFTTDetector*>(((pyopencv_GFTTDetector_t*)self)->v.get());
    int maxFeatures=0;

    const char* keywords[] = { "maxFeatures", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:GFTTDetector.setMaxFeatures", (char**)keywords, &maxFeatures) )
    {
        ERRWRAP2(_self_->setMaxFeatures(maxFeatures));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_GFTTDetector_setMinDistance(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_GFTTDetector_Type))
        return failmsgp("Incorrect type of self (must be 'GFTTDetector' or its derivative)");
    cv::GFTTDetector* _self_ = dynamic_cast<cv::GFTTDetector*>(((pyopencv_GFTTDetector_t*)self)->v.get());
    double minDistance=0;

    const char* keywords[] = { "minDistance", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:GFTTDetector.setMinDistance", (char**)keywords, &minDistance) )
    {
        ERRWRAP2(_self_->setMinDistance(minDistance));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_GFTTDetector_setQualityLevel(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_GFTTDetector_Type))
        return failmsgp("Incorrect type of self (must be 'GFTTDetector' or its derivative)");
    cv::GFTTDetector* _self_ = dynamic_cast<cv::GFTTDetector*>(((pyopencv_GFTTDetector_t*)self)->v.get());
    double qlevel=0;

    const char* keywords[] = { "qlevel", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:GFTTDetector.setQualityLevel", (char**)keywords, &qlevel) )
    {
        ERRWRAP2(_self_->setQualityLevel(qlevel));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_GFTTDetector_methods[] =
{
    {"getBlockSize", (PyCFunction)pyopencv_cv_GFTTDetector_getBlockSize, METH_VARARGS | METH_KEYWORDS, "getBlockSize() -> retval"},
    {"getHarrisDetector", (PyCFunction)pyopencv_cv_GFTTDetector_getHarrisDetector, METH_VARARGS | METH_KEYWORDS, "getHarrisDetector() -> retval"},
    {"getK", (PyCFunction)pyopencv_cv_GFTTDetector_getK, METH_VARARGS | METH_KEYWORDS, "getK() -> retval"},
    {"getMaxFeatures", (PyCFunction)pyopencv_cv_GFTTDetector_getMaxFeatures, METH_VARARGS | METH_KEYWORDS, "getMaxFeatures() -> retval"},
    {"getMinDistance", (PyCFunction)pyopencv_cv_GFTTDetector_getMinDistance, METH_VARARGS | METH_KEYWORDS, "getMinDistance() -> retval"},
    {"getQualityLevel", (PyCFunction)pyopencv_cv_GFTTDetector_getQualityLevel, METH_VARARGS | METH_KEYWORDS, "getQualityLevel() -> retval"},
    {"setBlockSize", (PyCFunction)pyopencv_cv_GFTTDetector_setBlockSize, METH_VARARGS | METH_KEYWORDS, "setBlockSize(blockSize) -> None"},
    {"setHarrisDetector", (PyCFunction)pyopencv_cv_GFTTDetector_setHarrisDetector, METH_VARARGS | METH_KEYWORDS, "setHarrisDetector(val) -> None"},
    {"setK", (PyCFunction)pyopencv_cv_GFTTDetector_setK, METH_VARARGS | METH_KEYWORDS, "setK(k) -> None"},
    {"setMaxFeatures", (PyCFunction)pyopencv_cv_GFTTDetector_setMaxFeatures, METH_VARARGS | METH_KEYWORDS, "setMaxFeatures(maxFeatures) -> None"},
    {"setMinDistance", (PyCFunction)pyopencv_cv_GFTTDetector_setMinDistance, METH_VARARGS | METH_KEYWORDS, "setMinDistance(minDistance) -> None"},
    {"setQualityLevel", (PyCFunction)pyopencv_cv_GFTTDetector_setQualityLevel, METH_VARARGS | METH_KEYWORDS, "setQualityLevel(qlevel) -> None"},

    {NULL,          NULL}
};

static void pyopencv_GFTTDetector_specials(void)
{
    pyopencv_GFTTDetector_Type.tp_base = &pyopencv_Feature2D_Type;
    pyopencv_GFTTDetector_Type.tp_dealloc = pyopencv_GFTTDetector_dealloc;
    pyopencv_GFTTDetector_Type.tp_repr = pyopencv_GFTTDetector_repr;
    pyopencv_GFTTDetector_Type.tp_getset = pyopencv_GFTTDetector_getseters;
    pyopencv_GFTTDetector_Type.tp_methods = pyopencv_GFTTDetector_methods;
}

static PyObject* pyopencv_SimpleBlobDetector_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<SimpleBlobDetector %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_SimpleBlobDetector_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_SimpleBlobDetector_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_SimpleBlobDetector_specials(void)
{
    pyopencv_SimpleBlobDetector_Type.tp_base = &pyopencv_Feature2D_Type;
    pyopencv_SimpleBlobDetector_Type.tp_dealloc = pyopencv_SimpleBlobDetector_dealloc;
    pyopencv_SimpleBlobDetector_Type.tp_repr = pyopencv_SimpleBlobDetector_repr;
    pyopencv_SimpleBlobDetector_Type.tp_getset = pyopencv_SimpleBlobDetector_getseters;
    pyopencv_SimpleBlobDetector_Type.tp_methods = pyopencv_SimpleBlobDetector_methods;
}

static PyObject* pyopencv_SimpleBlobDetector_Params_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<SimpleBlobDetector_Params %p>", self);
    return PyString_FromString(str);
}


static PyObject* pyopencv_SimpleBlobDetector_Params_get_blobColor(pyopencv_SimpleBlobDetector_Params_t* p, void *closure)
{
    return pyopencv_from(p->v.blobColor);
}

static int pyopencv_SimpleBlobDetector_Params_set_blobColor(pyopencv_SimpleBlobDetector_Params_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the blobColor attribute");
        return -1;
    }
    return pyopencv_to(value, p->v.blobColor) ? 0 : -1;
}

static PyObject* pyopencv_SimpleBlobDetector_Params_get_filterByArea(pyopencv_SimpleBlobDetector_Params_t* p, void *closure)
{
    return pyopencv_from(p->v.filterByArea);
}

static int pyopencv_SimpleBlobDetector_Params_set_filterByArea(pyopencv_SimpleBlobDetector_Params_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the filterByArea attribute");
        return -1;
    }
    return pyopencv_to(value, p->v.filterByArea) ? 0 : -1;
}

static PyObject* pyopencv_SimpleBlobDetector_Params_get_filterByCircularity(pyopencv_SimpleBlobDetector_Params_t* p, void *closure)
{
    return pyopencv_from(p->v.filterByCircularity);
}

static int pyopencv_SimpleBlobDetector_Params_set_filterByCircularity(pyopencv_SimpleBlobDetector_Params_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the filterByCircularity attribute");
        return -1;
    }
    return pyopencv_to(value, p->v.filterByCircularity) ? 0 : -1;
}

static PyObject* pyopencv_SimpleBlobDetector_Params_get_filterByColor(pyopencv_SimpleBlobDetector_Params_t* p, void *closure)
{
    return pyopencv_from(p->v.filterByColor);
}

static int pyopencv_SimpleBlobDetector_Params_set_filterByColor(pyopencv_SimpleBlobDetector_Params_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the filterByColor attribute");
        return -1;
    }
    return pyopencv_to(value, p->v.filterByColor) ? 0 : -1;
}

static PyObject* pyopencv_SimpleBlobDetector_Params_get_filterByConvexity(pyopencv_SimpleBlobDetector_Params_t* p, void *closure)
{
    return pyopencv_from(p->v.filterByConvexity);
}

static int pyopencv_SimpleBlobDetector_Params_set_filterByConvexity(pyopencv_SimpleBlobDetector_Params_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the filterByConvexity attribute");
        return -1;
    }
    return pyopencv_to(value, p->v.filterByConvexity) ? 0 : -1;
}

static PyObject* pyopencv_SimpleBlobDetector_Params_get_filterByInertia(pyopencv_SimpleBlobDetector_Params_t* p, void *closure)
{
    return pyopencv_from(p->v.filterByInertia);
}

static int pyopencv_SimpleBlobDetector_Params_set_filterByInertia(pyopencv_SimpleBlobDetector_Params_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the filterByInertia attribute");
        return -1;
    }
    return pyopencv_to(value, p->v.filterByInertia) ? 0 : -1;
}

static PyObject* pyopencv_SimpleBlobDetector_Params_get_maxArea(pyopencv_SimpleBlobDetector_Params_t* p, void *closure)
{
    return pyopencv_from(p->v.maxArea);
}

static int pyopencv_SimpleBlobDetector_Params_set_maxArea(pyopencv_SimpleBlobDetector_Params_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the maxArea attribute");
        return -1;
    }
    return pyopencv_to(value, p->v.maxArea) ? 0 : -1;
}

static PyObject* pyopencv_SimpleBlobDetector_Params_get_maxCircularity(pyopencv_SimpleBlobDetector_Params_t* p, void *closure)
{
    return pyopencv_from(p->v.maxCircularity);
}

static int pyopencv_SimpleBlobDetector_Params_set_maxCircularity(pyopencv_SimpleBlobDetector_Params_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the maxCircularity attribute");
        return -1;
    }
    return pyopencv_to(value, p->v.maxCircularity) ? 0 : -1;
}

static PyObject* pyopencv_SimpleBlobDetector_Params_get_maxConvexity(pyopencv_SimpleBlobDetector_Params_t* p, void *closure)
{
    return pyopencv_from(p->v.maxConvexity);
}

static int pyopencv_SimpleBlobDetector_Params_set_maxConvexity(pyopencv_SimpleBlobDetector_Params_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the maxConvexity attribute");
        return -1;
    }
    return pyopencv_to(value, p->v.maxConvexity) ? 0 : -1;
}

static PyObject* pyopencv_SimpleBlobDetector_Params_get_maxInertiaRatio(pyopencv_SimpleBlobDetector_Params_t* p, void *closure)
{
    return pyopencv_from(p->v.maxInertiaRatio);
}

static int pyopencv_SimpleBlobDetector_Params_set_maxInertiaRatio(pyopencv_SimpleBlobDetector_Params_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the maxInertiaRatio attribute");
        return -1;
    }
    return pyopencv_to(value, p->v.maxInertiaRatio) ? 0 : -1;
}

static PyObject* pyopencv_SimpleBlobDetector_Params_get_maxThreshold(pyopencv_SimpleBlobDetector_Params_t* p, void *closure)
{
    return pyopencv_from(p->v.maxThreshold);
}

static int pyopencv_SimpleBlobDetector_Params_set_maxThreshold(pyopencv_SimpleBlobDetector_Params_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the maxThreshold attribute");
        return -1;
    }
    return pyopencv_to(value, p->v.maxThreshold) ? 0 : -1;
}

static PyObject* pyopencv_SimpleBlobDetector_Params_get_minArea(pyopencv_SimpleBlobDetector_Params_t* p, void *closure)
{
    return pyopencv_from(p->v.minArea);
}

static int pyopencv_SimpleBlobDetector_Params_set_minArea(pyopencv_SimpleBlobDetector_Params_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the minArea attribute");
        return -1;
    }
    return pyopencv_to(value, p->v.minArea) ? 0 : -1;
}

static PyObject* pyopencv_SimpleBlobDetector_Params_get_minCircularity(pyopencv_SimpleBlobDetector_Params_t* p, void *closure)
{
    return pyopencv_from(p->v.minCircularity);
}

static int pyopencv_SimpleBlobDetector_Params_set_minCircularity(pyopencv_SimpleBlobDetector_Params_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the minCircularity attribute");
        return -1;
    }
    return pyopencv_to(value, p->v.minCircularity) ? 0 : -1;
}

static PyObject* pyopencv_SimpleBlobDetector_Params_get_minConvexity(pyopencv_SimpleBlobDetector_Params_t* p, void *closure)
{
    return pyopencv_from(p->v.minConvexity);
}

static int pyopencv_SimpleBlobDetector_Params_set_minConvexity(pyopencv_SimpleBlobDetector_Params_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the minConvexity attribute");
        return -1;
    }
    return pyopencv_to(value, p->v.minConvexity) ? 0 : -1;
}

static PyObject* pyopencv_SimpleBlobDetector_Params_get_minDistBetweenBlobs(pyopencv_SimpleBlobDetector_Params_t* p, void *closure)
{
    return pyopencv_from(p->v.minDistBetweenBlobs);
}

static int pyopencv_SimpleBlobDetector_Params_set_minDistBetweenBlobs(pyopencv_SimpleBlobDetector_Params_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the minDistBetweenBlobs attribute");
        return -1;
    }
    return pyopencv_to(value, p->v.minDistBetweenBlobs) ? 0 : -1;
}

static PyObject* pyopencv_SimpleBlobDetector_Params_get_minInertiaRatio(pyopencv_SimpleBlobDetector_Params_t* p, void *closure)
{
    return pyopencv_from(p->v.minInertiaRatio);
}

static int pyopencv_SimpleBlobDetector_Params_set_minInertiaRatio(pyopencv_SimpleBlobDetector_Params_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the minInertiaRatio attribute");
        return -1;
    }
    return pyopencv_to(value, p->v.minInertiaRatio) ? 0 : -1;
}

static PyObject* pyopencv_SimpleBlobDetector_Params_get_minRepeatability(pyopencv_SimpleBlobDetector_Params_t* p, void *closure)
{
    return pyopencv_from(p->v.minRepeatability);
}

static int pyopencv_SimpleBlobDetector_Params_set_minRepeatability(pyopencv_SimpleBlobDetector_Params_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the minRepeatability attribute");
        return -1;
    }
    return pyopencv_to(value, p->v.minRepeatability) ? 0 : -1;
}

static PyObject* pyopencv_SimpleBlobDetector_Params_get_minThreshold(pyopencv_SimpleBlobDetector_Params_t* p, void *closure)
{
    return pyopencv_from(p->v.minThreshold);
}

static int pyopencv_SimpleBlobDetector_Params_set_minThreshold(pyopencv_SimpleBlobDetector_Params_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the minThreshold attribute");
        return -1;
    }
    return pyopencv_to(value, p->v.minThreshold) ? 0 : -1;
}

static PyObject* pyopencv_SimpleBlobDetector_Params_get_thresholdStep(pyopencv_SimpleBlobDetector_Params_t* p, void *closure)
{
    return pyopencv_from(p->v.thresholdStep);
}

static int pyopencv_SimpleBlobDetector_Params_set_thresholdStep(pyopencv_SimpleBlobDetector_Params_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the thresholdStep attribute");
        return -1;
    }
    return pyopencv_to(value, p->v.thresholdStep) ? 0 : -1;
}


static PyGetSetDef pyopencv_SimpleBlobDetector_Params_getseters[] =
{
    {(char*)"blobColor", (getter)pyopencv_SimpleBlobDetector_Params_get_blobColor, (setter)pyopencv_SimpleBlobDetector_Params_set_blobColor, (char*)"blobColor", NULL},
    {(char*)"filterByArea", (getter)pyopencv_SimpleBlobDetector_Params_get_filterByArea, (setter)pyopencv_SimpleBlobDetector_Params_set_filterByArea, (char*)"filterByArea", NULL},
    {(char*)"filterByCircularity", (getter)pyopencv_SimpleBlobDetector_Params_get_filterByCircularity, (setter)pyopencv_SimpleBlobDetector_Params_set_filterByCircularity, (char*)"filterByCircularity", NULL},
    {(char*)"filterByColor", (getter)pyopencv_SimpleBlobDetector_Params_get_filterByColor, (setter)pyopencv_SimpleBlobDetector_Params_set_filterByColor, (char*)"filterByColor", NULL},
    {(char*)"filterByConvexity", (getter)pyopencv_SimpleBlobDetector_Params_get_filterByConvexity, (setter)pyopencv_SimpleBlobDetector_Params_set_filterByConvexity, (char*)"filterByConvexity", NULL},
    {(char*)"filterByInertia", (getter)pyopencv_SimpleBlobDetector_Params_get_filterByInertia, (setter)pyopencv_SimpleBlobDetector_Params_set_filterByInertia, (char*)"filterByInertia", NULL},
    {(char*)"maxArea", (getter)pyopencv_SimpleBlobDetector_Params_get_maxArea, (setter)pyopencv_SimpleBlobDetector_Params_set_maxArea, (char*)"maxArea", NULL},
    {(char*)"maxCircularity", (getter)pyopencv_SimpleBlobDetector_Params_get_maxCircularity, (setter)pyopencv_SimpleBlobDetector_Params_set_maxCircularity, (char*)"maxCircularity", NULL},
    {(char*)"maxConvexity", (getter)pyopencv_SimpleBlobDetector_Params_get_maxConvexity, (setter)pyopencv_SimpleBlobDetector_Params_set_maxConvexity, (char*)"maxConvexity", NULL},
    {(char*)"maxInertiaRatio", (getter)pyopencv_SimpleBlobDetector_Params_get_maxInertiaRatio, (setter)pyopencv_SimpleBlobDetector_Params_set_maxInertiaRatio, (char*)"maxInertiaRatio", NULL},
    {(char*)"maxThreshold", (getter)pyopencv_SimpleBlobDetector_Params_get_maxThreshold, (setter)pyopencv_SimpleBlobDetector_Params_set_maxThreshold, (char*)"maxThreshold", NULL},
    {(char*)"minArea", (getter)pyopencv_SimpleBlobDetector_Params_get_minArea, (setter)pyopencv_SimpleBlobDetector_Params_set_minArea, (char*)"minArea", NULL},
    {(char*)"minCircularity", (getter)pyopencv_SimpleBlobDetector_Params_get_minCircularity, (setter)pyopencv_SimpleBlobDetector_Params_set_minCircularity, (char*)"minCircularity", NULL},
    {(char*)"minConvexity", (getter)pyopencv_SimpleBlobDetector_Params_get_minConvexity, (setter)pyopencv_SimpleBlobDetector_Params_set_minConvexity, (char*)"minConvexity", NULL},
    {(char*)"minDistBetweenBlobs", (getter)pyopencv_SimpleBlobDetector_Params_get_minDistBetweenBlobs, (setter)pyopencv_SimpleBlobDetector_Params_set_minDistBetweenBlobs, (char*)"minDistBetweenBlobs", NULL},
    {(char*)"minInertiaRatio", (getter)pyopencv_SimpleBlobDetector_Params_get_minInertiaRatio, (setter)pyopencv_SimpleBlobDetector_Params_set_minInertiaRatio, (char*)"minInertiaRatio", NULL},
    {(char*)"minRepeatability", (getter)pyopencv_SimpleBlobDetector_Params_get_minRepeatability, (setter)pyopencv_SimpleBlobDetector_Params_set_minRepeatability, (char*)"minRepeatability", NULL},
    {(char*)"minThreshold", (getter)pyopencv_SimpleBlobDetector_Params_get_minThreshold, (setter)pyopencv_SimpleBlobDetector_Params_set_minThreshold, (char*)"minThreshold", NULL},
    {(char*)"thresholdStep", (getter)pyopencv_SimpleBlobDetector_Params_get_thresholdStep, (setter)pyopencv_SimpleBlobDetector_Params_set_thresholdStep, (char*)"thresholdStep", NULL},
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_SimpleBlobDetector_Params_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_SimpleBlobDetector_Params_specials(void)
{
    pyopencv_SimpleBlobDetector_Params_Type.tp_base = NULL;
    pyopencv_SimpleBlobDetector_Params_Type.tp_dealloc = pyopencv_SimpleBlobDetector_Params_dealloc;
    pyopencv_SimpleBlobDetector_Params_Type.tp_repr = pyopencv_SimpleBlobDetector_Params_repr;
    pyopencv_SimpleBlobDetector_Params_Type.tp_getset = pyopencv_SimpleBlobDetector_Params_getseters;
    pyopencv_SimpleBlobDetector_Params_Type.tp_methods = pyopencv_SimpleBlobDetector_Params_methods;
}

static PyObject* pyopencv_KAZE_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<KAZE %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_KAZE_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_KAZE_getDiffusivity(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_KAZE_Type))
        return failmsgp("Incorrect type of self (must be 'KAZE' or its derivative)");
    cv::KAZE* _self_ = dynamic_cast<cv::KAZE*>(((pyopencv_KAZE_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getDiffusivity());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_KAZE_getExtended(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_KAZE_Type))
        return failmsgp("Incorrect type of self (must be 'KAZE' or its derivative)");
    cv::KAZE* _self_ = dynamic_cast<cv::KAZE*>(((pyopencv_KAZE_t*)self)->v.get());
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getExtended());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_KAZE_getNOctaveLayers(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_KAZE_Type))
        return failmsgp("Incorrect type of self (must be 'KAZE' or its derivative)");
    cv::KAZE* _self_ = dynamic_cast<cv::KAZE*>(((pyopencv_KAZE_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getNOctaveLayers());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_KAZE_getNOctaves(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_KAZE_Type))
        return failmsgp("Incorrect type of self (must be 'KAZE' or its derivative)");
    cv::KAZE* _self_ = dynamic_cast<cv::KAZE*>(((pyopencv_KAZE_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getNOctaves());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_KAZE_getThreshold(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_KAZE_Type))
        return failmsgp("Incorrect type of self (must be 'KAZE' or its derivative)");
    cv::KAZE* _self_ = dynamic_cast<cv::KAZE*>(((pyopencv_KAZE_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getThreshold());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_KAZE_getUpright(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_KAZE_Type))
        return failmsgp("Incorrect type of self (must be 'KAZE' or its derivative)");
    cv::KAZE* _self_ = dynamic_cast<cv::KAZE*>(((pyopencv_KAZE_t*)self)->v.get());
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getUpright());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_KAZE_setDiffusivity(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_KAZE_Type))
        return failmsgp("Incorrect type of self (must be 'KAZE' or its derivative)");
    cv::KAZE* _self_ = dynamic_cast<cv::KAZE*>(((pyopencv_KAZE_t*)self)->v.get());
    int diff=0;

    const char* keywords[] = { "diff", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:KAZE.setDiffusivity", (char**)keywords, &diff) )
    {
        ERRWRAP2(_self_->setDiffusivity(diff));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_KAZE_setExtended(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_KAZE_Type))
        return failmsgp("Incorrect type of self (must be 'KAZE' or its derivative)");
    cv::KAZE* _self_ = dynamic_cast<cv::KAZE*>(((pyopencv_KAZE_t*)self)->v.get());
    bool extended=0;

    const char* keywords[] = { "extended", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "b:KAZE.setExtended", (char**)keywords, &extended) )
    {
        ERRWRAP2(_self_->setExtended(extended));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_KAZE_setNOctaveLayers(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_KAZE_Type))
        return failmsgp("Incorrect type of self (must be 'KAZE' or its derivative)");
    cv::KAZE* _self_ = dynamic_cast<cv::KAZE*>(((pyopencv_KAZE_t*)self)->v.get());
    int octaveLayers=0;

    const char* keywords[] = { "octaveLayers", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:KAZE.setNOctaveLayers", (char**)keywords, &octaveLayers) )
    {
        ERRWRAP2(_self_->setNOctaveLayers(octaveLayers));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_KAZE_setNOctaves(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_KAZE_Type))
        return failmsgp("Incorrect type of self (must be 'KAZE' or its derivative)");
    cv::KAZE* _self_ = dynamic_cast<cv::KAZE*>(((pyopencv_KAZE_t*)self)->v.get());
    int octaves=0;

    const char* keywords[] = { "octaves", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:KAZE.setNOctaves", (char**)keywords, &octaves) )
    {
        ERRWRAP2(_self_->setNOctaves(octaves));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_KAZE_setThreshold(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_KAZE_Type))
        return failmsgp("Incorrect type of self (must be 'KAZE' or its derivative)");
    cv::KAZE* _self_ = dynamic_cast<cv::KAZE*>(((pyopencv_KAZE_t*)self)->v.get());
    double threshold=0;

    const char* keywords[] = { "threshold", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:KAZE.setThreshold", (char**)keywords, &threshold) )
    {
        ERRWRAP2(_self_->setThreshold(threshold));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_KAZE_setUpright(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_KAZE_Type))
        return failmsgp("Incorrect type of self (must be 'KAZE' or its derivative)");
    cv::KAZE* _self_ = dynamic_cast<cv::KAZE*>(((pyopencv_KAZE_t*)self)->v.get());
    bool upright=0;

    const char* keywords[] = { "upright", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "b:KAZE.setUpright", (char**)keywords, &upright) )
    {
        ERRWRAP2(_self_->setUpright(upright));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_KAZE_methods[] =
{
    {"getDiffusivity", (PyCFunction)pyopencv_cv_KAZE_getDiffusivity, METH_VARARGS | METH_KEYWORDS, "getDiffusivity() -> retval"},
    {"getExtended", (PyCFunction)pyopencv_cv_KAZE_getExtended, METH_VARARGS | METH_KEYWORDS, "getExtended() -> retval"},
    {"getNOctaveLayers", (PyCFunction)pyopencv_cv_KAZE_getNOctaveLayers, METH_VARARGS | METH_KEYWORDS, "getNOctaveLayers() -> retval"},
    {"getNOctaves", (PyCFunction)pyopencv_cv_KAZE_getNOctaves, METH_VARARGS | METH_KEYWORDS, "getNOctaves() -> retval"},
    {"getThreshold", (PyCFunction)pyopencv_cv_KAZE_getThreshold, METH_VARARGS | METH_KEYWORDS, "getThreshold() -> retval"},
    {"getUpright", (PyCFunction)pyopencv_cv_KAZE_getUpright, METH_VARARGS | METH_KEYWORDS, "getUpright() -> retval"},
    {"setDiffusivity", (PyCFunction)pyopencv_cv_KAZE_setDiffusivity, METH_VARARGS | METH_KEYWORDS, "setDiffusivity(diff) -> None"},
    {"setExtended", (PyCFunction)pyopencv_cv_KAZE_setExtended, METH_VARARGS | METH_KEYWORDS, "setExtended(extended) -> None"},
    {"setNOctaveLayers", (PyCFunction)pyopencv_cv_KAZE_setNOctaveLayers, METH_VARARGS | METH_KEYWORDS, "setNOctaveLayers(octaveLayers) -> None"},
    {"setNOctaves", (PyCFunction)pyopencv_cv_KAZE_setNOctaves, METH_VARARGS | METH_KEYWORDS, "setNOctaves(octaves) -> None"},
    {"setThreshold", (PyCFunction)pyopencv_cv_KAZE_setThreshold, METH_VARARGS | METH_KEYWORDS, "setThreshold(threshold) -> None"},
    {"setUpright", (PyCFunction)pyopencv_cv_KAZE_setUpright, METH_VARARGS | METH_KEYWORDS, "setUpright(upright) -> None"},

    {NULL,          NULL}
};

static void pyopencv_KAZE_specials(void)
{
    pyopencv_KAZE_Type.tp_base = &pyopencv_Feature2D_Type;
    pyopencv_KAZE_Type.tp_dealloc = pyopencv_KAZE_dealloc;
    pyopencv_KAZE_Type.tp_repr = pyopencv_KAZE_repr;
    pyopencv_KAZE_Type.tp_getset = pyopencv_KAZE_getseters;
    pyopencv_KAZE_Type.tp_methods = pyopencv_KAZE_methods;
}

static PyObject* pyopencv_AKAZE_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<AKAZE %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_AKAZE_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_AKAZE_getDescriptorChannels(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_AKAZE_Type))
        return failmsgp("Incorrect type of self (must be 'AKAZE' or its derivative)");
    cv::AKAZE* _self_ = dynamic_cast<cv::AKAZE*>(((pyopencv_AKAZE_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getDescriptorChannels());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_AKAZE_getDescriptorSize(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_AKAZE_Type))
        return failmsgp("Incorrect type of self (must be 'AKAZE' or its derivative)");
    cv::AKAZE* _self_ = dynamic_cast<cv::AKAZE*>(((pyopencv_AKAZE_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getDescriptorSize());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_AKAZE_getDescriptorType(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_AKAZE_Type))
        return failmsgp("Incorrect type of self (must be 'AKAZE' or its derivative)");
    cv::AKAZE* _self_ = dynamic_cast<cv::AKAZE*>(((pyopencv_AKAZE_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getDescriptorType());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_AKAZE_getDiffusivity(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_AKAZE_Type))
        return failmsgp("Incorrect type of self (must be 'AKAZE' or its derivative)");
    cv::AKAZE* _self_ = dynamic_cast<cv::AKAZE*>(((pyopencv_AKAZE_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getDiffusivity());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_AKAZE_getNOctaveLayers(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_AKAZE_Type))
        return failmsgp("Incorrect type of self (must be 'AKAZE' or its derivative)");
    cv::AKAZE* _self_ = dynamic_cast<cv::AKAZE*>(((pyopencv_AKAZE_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getNOctaveLayers());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_AKAZE_getNOctaves(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_AKAZE_Type))
        return failmsgp("Incorrect type of self (must be 'AKAZE' or its derivative)");
    cv::AKAZE* _self_ = dynamic_cast<cv::AKAZE*>(((pyopencv_AKAZE_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getNOctaves());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_AKAZE_getThreshold(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_AKAZE_Type))
        return failmsgp("Incorrect type of self (must be 'AKAZE' or its derivative)");
    cv::AKAZE* _self_ = dynamic_cast<cv::AKAZE*>(((pyopencv_AKAZE_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getThreshold());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_AKAZE_setDescriptorChannels(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_AKAZE_Type))
        return failmsgp("Incorrect type of self (must be 'AKAZE' or its derivative)");
    cv::AKAZE* _self_ = dynamic_cast<cv::AKAZE*>(((pyopencv_AKAZE_t*)self)->v.get());
    int dch=0;

    const char* keywords[] = { "dch", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:AKAZE.setDescriptorChannels", (char**)keywords, &dch) )
    {
        ERRWRAP2(_self_->setDescriptorChannels(dch));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_AKAZE_setDescriptorSize(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_AKAZE_Type))
        return failmsgp("Incorrect type of self (must be 'AKAZE' or its derivative)");
    cv::AKAZE* _self_ = dynamic_cast<cv::AKAZE*>(((pyopencv_AKAZE_t*)self)->v.get());
    int dsize=0;

    const char* keywords[] = { "dsize", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:AKAZE.setDescriptorSize", (char**)keywords, &dsize) )
    {
        ERRWRAP2(_self_->setDescriptorSize(dsize));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_AKAZE_setDescriptorType(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_AKAZE_Type))
        return failmsgp("Incorrect type of self (must be 'AKAZE' or its derivative)");
    cv::AKAZE* _self_ = dynamic_cast<cv::AKAZE*>(((pyopencv_AKAZE_t*)self)->v.get());
    int dtype=0;

    const char* keywords[] = { "dtype", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:AKAZE.setDescriptorType", (char**)keywords, &dtype) )
    {
        ERRWRAP2(_self_->setDescriptorType(dtype));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_AKAZE_setDiffusivity(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_AKAZE_Type))
        return failmsgp("Incorrect type of self (must be 'AKAZE' or its derivative)");
    cv::AKAZE* _self_ = dynamic_cast<cv::AKAZE*>(((pyopencv_AKAZE_t*)self)->v.get());
    int diff=0;

    const char* keywords[] = { "diff", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:AKAZE.setDiffusivity", (char**)keywords, &diff) )
    {
        ERRWRAP2(_self_->setDiffusivity(diff));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_AKAZE_setNOctaveLayers(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_AKAZE_Type))
        return failmsgp("Incorrect type of self (must be 'AKAZE' or its derivative)");
    cv::AKAZE* _self_ = dynamic_cast<cv::AKAZE*>(((pyopencv_AKAZE_t*)self)->v.get());
    int octaveLayers=0;

    const char* keywords[] = { "octaveLayers", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:AKAZE.setNOctaveLayers", (char**)keywords, &octaveLayers) )
    {
        ERRWRAP2(_self_->setNOctaveLayers(octaveLayers));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_AKAZE_setNOctaves(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_AKAZE_Type))
        return failmsgp("Incorrect type of self (must be 'AKAZE' or its derivative)");
    cv::AKAZE* _self_ = dynamic_cast<cv::AKAZE*>(((pyopencv_AKAZE_t*)self)->v.get());
    int octaves=0;

    const char* keywords[] = { "octaves", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:AKAZE.setNOctaves", (char**)keywords, &octaves) )
    {
        ERRWRAP2(_self_->setNOctaves(octaves));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_AKAZE_setThreshold(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_AKAZE_Type))
        return failmsgp("Incorrect type of self (must be 'AKAZE' or its derivative)");
    cv::AKAZE* _self_ = dynamic_cast<cv::AKAZE*>(((pyopencv_AKAZE_t*)self)->v.get());
    double threshold=0;

    const char* keywords[] = { "threshold", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:AKAZE.setThreshold", (char**)keywords, &threshold) )
    {
        ERRWRAP2(_self_->setThreshold(threshold));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_AKAZE_methods[] =
{
    {"getDescriptorChannels", (PyCFunction)pyopencv_cv_AKAZE_getDescriptorChannels, METH_VARARGS | METH_KEYWORDS, "getDescriptorChannels() -> retval"},
    {"getDescriptorSize", (PyCFunction)pyopencv_cv_AKAZE_getDescriptorSize, METH_VARARGS | METH_KEYWORDS, "getDescriptorSize() -> retval"},
    {"getDescriptorType", (PyCFunction)pyopencv_cv_AKAZE_getDescriptorType, METH_VARARGS | METH_KEYWORDS, "getDescriptorType() -> retval"},
    {"getDiffusivity", (PyCFunction)pyopencv_cv_AKAZE_getDiffusivity, METH_VARARGS | METH_KEYWORDS, "getDiffusivity() -> retval"},
    {"getNOctaveLayers", (PyCFunction)pyopencv_cv_AKAZE_getNOctaveLayers, METH_VARARGS | METH_KEYWORDS, "getNOctaveLayers() -> retval"},
    {"getNOctaves", (PyCFunction)pyopencv_cv_AKAZE_getNOctaves, METH_VARARGS | METH_KEYWORDS, "getNOctaves() -> retval"},
    {"getThreshold", (PyCFunction)pyopencv_cv_AKAZE_getThreshold, METH_VARARGS | METH_KEYWORDS, "getThreshold() -> retval"},
    {"setDescriptorChannels", (PyCFunction)pyopencv_cv_AKAZE_setDescriptorChannels, METH_VARARGS | METH_KEYWORDS, "setDescriptorChannels(dch) -> None"},
    {"setDescriptorSize", (PyCFunction)pyopencv_cv_AKAZE_setDescriptorSize, METH_VARARGS | METH_KEYWORDS, "setDescriptorSize(dsize) -> None"},
    {"setDescriptorType", (PyCFunction)pyopencv_cv_AKAZE_setDescriptorType, METH_VARARGS | METH_KEYWORDS, "setDescriptorType(dtype) -> None"},
    {"setDiffusivity", (PyCFunction)pyopencv_cv_AKAZE_setDiffusivity, METH_VARARGS | METH_KEYWORDS, "setDiffusivity(diff) -> None"},
    {"setNOctaveLayers", (PyCFunction)pyopencv_cv_AKAZE_setNOctaveLayers, METH_VARARGS | METH_KEYWORDS, "setNOctaveLayers(octaveLayers) -> None"},
    {"setNOctaves", (PyCFunction)pyopencv_cv_AKAZE_setNOctaves, METH_VARARGS | METH_KEYWORDS, "setNOctaves(octaves) -> None"},
    {"setThreshold", (PyCFunction)pyopencv_cv_AKAZE_setThreshold, METH_VARARGS | METH_KEYWORDS, "setThreshold(threshold) -> None"},

    {NULL,          NULL}
};

static void pyopencv_AKAZE_specials(void)
{
    pyopencv_AKAZE_Type.tp_base = &pyopencv_Feature2D_Type;
    pyopencv_AKAZE_Type.tp_dealloc = pyopencv_AKAZE_dealloc;
    pyopencv_AKAZE_Type.tp_repr = pyopencv_AKAZE_repr;
    pyopencv_AKAZE_Type.tp_getset = pyopencv_AKAZE_getseters;
    pyopencv_AKAZE_Type.tp_methods = pyopencv_AKAZE_methods;
}

static PyObject* pyopencv_DescriptorMatcher_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<DescriptorMatcher %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_DescriptorMatcher_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_DescriptorMatcher_add(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_DescriptorMatcher_Type))
        return failmsgp("Incorrect type of self (must be 'DescriptorMatcher' or its derivative)");
    cv::DescriptorMatcher* _self_ = dynamic_cast<cv::DescriptorMatcher*>(((pyopencv_DescriptorMatcher_t*)self)->v.get());
    {
    PyObject* pyobj_descriptors = NULL;
    vector_Mat descriptors;

    const char* keywords[] = { "descriptors", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:DescriptorMatcher.add", (char**)keywords, &pyobj_descriptors) &&
        pyopencv_to(pyobj_descriptors, descriptors, ArgInfo("descriptors", 0)) )
    {
        ERRWRAP2(_self_->add(descriptors));
        Py_RETURN_NONE;
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_descriptors = NULL;
    vector_Mat descriptors;

    const char* keywords[] = { "descriptors", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:DescriptorMatcher.add", (char**)keywords, &pyobj_descriptors) &&
        pyopencv_to(pyobj_descriptors, descriptors, ArgInfo("descriptors", 0)) )
    {
        ERRWRAP2(_self_->add(descriptors));
        Py_RETURN_NONE;
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_DescriptorMatcher_clear(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_DescriptorMatcher_Type))
        return failmsgp("Incorrect type of self (must be 'DescriptorMatcher' or its derivative)");
    cv::DescriptorMatcher* _self_ = dynamic_cast<cv::DescriptorMatcher*>(((pyopencv_DescriptorMatcher_t*)self)->v.get());

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(_self_->clear());
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_DescriptorMatcher_clone(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_DescriptorMatcher_Type))
        return failmsgp("Incorrect type of self (must be 'DescriptorMatcher' or its derivative)");
    cv::DescriptorMatcher* _self_ = dynamic_cast<cv::DescriptorMatcher*>(((pyopencv_DescriptorMatcher_t*)self)->v.get());
    bool emptyTrainData=false;
    Ptr<DescriptorMatcher> retval;

    const char* keywords[] = { "emptyTrainData", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|b:DescriptorMatcher.clone", (char**)keywords, &emptyTrainData) )
    {
        ERRWRAP2(retval = _self_->clone(emptyTrainData));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_DescriptorMatcher_empty(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_DescriptorMatcher_Type))
        return failmsgp("Incorrect type of self (must be 'DescriptorMatcher' or its derivative)");
    cv::DescriptorMatcher* _self_ = dynamic_cast<cv::DescriptorMatcher*>(((pyopencv_DescriptorMatcher_t*)self)->v.get());
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->empty());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_DescriptorMatcher_getTrainDescriptors(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_DescriptorMatcher_Type))
        return failmsgp("Incorrect type of self (must be 'DescriptorMatcher' or its derivative)");
    cv::DescriptorMatcher* _self_ = dynamic_cast<cv::DescriptorMatcher*>(((pyopencv_DescriptorMatcher_t*)self)->v.get());
    std::vector<Mat> retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getTrainDescriptors());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_DescriptorMatcher_isMaskSupported(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_DescriptorMatcher_Type))
        return failmsgp("Incorrect type of self (must be 'DescriptorMatcher' or its derivative)");
    cv::DescriptorMatcher* _self_ = dynamic_cast<cv::DescriptorMatcher*>(((pyopencv_DescriptorMatcher_t*)self)->v.get());
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->isMaskSupported());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_DescriptorMatcher_knnMatch(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_DescriptorMatcher_Type))
        return failmsgp("Incorrect type of self (must be 'DescriptorMatcher' or its derivative)");
    cv::DescriptorMatcher* _self_ = dynamic_cast<cv::DescriptorMatcher*>(((pyopencv_DescriptorMatcher_t*)self)->v.get());
    {
    PyObject* pyobj_queryDescriptors = NULL;
    Mat queryDescriptors;
    PyObject* pyobj_trainDescriptors = NULL;
    Mat trainDescriptors;
    vector_vector_DMatch matches;
    int k=0;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    bool compactResult=false;

    const char* keywords[] = { "queryDescriptors", "trainDescriptors", "k", "mask", "compactResult", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OOi|Ob:DescriptorMatcher.knnMatch", (char**)keywords, &pyobj_queryDescriptors, &pyobj_trainDescriptors, &k, &pyobj_mask, &compactResult) &&
        pyopencv_to(pyobj_queryDescriptors, queryDescriptors, ArgInfo("queryDescriptors", 0)) &&
        pyopencv_to(pyobj_trainDescriptors, trainDescriptors, ArgInfo("trainDescriptors", 0)) &&
        pyopencv_to(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(_self_->knnMatch(queryDescriptors, trainDescriptors, matches, k, mask, compactResult));
        return pyopencv_from(matches);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_queryDescriptors = NULL;
    UMat queryDescriptors;
    PyObject* pyobj_trainDescriptors = NULL;
    UMat trainDescriptors;
    vector_vector_DMatch matches;
    int k=0;
    PyObject* pyobj_mask = NULL;
    UMat mask;
    bool compactResult=false;

    const char* keywords[] = { "queryDescriptors", "trainDescriptors", "k", "mask", "compactResult", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OOi|Ob:DescriptorMatcher.knnMatch", (char**)keywords, &pyobj_queryDescriptors, &pyobj_trainDescriptors, &k, &pyobj_mask, &compactResult) &&
        pyopencv_to(pyobj_queryDescriptors, queryDescriptors, ArgInfo("queryDescriptors", 0)) &&
        pyopencv_to(pyobj_trainDescriptors, trainDescriptors, ArgInfo("trainDescriptors", 0)) &&
        pyopencv_to(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(_self_->knnMatch(queryDescriptors, trainDescriptors, matches, k, mask, compactResult));
        return pyopencv_from(matches);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_queryDescriptors = NULL;
    Mat queryDescriptors;
    vector_vector_DMatch matches;
    int k=0;
    PyObject* pyobj_masks = NULL;
    vector_Mat masks;
    bool compactResult=false;

    const char* keywords[] = { "queryDescriptors", "k", "masks", "compactResult", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "Oi|Ob:DescriptorMatcher.knnMatch", (char**)keywords, &pyobj_queryDescriptors, &k, &pyobj_masks, &compactResult) &&
        pyopencv_to(pyobj_queryDescriptors, queryDescriptors, ArgInfo("queryDescriptors", 0)) &&
        pyopencv_to(pyobj_masks, masks, ArgInfo("masks", 0)) )
    {
        ERRWRAP2(_self_->knnMatch(queryDescriptors, matches, k, masks, compactResult));
        return pyopencv_from(matches);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_queryDescriptors = NULL;
    UMat queryDescriptors;
    vector_vector_DMatch matches;
    int k=0;
    PyObject* pyobj_masks = NULL;
    vector_Mat masks;
    bool compactResult=false;

    const char* keywords[] = { "queryDescriptors", "k", "masks", "compactResult", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "Oi|Ob:DescriptorMatcher.knnMatch", (char**)keywords, &pyobj_queryDescriptors, &k, &pyobj_masks, &compactResult) &&
        pyopencv_to(pyobj_queryDescriptors, queryDescriptors, ArgInfo("queryDescriptors", 0)) &&
        pyopencv_to(pyobj_masks, masks, ArgInfo("masks", 0)) )
    {
        ERRWRAP2(_self_->knnMatch(queryDescriptors, matches, k, masks, compactResult));
        return pyopencv_from(matches);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_DescriptorMatcher_match(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_DescriptorMatcher_Type))
        return failmsgp("Incorrect type of self (must be 'DescriptorMatcher' or its derivative)");
    cv::DescriptorMatcher* _self_ = dynamic_cast<cv::DescriptorMatcher*>(((pyopencv_DescriptorMatcher_t*)self)->v.get());
    {
    PyObject* pyobj_queryDescriptors = NULL;
    Mat queryDescriptors;
    PyObject* pyobj_trainDescriptors = NULL;
    Mat trainDescriptors;
    vector_DMatch matches;
    PyObject* pyobj_mask = NULL;
    Mat mask;

    const char* keywords[] = { "queryDescriptors", "trainDescriptors", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|O:DescriptorMatcher.match", (char**)keywords, &pyobj_queryDescriptors, &pyobj_trainDescriptors, &pyobj_mask) &&
        pyopencv_to(pyobj_queryDescriptors, queryDescriptors, ArgInfo("queryDescriptors", 0)) &&
        pyopencv_to(pyobj_trainDescriptors, trainDescriptors, ArgInfo("trainDescriptors", 0)) &&
        pyopencv_to(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(_self_->match(queryDescriptors, trainDescriptors, matches, mask));
        return pyopencv_from(matches);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_queryDescriptors = NULL;
    UMat queryDescriptors;
    PyObject* pyobj_trainDescriptors = NULL;
    UMat trainDescriptors;
    vector_DMatch matches;
    PyObject* pyobj_mask = NULL;
    UMat mask;

    const char* keywords[] = { "queryDescriptors", "trainDescriptors", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|O:DescriptorMatcher.match", (char**)keywords, &pyobj_queryDescriptors, &pyobj_trainDescriptors, &pyobj_mask) &&
        pyopencv_to(pyobj_queryDescriptors, queryDescriptors, ArgInfo("queryDescriptors", 0)) &&
        pyopencv_to(pyobj_trainDescriptors, trainDescriptors, ArgInfo("trainDescriptors", 0)) &&
        pyopencv_to(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(_self_->match(queryDescriptors, trainDescriptors, matches, mask));
        return pyopencv_from(matches);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_queryDescriptors = NULL;
    Mat queryDescriptors;
    vector_DMatch matches;
    PyObject* pyobj_masks = NULL;
    vector_Mat masks;

    const char* keywords[] = { "queryDescriptors", "masks", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:DescriptorMatcher.match", (char**)keywords, &pyobj_queryDescriptors, &pyobj_masks) &&
        pyopencv_to(pyobj_queryDescriptors, queryDescriptors, ArgInfo("queryDescriptors", 0)) &&
        pyopencv_to(pyobj_masks, masks, ArgInfo("masks", 0)) )
    {
        ERRWRAP2(_self_->match(queryDescriptors, matches, masks));
        return pyopencv_from(matches);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_queryDescriptors = NULL;
    UMat queryDescriptors;
    vector_DMatch matches;
    PyObject* pyobj_masks = NULL;
    vector_Mat masks;

    const char* keywords[] = { "queryDescriptors", "masks", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:DescriptorMatcher.match", (char**)keywords, &pyobj_queryDescriptors, &pyobj_masks) &&
        pyopencv_to(pyobj_queryDescriptors, queryDescriptors, ArgInfo("queryDescriptors", 0)) &&
        pyopencv_to(pyobj_masks, masks, ArgInfo("masks", 0)) )
    {
        ERRWRAP2(_self_->match(queryDescriptors, matches, masks));
        return pyopencv_from(matches);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_DescriptorMatcher_radiusMatch(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_DescriptorMatcher_Type))
        return failmsgp("Incorrect type of self (must be 'DescriptorMatcher' or its derivative)");
    cv::DescriptorMatcher* _self_ = dynamic_cast<cv::DescriptorMatcher*>(((pyopencv_DescriptorMatcher_t*)self)->v.get());
    {
    PyObject* pyobj_queryDescriptors = NULL;
    Mat queryDescriptors;
    PyObject* pyobj_trainDescriptors = NULL;
    Mat trainDescriptors;
    vector_vector_DMatch matches;
    float maxDistance=0.f;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    bool compactResult=false;

    const char* keywords[] = { "queryDescriptors", "trainDescriptors", "maxDistance", "mask", "compactResult", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OOf|Ob:DescriptorMatcher.radiusMatch", (char**)keywords, &pyobj_queryDescriptors, &pyobj_trainDescriptors, &maxDistance, &pyobj_mask, &compactResult) &&
        pyopencv_to(pyobj_queryDescriptors, queryDescriptors, ArgInfo("queryDescriptors", 0)) &&
        pyopencv_to(pyobj_trainDescriptors, trainDescriptors, ArgInfo("trainDescriptors", 0)) &&
        pyopencv_to(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(_self_->radiusMatch(queryDescriptors, trainDescriptors, matches, maxDistance, mask, compactResult));
        return pyopencv_from(matches);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_queryDescriptors = NULL;
    UMat queryDescriptors;
    PyObject* pyobj_trainDescriptors = NULL;
    UMat trainDescriptors;
    vector_vector_DMatch matches;
    float maxDistance=0.f;
    PyObject* pyobj_mask = NULL;
    UMat mask;
    bool compactResult=false;

    const char* keywords[] = { "queryDescriptors", "trainDescriptors", "maxDistance", "mask", "compactResult", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OOf|Ob:DescriptorMatcher.radiusMatch", (char**)keywords, &pyobj_queryDescriptors, &pyobj_trainDescriptors, &maxDistance, &pyobj_mask, &compactResult) &&
        pyopencv_to(pyobj_queryDescriptors, queryDescriptors, ArgInfo("queryDescriptors", 0)) &&
        pyopencv_to(pyobj_trainDescriptors, trainDescriptors, ArgInfo("trainDescriptors", 0)) &&
        pyopencv_to(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(_self_->radiusMatch(queryDescriptors, trainDescriptors, matches, maxDistance, mask, compactResult));
        return pyopencv_from(matches);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_queryDescriptors = NULL;
    Mat queryDescriptors;
    vector_vector_DMatch matches;
    float maxDistance=0.f;
    PyObject* pyobj_masks = NULL;
    vector_Mat masks;
    bool compactResult=false;

    const char* keywords[] = { "queryDescriptors", "maxDistance", "masks", "compactResult", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "Of|Ob:DescriptorMatcher.radiusMatch", (char**)keywords, &pyobj_queryDescriptors, &maxDistance, &pyobj_masks, &compactResult) &&
        pyopencv_to(pyobj_queryDescriptors, queryDescriptors, ArgInfo("queryDescriptors", 0)) &&
        pyopencv_to(pyobj_masks, masks, ArgInfo("masks", 0)) )
    {
        ERRWRAP2(_self_->radiusMatch(queryDescriptors, matches, maxDistance, masks, compactResult));
        return pyopencv_from(matches);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_queryDescriptors = NULL;
    UMat queryDescriptors;
    vector_vector_DMatch matches;
    float maxDistance=0.f;
    PyObject* pyobj_masks = NULL;
    vector_Mat masks;
    bool compactResult=false;

    const char* keywords[] = { "queryDescriptors", "maxDistance", "masks", "compactResult", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "Of|Ob:DescriptorMatcher.radiusMatch", (char**)keywords, &pyobj_queryDescriptors, &maxDistance, &pyobj_masks, &compactResult) &&
        pyopencv_to(pyobj_queryDescriptors, queryDescriptors, ArgInfo("queryDescriptors", 0)) &&
        pyopencv_to(pyobj_masks, masks, ArgInfo("masks", 0)) )
    {
        ERRWRAP2(_self_->radiusMatch(queryDescriptors, matches, maxDistance, masks, compactResult));
        return pyopencv_from(matches);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_DescriptorMatcher_read(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_DescriptorMatcher_Type))
        return failmsgp("Incorrect type of self (must be 'DescriptorMatcher' or its derivative)");
    cv::DescriptorMatcher* _self_ = dynamic_cast<cv::DescriptorMatcher*>(((pyopencv_DescriptorMatcher_t*)self)->v.get());
    PyObject* pyobj_fileName = NULL;
    String fileName;

    const char* keywords[] = { "fileName", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:DescriptorMatcher.read", (char**)keywords, &pyobj_fileName) &&
        pyopencv_to(pyobj_fileName, fileName, ArgInfo("fileName", 0)) )
    {
        ERRWRAP2(_self_->read(fileName));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_DescriptorMatcher_train(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_DescriptorMatcher_Type))
        return failmsgp("Incorrect type of self (must be 'DescriptorMatcher' or its derivative)");
    cv::DescriptorMatcher* _self_ = dynamic_cast<cv::DescriptorMatcher*>(((pyopencv_DescriptorMatcher_t*)self)->v.get());

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(_self_->train());
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_DescriptorMatcher_write(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_DescriptorMatcher_Type))
        return failmsgp("Incorrect type of self (must be 'DescriptorMatcher' or its derivative)");
    cv::DescriptorMatcher* _self_ = dynamic_cast<cv::DescriptorMatcher*>(((pyopencv_DescriptorMatcher_t*)self)->v.get());
    PyObject* pyobj_fileName = NULL;
    String fileName;

    const char* keywords[] = { "fileName", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:DescriptorMatcher.write", (char**)keywords, &pyobj_fileName) &&
        pyopencv_to(pyobj_fileName, fileName, ArgInfo("fileName", 0)) )
    {
        ERRWRAP2(_self_->write(fileName));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_DescriptorMatcher_methods[] =
{
    {"add", (PyCFunction)pyopencv_cv_DescriptorMatcher_add, METH_VARARGS | METH_KEYWORDS, "add(descriptors) -> None"},
    {"clear", (PyCFunction)pyopencv_cv_DescriptorMatcher_clear, METH_VARARGS | METH_KEYWORDS, "clear() -> None"},
    {"clone", (PyCFunction)pyopencv_cv_DescriptorMatcher_clone, METH_VARARGS | METH_KEYWORDS, "clone([, emptyTrainData]) -> retval"},
    {"empty", (PyCFunction)pyopencv_cv_DescriptorMatcher_empty, METH_VARARGS | METH_KEYWORDS, "empty() -> retval"},
    {"getTrainDescriptors", (PyCFunction)pyopencv_cv_DescriptorMatcher_getTrainDescriptors, METH_VARARGS | METH_KEYWORDS, "getTrainDescriptors() -> retval"},
    {"isMaskSupported", (PyCFunction)pyopencv_cv_DescriptorMatcher_isMaskSupported, METH_VARARGS | METH_KEYWORDS, "isMaskSupported() -> retval"},
    {"knnMatch", (PyCFunction)pyopencv_cv_DescriptorMatcher_knnMatch, METH_VARARGS | METH_KEYWORDS, "knnMatch(queryDescriptors, trainDescriptors, k[, mask[, compactResult]]) -> matches  or  knnMatch(queryDescriptors, k[, masks[, compactResult]]) -> matches"},
    {"match", (PyCFunction)pyopencv_cv_DescriptorMatcher_match, METH_VARARGS | METH_KEYWORDS, "match(queryDescriptors, trainDescriptors[, mask]) -> matches  or  match(queryDescriptors[, masks]) -> matches"},
    {"radiusMatch", (PyCFunction)pyopencv_cv_DescriptorMatcher_radiusMatch, METH_VARARGS | METH_KEYWORDS, "radiusMatch(queryDescriptors, trainDescriptors, maxDistance[, mask[, compactResult]]) -> matches  or  radiusMatch(queryDescriptors, maxDistance[, masks[, compactResult]]) -> matches"},
    {"read", (PyCFunction)pyopencv_cv_DescriptorMatcher_read, METH_VARARGS | METH_KEYWORDS, "read(fileName) -> None"},
    {"train", (PyCFunction)pyopencv_cv_DescriptorMatcher_train, METH_VARARGS | METH_KEYWORDS, "train() -> None"},
    {"write", (PyCFunction)pyopencv_cv_DescriptorMatcher_write, METH_VARARGS | METH_KEYWORDS, "write(fileName) -> None"},

    {NULL,          NULL}
};

static void pyopencv_DescriptorMatcher_specials(void)
{
    pyopencv_DescriptorMatcher_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_DescriptorMatcher_Type.tp_dealloc = pyopencv_DescriptorMatcher_dealloc;
    pyopencv_DescriptorMatcher_Type.tp_repr = pyopencv_DescriptorMatcher_repr;
    pyopencv_DescriptorMatcher_Type.tp_getset = pyopencv_DescriptorMatcher_getseters;
    pyopencv_DescriptorMatcher_Type.tp_methods = pyopencv_DescriptorMatcher_methods;
}

static PyObject* pyopencv_BFMatcher_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<BFMatcher %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_BFMatcher_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_BFMatcher_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_BFMatcher_specials(void)
{
    pyopencv_BFMatcher_Type.tp_base = &pyopencv_DescriptorMatcher_Type;
    pyopencv_BFMatcher_Type.tp_dealloc = pyopencv_BFMatcher_dealloc;
    pyopencv_BFMatcher_Type.tp_repr = pyopencv_BFMatcher_repr;
    pyopencv_BFMatcher_Type.tp_getset = pyopencv_BFMatcher_getseters;
    pyopencv_BFMatcher_Type.tp_methods = pyopencv_BFMatcher_methods;
}

static PyObject* pyopencv_FlannBasedMatcher_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<FlannBasedMatcher %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_FlannBasedMatcher_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_FlannBasedMatcher_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_FlannBasedMatcher_specials(void)
{
    pyopencv_FlannBasedMatcher_Type.tp_base = &pyopencv_DescriptorMatcher_Type;
    pyopencv_FlannBasedMatcher_Type.tp_dealloc = pyopencv_FlannBasedMatcher_dealloc;
    pyopencv_FlannBasedMatcher_Type.tp_repr = pyopencv_FlannBasedMatcher_repr;
    pyopencv_FlannBasedMatcher_Type.tp_getset = pyopencv_FlannBasedMatcher_getseters;
    pyopencv_FlannBasedMatcher_Type.tp_methods = pyopencv_FlannBasedMatcher_methods;
}

static PyObject* pyopencv_BOWTrainer_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<BOWTrainer %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_BOWTrainer_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_BOWTrainer_add(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BOWTrainer_Type))
        return failmsgp("Incorrect type of self (must be 'BOWTrainer' or its derivative)");
    cv::BOWTrainer* _self_ = ((pyopencv_BOWTrainer_t*)self)->v.get();
    {
    PyObject* pyobj_descriptors = NULL;
    Mat descriptors;

    const char* keywords[] = { "descriptors", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:BOWTrainer.add", (char**)keywords, &pyobj_descriptors) &&
        pyopencv_to(pyobj_descriptors, descriptors, ArgInfo("descriptors", 0)) )
    {
        ERRWRAP2(_self_->add(descriptors));
        Py_RETURN_NONE;
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_descriptors = NULL;
    Mat descriptors;

    const char* keywords[] = { "descriptors", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:BOWTrainer.add", (char**)keywords, &pyobj_descriptors) &&
        pyopencv_to(pyobj_descriptors, descriptors, ArgInfo("descriptors", 0)) )
    {
        ERRWRAP2(_self_->add(descriptors));
        Py_RETURN_NONE;
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_BOWTrainer_clear(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BOWTrainer_Type))
        return failmsgp("Incorrect type of self (must be 'BOWTrainer' or its derivative)");
    cv::BOWTrainer* _self_ = ((pyopencv_BOWTrainer_t*)self)->v.get();

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(_self_->clear());
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_BOWTrainer_cluster(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BOWTrainer_Type))
        return failmsgp("Incorrect type of self (must be 'BOWTrainer' or its derivative)");
    cv::BOWTrainer* _self_ = ((pyopencv_BOWTrainer_t*)self)->v.get();
    {
    Mat retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->cluster());
        return pyopencv_from(retval);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_descriptors = NULL;
    Mat descriptors;
    Mat retval;

    const char* keywords[] = { "descriptors", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:BOWTrainer.cluster", (char**)keywords, &pyobj_descriptors) &&
        pyopencv_to(pyobj_descriptors, descriptors, ArgInfo("descriptors", 0)) )
    {
        ERRWRAP2(retval = _self_->cluster(descriptors));
        return pyopencv_from(retval);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_descriptors = NULL;
    Mat descriptors;
    Mat retval;

    const char* keywords[] = { "descriptors", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:BOWTrainer.cluster", (char**)keywords, &pyobj_descriptors) &&
        pyopencv_to(pyobj_descriptors, descriptors, ArgInfo("descriptors", 0)) )
    {
        ERRWRAP2(retval = _self_->cluster(descriptors));
        return pyopencv_from(retval);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_BOWTrainer_descriptorsCount(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BOWTrainer_Type))
        return failmsgp("Incorrect type of self (must be 'BOWTrainer' or its derivative)");
    cv::BOWTrainer* _self_ = ((pyopencv_BOWTrainer_t*)self)->v.get();
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->descriptorsCount());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_BOWTrainer_getDescriptors(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BOWTrainer_Type))
        return failmsgp("Incorrect type of self (must be 'BOWTrainer' or its derivative)");
    cv::BOWTrainer* _self_ = ((pyopencv_BOWTrainer_t*)self)->v.get();
    std::vector<Mat> retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getDescriptors());
        return pyopencv_from(retval);
    }

    return NULL;
}



static PyMethodDef pyopencv_BOWTrainer_methods[] =
{
    {"add", (PyCFunction)pyopencv_cv_BOWTrainer_add, METH_VARARGS | METH_KEYWORDS, "add(descriptors) -> None"},
    {"clear", (PyCFunction)pyopencv_cv_BOWTrainer_clear, METH_VARARGS | METH_KEYWORDS, "clear() -> None"},
    {"cluster", (PyCFunction)pyopencv_cv_BOWTrainer_cluster, METH_VARARGS | METH_KEYWORDS, "cluster() -> retval  or  cluster(descriptors) -> retval"},
    {"descriptorsCount", (PyCFunction)pyopencv_cv_BOWTrainer_descriptorsCount, METH_VARARGS | METH_KEYWORDS, "descriptorsCount() -> retval"},
    {"getDescriptors", (PyCFunction)pyopencv_cv_BOWTrainer_getDescriptors, METH_VARARGS | METH_KEYWORDS, "getDescriptors() -> retval"},

    {NULL,          NULL}
};

static void pyopencv_BOWTrainer_specials(void)
{
    pyopencv_BOWTrainer_Type.tp_base = NULL;
    pyopencv_BOWTrainer_Type.tp_dealloc = pyopencv_BOWTrainer_dealloc;
    pyopencv_BOWTrainer_Type.tp_repr = pyopencv_BOWTrainer_repr;
    pyopencv_BOWTrainer_Type.tp_getset = pyopencv_BOWTrainer_getseters;
    pyopencv_BOWTrainer_Type.tp_methods = pyopencv_BOWTrainer_methods;
}

static PyObject* pyopencv_BOWKMeansTrainer_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<BOWKMeansTrainer %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_BOWKMeansTrainer_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_BOWKMeansTrainer_cluster(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BOWKMeansTrainer_Type))
        return failmsgp("Incorrect type of self (must be 'BOWKMeansTrainer' or its derivative)");
    cv::BOWKMeansTrainer* _self_ = ((pyopencv_BOWKMeansTrainer_t*)self)->v.get();
    {
    Mat retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->cluster());
        return pyopencv_from(retval);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_descriptors = NULL;
    Mat descriptors;
    Mat retval;

    const char* keywords[] = { "descriptors", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:BOWKMeansTrainer.cluster", (char**)keywords, &pyobj_descriptors) &&
        pyopencv_to(pyobj_descriptors, descriptors, ArgInfo("descriptors", 0)) )
    {
        ERRWRAP2(retval = _self_->cluster(descriptors));
        return pyopencv_from(retval);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_descriptors = NULL;
    Mat descriptors;
    Mat retval;

    const char* keywords[] = { "descriptors", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:BOWKMeansTrainer.cluster", (char**)keywords, &pyobj_descriptors) &&
        pyopencv_to(pyobj_descriptors, descriptors, ArgInfo("descriptors", 0)) )
    {
        ERRWRAP2(retval = _self_->cluster(descriptors));
        return pyopencv_from(retval);
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_BOWKMeansTrainer_methods[] =
{
    {"cluster", (PyCFunction)pyopencv_cv_BOWKMeansTrainer_cluster, METH_VARARGS | METH_KEYWORDS, "cluster() -> retval  or  cluster(descriptors) -> retval"},

    {NULL,          NULL}
};

static void pyopencv_BOWKMeansTrainer_specials(void)
{
    pyopencv_BOWKMeansTrainer_Type.tp_base = &pyopencv_BOWTrainer_Type;
    pyopencv_BOWKMeansTrainer_Type.tp_dealloc = pyopencv_BOWKMeansTrainer_dealloc;
    pyopencv_BOWKMeansTrainer_Type.tp_repr = pyopencv_BOWKMeansTrainer_repr;
    pyopencv_BOWKMeansTrainer_Type.tp_getset = pyopencv_BOWKMeansTrainer_getseters;
    pyopencv_BOWKMeansTrainer_Type.tp_methods = pyopencv_BOWKMeansTrainer_methods;
}

static PyObject* pyopencv_BOWImgDescriptorExtractor_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<BOWImgDescriptorExtractor %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_BOWImgDescriptorExtractor_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_BOWImgDescriptorExtractor_compute(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BOWImgDescriptorExtractor_Type))
        return failmsgp("Incorrect type of self (must be 'BOWImgDescriptorExtractor' or its derivative)");
    cv::BOWImgDescriptorExtractor* _self_ = ((pyopencv_BOWImgDescriptorExtractor_t*)self)->v.get();
    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_keypoints = NULL;
    vector_KeyPoint keypoints;
    PyObject* pyobj_imgDescriptor = NULL;
    Mat imgDescriptor;

    const char* keywords[] = { "image", "keypoints", "imgDescriptor", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|O:BOWImgDescriptorExtractor.compute", (char**)keywords, &pyobj_image, &pyobj_keypoints, &pyobj_imgDescriptor) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_keypoints, keypoints, ArgInfo("keypoints", 0)) &&
        pyopencv_to(pyobj_imgDescriptor, imgDescriptor, ArgInfo("imgDescriptor", 1)) )
    {
        ERRWRAP2(_self_->compute2(image, keypoints, imgDescriptor));
        return pyopencv_from(imgDescriptor);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_keypoints = NULL;
    vector_KeyPoint keypoints;
    PyObject* pyobj_imgDescriptor = NULL;
    Mat imgDescriptor;

    const char* keywords[] = { "image", "keypoints", "imgDescriptor", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|O:BOWImgDescriptorExtractor.compute", (char**)keywords, &pyobj_image, &pyobj_keypoints, &pyobj_imgDescriptor) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_keypoints, keypoints, ArgInfo("keypoints", 0)) &&
        pyopencv_to(pyobj_imgDescriptor, imgDescriptor, ArgInfo("imgDescriptor", 1)) )
    {
        ERRWRAP2(_self_->compute2(image, keypoints, imgDescriptor));
        return pyopencv_from(imgDescriptor);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_BOWImgDescriptorExtractor_descriptorSize(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BOWImgDescriptorExtractor_Type))
        return failmsgp("Incorrect type of self (must be 'BOWImgDescriptorExtractor' or its derivative)");
    cv::BOWImgDescriptorExtractor* _self_ = ((pyopencv_BOWImgDescriptorExtractor_t*)self)->v.get();
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->descriptorSize());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_BOWImgDescriptorExtractor_descriptorType(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BOWImgDescriptorExtractor_Type))
        return failmsgp("Incorrect type of self (must be 'BOWImgDescriptorExtractor' or its derivative)");
    cv::BOWImgDescriptorExtractor* _self_ = ((pyopencv_BOWImgDescriptorExtractor_t*)self)->v.get();
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->descriptorType());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_BOWImgDescriptorExtractor_getVocabulary(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BOWImgDescriptorExtractor_Type))
        return failmsgp("Incorrect type of self (must be 'BOWImgDescriptorExtractor' or its derivative)");
    cv::BOWImgDescriptorExtractor* _self_ = ((pyopencv_BOWImgDescriptorExtractor_t*)self)->v.get();
    Mat retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getVocabulary());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_BOWImgDescriptorExtractor_setVocabulary(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_BOWImgDescriptorExtractor_Type))
        return failmsgp("Incorrect type of self (must be 'BOWImgDescriptorExtractor' or its derivative)");
    cv::BOWImgDescriptorExtractor* _self_ = ((pyopencv_BOWImgDescriptorExtractor_t*)self)->v.get();
    {
    PyObject* pyobj_vocabulary = NULL;
    Mat vocabulary;

    const char* keywords[] = { "vocabulary", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:BOWImgDescriptorExtractor.setVocabulary", (char**)keywords, &pyobj_vocabulary) &&
        pyopencv_to(pyobj_vocabulary, vocabulary, ArgInfo("vocabulary", 0)) )
    {
        ERRWRAP2(_self_->setVocabulary(vocabulary));
        Py_RETURN_NONE;
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_vocabulary = NULL;
    Mat vocabulary;

    const char* keywords[] = { "vocabulary", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:BOWImgDescriptorExtractor.setVocabulary", (char**)keywords, &pyobj_vocabulary) &&
        pyopencv_to(pyobj_vocabulary, vocabulary, ArgInfo("vocabulary", 0)) )
    {
        ERRWRAP2(_self_->setVocabulary(vocabulary));
        Py_RETURN_NONE;
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_BOWImgDescriptorExtractor_methods[] =
{
    {"compute", (PyCFunction)pyopencv_cv_BOWImgDescriptorExtractor_compute, METH_VARARGS | METH_KEYWORDS, "compute(image, keypoints[, imgDescriptor]) -> imgDescriptor"},
    {"descriptorSize", (PyCFunction)pyopencv_cv_BOWImgDescriptorExtractor_descriptorSize, METH_VARARGS | METH_KEYWORDS, "descriptorSize() -> retval"},
    {"descriptorType", (PyCFunction)pyopencv_cv_BOWImgDescriptorExtractor_descriptorType, METH_VARARGS | METH_KEYWORDS, "descriptorType() -> retval"},
    {"getVocabulary", (PyCFunction)pyopencv_cv_BOWImgDescriptorExtractor_getVocabulary, METH_VARARGS | METH_KEYWORDS, "getVocabulary() -> retval"},
    {"setVocabulary", (PyCFunction)pyopencv_cv_BOWImgDescriptorExtractor_setVocabulary, METH_VARARGS | METH_KEYWORDS, "setVocabulary(vocabulary) -> None"},

    {NULL,          NULL}
};

static void pyopencv_BOWImgDescriptorExtractor_specials(void)
{
    pyopencv_BOWImgDescriptorExtractor_Type.tp_base = NULL;
    pyopencv_BOWImgDescriptorExtractor_Type.tp_dealloc = pyopencv_BOWImgDescriptorExtractor_dealloc;
    pyopencv_BOWImgDescriptorExtractor_Type.tp_repr = pyopencv_BOWImgDescriptorExtractor_repr;
    pyopencv_BOWImgDescriptorExtractor_Type.tp_getset = pyopencv_BOWImgDescriptorExtractor_getseters;
    pyopencv_BOWImgDescriptorExtractor_Type.tp_methods = pyopencv_BOWImgDescriptorExtractor_methods;
}

static PyObject* pyopencv_saliency_Saliency_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<saliency_Saliency %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_saliency_Saliency_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_saliency_saliency_Saliency_computeSaliency(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::saliency;

    if(!PyObject_TypeCheck(self, &pyopencv_saliency_Saliency_Type))
        return failmsgp("Incorrect type of self (must be 'saliency_Saliency' or its derivative)");
    cv::saliency::Saliency* _self_ = dynamic_cast<cv::saliency::Saliency*>(((pyopencv_saliency_Saliency_t*)self)->v.get());
    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_saliencyMap = NULL;
    Mat saliencyMap;
    bool retval;

    const char* keywords[] = { "image", "saliencyMap", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:saliency_Saliency.computeSaliency", (char**)keywords, &pyobj_image, &pyobj_saliencyMap) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_saliencyMap, saliencyMap, ArgInfo("saliencyMap", 1)) )
    {
        ERRWRAP2(retval = _self_->computeSaliency(image, saliencyMap));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(saliencyMap));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_saliencyMap = NULL;
    UMat saliencyMap;
    bool retval;

    const char* keywords[] = { "image", "saliencyMap", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:saliency_Saliency.computeSaliency", (char**)keywords, &pyobj_image, &pyobj_saliencyMap) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_saliencyMap, saliencyMap, ArgInfo("saliencyMap", 1)) )
    {
        ERRWRAP2(retval = _self_->computeSaliency(image, saliencyMap));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(saliencyMap));
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_saliency_saliency_Saliency_getClassName(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::saliency;

    if(!PyObject_TypeCheck(self, &pyopencv_saliency_Saliency_Type))
        return failmsgp("Incorrect type of self (must be 'saliency_Saliency' or its derivative)");
    cv::saliency::Saliency* _self_ = dynamic_cast<cv::saliency::Saliency*>(((pyopencv_saliency_Saliency_t*)self)->v.get());
    String retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getClassName());
        return pyopencv_from(retval);
    }

    return NULL;
}



static PyMethodDef pyopencv_saliency_Saliency_methods[] =
{
    {"computeSaliency", (PyCFunction)pyopencv_cv_saliency_saliency_Saliency_computeSaliency, METH_VARARGS | METH_KEYWORDS, "computeSaliency(image[, saliencyMap]) -> retval, saliencyMap"},
    {"getClassName", (PyCFunction)pyopencv_cv_saliency_saliency_Saliency_getClassName, METH_VARARGS | METH_KEYWORDS, "getClassName() -> retval"},

    {NULL,          NULL}
};

static void pyopencv_saliency_Saliency_specials(void)
{
    pyopencv_saliency_Saliency_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_saliency_Saliency_Type.tp_dealloc = pyopencv_saliency_Saliency_dealloc;
    pyopencv_saliency_Saliency_Type.tp_repr = pyopencv_saliency_Saliency_repr;
    pyopencv_saliency_Saliency_Type.tp_getset = pyopencv_saliency_Saliency_getseters;
    pyopencv_saliency_Saliency_Type.tp_methods = pyopencv_saliency_Saliency_methods;
}

static PyObject* pyopencv_saliency_StaticSaliency_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<saliency_StaticSaliency %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_saliency_StaticSaliency_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_saliency_saliency_StaticSaliency_computeBinaryMap(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::saliency;

    if(!PyObject_TypeCheck(self, &pyopencv_saliency_StaticSaliency_Type))
        return failmsgp("Incorrect type of self (must be 'saliency_StaticSaliency' or its derivative)");
    cv::saliency::StaticSaliency* _self_ = dynamic_cast<cv::saliency::StaticSaliency*>(((pyopencv_saliency_StaticSaliency_t*)self)->v.get());
    {
    PyObject* pyobj__saliencyMap = NULL;
    Mat _saliencyMap;
    PyObject* pyobj__binaryMap = NULL;
    Mat _binaryMap;
    bool retval;

    const char* keywords[] = { "_saliencyMap", "_binaryMap", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:saliency_StaticSaliency.computeBinaryMap", (char**)keywords, &pyobj__saliencyMap, &pyobj__binaryMap) &&
        pyopencv_to(pyobj__saliencyMap, _saliencyMap, ArgInfo("_saliencyMap", 0)) &&
        pyopencv_to(pyobj__binaryMap, _binaryMap, ArgInfo("_binaryMap", 1)) )
    {
        ERRWRAP2(retval = _self_->computeBinaryMap(_saliencyMap, _binaryMap));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(_binaryMap));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj__saliencyMap = NULL;
    UMat _saliencyMap;
    PyObject* pyobj__binaryMap = NULL;
    UMat _binaryMap;
    bool retval;

    const char* keywords[] = { "_saliencyMap", "_binaryMap", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:saliency_StaticSaliency.computeBinaryMap", (char**)keywords, &pyobj__saliencyMap, &pyobj__binaryMap) &&
        pyopencv_to(pyobj__saliencyMap, _saliencyMap, ArgInfo("_saliencyMap", 0)) &&
        pyopencv_to(pyobj__binaryMap, _binaryMap, ArgInfo("_binaryMap", 1)) )
    {
        ERRWRAP2(retval = _self_->computeBinaryMap(_saliencyMap, _binaryMap));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(_binaryMap));
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_saliency_StaticSaliency_methods[] =
{
    {"computeBinaryMap", (PyCFunction)pyopencv_cv_saliency_saliency_StaticSaliency_computeBinaryMap, METH_VARARGS | METH_KEYWORDS, "computeBinaryMap(_saliencyMap[, _binaryMap]) -> retval, _binaryMap"},

    {NULL,          NULL}
};

static void pyopencv_saliency_StaticSaliency_specials(void)
{
    pyopencv_saliency_StaticSaliency_Type.tp_base = &pyopencv_saliency_Saliency_Type;
    pyopencv_saliency_StaticSaliency_Type.tp_dealloc = pyopencv_saliency_StaticSaliency_dealloc;
    pyopencv_saliency_StaticSaliency_Type.tp_repr = pyopencv_saliency_StaticSaliency_repr;
    pyopencv_saliency_StaticSaliency_Type.tp_getset = pyopencv_saliency_StaticSaliency_getseters;
    pyopencv_saliency_StaticSaliency_Type.tp_methods = pyopencv_saliency_StaticSaliency_methods;
}

static PyObject* pyopencv_saliency_MotionSaliency_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<saliency_MotionSaliency %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_saliency_MotionSaliency_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_saliency_MotionSaliency_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_saliency_MotionSaliency_specials(void)
{
    pyopencv_saliency_MotionSaliency_Type.tp_base = &pyopencv_saliency_Saliency_Type;
    pyopencv_saliency_MotionSaliency_Type.tp_dealloc = pyopencv_saliency_MotionSaliency_dealloc;
    pyopencv_saliency_MotionSaliency_Type.tp_repr = pyopencv_saliency_MotionSaliency_repr;
    pyopencv_saliency_MotionSaliency_Type.tp_getset = pyopencv_saliency_MotionSaliency_getseters;
    pyopencv_saliency_MotionSaliency_Type.tp_methods = pyopencv_saliency_MotionSaliency_methods;
}

static PyObject* pyopencv_saliency_Objectness_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<saliency_Objectness %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_saliency_Objectness_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_saliency_Objectness_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_saliency_Objectness_specials(void)
{
    pyopencv_saliency_Objectness_Type.tp_base = &pyopencv_saliency_Saliency_Type;
    pyopencv_saliency_Objectness_Type.tp_dealloc = pyopencv_saliency_Objectness_dealloc;
    pyopencv_saliency_Objectness_Type.tp_repr = pyopencv_saliency_Objectness_repr;
    pyopencv_saliency_Objectness_Type.tp_getset = pyopencv_saliency_Objectness_getseters;
    pyopencv_saliency_Objectness_Type.tp_methods = pyopencv_saliency_Objectness_methods;
}

static PyObject* pyopencv_saliency_StaticSaliencySpectralResidual_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<saliency_StaticSaliencySpectralResidual %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_saliency_StaticSaliencySpectralResidual_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_saliency_saliency_StaticSaliencySpectralResidual_computeSaliency(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::saliency;

    if(!PyObject_TypeCheck(self, &pyopencv_saliency_StaticSaliencySpectralResidual_Type))
        return failmsgp("Incorrect type of self (must be 'saliency_StaticSaliencySpectralResidual' or its derivative)");
    cv::saliency::StaticSaliencySpectralResidual* _self_ = dynamic_cast<cv::saliency::StaticSaliencySpectralResidual*>(((pyopencv_saliency_StaticSaliencySpectralResidual_t*)self)->v.get());
    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_saliencyMap = NULL;
    Mat saliencyMap;
    bool retval;

    const char* keywords[] = { "image", "saliencyMap", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:saliency_StaticSaliencySpectralResidual.computeSaliency", (char**)keywords, &pyobj_image, &pyobj_saliencyMap) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_saliencyMap, saliencyMap, ArgInfo("saliencyMap", 1)) )
    {
        ERRWRAP2(retval = _self_->computeSaliency(image, saliencyMap));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(saliencyMap));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_saliencyMap = NULL;
    UMat saliencyMap;
    bool retval;

    const char* keywords[] = { "image", "saliencyMap", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:saliency_StaticSaliencySpectralResidual.computeSaliency", (char**)keywords, &pyobj_image, &pyobj_saliencyMap) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_saliencyMap, saliencyMap, ArgInfo("saliencyMap", 1)) )
    {
        ERRWRAP2(retval = _self_->computeSaliency(image, saliencyMap));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(saliencyMap));
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_saliency_saliency_StaticSaliencySpectralResidual_getImageHeight(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::saliency;

    if(!PyObject_TypeCheck(self, &pyopencv_saliency_StaticSaliencySpectralResidual_Type))
        return failmsgp("Incorrect type of self (must be 'saliency_StaticSaliencySpectralResidual' or its derivative)");
    cv::saliency::StaticSaliencySpectralResidual* _self_ = dynamic_cast<cv::saliency::StaticSaliencySpectralResidual*>(((pyopencv_saliency_StaticSaliencySpectralResidual_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getImageHeight());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_saliency_saliency_StaticSaliencySpectralResidual_getImageWidth(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::saliency;

    if(!PyObject_TypeCheck(self, &pyopencv_saliency_StaticSaliencySpectralResidual_Type))
        return failmsgp("Incorrect type of self (must be 'saliency_StaticSaliencySpectralResidual' or its derivative)");
    cv::saliency::StaticSaliencySpectralResidual* _self_ = dynamic_cast<cv::saliency::StaticSaliencySpectralResidual*>(((pyopencv_saliency_StaticSaliencySpectralResidual_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getImageWidth());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_saliency_saliency_StaticSaliencySpectralResidual_read(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::saliency;

    if(!PyObject_TypeCheck(self, &pyopencv_saliency_StaticSaliencySpectralResidual_Type))
        return failmsgp("Incorrect type of self (must be 'saliency_StaticSaliencySpectralResidual' or its derivative)");
    cv::saliency::StaticSaliencySpectralResidual* _self_ = dynamic_cast<cv::saliency::StaticSaliencySpectralResidual*>(((pyopencv_saliency_StaticSaliencySpectralResidual_t*)self)->v.get());
    PyObject* pyobj_fn = NULL;
    FileNode fn;

    const char* keywords[] = { "fn", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:saliency_StaticSaliencySpectralResidual.read", (char**)keywords, &pyobj_fn) &&
        pyopencv_to(pyobj_fn, fn, ArgInfo("fn", 0)) )
    {
        ERRWRAP2(_self_->read(fn));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_saliency_saliency_StaticSaliencySpectralResidual_setImageHeight(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::saliency;

    if(!PyObject_TypeCheck(self, &pyopencv_saliency_StaticSaliencySpectralResidual_Type))
        return failmsgp("Incorrect type of self (must be 'saliency_StaticSaliencySpectralResidual' or its derivative)");
    cv::saliency::StaticSaliencySpectralResidual* _self_ = dynamic_cast<cv::saliency::StaticSaliencySpectralResidual*>(((pyopencv_saliency_StaticSaliencySpectralResidual_t*)self)->v.get());
    int val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:saliency_StaticSaliencySpectralResidual.setImageHeight", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setImageHeight(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_saliency_saliency_StaticSaliencySpectralResidual_setImageWidth(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::saliency;

    if(!PyObject_TypeCheck(self, &pyopencv_saliency_StaticSaliencySpectralResidual_Type))
        return failmsgp("Incorrect type of self (must be 'saliency_StaticSaliencySpectralResidual' or its derivative)");
    cv::saliency::StaticSaliencySpectralResidual* _self_ = dynamic_cast<cv::saliency::StaticSaliencySpectralResidual*>(((pyopencv_saliency_StaticSaliencySpectralResidual_t*)self)->v.get());
    int val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:saliency_StaticSaliencySpectralResidual.setImageWidth", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setImageWidth(val));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_saliency_StaticSaliencySpectralResidual_methods[] =
{
    {"computeSaliency", (PyCFunction)pyopencv_cv_saliency_saliency_StaticSaliencySpectralResidual_computeSaliency, METH_VARARGS | METH_KEYWORDS, "computeSaliency(image[, saliencyMap]) -> retval, saliencyMap"},
    {"getImageHeight", (PyCFunction)pyopencv_cv_saliency_saliency_StaticSaliencySpectralResidual_getImageHeight, METH_VARARGS | METH_KEYWORDS, "getImageHeight() -> retval"},
    {"getImageWidth", (PyCFunction)pyopencv_cv_saliency_saliency_StaticSaliencySpectralResidual_getImageWidth, METH_VARARGS | METH_KEYWORDS, "getImageWidth() -> retval"},
    {"read", (PyCFunction)pyopencv_cv_saliency_saliency_StaticSaliencySpectralResidual_read, METH_VARARGS | METH_KEYWORDS, "read(fn) -> None"},
    {"setImageHeight", (PyCFunction)pyopencv_cv_saliency_saliency_StaticSaliencySpectralResidual_setImageHeight, METH_VARARGS | METH_KEYWORDS, "setImageHeight(val) -> None"},
    {"setImageWidth", (PyCFunction)pyopencv_cv_saliency_saliency_StaticSaliencySpectralResidual_setImageWidth, METH_VARARGS | METH_KEYWORDS, "setImageWidth(val) -> None"},

    {NULL,          NULL}
};

static void pyopencv_saliency_StaticSaliencySpectralResidual_specials(void)
{
    pyopencv_saliency_StaticSaliencySpectralResidual_Type.tp_base = &pyopencv_saliency_StaticSaliency_Type;
    pyopencv_saliency_StaticSaliencySpectralResidual_Type.tp_dealloc = pyopencv_saliency_StaticSaliencySpectralResidual_dealloc;
    pyopencv_saliency_StaticSaliencySpectralResidual_Type.tp_repr = pyopencv_saliency_StaticSaliencySpectralResidual_repr;
    pyopencv_saliency_StaticSaliencySpectralResidual_Type.tp_getset = pyopencv_saliency_StaticSaliencySpectralResidual_getseters;
    pyopencv_saliency_StaticSaliencySpectralResidual_Type.tp_methods = pyopencv_saliency_StaticSaliencySpectralResidual_methods;
}

static PyObject* pyopencv_saliency_StaticSaliencyFineGrained_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<saliency_StaticSaliencyFineGrained %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_saliency_StaticSaliencyFineGrained_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_saliency_saliency_StaticSaliencyFineGrained_computeSaliency(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::saliency;

    if(!PyObject_TypeCheck(self, &pyopencv_saliency_StaticSaliencyFineGrained_Type))
        return failmsgp("Incorrect type of self (must be 'saliency_StaticSaliencyFineGrained' or its derivative)");
    cv::saliency::StaticSaliencyFineGrained* _self_ = ((pyopencv_saliency_StaticSaliencyFineGrained_t*)self)->v.get();
    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_saliencyMap = NULL;
    Mat saliencyMap;
    bool retval;

    const char* keywords[] = { "image", "saliencyMap", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:saliency_StaticSaliencyFineGrained.computeSaliency", (char**)keywords, &pyobj_image, &pyobj_saliencyMap) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_saliencyMap, saliencyMap, ArgInfo("saliencyMap", 1)) )
    {
        ERRWRAP2(retval = _self_->computeSaliency(image, saliencyMap));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(saliencyMap));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_saliencyMap = NULL;
    UMat saliencyMap;
    bool retval;

    const char* keywords[] = { "image", "saliencyMap", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:saliency_StaticSaliencyFineGrained.computeSaliency", (char**)keywords, &pyobj_image, &pyobj_saliencyMap) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_saliencyMap, saliencyMap, ArgInfo("saliencyMap", 1)) )
    {
        ERRWRAP2(retval = _self_->computeSaliency(image, saliencyMap));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(saliencyMap));
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_saliency_StaticSaliencyFineGrained_methods[] =
{
    {"computeSaliency", (PyCFunction)pyopencv_cv_saliency_saliency_StaticSaliencyFineGrained_computeSaliency, METH_VARARGS | METH_KEYWORDS, "computeSaliency(image[, saliencyMap]) -> retval, saliencyMap"},

    {NULL,          NULL}
};

static void pyopencv_saliency_StaticSaliencyFineGrained_specials(void)
{
    pyopencv_saliency_StaticSaliencyFineGrained_Type.tp_base = &pyopencv_saliency_StaticSaliency_Type;
    pyopencv_saliency_StaticSaliencyFineGrained_Type.tp_dealloc = pyopencv_saliency_StaticSaliencyFineGrained_dealloc;
    pyopencv_saliency_StaticSaliencyFineGrained_Type.tp_repr = pyopencv_saliency_StaticSaliencyFineGrained_repr;
    pyopencv_saliency_StaticSaliencyFineGrained_Type.tp_getset = pyopencv_saliency_StaticSaliencyFineGrained_getseters;
    pyopencv_saliency_StaticSaliencyFineGrained_Type.tp_methods = pyopencv_saliency_StaticSaliencyFineGrained_methods;
}

static PyObject* pyopencv_saliency_MotionSaliencyBinWangApr2014_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<saliency_MotionSaliencyBinWangApr2014 %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_saliency_MotionSaliencyBinWangApr2014_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_saliency_saliency_MotionSaliencyBinWangApr2014_computeSaliency(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::saliency;

    if(!PyObject_TypeCheck(self, &pyopencv_saliency_MotionSaliencyBinWangApr2014_Type))
        return failmsgp("Incorrect type of self (must be 'saliency_MotionSaliencyBinWangApr2014' or its derivative)");
    cv::saliency::MotionSaliencyBinWangApr2014* _self_ = ((pyopencv_saliency_MotionSaliencyBinWangApr2014_t*)self)->v.get();
    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_saliencyMap = NULL;
    Mat saliencyMap;
    bool retval;

    const char* keywords[] = { "image", "saliencyMap", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:saliency_MotionSaliencyBinWangApr2014.computeSaliency", (char**)keywords, &pyobj_image, &pyobj_saliencyMap) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_saliencyMap, saliencyMap, ArgInfo("saliencyMap", 1)) )
    {
        ERRWRAP2(retval = _self_->computeSaliency(image, saliencyMap));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(saliencyMap));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_saliencyMap = NULL;
    UMat saliencyMap;
    bool retval;

    const char* keywords[] = { "image", "saliencyMap", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:saliency_MotionSaliencyBinWangApr2014.computeSaliency", (char**)keywords, &pyobj_image, &pyobj_saliencyMap) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_saliencyMap, saliencyMap, ArgInfo("saliencyMap", 1)) )
    {
        ERRWRAP2(retval = _self_->computeSaliency(image, saliencyMap));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(saliencyMap));
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_saliency_saliency_MotionSaliencyBinWangApr2014_getImageHeight(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::saliency;

    if(!PyObject_TypeCheck(self, &pyopencv_saliency_MotionSaliencyBinWangApr2014_Type))
        return failmsgp("Incorrect type of self (must be 'saliency_MotionSaliencyBinWangApr2014' or its derivative)");
    cv::saliency::MotionSaliencyBinWangApr2014* _self_ = ((pyopencv_saliency_MotionSaliencyBinWangApr2014_t*)self)->v.get();
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getImageHeight());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_saliency_saliency_MotionSaliencyBinWangApr2014_getImageWidth(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::saliency;

    if(!PyObject_TypeCheck(self, &pyopencv_saliency_MotionSaliencyBinWangApr2014_Type))
        return failmsgp("Incorrect type of self (must be 'saliency_MotionSaliencyBinWangApr2014' or its derivative)");
    cv::saliency::MotionSaliencyBinWangApr2014* _self_ = ((pyopencv_saliency_MotionSaliencyBinWangApr2014_t*)self)->v.get();
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getImageWidth());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_saliency_saliency_MotionSaliencyBinWangApr2014_init(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::saliency;

    if(!PyObject_TypeCheck(self, &pyopencv_saliency_MotionSaliencyBinWangApr2014_Type))
        return failmsgp("Incorrect type of self (must be 'saliency_MotionSaliencyBinWangApr2014' or its derivative)");
    cv::saliency::MotionSaliencyBinWangApr2014* _self_ = ((pyopencv_saliency_MotionSaliencyBinWangApr2014_t*)self)->v.get();
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->init());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_saliency_saliency_MotionSaliencyBinWangApr2014_setImageHeight(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::saliency;

    if(!PyObject_TypeCheck(self, &pyopencv_saliency_MotionSaliencyBinWangApr2014_Type))
        return failmsgp("Incorrect type of self (must be 'saliency_MotionSaliencyBinWangApr2014' or its derivative)");
    cv::saliency::MotionSaliencyBinWangApr2014* _self_ = ((pyopencv_saliency_MotionSaliencyBinWangApr2014_t*)self)->v.get();
    int val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:saliency_MotionSaliencyBinWangApr2014.setImageHeight", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setImageHeight(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_saliency_saliency_MotionSaliencyBinWangApr2014_setImageWidth(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::saliency;

    if(!PyObject_TypeCheck(self, &pyopencv_saliency_MotionSaliencyBinWangApr2014_Type))
        return failmsgp("Incorrect type of self (must be 'saliency_MotionSaliencyBinWangApr2014' or its derivative)");
    cv::saliency::MotionSaliencyBinWangApr2014* _self_ = ((pyopencv_saliency_MotionSaliencyBinWangApr2014_t*)self)->v.get();
    int val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:saliency_MotionSaliencyBinWangApr2014.setImageWidth", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setImageWidth(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_saliency_saliency_MotionSaliencyBinWangApr2014_setImagesize(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::saliency;

    if(!PyObject_TypeCheck(self, &pyopencv_saliency_MotionSaliencyBinWangApr2014_Type))
        return failmsgp("Incorrect type of self (must be 'saliency_MotionSaliencyBinWangApr2014' or its derivative)");
    cv::saliency::MotionSaliencyBinWangApr2014* _self_ = ((pyopencv_saliency_MotionSaliencyBinWangApr2014_t*)self)->v.get();
    int W=0;
    int H=0;

    const char* keywords[] = { "W", "H", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "ii:saliency_MotionSaliencyBinWangApr2014.setImagesize", (char**)keywords, &W, &H) )
    {
        ERRWRAP2(_self_->setImagesize(W, H));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_saliency_MotionSaliencyBinWangApr2014_methods[] =
{
    {"computeSaliency", (PyCFunction)pyopencv_cv_saliency_saliency_MotionSaliencyBinWangApr2014_computeSaliency, METH_VARARGS | METH_KEYWORDS, "computeSaliency(image[, saliencyMap]) -> retval, saliencyMap"},
    {"getImageHeight", (PyCFunction)pyopencv_cv_saliency_saliency_MotionSaliencyBinWangApr2014_getImageHeight, METH_VARARGS | METH_KEYWORDS, "getImageHeight() -> retval"},
    {"getImageWidth", (PyCFunction)pyopencv_cv_saliency_saliency_MotionSaliencyBinWangApr2014_getImageWidth, METH_VARARGS | METH_KEYWORDS, "getImageWidth() -> retval"},
    {"init", (PyCFunction)pyopencv_cv_saliency_saliency_MotionSaliencyBinWangApr2014_init, METH_VARARGS | METH_KEYWORDS, "init() -> retval"},
    {"setImageHeight", (PyCFunction)pyopencv_cv_saliency_saliency_MotionSaliencyBinWangApr2014_setImageHeight, METH_VARARGS | METH_KEYWORDS, "setImageHeight(val) -> None"},
    {"setImageWidth", (PyCFunction)pyopencv_cv_saliency_saliency_MotionSaliencyBinWangApr2014_setImageWidth, METH_VARARGS | METH_KEYWORDS, "setImageWidth(val) -> None"},
    {"setImagesize", (PyCFunction)pyopencv_cv_saliency_saliency_MotionSaliencyBinWangApr2014_setImagesize, METH_VARARGS | METH_KEYWORDS, "setImagesize(W, H) -> None"},

    {NULL,          NULL}
};

static void pyopencv_saliency_MotionSaliencyBinWangApr2014_specials(void)
{
    pyopencv_saliency_MotionSaliencyBinWangApr2014_Type.tp_base = &pyopencv_saliency_MotionSaliency_Type;
    pyopencv_saliency_MotionSaliencyBinWangApr2014_Type.tp_dealloc = pyopencv_saliency_MotionSaliencyBinWangApr2014_dealloc;
    pyopencv_saliency_MotionSaliencyBinWangApr2014_Type.tp_repr = pyopencv_saliency_MotionSaliencyBinWangApr2014_repr;
    pyopencv_saliency_MotionSaliencyBinWangApr2014_Type.tp_getset = pyopencv_saliency_MotionSaliencyBinWangApr2014_getseters;
    pyopencv_saliency_MotionSaliencyBinWangApr2014_Type.tp_methods = pyopencv_saliency_MotionSaliencyBinWangApr2014_methods;
}

static PyObject* pyopencv_saliency_ObjectnessBING_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<saliency_ObjectnessBING %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_saliency_ObjectnessBING_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_saliency_saliency_ObjectnessBING_computeSaliency(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::saliency;

    if(!PyObject_TypeCheck(self, &pyopencv_saliency_ObjectnessBING_Type))
        return failmsgp("Incorrect type of self (must be 'saliency_ObjectnessBING' or its derivative)");
    cv::saliency::ObjectnessBING* _self_ = dynamic_cast<cv::saliency::ObjectnessBING*>(((pyopencv_saliency_ObjectnessBING_t*)self)->v.get());
    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_saliencyMap = NULL;
    Mat saliencyMap;
    bool retval;

    const char* keywords[] = { "image", "saliencyMap", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:saliency_ObjectnessBING.computeSaliency", (char**)keywords, &pyobj_image, &pyobj_saliencyMap) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_saliencyMap, saliencyMap, ArgInfo("saliencyMap", 1)) )
    {
        ERRWRAP2(retval = _self_->computeSaliency(image, saliencyMap));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(saliencyMap));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_saliencyMap = NULL;
    UMat saliencyMap;
    bool retval;

    const char* keywords[] = { "image", "saliencyMap", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:saliency_ObjectnessBING.computeSaliency", (char**)keywords, &pyobj_image, &pyobj_saliencyMap) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_saliencyMap, saliencyMap, ArgInfo("saliencyMap", 1)) )
    {
        ERRWRAP2(retval = _self_->computeSaliency(image, saliencyMap));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(saliencyMap));
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_saliency_saliency_ObjectnessBING_getBase(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::saliency;

    if(!PyObject_TypeCheck(self, &pyopencv_saliency_ObjectnessBING_Type))
        return failmsgp("Incorrect type of self (must be 'saliency_ObjectnessBING' or its derivative)");
    cv::saliency::ObjectnessBING* _self_ = dynamic_cast<cv::saliency::ObjectnessBING*>(((pyopencv_saliency_ObjectnessBING_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getBase());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_saliency_saliency_ObjectnessBING_getNSS(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::saliency;

    if(!PyObject_TypeCheck(self, &pyopencv_saliency_ObjectnessBING_Type))
        return failmsgp("Incorrect type of self (must be 'saliency_ObjectnessBING' or its derivative)");
    cv::saliency::ObjectnessBING* _self_ = dynamic_cast<cv::saliency::ObjectnessBING*>(((pyopencv_saliency_ObjectnessBING_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getNSS());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_saliency_saliency_ObjectnessBING_getW(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::saliency;

    if(!PyObject_TypeCheck(self, &pyopencv_saliency_ObjectnessBING_Type))
        return failmsgp("Incorrect type of self (must be 'saliency_ObjectnessBING' or its derivative)");
    cv::saliency::ObjectnessBING* _self_ = dynamic_cast<cv::saliency::ObjectnessBING*>(((pyopencv_saliency_ObjectnessBING_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getW());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_saliency_saliency_ObjectnessBING_read(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::saliency;

    if(!PyObject_TypeCheck(self, &pyopencv_saliency_ObjectnessBING_Type))
        return failmsgp("Incorrect type of self (must be 'saliency_ObjectnessBING' or its derivative)");
    cv::saliency::ObjectnessBING* _self_ = dynamic_cast<cv::saliency::ObjectnessBING*>(((pyopencv_saliency_ObjectnessBING_t*)self)->v.get());

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(_self_->read());
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_saliency_saliency_ObjectnessBING_setBBResDir(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::saliency;

    if(!PyObject_TypeCheck(self, &pyopencv_saliency_ObjectnessBING_Type))
        return failmsgp("Incorrect type of self (must be 'saliency_ObjectnessBING' or its derivative)");
    cv::saliency::ObjectnessBING* _self_ = dynamic_cast<cv::saliency::ObjectnessBING*>(((pyopencv_saliency_ObjectnessBING_t*)self)->v.get());
    PyObject* pyobj_resultsDir = NULL;
    String resultsDir;

    const char* keywords[] = { "resultsDir", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:saliency_ObjectnessBING.setBBResDir", (char**)keywords, &pyobj_resultsDir) &&
        pyopencv_to(pyobj_resultsDir, resultsDir, ArgInfo("resultsDir", 0)) )
    {
        ERRWRAP2(_self_->setBBResDir(resultsDir));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_saliency_saliency_ObjectnessBING_setBase(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::saliency;

    if(!PyObject_TypeCheck(self, &pyopencv_saliency_ObjectnessBING_Type))
        return failmsgp("Incorrect type of self (must be 'saliency_ObjectnessBING' or its derivative)");
    cv::saliency::ObjectnessBING* _self_ = dynamic_cast<cv::saliency::ObjectnessBING*>(((pyopencv_saliency_ObjectnessBING_t*)self)->v.get());
    double val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:saliency_ObjectnessBING.setBase", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setBase(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_saliency_saliency_ObjectnessBING_setNSS(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::saliency;

    if(!PyObject_TypeCheck(self, &pyopencv_saliency_ObjectnessBING_Type))
        return failmsgp("Incorrect type of self (must be 'saliency_ObjectnessBING' or its derivative)");
    cv::saliency::ObjectnessBING* _self_ = dynamic_cast<cv::saliency::ObjectnessBING*>(((pyopencv_saliency_ObjectnessBING_t*)self)->v.get());
    int val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:saliency_ObjectnessBING.setNSS", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setNSS(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_saliency_saliency_ObjectnessBING_setTrainingPath(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::saliency;

    if(!PyObject_TypeCheck(self, &pyopencv_saliency_ObjectnessBING_Type))
        return failmsgp("Incorrect type of self (must be 'saliency_ObjectnessBING' or its derivative)");
    cv::saliency::ObjectnessBING* _self_ = dynamic_cast<cv::saliency::ObjectnessBING*>(((pyopencv_saliency_ObjectnessBING_t*)self)->v.get());
    PyObject* pyobj_trainingPath = NULL;
    String trainingPath;

    const char* keywords[] = { "trainingPath", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:saliency_ObjectnessBING.setTrainingPath", (char**)keywords, &pyobj_trainingPath) &&
        pyopencv_to(pyobj_trainingPath, trainingPath, ArgInfo("trainingPath", 0)) )
    {
        ERRWRAP2(_self_->setTrainingPath(trainingPath));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_saliency_saliency_ObjectnessBING_setW(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::saliency;

    if(!PyObject_TypeCheck(self, &pyopencv_saliency_ObjectnessBING_Type))
        return failmsgp("Incorrect type of self (must be 'saliency_ObjectnessBING' or its derivative)");
    cv::saliency::ObjectnessBING* _self_ = dynamic_cast<cv::saliency::ObjectnessBING*>(((pyopencv_saliency_ObjectnessBING_t*)self)->v.get());
    int val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:saliency_ObjectnessBING.setW", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setW(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_saliency_saliency_ObjectnessBING_write(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::saliency;

    if(!PyObject_TypeCheck(self, &pyopencv_saliency_ObjectnessBING_Type))
        return failmsgp("Incorrect type of self (must be 'saliency_ObjectnessBING' or its derivative)");
    cv::saliency::ObjectnessBING* _self_ = dynamic_cast<cv::saliency::ObjectnessBING*>(((pyopencv_saliency_ObjectnessBING_t*)self)->v.get());

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(_self_->write());
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_saliency_ObjectnessBING_methods[] =
{
    {"computeSaliency", (PyCFunction)pyopencv_cv_saliency_saliency_ObjectnessBING_computeSaliency, METH_VARARGS | METH_KEYWORDS, "computeSaliency(image[, saliencyMap]) -> retval, saliencyMap"},
    {"getBase", (PyCFunction)pyopencv_cv_saliency_saliency_ObjectnessBING_getBase, METH_VARARGS | METH_KEYWORDS, "getBase() -> retval"},
    {"getNSS", (PyCFunction)pyopencv_cv_saliency_saliency_ObjectnessBING_getNSS, METH_VARARGS | METH_KEYWORDS, "getNSS() -> retval"},
    {"getW", (PyCFunction)pyopencv_cv_saliency_saliency_ObjectnessBING_getW, METH_VARARGS | METH_KEYWORDS, "getW() -> retval"},
    {"read", (PyCFunction)pyopencv_cv_saliency_saliency_ObjectnessBING_read, METH_VARARGS | METH_KEYWORDS, "read() -> None"},
    {"setBBResDir", (PyCFunction)pyopencv_cv_saliency_saliency_ObjectnessBING_setBBResDir, METH_VARARGS | METH_KEYWORDS, "setBBResDir(resultsDir) -> None"},
    {"setBase", (PyCFunction)pyopencv_cv_saliency_saliency_ObjectnessBING_setBase, METH_VARARGS | METH_KEYWORDS, "setBase(val) -> None"},
    {"setNSS", (PyCFunction)pyopencv_cv_saliency_saliency_ObjectnessBING_setNSS, METH_VARARGS | METH_KEYWORDS, "setNSS(val) -> None"},
    {"setTrainingPath", (PyCFunction)pyopencv_cv_saliency_saliency_ObjectnessBING_setTrainingPath, METH_VARARGS | METH_KEYWORDS, "setTrainingPath(trainingPath) -> None"},
    {"setW", (PyCFunction)pyopencv_cv_saliency_saliency_ObjectnessBING_setW, METH_VARARGS | METH_KEYWORDS, "setW(val) -> None"},
    {"write", (PyCFunction)pyopencv_cv_saliency_saliency_ObjectnessBING_write, METH_VARARGS | METH_KEYWORDS, "write() -> None"},

    {NULL,          NULL}
};

static void pyopencv_saliency_ObjectnessBING_specials(void)
{
    pyopencv_saliency_ObjectnessBING_Type.tp_base = &pyopencv_saliency_Objectness_Type;
    pyopencv_saliency_ObjectnessBING_Type.tp_dealloc = pyopencv_saliency_ObjectnessBING_dealloc;
    pyopencv_saliency_ObjectnessBING_Type.tp_repr = pyopencv_saliency_ObjectnessBING_repr;
    pyopencv_saliency_ObjectnessBING_Type.tp_getset = pyopencv_saliency_ObjectnessBING_getseters;
    pyopencv_saliency_ObjectnessBING_Type.tp_methods = pyopencv_saliency_ObjectnessBING_methods;
}

static PyObject* pyopencv_text_ERFilter_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<text_ERFilter %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_text_ERFilter_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_text_ERFilter_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_text_ERFilter_specials(void)
{
    pyopencv_text_ERFilter_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_text_ERFilter_Type.tp_dealloc = pyopencv_text_ERFilter_dealloc;
    pyopencv_text_ERFilter_Type.tp_repr = pyopencv_text_ERFilter_repr;
    pyopencv_text_ERFilter_Type.tp_getset = pyopencv_text_ERFilter_getseters;
    pyopencv_text_ERFilter_Type.tp_methods = pyopencv_text_ERFilter_methods;
}

static PyObject* pyopencv_text_ERFilter_Callback_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<text_ERFilter_Callback %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_text_ERFilter_Callback_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_text_ERFilter_Callback_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_text_ERFilter_Callback_specials(void)
{
    pyopencv_text_ERFilter_Callback_Type.tp_base = NULL;
    pyopencv_text_ERFilter_Callback_Type.tp_dealloc = pyopencv_text_ERFilter_Callback_dealloc;
    pyopencv_text_ERFilter_Callback_Type.tp_repr = pyopencv_text_ERFilter_Callback_repr;
    pyopencv_text_ERFilter_Callback_Type.tp_getset = pyopencv_text_ERFilter_Callback_getseters;
    pyopencv_text_ERFilter_Callback_Type.tp_methods = pyopencv_text_ERFilter_Callback_methods;
}

static PyObject* pyopencv_text_BaseOCR_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<text_BaseOCR %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_text_BaseOCR_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_text_BaseOCR_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_text_BaseOCR_specials(void)
{
    pyopencv_text_BaseOCR_Type.tp_base = NULL;
    pyopencv_text_BaseOCR_Type.tp_dealloc = pyopencv_text_BaseOCR_dealloc;
    pyopencv_text_BaseOCR_Type.tp_repr = pyopencv_text_BaseOCR_repr;
    pyopencv_text_BaseOCR_Type.tp_getset = pyopencv_text_BaseOCR_getseters;
    pyopencv_text_BaseOCR_Type.tp_methods = pyopencv_text_BaseOCR_methods;
}

static PyObject* pyopencv_text_OCRTesseract_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<text_OCRTesseract %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_text_OCRTesseract_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_text_text_OCRTesseract_run(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::text;

    if(!PyObject_TypeCheck(self, &pyopencv_text_OCRTesseract_Type))
        return failmsgp("Incorrect type of self (must be 'text_OCRTesseract' or its derivative)");
    cv::text::OCRTesseract* _self_ = ((pyopencv_text_OCRTesseract_t*)self)->v.get();
    {
    PyObject* pyobj_image = NULL;
    Mat image;
    int min_confidence=0;
    int component_level=0;
    String retval;

    const char* keywords[] = { "image", "min_confidence", "component_level", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "Oi|i:text_OCRTesseract.run", (char**)keywords, &pyobj_image, &min_confidence, &component_level) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) )
    {
        ERRWRAP2(retval = _self_->run(image, min_confidence, component_level));
        return pyopencv_from(retval);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    int min_confidence=0;
    int component_level=0;
    String retval;

    const char* keywords[] = { "image", "min_confidence", "component_level", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "Oi|i:text_OCRTesseract.run", (char**)keywords, &pyobj_image, &min_confidence, &component_level) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) )
    {
        ERRWRAP2(retval = _self_->run(image, min_confidence, component_level));
        return pyopencv_from(retval);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    int min_confidence=0;
    int component_level=0;
    String retval;

    const char* keywords[] = { "image", "mask", "min_confidence", "component_level", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OOi|i:text_OCRTesseract.run", (char**)keywords, &pyobj_image, &pyobj_mask, &min_confidence, &component_level) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(retval = _self_->run(image, mask, min_confidence, component_level));
        return pyopencv_from(retval);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_mask = NULL;
    UMat mask;
    int min_confidence=0;
    int component_level=0;
    String retval;

    const char* keywords[] = { "image", "mask", "min_confidence", "component_level", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OOi|i:text_OCRTesseract.run", (char**)keywords, &pyobj_image, &pyobj_mask, &min_confidence, &component_level) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(retval = _self_->run(image, mask, min_confidence, component_level));
        return pyopencv_from(retval);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_text_text_OCRTesseract_setWhiteList(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::text;

    if(!PyObject_TypeCheck(self, &pyopencv_text_OCRTesseract_Type))
        return failmsgp("Incorrect type of self (must be 'text_OCRTesseract' or its derivative)");
    cv::text::OCRTesseract* _self_ = ((pyopencv_text_OCRTesseract_t*)self)->v.get();
    PyObject* pyobj_char_whitelist = NULL;
    String char_whitelist;

    const char* keywords[] = { "char_whitelist", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:text_OCRTesseract.setWhiteList", (char**)keywords, &pyobj_char_whitelist) &&
        pyopencv_to(pyobj_char_whitelist, char_whitelist, ArgInfo("char_whitelist", 0)) )
    {
        ERRWRAP2(_self_->setWhiteList(char_whitelist));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_text_OCRTesseract_methods[] =
{
    {"run", (PyCFunction)pyopencv_cv_text_text_OCRTesseract_run, METH_VARARGS | METH_KEYWORDS, "run(image, min_confidence[, component_level]) -> retval  or  run(image, mask, min_confidence[, component_level]) -> retval"},
    {"setWhiteList", (PyCFunction)pyopencv_cv_text_text_OCRTesseract_setWhiteList, METH_VARARGS | METH_KEYWORDS, "setWhiteList(char_whitelist) -> None"},

    {NULL,          NULL}
};

static void pyopencv_text_OCRTesseract_specials(void)
{
    pyopencv_text_OCRTesseract_Type.tp_base = &pyopencv_text_BaseOCR_Type;
    pyopencv_text_OCRTesseract_Type.tp_dealloc = pyopencv_text_OCRTesseract_dealloc;
    pyopencv_text_OCRTesseract_Type.tp_repr = pyopencv_text_OCRTesseract_repr;
    pyopencv_text_OCRTesseract_Type.tp_getset = pyopencv_text_OCRTesseract_getseters;
    pyopencv_text_OCRTesseract_Type.tp_methods = pyopencv_text_OCRTesseract_methods;
}

static PyObject* pyopencv_text_OCRHMMDecoder_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<text_OCRHMMDecoder %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_text_OCRHMMDecoder_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_text_text_OCRHMMDecoder_run(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::text;

    if(!PyObject_TypeCheck(self, &pyopencv_text_OCRHMMDecoder_Type))
        return failmsgp("Incorrect type of self (must be 'text_OCRHMMDecoder' or its derivative)");
    cv::text::OCRHMMDecoder* _self_ = ((pyopencv_text_OCRHMMDecoder_t*)self)->v.get();
    {
    PyObject* pyobj_image = NULL;
    Mat image;
    int min_confidence=0;
    int component_level=0;
    String retval;

    const char* keywords[] = { "image", "min_confidence", "component_level", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "Oi|i:text_OCRHMMDecoder.run", (char**)keywords, &pyobj_image, &min_confidence, &component_level) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) )
    {
        ERRWRAP2(retval = _self_->run(image, min_confidence, component_level));
        return pyopencv_from(retval);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    int min_confidence=0;
    int component_level=0;
    String retval;

    const char* keywords[] = { "image", "min_confidence", "component_level", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "Oi|i:text_OCRHMMDecoder.run", (char**)keywords, &pyobj_image, &min_confidence, &component_level) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) )
    {
        ERRWRAP2(retval = _self_->run(image, min_confidence, component_level));
        return pyopencv_from(retval);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    int min_confidence=0;
    int component_level=0;
    String retval;

    const char* keywords[] = { "image", "mask", "min_confidence", "component_level", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OOi|i:text_OCRHMMDecoder.run", (char**)keywords, &pyobj_image, &pyobj_mask, &min_confidence, &component_level) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(retval = _self_->run(image, mask, min_confidence, component_level));
        return pyopencv_from(retval);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_mask = NULL;
    UMat mask;
    int min_confidence=0;
    int component_level=0;
    String retval;

    const char* keywords[] = { "image", "mask", "min_confidence", "component_level", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OOi|i:text_OCRHMMDecoder.run", (char**)keywords, &pyobj_image, &pyobj_mask, &min_confidence, &component_level) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(retval = _self_->run(image, mask, min_confidence, component_level));
        return pyopencv_from(retval);
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_text_OCRHMMDecoder_methods[] =
{
    {"run", (PyCFunction)pyopencv_cv_text_text_OCRHMMDecoder_run, METH_VARARGS | METH_KEYWORDS, "run(image, min_confidence[, component_level]) -> retval  or  run(image, mask, min_confidence[, component_level]) -> retval"},

    {NULL,          NULL}
};

static void pyopencv_text_OCRHMMDecoder_specials(void)
{
    pyopencv_text_OCRHMMDecoder_Type.tp_base = &pyopencv_text_BaseOCR_Type;
    pyopencv_text_OCRHMMDecoder_Type.tp_dealloc = pyopencv_text_OCRHMMDecoder_dealloc;
    pyopencv_text_OCRHMMDecoder_Type.tp_repr = pyopencv_text_OCRHMMDecoder_repr;
    pyopencv_text_OCRHMMDecoder_Type.tp_getset = pyopencv_text_OCRHMMDecoder_getseters;
    pyopencv_text_OCRHMMDecoder_Type.tp_methods = pyopencv_text_OCRHMMDecoder_methods;
}

static PyObject* pyopencv_text_OCRHMMDecoder_ClassifierCallback_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<text_OCRHMMDecoder_ClassifierCallback %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_text_OCRHMMDecoder_ClassifierCallback_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_text_OCRHMMDecoder_ClassifierCallback_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_text_OCRHMMDecoder_ClassifierCallback_specials(void)
{
    pyopencv_text_OCRHMMDecoder_ClassifierCallback_Type.tp_base = NULL;
    pyopencv_text_OCRHMMDecoder_ClassifierCallback_Type.tp_dealloc = pyopencv_text_OCRHMMDecoder_ClassifierCallback_dealloc;
    pyopencv_text_OCRHMMDecoder_ClassifierCallback_Type.tp_repr = pyopencv_text_OCRHMMDecoder_ClassifierCallback_repr;
    pyopencv_text_OCRHMMDecoder_ClassifierCallback_Type.tp_getset = pyopencv_text_OCRHMMDecoder_ClassifierCallback_getseters;
    pyopencv_text_OCRHMMDecoder_ClassifierCallback_Type.tp_methods = pyopencv_text_OCRHMMDecoder_ClassifierCallback_methods;
}

static PyObject* pyopencv_text_OCRBeamSearchDecoder_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<text_OCRBeamSearchDecoder %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_text_OCRBeamSearchDecoder_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_text_text_OCRBeamSearchDecoder_run(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::text;

    if(!PyObject_TypeCheck(self, &pyopencv_text_OCRBeamSearchDecoder_Type))
        return failmsgp("Incorrect type of self (must be 'text_OCRBeamSearchDecoder' or its derivative)");
    cv::text::OCRBeamSearchDecoder* _self_ = ((pyopencv_text_OCRBeamSearchDecoder_t*)self)->v.get();
    {
    PyObject* pyobj_image = NULL;
    Mat image;
    int min_confidence=0;
    int component_level=0;
    String retval;

    const char* keywords[] = { "image", "min_confidence", "component_level", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "Oi|i:text_OCRBeamSearchDecoder.run", (char**)keywords, &pyobj_image, &min_confidence, &component_level) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) )
    {
        ERRWRAP2(retval = _self_->run(image, min_confidence, component_level));
        return pyopencv_from(retval);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    int min_confidence=0;
    int component_level=0;
    String retval;

    const char* keywords[] = { "image", "min_confidence", "component_level", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "Oi|i:text_OCRBeamSearchDecoder.run", (char**)keywords, &pyobj_image, &min_confidence, &component_level) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) )
    {
        ERRWRAP2(retval = _self_->run(image, min_confidence, component_level));
        return pyopencv_from(retval);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    int min_confidence=0;
    int component_level=0;
    String retval;

    const char* keywords[] = { "image", "mask", "min_confidence", "component_level", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OOi|i:text_OCRBeamSearchDecoder.run", (char**)keywords, &pyobj_image, &pyobj_mask, &min_confidence, &component_level) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(retval = _self_->run(image, mask, min_confidence, component_level));
        return pyopencv_from(retval);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_mask = NULL;
    UMat mask;
    int min_confidence=0;
    int component_level=0;
    String retval;

    const char* keywords[] = { "image", "mask", "min_confidence", "component_level", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OOi|i:text_OCRBeamSearchDecoder.run", (char**)keywords, &pyobj_image, &pyobj_mask, &min_confidence, &component_level) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(retval = _self_->run(image, mask, min_confidence, component_level));
        return pyopencv_from(retval);
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_text_OCRBeamSearchDecoder_methods[] =
{
    {"run", (PyCFunction)pyopencv_cv_text_text_OCRBeamSearchDecoder_run, METH_VARARGS | METH_KEYWORDS, "run(image, min_confidence[, component_level]) -> retval  or  run(image, mask, min_confidence[, component_level]) -> retval"},

    {NULL,          NULL}
};

static void pyopencv_text_OCRBeamSearchDecoder_specials(void)
{
    pyopencv_text_OCRBeamSearchDecoder_Type.tp_base = &pyopencv_text_BaseOCR_Type;
    pyopencv_text_OCRBeamSearchDecoder_Type.tp_dealloc = pyopencv_text_OCRBeamSearchDecoder_dealloc;
    pyopencv_text_OCRBeamSearchDecoder_Type.tp_repr = pyopencv_text_OCRBeamSearchDecoder_repr;
    pyopencv_text_OCRBeamSearchDecoder_Type.tp_getset = pyopencv_text_OCRBeamSearchDecoder_getseters;
    pyopencv_text_OCRBeamSearchDecoder_Type.tp_methods = pyopencv_text_OCRBeamSearchDecoder_methods;
}

static PyObject* pyopencv_text_OCRBeamSearchDecoder_ClassifierCallback_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<text_OCRBeamSearchDecoder_ClassifierCallback %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_text_OCRBeamSearchDecoder_ClassifierCallback_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_text_OCRBeamSearchDecoder_ClassifierCallback_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_text_OCRBeamSearchDecoder_ClassifierCallback_specials(void)
{
    pyopencv_text_OCRBeamSearchDecoder_ClassifierCallback_Type.tp_base = NULL;
    pyopencv_text_OCRBeamSearchDecoder_ClassifierCallback_Type.tp_dealloc = pyopencv_text_OCRBeamSearchDecoder_ClassifierCallback_dealloc;
    pyopencv_text_OCRBeamSearchDecoder_ClassifierCallback_Type.tp_repr = pyopencv_text_OCRBeamSearchDecoder_ClassifierCallback_repr;
    pyopencv_text_OCRBeamSearchDecoder_ClassifierCallback_Type.tp_getset = pyopencv_text_OCRBeamSearchDecoder_ClassifierCallback_getseters;
    pyopencv_text_OCRBeamSearchDecoder_ClassifierCallback_Type.tp_methods = pyopencv_text_OCRBeamSearchDecoder_ClassifierCallback_methods;
}

static PyObject* pyopencv_StereoMatcher_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<StereoMatcher %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_StereoMatcher_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_StereoMatcher_compute(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_StereoMatcher_Type))
        return failmsgp("Incorrect type of self (must be 'StereoMatcher' or its derivative)");
    cv::StereoMatcher* _self_ = dynamic_cast<cv::StereoMatcher*>(((pyopencv_StereoMatcher_t*)self)->v.get());
    {
    PyObject* pyobj_left = NULL;
    Mat left;
    PyObject* pyobj_right = NULL;
    Mat right;
    PyObject* pyobj_disparity = NULL;
    Mat disparity;

    const char* keywords[] = { "left", "right", "disparity", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|O:StereoMatcher.compute", (char**)keywords, &pyobj_left, &pyobj_right, &pyobj_disparity) &&
        pyopencv_to(pyobj_left, left, ArgInfo("left", 0)) &&
        pyopencv_to(pyobj_right, right, ArgInfo("right", 0)) &&
        pyopencv_to(pyobj_disparity, disparity, ArgInfo("disparity", 1)) )
    {
        ERRWRAP2(_self_->compute(left, right, disparity));
        return pyopencv_from(disparity);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_left = NULL;
    UMat left;
    PyObject* pyobj_right = NULL;
    UMat right;
    PyObject* pyobj_disparity = NULL;
    UMat disparity;

    const char* keywords[] = { "left", "right", "disparity", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|O:StereoMatcher.compute", (char**)keywords, &pyobj_left, &pyobj_right, &pyobj_disparity) &&
        pyopencv_to(pyobj_left, left, ArgInfo("left", 0)) &&
        pyopencv_to(pyobj_right, right, ArgInfo("right", 0)) &&
        pyopencv_to(pyobj_disparity, disparity, ArgInfo("disparity", 1)) )
    {
        ERRWRAP2(_self_->compute(left, right, disparity));
        return pyopencv_from(disparity);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_StereoMatcher_getBlockSize(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_StereoMatcher_Type))
        return failmsgp("Incorrect type of self (must be 'StereoMatcher' or its derivative)");
    cv::StereoMatcher* _self_ = dynamic_cast<cv::StereoMatcher*>(((pyopencv_StereoMatcher_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getBlockSize());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_StereoMatcher_getDisp12MaxDiff(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_StereoMatcher_Type))
        return failmsgp("Incorrect type of self (must be 'StereoMatcher' or its derivative)");
    cv::StereoMatcher* _self_ = dynamic_cast<cv::StereoMatcher*>(((pyopencv_StereoMatcher_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getDisp12MaxDiff());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_StereoMatcher_getMinDisparity(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_StereoMatcher_Type))
        return failmsgp("Incorrect type of self (must be 'StereoMatcher' or its derivative)");
    cv::StereoMatcher* _self_ = dynamic_cast<cv::StereoMatcher*>(((pyopencv_StereoMatcher_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getMinDisparity());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_StereoMatcher_getNumDisparities(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_StereoMatcher_Type))
        return failmsgp("Incorrect type of self (must be 'StereoMatcher' or its derivative)");
    cv::StereoMatcher* _self_ = dynamic_cast<cv::StereoMatcher*>(((pyopencv_StereoMatcher_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getNumDisparities());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_StereoMatcher_getSpeckleRange(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_StereoMatcher_Type))
        return failmsgp("Incorrect type of self (must be 'StereoMatcher' or its derivative)");
    cv::StereoMatcher* _self_ = dynamic_cast<cv::StereoMatcher*>(((pyopencv_StereoMatcher_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getSpeckleRange());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_StereoMatcher_getSpeckleWindowSize(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_StereoMatcher_Type))
        return failmsgp("Incorrect type of self (must be 'StereoMatcher' or its derivative)");
    cv::StereoMatcher* _self_ = dynamic_cast<cv::StereoMatcher*>(((pyopencv_StereoMatcher_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getSpeckleWindowSize());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_StereoMatcher_setBlockSize(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_StereoMatcher_Type))
        return failmsgp("Incorrect type of self (must be 'StereoMatcher' or its derivative)");
    cv::StereoMatcher* _self_ = dynamic_cast<cv::StereoMatcher*>(((pyopencv_StereoMatcher_t*)self)->v.get());
    int blockSize=0;

    const char* keywords[] = { "blockSize", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:StereoMatcher.setBlockSize", (char**)keywords, &blockSize) )
    {
        ERRWRAP2(_self_->setBlockSize(blockSize));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_StereoMatcher_setDisp12MaxDiff(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_StereoMatcher_Type))
        return failmsgp("Incorrect type of self (must be 'StereoMatcher' or its derivative)");
    cv::StereoMatcher* _self_ = dynamic_cast<cv::StereoMatcher*>(((pyopencv_StereoMatcher_t*)self)->v.get());
    int disp12MaxDiff=0;

    const char* keywords[] = { "disp12MaxDiff", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:StereoMatcher.setDisp12MaxDiff", (char**)keywords, &disp12MaxDiff) )
    {
        ERRWRAP2(_self_->setDisp12MaxDiff(disp12MaxDiff));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_StereoMatcher_setMinDisparity(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_StereoMatcher_Type))
        return failmsgp("Incorrect type of self (must be 'StereoMatcher' or its derivative)");
    cv::StereoMatcher* _self_ = dynamic_cast<cv::StereoMatcher*>(((pyopencv_StereoMatcher_t*)self)->v.get());
    int minDisparity=0;

    const char* keywords[] = { "minDisparity", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:StereoMatcher.setMinDisparity", (char**)keywords, &minDisparity) )
    {
        ERRWRAP2(_self_->setMinDisparity(minDisparity));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_StereoMatcher_setNumDisparities(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_StereoMatcher_Type))
        return failmsgp("Incorrect type of self (must be 'StereoMatcher' or its derivative)");
    cv::StereoMatcher* _self_ = dynamic_cast<cv::StereoMatcher*>(((pyopencv_StereoMatcher_t*)self)->v.get());
    int numDisparities=0;

    const char* keywords[] = { "numDisparities", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:StereoMatcher.setNumDisparities", (char**)keywords, &numDisparities) )
    {
        ERRWRAP2(_self_->setNumDisparities(numDisparities));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_StereoMatcher_setSpeckleRange(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_StereoMatcher_Type))
        return failmsgp("Incorrect type of self (must be 'StereoMatcher' or its derivative)");
    cv::StereoMatcher* _self_ = dynamic_cast<cv::StereoMatcher*>(((pyopencv_StereoMatcher_t*)self)->v.get());
    int speckleRange=0;

    const char* keywords[] = { "speckleRange", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:StereoMatcher.setSpeckleRange", (char**)keywords, &speckleRange) )
    {
        ERRWRAP2(_self_->setSpeckleRange(speckleRange));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_StereoMatcher_setSpeckleWindowSize(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_StereoMatcher_Type))
        return failmsgp("Incorrect type of self (must be 'StereoMatcher' or its derivative)");
    cv::StereoMatcher* _self_ = dynamic_cast<cv::StereoMatcher*>(((pyopencv_StereoMatcher_t*)self)->v.get());
    int speckleWindowSize=0;

    const char* keywords[] = { "speckleWindowSize", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:StereoMatcher.setSpeckleWindowSize", (char**)keywords, &speckleWindowSize) )
    {
        ERRWRAP2(_self_->setSpeckleWindowSize(speckleWindowSize));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_StereoMatcher_methods[] =
{
    {"compute", (PyCFunction)pyopencv_cv_StereoMatcher_compute, METH_VARARGS | METH_KEYWORDS, "compute(left, right[, disparity]) -> disparity"},
    {"getBlockSize", (PyCFunction)pyopencv_cv_StereoMatcher_getBlockSize, METH_VARARGS | METH_KEYWORDS, "getBlockSize() -> retval"},
    {"getDisp12MaxDiff", (PyCFunction)pyopencv_cv_StereoMatcher_getDisp12MaxDiff, METH_VARARGS | METH_KEYWORDS, "getDisp12MaxDiff() -> retval"},
    {"getMinDisparity", (PyCFunction)pyopencv_cv_StereoMatcher_getMinDisparity, METH_VARARGS | METH_KEYWORDS, "getMinDisparity() -> retval"},
    {"getNumDisparities", (PyCFunction)pyopencv_cv_StereoMatcher_getNumDisparities, METH_VARARGS | METH_KEYWORDS, "getNumDisparities() -> retval"},
    {"getSpeckleRange", (PyCFunction)pyopencv_cv_StereoMatcher_getSpeckleRange, METH_VARARGS | METH_KEYWORDS, "getSpeckleRange() -> retval"},
    {"getSpeckleWindowSize", (PyCFunction)pyopencv_cv_StereoMatcher_getSpeckleWindowSize, METH_VARARGS | METH_KEYWORDS, "getSpeckleWindowSize() -> retval"},
    {"setBlockSize", (PyCFunction)pyopencv_cv_StereoMatcher_setBlockSize, METH_VARARGS | METH_KEYWORDS, "setBlockSize(blockSize) -> None"},
    {"setDisp12MaxDiff", (PyCFunction)pyopencv_cv_StereoMatcher_setDisp12MaxDiff, METH_VARARGS | METH_KEYWORDS, "setDisp12MaxDiff(disp12MaxDiff) -> None"},
    {"setMinDisparity", (PyCFunction)pyopencv_cv_StereoMatcher_setMinDisparity, METH_VARARGS | METH_KEYWORDS, "setMinDisparity(minDisparity) -> None"},
    {"setNumDisparities", (PyCFunction)pyopencv_cv_StereoMatcher_setNumDisparities, METH_VARARGS | METH_KEYWORDS, "setNumDisparities(numDisparities) -> None"},
    {"setSpeckleRange", (PyCFunction)pyopencv_cv_StereoMatcher_setSpeckleRange, METH_VARARGS | METH_KEYWORDS, "setSpeckleRange(speckleRange) -> None"},
    {"setSpeckleWindowSize", (PyCFunction)pyopencv_cv_StereoMatcher_setSpeckleWindowSize, METH_VARARGS | METH_KEYWORDS, "setSpeckleWindowSize(speckleWindowSize) -> None"},

    {NULL,          NULL}
};

static void pyopencv_StereoMatcher_specials(void)
{
    pyopencv_StereoMatcher_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_StereoMatcher_Type.tp_dealloc = pyopencv_StereoMatcher_dealloc;
    pyopencv_StereoMatcher_Type.tp_repr = pyopencv_StereoMatcher_repr;
    pyopencv_StereoMatcher_Type.tp_getset = pyopencv_StereoMatcher_getseters;
    pyopencv_StereoMatcher_Type.tp_methods = pyopencv_StereoMatcher_methods;
}

static PyObject* pyopencv_StereoBM_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<StereoBM %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_StereoBM_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_StereoBM_getPreFilterCap(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_StereoBM_Type))
        return failmsgp("Incorrect type of self (must be 'StereoBM' or its derivative)");
    cv::StereoBM* _self_ = dynamic_cast<cv::StereoBM*>(((pyopencv_StereoBM_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getPreFilterCap());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_StereoBM_getPreFilterSize(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_StereoBM_Type))
        return failmsgp("Incorrect type of self (must be 'StereoBM' or its derivative)");
    cv::StereoBM* _self_ = dynamic_cast<cv::StereoBM*>(((pyopencv_StereoBM_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getPreFilterSize());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_StereoBM_getPreFilterType(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_StereoBM_Type))
        return failmsgp("Incorrect type of self (must be 'StereoBM' or its derivative)");
    cv::StereoBM* _self_ = dynamic_cast<cv::StereoBM*>(((pyopencv_StereoBM_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getPreFilterType());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_StereoBM_getROI1(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_StereoBM_Type))
        return failmsgp("Incorrect type of self (must be 'StereoBM' or its derivative)");
    cv::StereoBM* _self_ = dynamic_cast<cv::StereoBM*>(((pyopencv_StereoBM_t*)self)->v.get());
    Rect retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getROI1());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_StereoBM_getROI2(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_StereoBM_Type))
        return failmsgp("Incorrect type of self (must be 'StereoBM' or its derivative)");
    cv::StereoBM* _self_ = dynamic_cast<cv::StereoBM*>(((pyopencv_StereoBM_t*)self)->v.get());
    Rect retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getROI2());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_StereoBM_getSmallerBlockSize(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_StereoBM_Type))
        return failmsgp("Incorrect type of self (must be 'StereoBM' or its derivative)");
    cv::StereoBM* _self_ = dynamic_cast<cv::StereoBM*>(((pyopencv_StereoBM_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getSmallerBlockSize());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_StereoBM_getTextureThreshold(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_StereoBM_Type))
        return failmsgp("Incorrect type of self (must be 'StereoBM' or its derivative)");
    cv::StereoBM* _self_ = dynamic_cast<cv::StereoBM*>(((pyopencv_StereoBM_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getTextureThreshold());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_StereoBM_getUniquenessRatio(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_StereoBM_Type))
        return failmsgp("Incorrect type of self (must be 'StereoBM' or its derivative)");
    cv::StereoBM* _self_ = dynamic_cast<cv::StereoBM*>(((pyopencv_StereoBM_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getUniquenessRatio());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_StereoBM_setPreFilterCap(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_StereoBM_Type))
        return failmsgp("Incorrect type of self (must be 'StereoBM' or its derivative)");
    cv::StereoBM* _self_ = dynamic_cast<cv::StereoBM*>(((pyopencv_StereoBM_t*)self)->v.get());
    int preFilterCap=0;

    const char* keywords[] = { "preFilterCap", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:StereoBM.setPreFilterCap", (char**)keywords, &preFilterCap) )
    {
        ERRWRAP2(_self_->setPreFilterCap(preFilterCap));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_StereoBM_setPreFilterSize(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_StereoBM_Type))
        return failmsgp("Incorrect type of self (must be 'StereoBM' or its derivative)");
    cv::StereoBM* _self_ = dynamic_cast<cv::StereoBM*>(((pyopencv_StereoBM_t*)self)->v.get());
    int preFilterSize=0;

    const char* keywords[] = { "preFilterSize", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:StereoBM.setPreFilterSize", (char**)keywords, &preFilterSize) )
    {
        ERRWRAP2(_self_->setPreFilterSize(preFilterSize));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_StereoBM_setPreFilterType(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_StereoBM_Type))
        return failmsgp("Incorrect type of self (must be 'StereoBM' or its derivative)");
    cv::StereoBM* _self_ = dynamic_cast<cv::StereoBM*>(((pyopencv_StereoBM_t*)self)->v.get());
    int preFilterType=0;

    const char* keywords[] = { "preFilterType", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:StereoBM.setPreFilterType", (char**)keywords, &preFilterType) )
    {
        ERRWRAP2(_self_->setPreFilterType(preFilterType));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_StereoBM_setROI1(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_StereoBM_Type))
        return failmsgp("Incorrect type of self (must be 'StereoBM' or its derivative)");
    cv::StereoBM* _self_ = dynamic_cast<cv::StereoBM*>(((pyopencv_StereoBM_t*)self)->v.get());
    PyObject* pyobj_roi1 = NULL;
    Rect roi1;

    const char* keywords[] = { "roi1", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:StereoBM.setROI1", (char**)keywords, &pyobj_roi1) &&
        pyopencv_to(pyobj_roi1, roi1, ArgInfo("roi1", 0)) )
    {
        ERRWRAP2(_self_->setROI1(roi1));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_StereoBM_setROI2(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_StereoBM_Type))
        return failmsgp("Incorrect type of self (must be 'StereoBM' or its derivative)");
    cv::StereoBM* _self_ = dynamic_cast<cv::StereoBM*>(((pyopencv_StereoBM_t*)self)->v.get());
    PyObject* pyobj_roi2 = NULL;
    Rect roi2;

    const char* keywords[] = { "roi2", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:StereoBM.setROI2", (char**)keywords, &pyobj_roi2) &&
        pyopencv_to(pyobj_roi2, roi2, ArgInfo("roi2", 0)) )
    {
        ERRWRAP2(_self_->setROI2(roi2));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_StereoBM_setSmallerBlockSize(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_StereoBM_Type))
        return failmsgp("Incorrect type of self (must be 'StereoBM' or its derivative)");
    cv::StereoBM* _self_ = dynamic_cast<cv::StereoBM*>(((pyopencv_StereoBM_t*)self)->v.get());
    int blockSize=0;

    const char* keywords[] = { "blockSize", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:StereoBM.setSmallerBlockSize", (char**)keywords, &blockSize) )
    {
        ERRWRAP2(_self_->setSmallerBlockSize(blockSize));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_StereoBM_setTextureThreshold(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_StereoBM_Type))
        return failmsgp("Incorrect type of self (must be 'StereoBM' or its derivative)");
    cv::StereoBM* _self_ = dynamic_cast<cv::StereoBM*>(((pyopencv_StereoBM_t*)self)->v.get());
    int textureThreshold=0;

    const char* keywords[] = { "textureThreshold", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:StereoBM.setTextureThreshold", (char**)keywords, &textureThreshold) )
    {
        ERRWRAP2(_self_->setTextureThreshold(textureThreshold));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_StereoBM_setUniquenessRatio(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_StereoBM_Type))
        return failmsgp("Incorrect type of self (must be 'StereoBM' or its derivative)");
    cv::StereoBM* _self_ = dynamic_cast<cv::StereoBM*>(((pyopencv_StereoBM_t*)self)->v.get());
    int uniquenessRatio=0;

    const char* keywords[] = { "uniquenessRatio", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:StereoBM.setUniquenessRatio", (char**)keywords, &uniquenessRatio) )
    {
        ERRWRAP2(_self_->setUniquenessRatio(uniquenessRatio));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_StereoBM_methods[] =
{
    {"getPreFilterCap", (PyCFunction)pyopencv_cv_StereoBM_getPreFilterCap, METH_VARARGS | METH_KEYWORDS, "getPreFilterCap() -> retval"},
    {"getPreFilterSize", (PyCFunction)pyopencv_cv_StereoBM_getPreFilterSize, METH_VARARGS | METH_KEYWORDS, "getPreFilterSize() -> retval"},
    {"getPreFilterType", (PyCFunction)pyopencv_cv_StereoBM_getPreFilterType, METH_VARARGS | METH_KEYWORDS, "getPreFilterType() -> retval"},
    {"getROI1", (PyCFunction)pyopencv_cv_StereoBM_getROI1, METH_VARARGS | METH_KEYWORDS, "getROI1() -> retval"},
    {"getROI2", (PyCFunction)pyopencv_cv_StereoBM_getROI2, METH_VARARGS | METH_KEYWORDS, "getROI2() -> retval"},
    {"getSmallerBlockSize", (PyCFunction)pyopencv_cv_StereoBM_getSmallerBlockSize, METH_VARARGS | METH_KEYWORDS, "getSmallerBlockSize() -> retval"},
    {"getTextureThreshold", (PyCFunction)pyopencv_cv_StereoBM_getTextureThreshold, METH_VARARGS | METH_KEYWORDS, "getTextureThreshold() -> retval"},
    {"getUniquenessRatio", (PyCFunction)pyopencv_cv_StereoBM_getUniquenessRatio, METH_VARARGS | METH_KEYWORDS, "getUniquenessRatio() -> retval"},
    {"setPreFilterCap", (PyCFunction)pyopencv_cv_StereoBM_setPreFilterCap, METH_VARARGS | METH_KEYWORDS, "setPreFilterCap(preFilterCap) -> None"},
    {"setPreFilterSize", (PyCFunction)pyopencv_cv_StereoBM_setPreFilterSize, METH_VARARGS | METH_KEYWORDS, "setPreFilterSize(preFilterSize) -> None"},
    {"setPreFilterType", (PyCFunction)pyopencv_cv_StereoBM_setPreFilterType, METH_VARARGS | METH_KEYWORDS, "setPreFilterType(preFilterType) -> None"},
    {"setROI1", (PyCFunction)pyopencv_cv_StereoBM_setROI1, METH_VARARGS | METH_KEYWORDS, "setROI1(roi1) -> None"},
    {"setROI2", (PyCFunction)pyopencv_cv_StereoBM_setROI2, METH_VARARGS | METH_KEYWORDS, "setROI2(roi2) -> None"},
    {"setSmallerBlockSize", (PyCFunction)pyopencv_cv_StereoBM_setSmallerBlockSize, METH_VARARGS | METH_KEYWORDS, "setSmallerBlockSize(blockSize) -> None"},
    {"setTextureThreshold", (PyCFunction)pyopencv_cv_StereoBM_setTextureThreshold, METH_VARARGS | METH_KEYWORDS, "setTextureThreshold(textureThreshold) -> None"},
    {"setUniquenessRatio", (PyCFunction)pyopencv_cv_StereoBM_setUniquenessRatio, METH_VARARGS | METH_KEYWORDS, "setUniquenessRatio(uniquenessRatio) -> None"},

    {NULL,          NULL}
};

static void pyopencv_StereoBM_specials(void)
{
    pyopencv_StereoBM_Type.tp_base = &pyopencv_StereoMatcher_Type;
    pyopencv_StereoBM_Type.tp_dealloc = pyopencv_StereoBM_dealloc;
    pyopencv_StereoBM_Type.tp_repr = pyopencv_StereoBM_repr;
    pyopencv_StereoBM_Type.tp_getset = pyopencv_StereoBM_getseters;
    pyopencv_StereoBM_Type.tp_methods = pyopencv_StereoBM_methods;
}

static PyObject* pyopencv_StereoSGBM_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<StereoSGBM %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_StereoSGBM_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_StereoSGBM_getMode(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_StereoSGBM_Type))
        return failmsgp("Incorrect type of self (must be 'StereoSGBM' or its derivative)");
    cv::StereoSGBM* _self_ = dynamic_cast<cv::StereoSGBM*>(((pyopencv_StereoSGBM_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getMode());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_StereoSGBM_getP1(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_StereoSGBM_Type))
        return failmsgp("Incorrect type of self (must be 'StereoSGBM' or its derivative)");
    cv::StereoSGBM* _self_ = dynamic_cast<cv::StereoSGBM*>(((pyopencv_StereoSGBM_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getP1());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_StereoSGBM_getP2(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_StereoSGBM_Type))
        return failmsgp("Incorrect type of self (must be 'StereoSGBM' or its derivative)");
    cv::StereoSGBM* _self_ = dynamic_cast<cv::StereoSGBM*>(((pyopencv_StereoSGBM_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getP2());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_StereoSGBM_getPreFilterCap(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_StereoSGBM_Type))
        return failmsgp("Incorrect type of self (must be 'StereoSGBM' or its derivative)");
    cv::StereoSGBM* _self_ = dynamic_cast<cv::StereoSGBM*>(((pyopencv_StereoSGBM_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getPreFilterCap());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_StereoSGBM_getUniquenessRatio(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_StereoSGBM_Type))
        return failmsgp("Incorrect type of self (must be 'StereoSGBM' or its derivative)");
    cv::StereoSGBM* _self_ = dynamic_cast<cv::StereoSGBM*>(((pyopencv_StereoSGBM_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getUniquenessRatio());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_StereoSGBM_setMode(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_StereoSGBM_Type))
        return failmsgp("Incorrect type of self (must be 'StereoSGBM' or its derivative)");
    cv::StereoSGBM* _self_ = dynamic_cast<cv::StereoSGBM*>(((pyopencv_StereoSGBM_t*)self)->v.get());
    int mode=0;

    const char* keywords[] = { "mode", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:StereoSGBM.setMode", (char**)keywords, &mode) )
    {
        ERRWRAP2(_self_->setMode(mode));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_StereoSGBM_setP1(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_StereoSGBM_Type))
        return failmsgp("Incorrect type of self (must be 'StereoSGBM' or its derivative)");
    cv::StereoSGBM* _self_ = dynamic_cast<cv::StereoSGBM*>(((pyopencv_StereoSGBM_t*)self)->v.get());
    int P1=0;

    const char* keywords[] = { "P1", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:StereoSGBM.setP1", (char**)keywords, &P1) )
    {
        ERRWRAP2(_self_->setP1(P1));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_StereoSGBM_setP2(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_StereoSGBM_Type))
        return failmsgp("Incorrect type of self (must be 'StereoSGBM' or its derivative)");
    cv::StereoSGBM* _self_ = dynamic_cast<cv::StereoSGBM*>(((pyopencv_StereoSGBM_t*)self)->v.get());
    int P2=0;

    const char* keywords[] = { "P2", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:StereoSGBM.setP2", (char**)keywords, &P2) )
    {
        ERRWRAP2(_self_->setP2(P2));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_StereoSGBM_setPreFilterCap(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_StereoSGBM_Type))
        return failmsgp("Incorrect type of self (must be 'StereoSGBM' or its derivative)");
    cv::StereoSGBM* _self_ = dynamic_cast<cv::StereoSGBM*>(((pyopencv_StereoSGBM_t*)self)->v.get());
    int preFilterCap=0;

    const char* keywords[] = { "preFilterCap", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:StereoSGBM.setPreFilterCap", (char**)keywords, &preFilterCap) )
    {
        ERRWRAP2(_self_->setPreFilterCap(preFilterCap));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_StereoSGBM_setUniquenessRatio(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_StereoSGBM_Type))
        return failmsgp("Incorrect type of self (must be 'StereoSGBM' or its derivative)");
    cv::StereoSGBM* _self_ = dynamic_cast<cv::StereoSGBM*>(((pyopencv_StereoSGBM_t*)self)->v.get());
    int uniquenessRatio=0;

    const char* keywords[] = { "uniquenessRatio", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:StereoSGBM.setUniquenessRatio", (char**)keywords, &uniquenessRatio) )
    {
        ERRWRAP2(_self_->setUniquenessRatio(uniquenessRatio));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_StereoSGBM_methods[] =
{
    {"getMode", (PyCFunction)pyopencv_cv_StereoSGBM_getMode, METH_VARARGS | METH_KEYWORDS, "getMode() -> retval"},
    {"getP1", (PyCFunction)pyopencv_cv_StereoSGBM_getP1, METH_VARARGS | METH_KEYWORDS, "getP1() -> retval"},
    {"getP2", (PyCFunction)pyopencv_cv_StereoSGBM_getP2, METH_VARARGS | METH_KEYWORDS, "getP2() -> retval"},
    {"getPreFilterCap", (PyCFunction)pyopencv_cv_StereoSGBM_getPreFilterCap, METH_VARARGS | METH_KEYWORDS, "getPreFilterCap() -> retval"},
    {"getUniquenessRatio", (PyCFunction)pyopencv_cv_StereoSGBM_getUniquenessRatio, METH_VARARGS | METH_KEYWORDS, "getUniquenessRatio() -> retval"},
    {"setMode", (PyCFunction)pyopencv_cv_StereoSGBM_setMode, METH_VARARGS | METH_KEYWORDS, "setMode(mode) -> None"},
    {"setP1", (PyCFunction)pyopencv_cv_StereoSGBM_setP1, METH_VARARGS | METH_KEYWORDS, "setP1(P1) -> None"},
    {"setP2", (PyCFunction)pyopencv_cv_StereoSGBM_setP2, METH_VARARGS | METH_KEYWORDS, "setP2(P2) -> None"},
    {"setPreFilterCap", (PyCFunction)pyopencv_cv_StereoSGBM_setPreFilterCap, METH_VARARGS | METH_KEYWORDS, "setPreFilterCap(preFilterCap) -> None"},
    {"setUniquenessRatio", (PyCFunction)pyopencv_cv_StereoSGBM_setUniquenessRatio, METH_VARARGS | METH_KEYWORDS, "setUniquenessRatio(uniquenessRatio) -> None"},

    {NULL,          NULL}
};

static void pyopencv_StereoSGBM_specials(void)
{
    pyopencv_StereoSGBM_Type.tp_base = &pyopencv_StereoMatcher_Type;
    pyopencv_StereoSGBM_Type.tp_dealloc = pyopencv_StereoSGBM_dealloc;
    pyopencv_StereoSGBM_Type.tp_repr = pyopencv_StereoSGBM_repr;
    pyopencv_StereoSGBM_Type.tp_getset = pyopencv_StereoSGBM_getseters;
    pyopencv_StereoSGBM_Type.tp_methods = pyopencv_StereoSGBM_methods;
}

static PyObject* pyopencv_Tracker_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<Tracker %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_Tracker_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_Tracker_init(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_Tracker_Type))
        return failmsgp("Incorrect type of self (must be 'Tracker' or its derivative)");
    cv::Tracker* _self_ = dynamic_cast<cv::Tracker*>(((pyopencv_Tracker_t*)self)->v.get());
    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_boundingBox = NULL;
    Rect2d boundingBox;
    bool retval;

    const char* keywords[] = { "image", "boundingBox", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO:Tracker.init", (char**)keywords, &pyobj_image, &pyobj_boundingBox) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_boundingBox, boundingBox, ArgInfo("boundingBox", 0)) )
    {
        ERRWRAP2(retval = _self_->init(image, boundingBox));
        return pyopencv_from(retval);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_boundingBox = NULL;
    Rect2d boundingBox;
    bool retval;

    const char* keywords[] = { "image", "boundingBox", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO:Tracker.init", (char**)keywords, &pyobj_image, &pyobj_boundingBox) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_boundingBox, boundingBox, ArgInfo("boundingBox", 0)) )
    {
        ERRWRAP2(retval = _self_->init(image, boundingBox));
        return pyopencv_from(retval);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_Tracker_update(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_Tracker_Type))
        return failmsgp("Incorrect type of self (must be 'Tracker' or its derivative)");
    cv::Tracker* _self_ = dynamic_cast<cv::Tracker*>(((pyopencv_Tracker_t*)self)->v.get());
    {
    PyObject* pyobj_image = NULL;
    Mat image;
    Rect2d boundingBox;
    bool retval;

    const char* keywords[] = { "image", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:Tracker.update", (char**)keywords, &pyobj_image) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) )
    {
        ERRWRAP2(retval = _self_->update(image, boundingBox));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(boundingBox));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    Rect2d boundingBox;
    bool retval;

    const char* keywords[] = { "image", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:Tracker.update", (char**)keywords, &pyobj_image) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) )
    {
        ERRWRAP2(retval = _self_->update(image, boundingBox));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(boundingBox));
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_Tracker_methods[] =
{
    {"init", (PyCFunction)pyopencv_cv_Tracker_init, METH_VARARGS | METH_KEYWORDS, "init(image, boundingBox) -> retval"},
    {"update", (PyCFunction)pyopencv_cv_Tracker_update, METH_VARARGS | METH_KEYWORDS, "update(image) -> retval, boundingBox"},

    {NULL,          NULL}
};

static void pyopencv_Tracker_specials(void)
{
    pyopencv_Tracker_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_Tracker_Type.tp_dealloc = pyopencv_Tracker_dealloc;
    pyopencv_Tracker_Type.tp_repr = pyopencv_Tracker_repr;
    pyopencv_Tracker_Type.tp_getset = pyopencv_Tracker_getseters;
    pyopencv_Tracker_Type.tp_methods = pyopencv_Tracker_methods;
}

static PyObject* pyopencv_MultiTracker_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<MultiTracker %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_MultiTracker_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_MultiTracker_add(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_MultiTracker_Type))
        return failmsgp("Incorrect type of self (must be 'MultiTracker' or its derivative)");
    cv::MultiTracker* _self_ = ((pyopencv_MultiTracker_t*)self)->v.get();
    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_boundingBox = NULL;
    Rect2d boundingBox;
    bool retval;

    const char* keywords[] = { "image", "boundingBox", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO:MultiTracker.add", (char**)keywords, &pyobj_image, &pyobj_boundingBox) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_boundingBox, boundingBox, ArgInfo("boundingBox", 0)) )
    {
        ERRWRAP2(retval = _self_->add(image, boundingBox));
        return pyopencv_from(retval);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_boundingBox = NULL;
    Rect2d boundingBox;
    bool retval;

    const char* keywords[] = { "image", "boundingBox", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO:MultiTracker.add", (char**)keywords, &pyobj_image, &pyobj_boundingBox) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_boundingBox, boundingBox, ArgInfo("boundingBox", 0)) )
    {
        ERRWRAP2(retval = _self_->add(image, boundingBox));
        return pyopencv_from(retval);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_trackerType = NULL;
    String trackerType;
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_boundingBox = NULL;
    Rect2d boundingBox;
    bool retval;

    const char* keywords[] = { "trackerType", "image", "boundingBox", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OOO:MultiTracker.add", (char**)keywords, &pyobj_trackerType, &pyobj_image, &pyobj_boundingBox) &&
        pyopencv_to(pyobj_trackerType, trackerType, ArgInfo("trackerType", 0)) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_boundingBox, boundingBox, ArgInfo("boundingBox", 0)) )
    {
        ERRWRAP2(retval = _self_->add(trackerType, image, boundingBox));
        return pyopencv_from(retval);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_trackerType = NULL;
    String trackerType;
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_boundingBox = NULL;
    Rect2d boundingBox;
    bool retval;

    const char* keywords[] = { "trackerType", "image", "boundingBox", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OOO:MultiTracker.add", (char**)keywords, &pyobj_trackerType, &pyobj_image, &pyobj_boundingBox) &&
        pyopencv_to(pyobj_trackerType, trackerType, ArgInfo("trackerType", 0)) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_boundingBox, boundingBox, ArgInfo("boundingBox", 0)) )
    {
        ERRWRAP2(retval = _self_->add(trackerType, image, boundingBox));
        return pyopencv_from(retval);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_trackerType = NULL;
    String trackerType;
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_boundingBox = NULL;
    vector_Rect2d boundingBox;
    bool retval;

    const char* keywords[] = { "trackerType", "image", "boundingBox", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OOO:MultiTracker.add", (char**)keywords, &pyobj_trackerType, &pyobj_image, &pyobj_boundingBox) &&
        pyopencv_to(pyobj_trackerType, trackerType, ArgInfo("trackerType", 0)) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_boundingBox, boundingBox, ArgInfo("boundingBox", 0)) )
    {
        ERRWRAP2(retval = _self_->add(trackerType, image, boundingBox));
        return pyopencv_from(retval);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_trackerType = NULL;
    String trackerType;
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_boundingBox = NULL;
    vector_Rect2d boundingBox;
    bool retval;

    const char* keywords[] = { "trackerType", "image", "boundingBox", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OOO:MultiTracker.add", (char**)keywords, &pyobj_trackerType, &pyobj_image, &pyobj_boundingBox) &&
        pyopencv_to(pyobj_trackerType, trackerType, ArgInfo("trackerType", 0)) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_boundingBox, boundingBox, ArgInfo("boundingBox", 0)) )
    {
        ERRWRAP2(retval = _self_->add(trackerType, image, boundingBox));
        return pyopencv_from(retval);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_boundingBox = NULL;
    vector_Rect2d boundingBox;
    bool retval;

    const char* keywords[] = { "image", "boundingBox", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO:MultiTracker.add", (char**)keywords, &pyobj_image, &pyobj_boundingBox) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_boundingBox, boundingBox, ArgInfo("boundingBox", 0)) )
    {
        ERRWRAP2(retval = _self_->add(image, boundingBox));
        return pyopencv_from(retval);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_boundingBox = NULL;
    vector_Rect2d boundingBox;
    bool retval;

    const char* keywords[] = { "image", "boundingBox", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO:MultiTracker.add", (char**)keywords, &pyobj_image, &pyobj_boundingBox) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_boundingBox, boundingBox, ArgInfo("boundingBox", 0)) )
    {
        ERRWRAP2(retval = _self_->add(image, boundingBox));
        return pyopencv_from(retval);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_MultiTracker_update(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_MultiTracker_Type))
        return failmsgp("Incorrect type of self (must be 'MultiTracker' or its derivative)");
    cv::MultiTracker* _self_ = ((pyopencv_MultiTracker_t*)self)->v.get();
    {
    PyObject* pyobj_image = NULL;
    Mat image;
    vector_Rect2d boundingBox;
    bool retval;

    const char* keywords[] = { "image", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:MultiTracker.update", (char**)keywords, &pyobj_image) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) )
    {
        ERRWRAP2(retval = _self_->update(image, boundingBox));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(boundingBox));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    vector_Rect2d boundingBox;
    bool retval;

    const char* keywords[] = { "image", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:MultiTracker.update", (char**)keywords, &pyobj_image) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) )
    {
        ERRWRAP2(retval = _self_->update(image, boundingBox));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(boundingBox));
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_MultiTracker_methods[] =
{
    {"add", (PyCFunction)pyopencv_cv_MultiTracker_add, METH_VARARGS | METH_KEYWORDS, "add(image, boundingBox) -> retval  or  add(trackerType, image, boundingBox) -> retval"},
    {"update", (PyCFunction)pyopencv_cv_MultiTracker_update, METH_VARARGS | METH_KEYWORDS, "update(image) -> retval, boundingBox"},

    {NULL,          NULL}
};

static void pyopencv_MultiTracker_specials(void)
{
    pyopencv_MultiTracker_Type.tp_base = NULL;
    pyopencv_MultiTracker_Type.tp_dealloc = pyopencv_MultiTracker_dealloc;
    pyopencv_MultiTracker_Type.tp_repr = pyopencv_MultiTracker_repr;
    pyopencv_MultiTracker_Type.tp_getset = pyopencv_MultiTracker_getseters;
    pyopencv_MultiTracker_Type.tp_methods = pyopencv_MultiTracker_methods;
}

static PyObject* pyopencv_xfeatures2d_FREAK_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<xfeatures2d_FREAK %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_xfeatures2d_FREAK_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_xfeatures2d_FREAK_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_xfeatures2d_FREAK_specials(void)
{
    pyopencv_xfeatures2d_FREAK_Type.tp_base = &pyopencv_Feature2D_Type;
    pyopencv_xfeatures2d_FREAK_Type.tp_dealloc = pyopencv_xfeatures2d_FREAK_dealloc;
    pyopencv_xfeatures2d_FREAK_Type.tp_repr = pyopencv_xfeatures2d_FREAK_repr;
    pyopencv_xfeatures2d_FREAK_Type.tp_getset = pyopencv_xfeatures2d_FREAK_getseters;
    pyopencv_xfeatures2d_FREAK_Type.tp_methods = pyopencv_xfeatures2d_FREAK_methods;
}

static PyObject* pyopencv_xfeatures2d_StarDetector_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<xfeatures2d_StarDetector %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_xfeatures2d_StarDetector_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_xfeatures2d_StarDetector_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_xfeatures2d_StarDetector_specials(void)
{
    pyopencv_xfeatures2d_StarDetector_Type.tp_base = &pyopencv_Feature2D_Type;
    pyopencv_xfeatures2d_StarDetector_Type.tp_dealloc = pyopencv_xfeatures2d_StarDetector_dealloc;
    pyopencv_xfeatures2d_StarDetector_Type.tp_repr = pyopencv_xfeatures2d_StarDetector_repr;
    pyopencv_xfeatures2d_StarDetector_Type.tp_getset = pyopencv_xfeatures2d_StarDetector_getseters;
    pyopencv_xfeatures2d_StarDetector_Type.tp_methods = pyopencv_xfeatures2d_StarDetector_methods;
}

static PyObject* pyopencv_xfeatures2d_BriefDescriptorExtractor_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<xfeatures2d_BriefDescriptorExtractor %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_xfeatures2d_BriefDescriptorExtractor_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_xfeatures2d_BriefDescriptorExtractor_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_xfeatures2d_BriefDescriptorExtractor_specials(void)
{
    pyopencv_xfeatures2d_BriefDescriptorExtractor_Type.tp_base = &pyopencv_Feature2D_Type;
    pyopencv_xfeatures2d_BriefDescriptorExtractor_Type.tp_dealloc = pyopencv_xfeatures2d_BriefDescriptorExtractor_dealloc;
    pyopencv_xfeatures2d_BriefDescriptorExtractor_Type.tp_repr = pyopencv_xfeatures2d_BriefDescriptorExtractor_repr;
    pyopencv_xfeatures2d_BriefDescriptorExtractor_Type.tp_getset = pyopencv_xfeatures2d_BriefDescriptorExtractor_getseters;
    pyopencv_xfeatures2d_BriefDescriptorExtractor_Type.tp_methods = pyopencv_xfeatures2d_BriefDescriptorExtractor_methods;
}

static PyObject* pyopencv_xfeatures2d_LUCID_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<xfeatures2d_LUCID %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_xfeatures2d_LUCID_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_xfeatures2d_LUCID_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_xfeatures2d_LUCID_specials(void)
{
    pyopencv_xfeatures2d_LUCID_Type.tp_base = &pyopencv_Feature2D_Type;
    pyopencv_xfeatures2d_LUCID_Type.tp_dealloc = pyopencv_xfeatures2d_LUCID_dealloc;
    pyopencv_xfeatures2d_LUCID_Type.tp_repr = pyopencv_xfeatures2d_LUCID_repr;
    pyopencv_xfeatures2d_LUCID_Type.tp_getset = pyopencv_xfeatures2d_LUCID_getseters;
    pyopencv_xfeatures2d_LUCID_Type.tp_methods = pyopencv_xfeatures2d_LUCID_methods;
}

static PyObject* pyopencv_xfeatures2d_LATCH_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<xfeatures2d_LATCH %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_xfeatures2d_LATCH_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_xfeatures2d_LATCH_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_xfeatures2d_LATCH_specials(void)
{
    pyopencv_xfeatures2d_LATCH_Type.tp_base = &pyopencv_Feature2D_Type;
    pyopencv_xfeatures2d_LATCH_Type.tp_dealloc = pyopencv_xfeatures2d_LATCH_dealloc;
    pyopencv_xfeatures2d_LATCH_Type.tp_repr = pyopencv_xfeatures2d_LATCH_repr;
    pyopencv_xfeatures2d_LATCH_Type.tp_getset = pyopencv_xfeatures2d_LATCH_getseters;
    pyopencv_xfeatures2d_LATCH_Type.tp_methods = pyopencv_xfeatures2d_LATCH_methods;
}

static PyObject* pyopencv_xfeatures2d_DAISY_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<xfeatures2d_DAISY %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_xfeatures2d_DAISY_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_xfeatures2d_DAISY_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_xfeatures2d_DAISY_specials(void)
{
    pyopencv_xfeatures2d_DAISY_Type.tp_base = &pyopencv_Feature2D_Type;
    pyopencv_xfeatures2d_DAISY_Type.tp_dealloc = pyopencv_xfeatures2d_DAISY_dealloc;
    pyopencv_xfeatures2d_DAISY_Type.tp_repr = pyopencv_xfeatures2d_DAISY_repr;
    pyopencv_xfeatures2d_DAISY_Type.tp_getset = pyopencv_xfeatures2d_DAISY_getseters;
    pyopencv_xfeatures2d_DAISY_Type.tp_methods = pyopencv_xfeatures2d_DAISY_methods;
}

static PyObject* pyopencv_xfeatures2d_MSDDetector_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<xfeatures2d_MSDDetector %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_xfeatures2d_MSDDetector_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_xfeatures2d_MSDDetector_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_xfeatures2d_MSDDetector_specials(void)
{
    pyopencv_xfeatures2d_MSDDetector_Type.tp_base = &pyopencv_Feature2D_Type;
    pyopencv_xfeatures2d_MSDDetector_Type.tp_dealloc = pyopencv_xfeatures2d_MSDDetector_dealloc;
    pyopencv_xfeatures2d_MSDDetector_Type.tp_repr = pyopencv_xfeatures2d_MSDDetector_repr;
    pyopencv_xfeatures2d_MSDDetector_Type.tp_getset = pyopencv_xfeatures2d_MSDDetector_getseters;
    pyopencv_xfeatures2d_MSDDetector_Type.tp_methods = pyopencv_xfeatures2d_MSDDetector_methods;
}

static PyObject* pyopencv_xfeatures2d_VGG_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<xfeatures2d_VGG %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_xfeatures2d_VGG_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_VGG_compute(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_VGG_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_VGG' or its derivative)");
    cv::xfeatures2d::VGG* _self_ = dynamic_cast<cv::xfeatures2d::VGG*>(((pyopencv_xfeatures2d_VGG_t*)self)->v.get());
    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_keypoints = NULL;
    vector_KeyPoint keypoints;
    PyObject* pyobj_descriptors = NULL;
    Mat descriptors;

    const char* keywords[] = { "image", "keypoints", "descriptors", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|O:xfeatures2d_VGG.compute", (char**)keywords, &pyobj_image, &pyobj_keypoints, &pyobj_descriptors) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_keypoints, keypoints, ArgInfo("keypoints", 0)) &&
        pyopencv_to(pyobj_descriptors, descriptors, ArgInfo("descriptors", 1)) )
    {
        ERRWRAP2(_self_->compute(image, keypoints, descriptors));
        return pyopencv_from(descriptors);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_keypoints = NULL;
    vector_KeyPoint keypoints;
    PyObject* pyobj_descriptors = NULL;
    UMat descriptors;

    const char* keywords[] = { "image", "keypoints", "descriptors", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|O:xfeatures2d_VGG.compute", (char**)keywords, &pyobj_image, &pyobj_keypoints, &pyobj_descriptors) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_keypoints, keypoints, ArgInfo("keypoints", 0)) &&
        pyopencv_to(pyobj_descriptors, descriptors, ArgInfo("descriptors", 1)) )
    {
        ERRWRAP2(_self_->compute(image, keypoints, descriptors));
        return pyopencv_from(descriptors);
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_xfeatures2d_VGG_methods[] =
{
    {"compute", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_VGG_compute, METH_VARARGS | METH_KEYWORDS, "compute(image, keypoints[, descriptors]) -> descriptors"},

    {NULL,          NULL}
};

static void pyopencv_xfeatures2d_VGG_specials(void)
{
    pyopencv_xfeatures2d_VGG_Type.tp_base = &pyopencv_Feature2D_Type;
    pyopencv_xfeatures2d_VGG_Type.tp_dealloc = pyopencv_xfeatures2d_VGG_dealloc;
    pyopencv_xfeatures2d_VGG_Type.tp_repr = pyopencv_xfeatures2d_VGG_repr;
    pyopencv_xfeatures2d_VGG_Type.tp_getset = pyopencv_xfeatures2d_VGG_getseters;
    pyopencv_xfeatures2d_VGG_Type.tp_methods = pyopencv_xfeatures2d_VGG_methods;
}

static PyObject* pyopencv_xfeatures2d_BoostDesc_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<xfeatures2d_BoostDesc %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_xfeatures2d_BoostDesc_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_xfeatures2d_BoostDesc_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_xfeatures2d_BoostDesc_specials(void)
{
    pyopencv_xfeatures2d_BoostDesc_Type.tp_base = &pyopencv_Feature2D_Type;
    pyopencv_xfeatures2d_BoostDesc_Type.tp_dealloc = pyopencv_xfeatures2d_BoostDesc_dealloc;
    pyopencv_xfeatures2d_BoostDesc_Type.tp_repr = pyopencv_xfeatures2d_BoostDesc_repr;
    pyopencv_xfeatures2d_BoostDesc_Type.tp_getset = pyopencv_xfeatures2d_BoostDesc_getseters;
    pyopencv_xfeatures2d_BoostDesc_Type.tp_methods = pyopencv_xfeatures2d_BoostDesc_methods;
}

static PyObject* pyopencv_xfeatures2d_PCTSignatures_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<xfeatures2d_PCTSignatures %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_xfeatures2d_PCTSignatures_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_computeSignature(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_PCTSignatures_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_PCTSignatures' or its derivative)");
    cv::xfeatures2d::PCTSignatures* _self_ = dynamic_cast<cv::xfeatures2d::PCTSignatures*>(((pyopencv_xfeatures2d_PCTSignatures_t*)self)->v.get());
    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_signature = NULL;
    Mat signature;

    const char* keywords[] = { "image", "signature", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:xfeatures2d_PCTSignatures.computeSignature", (char**)keywords, &pyobj_image, &pyobj_signature) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_signature, signature, ArgInfo("signature", 1)) )
    {
        ERRWRAP2(_self_->computeSignature(image, signature));
        return pyopencv_from(signature);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_signature = NULL;
    UMat signature;

    const char* keywords[] = { "image", "signature", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:xfeatures2d_PCTSignatures.computeSignature", (char**)keywords, &pyobj_image, &pyobj_signature) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to(pyobj_signature, signature, ArgInfo("signature", 1)) )
    {
        ERRWRAP2(_self_->computeSignature(image, signature));
        return pyopencv_from(signature);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_computeSignatures(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_PCTSignatures_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_PCTSignatures' or its derivative)");
    cv::xfeatures2d::PCTSignatures* _self_ = dynamic_cast<cv::xfeatures2d::PCTSignatures*>(((pyopencv_xfeatures2d_PCTSignatures_t*)self)->v.get());
    {
    PyObject* pyobj_images = NULL;
    vector_Mat images;
    PyObject* pyobj_signatures = NULL;
    vector_Mat signatures;

    const char* keywords[] = { "images", "signatures", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO:xfeatures2d_PCTSignatures.computeSignatures", (char**)keywords, &pyobj_images, &pyobj_signatures) &&
        pyopencv_to(pyobj_images, images, ArgInfo("images", 0)) &&
        pyopencv_to(pyobj_signatures, signatures, ArgInfo("signatures", 0)) )
    {
        ERRWRAP2(_self_->computeSignatures(images, signatures));
        Py_RETURN_NONE;
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_images = NULL;
    vector_Mat images;
    PyObject* pyobj_signatures = NULL;
    vector_Mat signatures;

    const char* keywords[] = { "images", "signatures", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO:xfeatures2d_PCTSignatures.computeSignatures", (char**)keywords, &pyobj_images, &pyobj_signatures) &&
        pyopencv_to(pyobj_images, images, ArgInfo("images", 0)) &&
        pyopencv_to(pyobj_signatures, signatures, ArgInfo("signatures", 0)) )
    {
        ERRWRAP2(_self_->computeSignatures(images, signatures));
        Py_RETURN_NONE;
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_getClusterMinSize(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_PCTSignatures_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_PCTSignatures' or its derivative)");
    cv::xfeatures2d::PCTSignatures* _self_ = dynamic_cast<cv::xfeatures2d::PCTSignatures*>(((pyopencv_xfeatures2d_PCTSignatures_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getClusterMinSize());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_getDistanceFunction(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_PCTSignatures_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_PCTSignatures' or its derivative)");
    cv::xfeatures2d::PCTSignatures* _self_ = dynamic_cast<cv::xfeatures2d::PCTSignatures*>(((pyopencv_xfeatures2d_PCTSignatures_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getDistanceFunction());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_getDropThreshold(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_PCTSignatures_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_PCTSignatures' or its derivative)");
    cv::xfeatures2d::PCTSignatures* _self_ = dynamic_cast<cv::xfeatures2d::PCTSignatures*>(((pyopencv_xfeatures2d_PCTSignatures_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getDropThreshold());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_getGrayscaleBits(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_PCTSignatures_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_PCTSignatures' or its derivative)");
    cv::xfeatures2d::PCTSignatures* _self_ = dynamic_cast<cv::xfeatures2d::PCTSignatures*>(((pyopencv_xfeatures2d_PCTSignatures_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getGrayscaleBits());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_getInitSeedCount(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_PCTSignatures_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_PCTSignatures' or its derivative)");
    cv::xfeatures2d::PCTSignatures* _self_ = dynamic_cast<cv::xfeatures2d::PCTSignatures*>(((pyopencv_xfeatures2d_PCTSignatures_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getInitSeedCount());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_getInitSeedIndexes(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_PCTSignatures_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_PCTSignatures' or its derivative)");
    cv::xfeatures2d::PCTSignatures* _self_ = dynamic_cast<cv::xfeatures2d::PCTSignatures*>(((pyopencv_xfeatures2d_PCTSignatures_t*)self)->v.get());
    std::vector<int> retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getInitSeedIndexes());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_getIterationCount(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_PCTSignatures_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_PCTSignatures' or its derivative)");
    cv::xfeatures2d::PCTSignatures* _self_ = dynamic_cast<cv::xfeatures2d::PCTSignatures*>(((pyopencv_xfeatures2d_PCTSignatures_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getIterationCount());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_getJoiningDistance(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_PCTSignatures_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_PCTSignatures' or its derivative)");
    cv::xfeatures2d::PCTSignatures* _self_ = dynamic_cast<cv::xfeatures2d::PCTSignatures*>(((pyopencv_xfeatures2d_PCTSignatures_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getJoiningDistance());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_getMaxClustersCount(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_PCTSignatures_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_PCTSignatures' or its derivative)");
    cv::xfeatures2d::PCTSignatures* _self_ = dynamic_cast<cv::xfeatures2d::PCTSignatures*>(((pyopencv_xfeatures2d_PCTSignatures_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getMaxClustersCount());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_getSampleCount(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_PCTSignatures_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_PCTSignatures' or its derivative)");
    cv::xfeatures2d::PCTSignatures* _self_ = dynamic_cast<cv::xfeatures2d::PCTSignatures*>(((pyopencv_xfeatures2d_PCTSignatures_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getSampleCount());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_getSamplingPoints(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_PCTSignatures_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_PCTSignatures' or its derivative)");
    cv::xfeatures2d::PCTSignatures* _self_ = dynamic_cast<cv::xfeatures2d::PCTSignatures*>(((pyopencv_xfeatures2d_PCTSignatures_t*)self)->v.get());
    std::vector<Point2f> retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getSamplingPoints());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_getWeightA(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_PCTSignatures_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_PCTSignatures' or its derivative)");
    cv::xfeatures2d::PCTSignatures* _self_ = dynamic_cast<cv::xfeatures2d::PCTSignatures*>(((pyopencv_xfeatures2d_PCTSignatures_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getWeightA());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_getWeightB(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_PCTSignatures_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_PCTSignatures' or its derivative)");
    cv::xfeatures2d::PCTSignatures* _self_ = dynamic_cast<cv::xfeatures2d::PCTSignatures*>(((pyopencv_xfeatures2d_PCTSignatures_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getWeightB());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_getWeightConstrast(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_PCTSignatures_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_PCTSignatures' or its derivative)");
    cv::xfeatures2d::PCTSignatures* _self_ = dynamic_cast<cv::xfeatures2d::PCTSignatures*>(((pyopencv_xfeatures2d_PCTSignatures_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getWeightConstrast());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_getWeightEntropy(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_PCTSignatures_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_PCTSignatures' or its derivative)");
    cv::xfeatures2d::PCTSignatures* _self_ = dynamic_cast<cv::xfeatures2d::PCTSignatures*>(((pyopencv_xfeatures2d_PCTSignatures_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getWeightEntropy());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_getWeightL(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_PCTSignatures_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_PCTSignatures' or its derivative)");
    cv::xfeatures2d::PCTSignatures* _self_ = dynamic_cast<cv::xfeatures2d::PCTSignatures*>(((pyopencv_xfeatures2d_PCTSignatures_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getWeightL());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_getWeightX(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_PCTSignatures_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_PCTSignatures' or its derivative)");
    cv::xfeatures2d::PCTSignatures* _self_ = dynamic_cast<cv::xfeatures2d::PCTSignatures*>(((pyopencv_xfeatures2d_PCTSignatures_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getWeightX());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_getWeightY(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_PCTSignatures_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_PCTSignatures' or its derivative)");
    cv::xfeatures2d::PCTSignatures* _self_ = dynamic_cast<cv::xfeatures2d::PCTSignatures*>(((pyopencv_xfeatures2d_PCTSignatures_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getWeightY());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_getWindowRadius(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_PCTSignatures_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_PCTSignatures' or its derivative)");
    cv::xfeatures2d::PCTSignatures* _self_ = dynamic_cast<cv::xfeatures2d::PCTSignatures*>(((pyopencv_xfeatures2d_PCTSignatures_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getWindowRadius());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_setClusterMinSize(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_PCTSignatures_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_PCTSignatures' or its derivative)");
    cv::xfeatures2d::PCTSignatures* _self_ = dynamic_cast<cv::xfeatures2d::PCTSignatures*>(((pyopencv_xfeatures2d_PCTSignatures_t*)self)->v.get());
    int clusterMinSize=0;

    const char* keywords[] = { "clusterMinSize", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:xfeatures2d_PCTSignatures.setClusterMinSize", (char**)keywords, &clusterMinSize) )
    {
        ERRWRAP2(_self_->setClusterMinSize(clusterMinSize));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_setDistanceFunction(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_PCTSignatures_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_PCTSignatures' or its derivative)");
    cv::xfeatures2d::PCTSignatures* _self_ = dynamic_cast<cv::xfeatures2d::PCTSignatures*>(((pyopencv_xfeatures2d_PCTSignatures_t*)self)->v.get());
    int distanceFunction=0;

    const char* keywords[] = { "distanceFunction", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:xfeatures2d_PCTSignatures.setDistanceFunction", (char**)keywords, &distanceFunction) )
    {
        ERRWRAP2(_self_->setDistanceFunction(distanceFunction));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_setDropThreshold(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_PCTSignatures_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_PCTSignatures' or its derivative)");
    cv::xfeatures2d::PCTSignatures* _self_ = dynamic_cast<cv::xfeatures2d::PCTSignatures*>(((pyopencv_xfeatures2d_PCTSignatures_t*)self)->v.get());
    float dropThreshold=0.f;

    const char* keywords[] = { "dropThreshold", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:xfeatures2d_PCTSignatures.setDropThreshold", (char**)keywords, &dropThreshold) )
    {
        ERRWRAP2(_self_->setDropThreshold(dropThreshold));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_setGrayscaleBits(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_PCTSignatures_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_PCTSignatures' or its derivative)");
    cv::xfeatures2d::PCTSignatures* _self_ = dynamic_cast<cv::xfeatures2d::PCTSignatures*>(((pyopencv_xfeatures2d_PCTSignatures_t*)self)->v.get());
    int grayscaleBits=0;

    const char* keywords[] = { "grayscaleBits", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:xfeatures2d_PCTSignatures.setGrayscaleBits", (char**)keywords, &grayscaleBits) )
    {
        ERRWRAP2(_self_->setGrayscaleBits(grayscaleBits));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_setInitSeedIndexes(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_PCTSignatures_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_PCTSignatures' or its derivative)");
    cv::xfeatures2d::PCTSignatures* _self_ = dynamic_cast<cv::xfeatures2d::PCTSignatures*>(((pyopencv_xfeatures2d_PCTSignatures_t*)self)->v.get());
    PyObject* pyobj_initSeedIndexes = NULL;
    vector_int initSeedIndexes;

    const char* keywords[] = { "initSeedIndexes", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:xfeatures2d_PCTSignatures.setInitSeedIndexes", (char**)keywords, &pyobj_initSeedIndexes) &&
        pyopencv_to(pyobj_initSeedIndexes, initSeedIndexes, ArgInfo("initSeedIndexes", 0)) )
    {
        ERRWRAP2(_self_->setInitSeedIndexes(initSeedIndexes));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_setIterationCount(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_PCTSignatures_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_PCTSignatures' or its derivative)");
    cv::xfeatures2d::PCTSignatures* _self_ = dynamic_cast<cv::xfeatures2d::PCTSignatures*>(((pyopencv_xfeatures2d_PCTSignatures_t*)self)->v.get());
    int iterationCount=0;

    const char* keywords[] = { "iterationCount", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:xfeatures2d_PCTSignatures.setIterationCount", (char**)keywords, &iterationCount) )
    {
        ERRWRAP2(_self_->setIterationCount(iterationCount));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_setJoiningDistance(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_PCTSignatures_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_PCTSignatures' or its derivative)");
    cv::xfeatures2d::PCTSignatures* _self_ = dynamic_cast<cv::xfeatures2d::PCTSignatures*>(((pyopencv_xfeatures2d_PCTSignatures_t*)self)->v.get());
    float joiningDistance=0.f;

    const char* keywords[] = { "joiningDistance", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:xfeatures2d_PCTSignatures.setJoiningDistance", (char**)keywords, &joiningDistance) )
    {
        ERRWRAP2(_self_->setJoiningDistance(joiningDistance));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_setMaxClustersCount(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_PCTSignatures_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_PCTSignatures' or its derivative)");
    cv::xfeatures2d::PCTSignatures* _self_ = dynamic_cast<cv::xfeatures2d::PCTSignatures*>(((pyopencv_xfeatures2d_PCTSignatures_t*)self)->v.get());
    int maxClustersCount=0;

    const char* keywords[] = { "maxClustersCount", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:xfeatures2d_PCTSignatures.setMaxClustersCount", (char**)keywords, &maxClustersCount) )
    {
        ERRWRAP2(_self_->setMaxClustersCount(maxClustersCount));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_setSamplingPoints(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_PCTSignatures_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_PCTSignatures' or its derivative)");
    cv::xfeatures2d::PCTSignatures* _self_ = dynamic_cast<cv::xfeatures2d::PCTSignatures*>(((pyopencv_xfeatures2d_PCTSignatures_t*)self)->v.get());
    PyObject* pyobj_samplingPoints = NULL;
    vector_Point2f samplingPoints;

    const char* keywords[] = { "samplingPoints", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:xfeatures2d_PCTSignatures.setSamplingPoints", (char**)keywords, &pyobj_samplingPoints) &&
        pyopencv_to(pyobj_samplingPoints, samplingPoints, ArgInfo("samplingPoints", 0)) )
    {
        ERRWRAP2(_self_->setSamplingPoints(samplingPoints));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_setTranslation(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_PCTSignatures_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_PCTSignatures' or its derivative)");
    cv::xfeatures2d::PCTSignatures* _self_ = dynamic_cast<cv::xfeatures2d::PCTSignatures*>(((pyopencv_xfeatures2d_PCTSignatures_t*)self)->v.get());
    int idx=0;
    float value=0.f;

    const char* keywords[] = { "idx", "value", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "if:xfeatures2d_PCTSignatures.setTranslation", (char**)keywords, &idx, &value) )
    {
        ERRWRAP2(_self_->setTranslation(idx, value));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_setTranslations(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_PCTSignatures_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_PCTSignatures' or its derivative)");
    cv::xfeatures2d::PCTSignatures* _self_ = dynamic_cast<cv::xfeatures2d::PCTSignatures*>(((pyopencv_xfeatures2d_PCTSignatures_t*)self)->v.get());
    PyObject* pyobj_translations = NULL;
    vector_float translations;

    const char* keywords[] = { "translations", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:xfeatures2d_PCTSignatures.setTranslations", (char**)keywords, &pyobj_translations) &&
        pyopencv_to(pyobj_translations, translations, ArgInfo("translations", 0)) )
    {
        ERRWRAP2(_self_->setTranslations(translations));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_setWeight(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_PCTSignatures_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_PCTSignatures' or its derivative)");
    cv::xfeatures2d::PCTSignatures* _self_ = dynamic_cast<cv::xfeatures2d::PCTSignatures*>(((pyopencv_xfeatures2d_PCTSignatures_t*)self)->v.get());
    int idx=0;
    float value=0.f;

    const char* keywords[] = { "idx", "value", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "if:xfeatures2d_PCTSignatures.setWeight", (char**)keywords, &idx, &value) )
    {
        ERRWRAP2(_self_->setWeight(idx, value));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_setWeightA(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_PCTSignatures_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_PCTSignatures' or its derivative)");
    cv::xfeatures2d::PCTSignatures* _self_ = dynamic_cast<cv::xfeatures2d::PCTSignatures*>(((pyopencv_xfeatures2d_PCTSignatures_t*)self)->v.get());
    float weight=0.f;

    const char* keywords[] = { "weight", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:xfeatures2d_PCTSignatures.setWeightA", (char**)keywords, &weight) )
    {
        ERRWRAP2(_self_->setWeightA(weight));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_setWeightB(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_PCTSignatures_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_PCTSignatures' or its derivative)");
    cv::xfeatures2d::PCTSignatures* _self_ = dynamic_cast<cv::xfeatures2d::PCTSignatures*>(((pyopencv_xfeatures2d_PCTSignatures_t*)self)->v.get());
    float weight=0.f;

    const char* keywords[] = { "weight", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:xfeatures2d_PCTSignatures.setWeightB", (char**)keywords, &weight) )
    {
        ERRWRAP2(_self_->setWeightB(weight));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_setWeightContrast(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_PCTSignatures_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_PCTSignatures' or its derivative)");
    cv::xfeatures2d::PCTSignatures* _self_ = dynamic_cast<cv::xfeatures2d::PCTSignatures*>(((pyopencv_xfeatures2d_PCTSignatures_t*)self)->v.get());
    float weight=0.f;

    const char* keywords[] = { "weight", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:xfeatures2d_PCTSignatures.setWeightContrast", (char**)keywords, &weight) )
    {
        ERRWRAP2(_self_->setWeightContrast(weight));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_setWeightEntropy(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_PCTSignatures_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_PCTSignatures' or its derivative)");
    cv::xfeatures2d::PCTSignatures* _self_ = dynamic_cast<cv::xfeatures2d::PCTSignatures*>(((pyopencv_xfeatures2d_PCTSignatures_t*)self)->v.get());
    float weight=0.f;

    const char* keywords[] = { "weight", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:xfeatures2d_PCTSignatures.setWeightEntropy", (char**)keywords, &weight) )
    {
        ERRWRAP2(_self_->setWeightEntropy(weight));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_setWeightL(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_PCTSignatures_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_PCTSignatures' or its derivative)");
    cv::xfeatures2d::PCTSignatures* _self_ = dynamic_cast<cv::xfeatures2d::PCTSignatures*>(((pyopencv_xfeatures2d_PCTSignatures_t*)self)->v.get());
    float weight=0.f;

    const char* keywords[] = { "weight", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:xfeatures2d_PCTSignatures.setWeightL", (char**)keywords, &weight) )
    {
        ERRWRAP2(_self_->setWeightL(weight));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_setWeightX(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_PCTSignatures_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_PCTSignatures' or its derivative)");
    cv::xfeatures2d::PCTSignatures* _self_ = dynamic_cast<cv::xfeatures2d::PCTSignatures*>(((pyopencv_xfeatures2d_PCTSignatures_t*)self)->v.get());
    float weight=0.f;

    const char* keywords[] = { "weight", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:xfeatures2d_PCTSignatures.setWeightX", (char**)keywords, &weight) )
    {
        ERRWRAP2(_self_->setWeightX(weight));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_setWeightY(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_PCTSignatures_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_PCTSignatures' or its derivative)");
    cv::xfeatures2d::PCTSignatures* _self_ = dynamic_cast<cv::xfeatures2d::PCTSignatures*>(((pyopencv_xfeatures2d_PCTSignatures_t*)self)->v.get());
    float weight=0.f;

    const char* keywords[] = { "weight", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:xfeatures2d_PCTSignatures.setWeightY", (char**)keywords, &weight) )
    {
        ERRWRAP2(_self_->setWeightY(weight));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_setWeights(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_PCTSignatures_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_PCTSignatures' or its derivative)");
    cv::xfeatures2d::PCTSignatures* _self_ = dynamic_cast<cv::xfeatures2d::PCTSignatures*>(((pyopencv_xfeatures2d_PCTSignatures_t*)self)->v.get());
    PyObject* pyobj_weights = NULL;
    vector_float weights;

    const char* keywords[] = { "weights", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:xfeatures2d_PCTSignatures.setWeights", (char**)keywords, &pyobj_weights) &&
        pyopencv_to(pyobj_weights, weights, ArgInfo("weights", 0)) )
    {
        ERRWRAP2(_self_->setWeights(weights));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_setWindowRadius(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_PCTSignatures_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_PCTSignatures' or its derivative)");
    cv::xfeatures2d::PCTSignatures* _self_ = dynamic_cast<cv::xfeatures2d::PCTSignatures*>(((pyopencv_xfeatures2d_PCTSignatures_t*)self)->v.get());
    int radius=0;

    const char* keywords[] = { "radius", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:xfeatures2d_PCTSignatures.setWindowRadius", (char**)keywords, &radius) )
    {
        ERRWRAP2(_self_->setWindowRadius(radius));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_xfeatures2d_PCTSignatures_methods[] =
{
    {"computeSignature", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_computeSignature, METH_VARARGS | METH_KEYWORDS, "computeSignature(image[, signature]) -> signature"},
    {"computeSignatures", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_computeSignatures, METH_VARARGS | METH_KEYWORDS, "computeSignatures(images, signatures) -> None"},
    {"getClusterMinSize", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_getClusterMinSize, METH_VARARGS | METH_KEYWORDS, "getClusterMinSize() -> retval"},
    {"getDistanceFunction", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_getDistanceFunction, METH_VARARGS | METH_KEYWORDS, "getDistanceFunction() -> retval"},
    {"getDropThreshold", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_getDropThreshold, METH_VARARGS | METH_KEYWORDS, "getDropThreshold() -> retval"},
    {"getGrayscaleBits", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_getGrayscaleBits, METH_VARARGS | METH_KEYWORDS, "getGrayscaleBits() -> retval"},
    {"getInitSeedCount", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_getInitSeedCount, METH_VARARGS | METH_KEYWORDS, "getInitSeedCount() -> retval"},
    {"getInitSeedIndexes", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_getInitSeedIndexes, METH_VARARGS | METH_KEYWORDS, "getInitSeedIndexes() -> retval"},
    {"getIterationCount", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_getIterationCount, METH_VARARGS | METH_KEYWORDS, "getIterationCount() -> retval"},
    {"getJoiningDistance", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_getJoiningDistance, METH_VARARGS | METH_KEYWORDS, "getJoiningDistance() -> retval"},
    {"getMaxClustersCount", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_getMaxClustersCount, METH_VARARGS | METH_KEYWORDS, "getMaxClustersCount() -> retval"},
    {"getSampleCount", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_getSampleCount, METH_VARARGS | METH_KEYWORDS, "getSampleCount() -> retval"},
    {"getSamplingPoints", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_getSamplingPoints, METH_VARARGS | METH_KEYWORDS, "getSamplingPoints() -> retval"},
    {"getWeightA", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_getWeightA, METH_VARARGS | METH_KEYWORDS, "getWeightA() -> retval"},
    {"getWeightB", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_getWeightB, METH_VARARGS | METH_KEYWORDS, "getWeightB() -> retval"},
    {"getWeightConstrast", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_getWeightConstrast, METH_VARARGS | METH_KEYWORDS, "getWeightConstrast() -> retval"},
    {"getWeightEntropy", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_getWeightEntropy, METH_VARARGS | METH_KEYWORDS, "getWeightEntropy() -> retval"},
    {"getWeightL", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_getWeightL, METH_VARARGS | METH_KEYWORDS, "getWeightL() -> retval"},
    {"getWeightX", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_getWeightX, METH_VARARGS | METH_KEYWORDS, "getWeightX() -> retval"},
    {"getWeightY", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_getWeightY, METH_VARARGS | METH_KEYWORDS, "getWeightY() -> retval"},
    {"getWindowRadius", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_getWindowRadius, METH_VARARGS | METH_KEYWORDS, "getWindowRadius() -> retval"},
    {"setClusterMinSize", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_setClusterMinSize, METH_VARARGS | METH_KEYWORDS, "setClusterMinSize(clusterMinSize) -> None"},
    {"setDistanceFunction", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_setDistanceFunction, METH_VARARGS | METH_KEYWORDS, "setDistanceFunction(distanceFunction) -> None"},
    {"setDropThreshold", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_setDropThreshold, METH_VARARGS | METH_KEYWORDS, "setDropThreshold(dropThreshold) -> None"},
    {"setGrayscaleBits", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_setGrayscaleBits, METH_VARARGS | METH_KEYWORDS, "setGrayscaleBits(grayscaleBits) -> None"},
    {"setInitSeedIndexes", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_setInitSeedIndexes, METH_VARARGS | METH_KEYWORDS, "setInitSeedIndexes(initSeedIndexes) -> None"},
    {"setIterationCount", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_setIterationCount, METH_VARARGS | METH_KEYWORDS, "setIterationCount(iterationCount) -> None"},
    {"setJoiningDistance", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_setJoiningDistance, METH_VARARGS | METH_KEYWORDS, "setJoiningDistance(joiningDistance) -> None"},
    {"setMaxClustersCount", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_setMaxClustersCount, METH_VARARGS | METH_KEYWORDS, "setMaxClustersCount(maxClustersCount) -> None"},
    {"setSamplingPoints", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_setSamplingPoints, METH_VARARGS | METH_KEYWORDS, "setSamplingPoints(samplingPoints) -> None"},
    {"setTranslation", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_setTranslation, METH_VARARGS | METH_KEYWORDS, "setTranslation(idx, value) -> None"},
    {"setTranslations", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_setTranslations, METH_VARARGS | METH_KEYWORDS, "setTranslations(translations) -> None"},
    {"setWeight", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_setWeight, METH_VARARGS | METH_KEYWORDS, "setWeight(idx, value) -> None"},
    {"setWeightA", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_setWeightA, METH_VARARGS | METH_KEYWORDS, "setWeightA(weight) -> None"},
    {"setWeightB", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_setWeightB, METH_VARARGS | METH_KEYWORDS, "setWeightB(weight) -> None"},
    {"setWeightContrast", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_setWeightContrast, METH_VARARGS | METH_KEYWORDS, "setWeightContrast(weight) -> None"},
    {"setWeightEntropy", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_setWeightEntropy, METH_VARARGS | METH_KEYWORDS, "setWeightEntropy(weight) -> None"},
    {"setWeightL", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_setWeightL, METH_VARARGS | METH_KEYWORDS, "setWeightL(weight) -> None"},
    {"setWeightX", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_setWeightX, METH_VARARGS | METH_KEYWORDS, "setWeightX(weight) -> None"},
    {"setWeightY", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_setWeightY, METH_VARARGS | METH_KEYWORDS, "setWeightY(weight) -> None"},
    {"setWeights", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_setWeights, METH_VARARGS | METH_KEYWORDS, "setWeights(weights) -> None"},
    {"setWindowRadius", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignatures_setWindowRadius, METH_VARARGS | METH_KEYWORDS, "setWindowRadius(radius) -> None"},

    {NULL,          NULL}
};

static void pyopencv_xfeatures2d_PCTSignatures_specials(void)
{
    pyopencv_xfeatures2d_PCTSignatures_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_xfeatures2d_PCTSignatures_Type.tp_dealloc = pyopencv_xfeatures2d_PCTSignatures_dealloc;
    pyopencv_xfeatures2d_PCTSignatures_Type.tp_repr = pyopencv_xfeatures2d_PCTSignatures_repr;
    pyopencv_xfeatures2d_PCTSignatures_Type.tp_getset = pyopencv_xfeatures2d_PCTSignatures_getseters;
    pyopencv_xfeatures2d_PCTSignatures_Type.tp_methods = pyopencv_xfeatures2d_PCTSignatures_methods;
}

static PyObject* pyopencv_xfeatures2d_PCTSignaturesSQFD_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<xfeatures2d_PCTSignaturesSQFD %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_xfeatures2d_PCTSignaturesSQFD_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignaturesSQFD_computeQuadraticFormDistance(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_PCTSignaturesSQFD_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_PCTSignaturesSQFD' or its derivative)");
    cv::xfeatures2d::PCTSignaturesSQFD* _self_ = dynamic_cast<cv::xfeatures2d::PCTSignaturesSQFD*>(((pyopencv_xfeatures2d_PCTSignaturesSQFD_t*)self)->v.get());
    {
    PyObject* pyobj__signature0 = NULL;
    Mat _signature0;
    PyObject* pyobj__signature1 = NULL;
    Mat _signature1;
    float retval;

    const char* keywords[] = { "_signature0", "_signature1", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO:xfeatures2d_PCTSignaturesSQFD.computeQuadraticFormDistance", (char**)keywords, &pyobj__signature0, &pyobj__signature1) &&
        pyopencv_to(pyobj__signature0, _signature0, ArgInfo("_signature0", 0)) &&
        pyopencv_to(pyobj__signature1, _signature1, ArgInfo("_signature1", 0)) )
    {
        ERRWRAP2(retval = _self_->computeQuadraticFormDistance(_signature0, _signature1));
        return pyopencv_from(retval);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj__signature0 = NULL;
    UMat _signature0;
    PyObject* pyobj__signature1 = NULL;
    UMat _signature1;
    float retval;

    const char* keywords[] = { "_signature0", "_signature1", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO:xfeatures2d_PCTSignaturesSQFD.computeQuadraticFormDistance", (char**)keywords, &pyobj__signature0, &pyobj__signature1) &&
        pyopencv_to(pyobj__signature0, _signature0, ArgInfo("_signature0", 0)) &&
        pyopencv_to(pyobj__signature1, _signature1, ArgInfo("_signature1", 0)) )
    {
        ERRWRAP2(retval = _self_->computeQuadraticFormDistance(_signature0, _signature1));
        return pyopencv_from(retval);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignaturesSQFD_computeQuadraticFormDistances(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_PCTSignaturesSQFD_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_PCTSignaturesSQFD' or its derivative)");
    cv::xfeatures2d::PCTSignaturesSQFD* _self_ = dynamic_cast<cv::xfeatures2d::PCTSignaturesSQFD*>(((pyopencv_xfeatures2d_PCTSignaturesSQFD_t*)self)->v.get());
    {
    PyObject* pyobj_sourceSignature = NULL;
    Mat sourceSignature;
    PyObject* pyobj_imageSignatures = NULL;
    vector_Mat imageSignatures;
    PyObject* pyobj_distances = NULL;
    vector_float distances;

    const char* keywords[] = { "sourceSignature", "imageSignatures", "distances", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OOO:xfeatures2d_PCTSignaturesSQFD.computeQuadraticFormDistances", (char**)keywords, &pyobj_sourceSignature, &pyobj_imageSignatures, &pyobj_distances) &&
        pyopencv_to(pyobj_sourceSignature, sourceSignature, ArgInfo("sourceSignature", 0)) &&
        pyopencv_to(pyobj_imageSignatures, imageSignatures, ArgInfo("imageSignatures", 0)) &&
        pyopencv_to(pyobj_distances, distances, ArgInfo("distances", 0)) )
    {
        ERRWRAP2(_self_->computeQuadraticFormDistances(sourceSignature, imageSignatures, distances));
        Py_RETURN_NONE;
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_sourceSignature = NULL;
    Mat sourceSignature;
    PyObject* pyobj_imageSignatures = NULL;
    vector_Mat imageSignatures;
    PyObject* pyobj_distances = NULL;
    vector_float distances;

    const char* keywords[] = { "sourceSignature", "imageSignatures", "distances", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OOO:xfeatures2d_PCTSignaturesSQFD.computeQuadraticFormDistances", (char**)keywords, &pyobj_sourceSignature, &pyobj_imageSignatures, &pyobj_distances) &&
        pyopencv_to(pyobj_sourceSignature, sourceSignature, ArgInfo("sourceSignature", 0)) &&
        pyopencv_to(pyobj_imageSignatures, imageSignatures, ArgInfo("imageSignatures", 0)) &&
        pyopencv_to(pyobj_distances, distances, ArgInfo("distances", 0)) )
    {
        ERRWRAP2(_self_->computeQuadraticFormDistances(sourceSignature, imageSignatures, distances));
        Py_RETURN_NONE;
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_xfeatures2d_PCTSignaturesSQFD_methods[] =
{
    {"computeQuadraticFormDistance", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignaturesSQFD_computeQuadraticFormDistance, METH_VARARGS | METH_KEYWORDS, "computeQuadraticFormDistance(_signature0, _signature1) -> retval"},
    {"computeQuadraticFormDistances", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_PCTSignaturesSQFD_computeQuadraticFormDistances, METH_VARARGS | METH_KEYWORDS, "computeQuadraticFormDistances(sourceSignature, imageSignatures, distances) -> None"},

    {NULL,          NULL}
};

static void pyopencv_xfeatures2d_PCTSignaturesSQFD_specials(void)
{
    pyopencv_xfeatures2d_PCTSignaturesSQFD_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_xfeatures2d_PCTSignaturesSQFD_Type.tp_dealloc = pyopencv_xfeatures2d_PCTSignaturesSQFD_dealloc;
    pyopencv_xfeatures2d_PCTSignaturesSQFD_Type.tp_repr = pyopencv_xfeatures2d_PCTSignaturesSQFD_repr;
    pyopencv_xfeatures2d_PCTSignaturesSQFD_Type.tp_getset = pyopencv_xfeatures2d_PCTSignaturesSQFD_getseters;
    pyopencv_xfeatures2d_PCTSignaturesSQFD_Type.tp_methods = pyopencv_xfeatures2d_PCTSignaturesSQFD_methods;
}

static PyObject* pyopencv_xfeatures2d_HarrisLaplaceFeatureDetector_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<xfeatures2d_HarrisLaplaceFeatureDetector %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_xfeatures2d_HarrisLaplaceFeatureDetector_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_xfeatures2d_HarrisLaplaceFeatureDetector_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_xfeatures2d_HarrisLaplaceFeatureDetector_specials(void)
{
    pyopencv_xfeatures2d_HarrisLaplaceFeatureDetector_Type.tp_base = &pyopencv_Feature2D_Type;
    pyopencv_xfeatures2d_HarrisLaplaceFeatureDetector_Type.tp_dealloc = pyopencv_xfeatures2d_HarrisLaplaceFeatureDetector_dealloc;
    pyopencv_xfeatures2d_HarrisLaplaceFeatureDetector_Type.tp_repr = pyopencv_xfeatures2d_HarrisLaplaceFeatureDetector_repr;
    pyopencv_xfeatures2d_HarrisLaplaceFeatureDetector_Type.tp_getset = pyopencv_xfeatures2d_HarrisLaplaceFeatureDetector_getseters;
    pyopencv_xfeatures2d_HarrisLaplaceFeatureDetector_Type.tp_methods = pyopencv_xfeatures2d_HarrisLaplaceFeatureDetector_methods;
}

static PyObject* pyopencv_xfeatures2d_SIFT_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<xfeatures2d_SIFT %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_xfeatures2d_SIFT_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_xfeatures2d_SIFT_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_xfeatures2d_SIFT_specials(void)
{
    pyopencv_xfeatures2d_SIFT_Type.tp_base = &pyopencv_Feature2D_Type;
    pyopencv_xfeatures2d_SIFT_Type.tp_dealloc = pyopencv_xfeatures2d_SIFT_dealloc;
    pyopencv_xfeatures2d_SIFT_Type.tp_repr = pyopencv_xfeatures2d_SIFT_repr;
    pyopencv_xfeatures2d_SIFT_Type.tp_getset = pyopencv_xfeatures2d_SIFT_getseters;
    pyopencv_xfeatures2d_SIFT_Type.tp_methods = pyopencv_xfeatures2d_SIFT_methods;
}

static PyObject* pyopencv_xfeatures2d_SURF_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<xfeatures2d_SURF %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_xfeatures2d_SURF_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_SURF_getExtended(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_SURF_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_SURF' or its derivative)");
    cv::xfeatures2d::SURF* _self_ = dynamic_cast<cv::xfeatures2d::SURF*>(((pyopencv_xfeatures2d_SURF_t*)self)->v.get());
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getExtended());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_SURF_getHessianThreshold(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_SURF_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_SURF' or its derivative)");
    cv::xfeatures2d::SURF* _self_ = dynamic_cast<cv::xfeatures2d::SURF*>(((pyopencv_xfeatures2d_SURF_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getHessianThreshold());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_SURF_getNOctaveLayers(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_SURF_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_SURF' or its derivative)");
    cv::xfeatures2d::SURF* _self_ = dynamic_cast<cv::xfeatures2d::SURF*>(((pyopencv_xfeatures2d_SURF_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getNOctaveLayers());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_SURF_getNOctaves(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_SURF_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_SURF' or its derivative)");
    cv::xfeatures2d::SURF* _self_ = dynamic_cast<cv::xfeatures2d::SURF*>(((pyopencv_xfeatures2d_SURF_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getNOctaves());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_SURF_getUpright(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_SURF_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_SURF' or its derivative)");
    cv::xfeatures2d::SURF* _self_ = dynamic_cast<cv::xfeatures2d::SURF*>(((pyopencv_xfeatures2d_SURF_t*)self)->v.get());
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getUpright());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_SURF_setExtended(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_SURF_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_SURF' or its derivative)");
    cv::xfeatures2d::SURF* _self_ = dynamic_cast<cv::xfeatures2d::SURF*>(((pyopencv_xfeatures2d_SURF_t*)self)->v.get());
    bool extended=0;

    const char* keywords[] = { "extended", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "b:xfeatures2d_SURF.setExtended", (char**)keywords, &extended) )
    {
        ERRWRAP2(_self_->setExtended(extended));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_SURF_setHessianThreshold(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_SURF_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_SURF' or its derivative)");
    cv::xfeatures2d::SURF* _self_ = dynamic_cast<cv::xfeatures2d::SURF*>(((pyopencv_xfeatures2d_SURF_t*)self)->v.get());
    double hessianThreshold=0;

    const char* keywords[] = { "hessianThreshold", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:xfeatures2d_SURF.setHessianThreshold", (char**)keywords, &hessianThreshold) )
    {
        ERRWRAP2(_self_->setHessianThreshold(hessianThreshold));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_SURF_setNOctaveLayers(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_SURF_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_SURF' or its derivative)");
    cv::xfeatures2d::SURF* _self_ = dynamic_cast<cv::xfeatures2d::SURF*>(((pyopencv_xfeatures2d_SURF_t*)self)->v.get());
    int nOctaveLayers=0;

    const char* keywords[] = { "nOctaveLayers", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:xfeatures2d_SURF.setNOctaveLayers", (char**)keywords, &nOctaveLayers) )
    {
        ERRWRAP2(_self_->setNOctaveLayers(nOctaveLayers));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_SURF_setNOctaves(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_SURF_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_SURF' or its derivative)");
    cv::xfeatures2d::SURF* _self_ = dynamic_cast<cv::xfeatures2d::SURF*>(((pyopencv_xfeatures2d_SURF_t*)self)->v.get());
    int nOctaves=0;

    const char* keywords[] = { "nOctaves", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:xfeatures2d_SURF.setNOctaves", (char**)keywords, &nOctaves) )
    {
        ERRWRAP2(_self_->setNOctaves(nOctaves));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_xfeatures2d_SURF_setUpright(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    if(!PyObject_TypeCheck(self, &pyopencv_xfeatures2d_SURF_Type))
        return failmsgp("Incorrect type of self (must be 'xfeatures2d_SURF' or its derivative)");
    cv::xfeatures2d::SURF* _self_ = dynamic_cast<cv::xfeatures2d::SURF*>(((pyopencv_xfeatures2d_SURF_t*)self)->v.get());
    bool upright=0;

    const char* keywords[] = { "upright", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "b:xfeatures2d_SURF.setUpright", (char**)keywords, &upright) )
    {
        ERRWRAP2(_self_->setUpright(upright));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_xfeatures2d_SURF_methods[] =
{
    {"getExtended", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_SURF_getExtended, METH_VARARGS | METH_KEYWORDS, "getExtended() -> retval"},
    {"getHessianThreshold", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_SURF_getHessianThreshold, METH_VARARGS | METH_KEYWORDS, "getHessianThreshold() -> retval"},
    {"getNOctaveLayers", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_SURF_getNOctaveLayers, METH_VARARGS | METH_KEYWORDS, "getNOctaveLayers() -> retval"},
    {"getNOctaves", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_SURF_getNOctaves, METH_VARARGS | METH_KEYWORDS, "getNOctaves() -> retval"},
    {"getUpright", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_SURF_getUpright, METH_VARARGS | METH_KEYWORDS, "getUpright() -> retval"},
    {"setExtended", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_SURF_setExtended, METH_VARARGS | METH_KEYWORDS, "setExtended(extended) -> None"},
    {"setHessianThreshold", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_SURF_setHessianThreshold, METH_VARARGS | METH_KEYWORDS, "setHessianThreshold(hessianThreshold) -> None"},
    {"setNOctaveLayers", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_SURF_setNOctaveLayers, METH_VARARGS | METH_KEYWORDS, "setNOctaveLayers(nOctaveLayers) -> None"},
    {"setNOctaves", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_SURF_setNOctaves, METH_VARARGS | METH_KEYWORDS, "setNOctaves(nOctaves) -> None"},
    {"setUpright", (PyCFunction)pyopencv_cv_xfeatures2d_xfeatures2d_SURF_setUpright, METH_VARARGS | METH_KEYWORDS, "setUpright(upright) -> None"},

    {NULL,          NULL}
};

static void pyopencv_xfeatures2d_SURF_specials(void)
{
    pyopencv_xfeatures2d_SURF_Type.tp_base = &pyopencv_Feature2D_Type;
    pyopencv_xfeatures2d_SURF_Type.tp_dealloc = pyopencv_xfeatures2d_SURF_dealloc;
    pyopencv_xfeatures2d_SURF_Type.tp_repr = pyopencv_xfeatures2d_SURF_repr;
    pyopencv_xfeatures2d_SURF_Type.tp_getset = pyopencv_xfeatures2d_SURF_getseters;
    pyopencv_xfeatures2d_SURF_Type.tp_methods = pyopencv_xfeatures2d_SURF_methods;
}

static PyObject* pyopencv_ximgproc_DisparityFilter_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<ximgproc_DisparityFilter %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_ximgproc_DisparityFilter_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_ximgproc_ximgproc_DisparityFilter_filter(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_DisparityFilter_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_DisparityFilter' or its derivative)");
    cv::ximgproc::DisparityFilter* _self_ = dynamic_cast<cv::ximgproc::DisparityFilter*>(((pyopencv_ximgproc_DisparityFilter_t*)self)->v.get());
    {
    PyObject* pyobj_disparity_map_left = NULL;
    Mat disparity_map_left;
    PyObject* pyobj_left_view = NULL;
    Mat left_view;
    PyObject* pyobj_filtered_disparity_map = NULL;
    Mat filtered_disparity_map;
    PyObject* pyobj_disparity_map_right = NULL;
    Mat disparity_map_right;
    PyObject* pyobj_ROI = NULL;
    Rect ROI;
    PyObject* pyobj_right_view = NULL;
    Mat right_view;

    const char* keywords[] = { "disparity_map_left", "left_view", "filtered_disparity_map", "disparity_map_right", "ROI", "right_view", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|OOOO:ximgproc_DisparityFilter.filter", (char**)keywords, &pyobj_disparity_map_left, &pyobj_left_view, &pyobj_filtered_disparity_map, &pyobj_disparity_map_right, &pyobj_ROI, &pyobj_right_view) &&
        pyopencv_to(pyobj_disparity_map_left, disparity_map_left, ArgInfo("disparity_map_left", 0)) &&
        pyopencv_to(pyobj_left_view, left_view, ArgInfo("left_view", 0)) &&
        pyopencv_to(pyobj_filtered_disparity_map, filtered_disparity_map, ArgInfo("filtered_disparity_map", 1)) &&
        pyopencv_to(pyobj_disparity_map_right, disparity_map_right, ArgInfo("disparity_map_right", 0)) &&
        pyopencv_to(pyobj_ROI, ROI, ArgInfo("ROI", 0)) &&
        pyopencv_to(pyobj_right_view, right_view, ArgInfo("right_view", 0)) )
    {
        ERRWRAP2(_self_->filter(disparity_map_left, left_view, filtered_disparity_map, disparity_map_right, ROI, right_view));
        return pyopencv_from(filtered_disparity_map);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_disparity_map_left = NULL;
    UMat disparity_map_left;
    PyObject* pyobj_left_view = NULL;
    UMat left_view;
    PyObject* pyobj_filtered_disparity_map = NULL;
    UMat filtered_disparity_map;
    PyObject* pyobj_disparity_map_right = NULL;
    UMat disparity_map_right;
    PyObject* pyobj_ROI = NULL;
    Rect ROI;
    PyObject* pyobj_right_view = NULL;
    UMat right_view;

    const char* keywords[] = { "disparity_map_left", "left_view", "filtered_disparity_map", "disparity_map_right", "ROI", "right_view", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|OOOO:ximgproc_DisparityFilter.filter", (char**)keywords, &pyobj_disparity_map_left, &pyobj_left_view, &pyobj_filtered_disparity_map, &pyobj_disparity_map_right, &pyobj_ROI, &pyobj_right_view) &&
        pyopencv_to(pyobj_disparity_map_left, disparity_map_left, ArgInfo("disparity_map_left", 0)) &&
        pyopencv_to(pyobj_left_view, left_view, ArgInfo("left_view", 0)) &&
        pyopencv_to(pyobj_filtered_disparity_map, filtered_disparity_map, ArgInfo("filtered_disparity_map", 1)) &&
        pyopencv_to(pyobj_disparity_map_right, disparity_map_right, ArgInfo("disparity_map_right", 0)) &&
        pyopencv_to(pyobj_ROI, ROI, ArgInfo("ROI", 0)) &&
        pyopencv_to(pyobj_right_view, right_view, ArgInfo("right_view", 0)) )
    {
        ERRWRAP2(_self_->filter(disparity_map_left, left_view, filtered_disparity_map, disparity_map_right, ROI, right_view));
        return pyopencv_from(filtered_disparity_map);
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_ximgproc_DisparityFilter_methods[] =
{
    {"filter", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_DisparityFilter_filter, METH_VARARGS | METH_KEYWORDS, "filter(disparity_map_left, left_view[, filtered_disparity_map[, disparity_map_right[, ROI[, right_view]]]]) -> filtered_disparity_map"},

    {NULL,          NULL}
};

static void pyopencv_ximgproc_DisparityFilter_specials(void)
{
    pyopencv_ximgproc_DisparityFilter_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_ximgproc_DisparityFilter_Type.tp_dealloc = pyopencv_ximgproc_DisparityFilter_dealloc;
    pyopencv_ximgproc_DisparityFilter_Type.tp_repr = pyopencv_ximgproc_DisparityFilter_repr;
    pyopencv_ximgproc_DisparityFilter_Type.tp_getset = pyopencv_ximgproc_DisparityFilter_getseters;
    pyopencv_ximgproc_DisparityFilter_Type.tp_methods = pyopencv_ximgproc_DisparityFilter_methods;
}

static PyObject* pyopencv_ximgproc_DisparityWLSFilter_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<ximgproc_DisparityWLSFilter %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_ximgproc_DisparityWLSFilter_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_ximgproc_ximgproc_DisparityWLSFilter_getConfidenceMap(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_DisparityWLSFilter_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_DisparityWLSFilter' or its derivative)");
    cv::ximgproc::DisparityWLSFilter* _self_ = dynamic_cast<cv::ximgproc::DisparityWLSFilter*>(((pyopencv_ximgproc_DisparityWLSFilter_t*)self)->v.get());
    Mat retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getConfidenceMap());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_ximgproc_DisparityWLSFilter_getDepthDiscontinuityRadius(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_DisparityWLSFilter_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_DisparityWLSFilter' or its derivative)");
    cv::ximgproc::DisparityWLSFilter* _self_ = dynamic_cast<cv::ximgproc::DisparityWLSFilter*>(((pyopencv_ximgproc_DisparityWLSFilter_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getDepthDiscontinuityRadius());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_ximgproc_DisparityWLSFilter_getLRCthresh(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_DisparityWLSFilter_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_DisparityWLSFilter' or its derivative)");
    cv::ximgproc::DisparityWLSFilter* _self_ = dynamic_cast<cv::ximgproc::DisparityWLSFilter*>(((pyopencv_ximgproc_DisparityWLSFilter_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getLRCthresh());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_ximgproc_DisparityWLSFilter_getLambda(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_DisparityWLSFilter_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_DisparityWLSFilter' or its derivative)");
    cv::ximgproc::DisparityWLSFilter* _self_ = dynamic_cast<cv::ximgproc::DisparityWLSFilter*>(((pyopencv_ximgproc_DisparityWLSFilter_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getLambda());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_ximgproc_DisparityWLSFilter_getROI(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_DisparityWLSFilter_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_DisparityWLSFilter' or its derivative)");
    cv::ximgproc::DisparityWLSFilter* _self_ = dynamic_cast<cv::ximgproc::DisparityWLSFilter*>(((pyopencv_ximgproc_DisparityWLSFilter_t*)self)->v.get());
    Rect retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getROI());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_ximgproc_DisparityWLSFilter_getSigmaColor(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_DisparityWLSFilter_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_DisparityWLSFilter' or its derivative)");
    cv::ximgproc::DisparityWLSFilter* _self_ = dynamic_cast<cv::ximgproc::DisparityWLSFilter*>(((pyopencv_ximgproc_DisparityWLSFilter_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getSigmaColor());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_ximgproc_DisparityWLSFilter_setDepthDiscontinuityRadius(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_DisparityWLSFilter_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_DisparityWLSFilter' or its derivative)");
    cv::ximgproc::DisparityWLSFilter* _self_ = dynamic_cast<cv::ximgproc::DisparityWLSFilter*>(((pyopencv_ximgproc_DisparityWLSFilter_t*)self)->v.get());
    int _disc_radius=0;

    const char* keywords[] = { "_disc_radius", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:ximgproc_DisparityWLSFilter.setDepthDiscontinuityRadius", (char**)keywords, &_disc_radius) )
    {
        ERRWRAP2(_self_->setDepthDiscontinuityRadius(_disc_radius));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_ximgproc_DisparityWLSFilter_setLRCthresh(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_DisparityWLSFilter_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_DisparityWLSFilter' or its derivative)");
    cv::ximgproc::DisparityWLSFilter* _self_ = dynamic_cast<cv::ximgproc::DisparityWLSFilter*>(((pyopencv_ximgproc_DisparityWLSFilter_t*)self)->v.get());
    int _LRC_thresh=0;

    const char* keywords[] = { "_LRC_thresh", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:ximgproc_DisparityWLSFilter.setLRCthresh", (char**)keywords, &_LRC_thresh) )
    {
        ERRWRAP2(_self_->setLRCthresh(_LRC_thresh));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_ximgproc_DisparityWLSFilter_setLambda(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_DisparityWLSFilter_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_DisparityWLSFilter' or its derivative)");
    cv::ximgproc::DisparityWLSFilter* _self_ = dynamic_cast<cv::ximgproc::DisparityWLSFilter*>(((pyopencv_ximgproc_DisparityWLSFilter_t*)self)->v.get());
    double _lambda=0;

    const char* keywords[] = { "_lambda", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:ximgproc_DisparityWLSFilter.setLambda", (char**)keywords, &_lambda) )
    {
        ERRWRAP2(_self_->setLambda(_lambda));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_ximgproc_DisparityWLSFilter_setSigmaColor(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_DisparityWLSFilter_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_DisparityWLSFilter' or its derivative)");
    cv::ximgproc::DisparityWLSFilter* _self_ = dynamic_cast<cv::ximgproc::DisparityWLSFilter*>(((pyopencv_ximgproc_DisparityWLSFilter_t*)self)->v.get());
    double _sigma_color=0;

    const char* keywords[] = { "_sigma_color", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:ximgproc_DisparityWLSFilter.setSigmaColor", (char**)keywords, &_sigma_color) )
    {
        ERRWRAP2(_self_->setSigmaColor(_sigma_color));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_ximgproc_DisparityWLSFilter_methods[] =
{
    {"getConfidenceMap", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_DisparityWLSFilter_getConfidenceMap, METH_VARARGS | METH_KEYWORDS, "getConfidenceMap() -> retval"},
    {"getDepthDiscontinuityRadius", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_DisparityWLSFilter_getDepthDiscontinuityRadius, METH_VARARGS | METH_KEYWORDS, "getDepthDiscontinuityRadius() -> retval"},
    {"getLRCthresh", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_DisparityWLSFilter_getLRCthresh, METH_VARARGS | METH_KEYWORDS, "getLRCthresh() -> retval"},
    {"getLambda", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_DisparityWLSFilter_getLambda, METH_VARARGS | METH_KEYWORDS, "getLambda() -> retval"},
    {"getROI", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_DisparityWLSFilter_getROI, METH_VARARGS | METH_KEYWORDS, "getROI() -> retval"},
    {"getSigmaColor", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_DisparityWLSFilter_getSigmaColor, METH_VARARGS | METH_KEYWORDS, "getSigmaColor() -> retval"},
    {"setDepthDiscontinuityRadius", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_DisparityWLSFilter_setDepthDiscontinuityRadius, METH_VARARGS | METH_KEYWORDS, "setDepthDiscontinuityRadius(_disc_radius) -> None"},
    {"setLRCthresh", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_DisparityWLSFilter_setLRCthresh, METH_VARARGS | METH_KEYWORDS, "setLRCthresh(_LRC_thresh) -> None"},
    {"setLambda", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_DisparityWLSFilter_setLambda, METH_VARARGS | METH_KEYWORDS, "setLambda(_lambda) -> None"},
    {"setSigmaColor", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_DisparityWLSFilter_setSigmaColor, METH_VARARGS | METH_KEYWORDS, "setSigmaColor(_sigma_color) -> None"},

    {NULL,          NULL}
};

static void pyopencv_ximgproc_DisparityWLSFilter_specials(void)
{
    pyopencv_ximgproc_DisparityWLSFilter_Type.tp_base = &pyopencv_ximgproc_DisparityFilter_Type;
    pyopencv_ximgproc_DisparityWLSFilter_Type.tp_dealloc = pyopencv_ximgproc_DisparityWLSFilter_dealloc;
    pyopencv_ximgproc_DisparityWLSFilter_Type.tp_repr = pyopencv_ximgproc_DisparityWLSFilter_repr;
    pyopencv_ximgproc_DisparityWLSFilter_Type.tp_getset = pyopencv_ximgproc_DisparityWLSFilter_getseters;
    pyopencv_ximgproc_DisparityWLSFilter_Type.tp_methods = pyopencv_ximgproc_DisparityWLSFilter_methods;
}

static PyObject* pyopencv_ximgproc_DTFilter_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<ximgproc_DTFilter %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_ximgproc_DTFilter_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_ximgproc_ximgproc_DTFilter_filter(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_DTFilter_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_DTFilter' or its derivative)");
    cv::ximgproc::DTFilter* _self_ = dynamic_cast<cv::ximgproc::DTFilter*>(((pyopencv_ximgproc_DTFilter_t*)self)->v.get());
    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    int dDepth=-1;

    const char* keywords[] = { "src", "dst", "dDepth", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|Oi:ximgproc_DTFilter.filter", (char**)keywords, &pyobj_src, &pyobj_dst, &dDepth) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(_self_->filter(src, dst, dDepth));
        return pyopencv_from(dst);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    int dDepth=-1;

    const char* keywords[] = { "src", "dst", "dDepth", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|Oi:ximgproc_DTFilter.filter", (char**)keywords, &pyobj_src, &pyobj_dst, &dDepth) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(_self_->filter(src, dst, dDepth));
        return pyopencv_from(dst);
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_ximgproc_DTFilter_methods[] =
{
    {"filter", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_DTFilter_filter, METH_VARARGS | METH_KEYWORDS, "filter(src[, dst[, dDepth]]) -> dst"},

    {NULL,          NULL}
};

static void pyopencv_ximgproc_DTFilter_specials(void)
{
    pyopencv_ximgproc_DTFilter_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_ximgproc_DTFilter_Type.tp_dealloc = pyopencv_ximgproc_DTFilter_dealloc;
    pyopencv_ximgproc_DTFilter_Type.tp_repr = pyopencv_ximgproc_DTFilter_repr;
    pyopencv_ximgproc_DTFilter_Type.tp_getset = pyopencv_ximgproc_DTFilter_getseters;
    pyopencv_ximgproc_DTFilter_Type.tp_methods = pyopencv_ximgproc_DTFilter_methods;
}

static PyObject* pyopencv_ximgproc_GuidedFilter_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<ximgproc_GuidedFilter %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_ximgproc_GuidedFilter_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_ximgproc_ximgproc_GuidedFilter_filter(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_GuidedFilter_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_GuidedFilter' or its derivative)");
    cv::ximgproc::GuidedFilter* _self_ = dynamic_cast<cv::ximgproc::GuidedFilter*>(((pyopencv_ximgproc_GuidedFilter_t*)self)->v.get());
    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    int dDepth=-1;

    const char* keywords[] = { "src", "dst", "dDepth", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|Oi:ximgproc_GuidedFilter.filter", (char**)keywords, &pyobj_src, &pyobj_dst, &dDepth) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(_self_->filter(src, dst, dDepth));
        return pyopencv_from(dst);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    int dDepth=-1;

    const char* keywords[] = { "src", "dst", "dDepth", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|Oi:ximgproc_GuidedFilter.filter", (char**)keywords, &pyobj_src, &pyobj_dst, &dDepth) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(_self_->filter(src, dst, dDepth));
        return pyopencv_from(dst);
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_ximgproc_GuidedFilter_methods[] =
{
    {"filter", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_GuidedFilter_filter, METH_VARARGS | METH_KEYWORDS, "filter(src[, dst[, dDepth]]) -> dst"},

    {NULL,          NULL}
};

static void pyopencv_ximgproc_GuidedFilter_specials(void)
{
    pyopencv_ximgproc_GuidedFilter_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_ximgproc_GuidedFilter_Type.tp_dealloc = pyopencv_ximgproc_GuidedFilter_dealloc;
    pyopencv_ximgproc_GuidedFilter_Type.tp_repr = pyopencv_ximgproc_GuidedFilter_repr;
    pyopencv_ximgproc_GuidedFilter_Type.tp_getset = pyopencv_ximgproc_GuidedFilter_getseters;
    pyopencv_ximgproc_GuidedFilter_Type.tp_methods = pyopencv_ximgproc_GuidedFilter_methods;
}

static PyObject* pyopencv_ximgproc_AdaptiveManifoldFilter_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<ximgproc_AdaptiveManifoldFilter %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_ximgproc_AdaptiveManifoldFilter_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_ximgproc_ximgproc_AdaptiveManifoldFilter_collectGarbage(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_AdaptiveManifoldFilter_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_AdaptiveManifoldFilter' or its derivative)");
    cv::ximgproc::AdaptiveManifoldFilter* _self_ = dynamic_cast<cv::ximgproc::AdaptiveManifoldFilter*>(((pyopencv_ximgproc_AdaptiveManifoldFilter_t*)self)->v.get());

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(_self_->collectGarbage());
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_ximgproc_AdaptiveManifoldFilter_filter(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_AdaptiveManifoldFilter_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_AdaptiveManifoldFilter' or its derivative)");
    cv::ximgproc::AdaptiveManifoldFilter* _self_ = dynamic_cast<cv::ximgproc::AdaptiveManifoldFilter*>(((pyopencv_ximgproc_AdaptiveManifoldFilter_t*)self)->v.get());
    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_joint = NULL;
    Mat joint;

    const char* keywords[] = { "src", "dst", "joint", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|OO:ximgproc_AdaptiveManifoldFilter.filter", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_joint) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to(pyobj_joint, joint, ArgInfo("joint", 0)) )
    {
        ERRWRAP2(_self_->filter(src, dst, joint));
        return pyopencv_from(dst);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_joint = NULL;
    UMat joint;

    const char* keywords[] = { "src", "dst", "joint", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|OO:ximgproc_AdaptiveManifoldFilter.filter", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_joint) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to(pyobj_joint, joint, ArgInfo("joint", 0)) )
    {
        ERRWRAP2(_self_->filter(src, dst, joint));
        return pyopencv_from(dst);
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_ximgproc_AdaptiveManifoldFilter_methods[] =
{
    {"collectGarbage", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_AdaptiveManifoldFilter_collectGarbage, METH_VARARGS | METH_KEYWORDS, "collectGarbage() -> None"},
    {"filter", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_AdaptiveManifoldFilter_filter, METH_VARARGS | METH_KEYWORDS, "filter(src[, dst[, joint]]) -> dst"},

    {NULL,          NULL}
};

static void pyopencv_ximgproc_AdaptiveManifoldFilter_specials(void)
{
    pyopencv_ximgproc_AdaptiveManifoldFilter_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_ximgproc_AdaptiveManifoldFilter_Type.tp_dealloc = pyopencv_ximgproc_AdaptiveManifoldFilter_dealloc;
    pyopencv_ximgproc_AdaptiveManifoldFilter_Type.tp_repr = pyopencv_ximgproc_AdaptiveManifoldFilter_repr;
    pyopencv_ximgproc_AdaptiveManifoldFilter_Type.tp_getset = pyopencv_ximgproc_AdaptiveManifoldFilter_getseters;
    pyopencv_ximgproc_AdaptiveManifoldFilter_Type.tp_methods = pyopencv_ximgproc_AdaptiveManifoldFilter_methods;
}

static PyObject* pyopencv_ximgproc_FastGlobalSmootherFilter_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<ximgproc_FastGlobalSmootherFilter %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_ximgproc_FastGlobalSmootherFilter_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_ximgproc_ximgproc_FastGlobalSmootherFilter_filter(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_FastGlobalSmootherFilter_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_FastGlobalSmootherFilter' or its derivative)");
    cv::ximgproc::FastGlobalSmootherFilter* _self_ = dynamic_cast<cv::ximgproc::FastGlobalSmootherFilter*>(((pyopencv_ximgproc_FastGlobalSmootherFilter_t*)self)->v.get());
    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;

    const char* keywords[] = { "src", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:ximgproc_FastGlobalSmootherFilter.filter", (char**)keywords, &pyobj_src, &pyobj_dst) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(_self_->filter(src, dst));
        return pyopencv_from(dst);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;

    const char* keywords[] = { "src", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:ximgproc_FastGlobalSmootherFilter.filter", (char**)keywords, &pyobj_src, &pyobj_dst) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(_self_->filter(src, dst));
        return pyopencv_from(dst);
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_ximgproc_FastGlobalSmootherFilter_methods[] =
{
    {"filter", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_FastGlobalSmootherFilter_filter, METH_VARARGS | METH_KEYWORDS, "filter(src[, dst]) -> dst"},

    {NULL,          NULL}
};

static void pyopencv_ximgproc_FastGlobalSmootherFilter_specials(void)
{
    pyopencv_ximgproc_FastGlobalSmootherFilter_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_ximgproc_FastGlobalSmootherFilter_Type.tp_dealloc = pyopencv_ximgproc_FastGlobalSmootherFilter_dealloc;
    pyopencv_ximgproc_FastGlobalSmootherFilter_Type.tp_repr = pyopencv_ximgproc_FastGlobalSmootherFilter_repr;
    pyopencv_ximgproc_FastGlobalSmootherFilter_Type.tp_getset = pyopencv_ximgproc_FastGlobalSmootherFilter_getseters;
    pyopencv_ximgproc_FastGlobalSmootherFilter_Type.tp_methods = pyopencv_ximgproc_FastGlobalSmootherFilter_methods;
}

static PyObject* pyopencv_ximgproc_FastLineDetector_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<ximgproc_FastLineDetector %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_ximgproc_FastLineDetector_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_ximgproc_ximgproc_FastLineDetector_detect(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_FastLineDetector_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_FastLineDetector' or its derivative)");
    cv::ximgproc::FastLineDetector* _self_ = dynamic_cast<cv::ximgproc::FastLineDetector*>(((pyopencv_ximgproc_FastLineDetector_t*)self)->v.get());
    {
    PyObject* pyobj__image = NULL;
    Mat _image;
    PyObject* pyobj__lines = NULL;
    Mat _lines;

    const char* keywords[] = { "_image", "_lines", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:ximgproc_FastLineDetector.detect", (char**)keywords, &pyobj__image, &pyobj__lines) &&
        pyopencv_to(pyobj__image, _image, ArgInfo("_image", 0)) &&
        pyopencv_to(pyobj__lines, _lines, ArgInfo("_lines", 1)) )
    {
        ERRWRAP2(_self_->detect(_image, _lines));
        return pyopencv_from(_lines);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj__image = NULL;
    UMat _image;
    PyObject* pyobj__lines = NULL;
    UMat _lines;

    const char* keywords[] = { "_image", "_lines", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:ximgproc_FastLineDetector.detect", (char**)keywords, &pyobj__image, &pyobj__lines) &&
        pyopencv_to(pyobj__image, _image, ArgInfo("_image", 0)) &&
        pyopencv_to(pyobj__lines, _lines, ArgInfo("_lines", 1)) )
    {
        ERRWRAP2(_self_->detect(_image, _lines));
        return pyopencv_from(_lines);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_ximgproc_FastLineDetector_drawSegments(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_FastLineDetector_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_FastLineDetector' or its derivative)");
    cv::ximgproc::FastLineDetector* _self_ = dynamic_cast<cv::ximgproc::FastLineDetector*>(((pyopencv_ximgproc_FastLineDetector_t*)self)->v.get());
    {
    PyObject* pyobj__image = NULL;
    Mat _image;
    PyObject* pyobj_lines = NULL;
    Mat lines;
    bool draw_arrow=false;

    const char* keywords[] = { "_image", "lines", "draw_arrow", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|b:ximgproc_FastLineDetector.drawSegments", (char**)keywords, &pyobj__image, &pyobj_lines, &draw_arrow) &&
        pyopencv_to(pyobj__image, _image, ArgInfo("_image", 1)) &&
        pyopencv_to(pyobj_lines, lines, ArgInfo("lines", 0)) )
    {
        ERRWRAP2(_self_->drawSegments(_image, lines, draw_arrow));
        return pyopencv_from(_image);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj__image = NULL;
    UMat _image;
    PyObject* pyobj_lines = NULL;
    UMat lines;
    bool draw_arrow=false;

    const char* keywords[] = { "_image", "lines", "draw_arrow", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|b:ximgproc_FastLineDetector.drawSegments", (char**)keywords, &pyobj__image, &pyobj_lines, &draw_arrow) &&
        pyopencv_to(pyobj__image, _image, ArgInfo("_image", 1)) &&
        pyopencv_to(pyobj_lines, lines, ArgInfo("lines", 0)) )
    {
        ERRWRAP2(_self_->drawSegments(_image, lines, draw_arrow));
        return pyopencv_from(_image);
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_ximgproc_FastLineDetector_methods[] =
{
    {"detect", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_FastLineDetector_detect, METH_VARARGS | METH_KEYWORDS, "detect(_image[, _lines]) -> _lines"},
    {"drawSegments", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_FastLineDetector_drawSegments, METH_VARARGS | METH_KEYWORDS, "drawSegments(_image, lines[, draw_arrow]) -> _image"},

    {NULL,          NULL}
};

static void pyopencv_ximgproc_FastLineDetector_specials(void)
{
    pyopencv_ximgproc_FastLineDetector_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_ximgproc_FastLineDetector_Type.tp_dealloc = pyopencv_ximgproc_FastLineDetector_dealloc;
    pyopencv_ximgproc_FastLineDetector_Type.tp_repr = pyopencv_ximgproc_FastLineDetector_repr;
    pyopencv_ximgproc_FastLineDetector_Type.tp_getset = pyopencv_ximgproc_FastLineDetector_getseters;
    pyopencv_ximgproc_FastLineDetector_Type.tp_methods = pyopencv_ximgproc_FastLineDetector_methods;
}

static PyObject* pyopencv_ximgproc_SuperpixelLSC_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<ximgproc_SuperpixelLSC %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_ximgproc_SuperpixelLSC_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_ximgproc_ximgproc_SuperpixelLSC_enforceLabelConnectivity(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_SuperpixelLSC_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_SuperpixelLSC' or its derivative)");
    cv::ximgproc::SuperpixelLSC* _self_ = dynamic_cast<cv::ximgproc::SuperpixelLSC*>(((pyopencv_ximgproc_SuperpixelLSC_t*)self)->v.get());
    int min_element_size=20;

    const char* keywords[] = { "min_element_size", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|i:ximgproc_SuperpixelLSC.enforceLabelConnectivity", (char**)keywords, &min_element_size) )
    {
        ERRWRAP2(_self_->enforceLabelConnectivity(min_element_size));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_ximgproc_SuperpixelLSC_getLabelContourMask(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_SuperpixelLSC_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_SuperpixelLSC' or its derivative)");
    cv::ximgproc::SuperpixelLSC* _self_ = dynamic_cast<cv::ximgproc::SuperpixelLSC*>(((pyopencv_ximgproc_SuperpixelLSC_t*)self)->v.get());
    {
    PyObject* pyobj_image = NULL;
    Mat image;
    bool thick_line=true;

    const char* keywords[] = { "image", "thick_line", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|Ob:ximgproc_SuperpixelLSC.getLabelContourMask", (char**)keywords, &pyobj_image, &thick_line) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 1)) )
    {
        ERRWRAP2(_self_->getLabelContourMask(image, thick_line));
        return pyopencv_from(image);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    bool thick_line=true;

    const char* keywords[] = { "image", "thick_line", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|Ob:ximgproc_SuperpixelLSC.getLabelContourMask", (char**)keywords, &pyobj_image, &thick_line) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 1)) )
    {
        ERRWRAP2(_self_->getLabelContourMask(image, thick_line));
        return pyopencv_from(image);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_ximgproc_SuperpixelLSC_getLabels(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_SuperpixelLSC_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_SuperpixelLSC' or its derivative)");
    cv::ximgproc::SuperpixelLSC* _self_ = dynamic_cast<cv::ximgproc::SuperpixelLSC*>(((pyopencv_ximgproc_SuperpixelLSC_t*)self)->v.get());
    {
    PyObject* pyobj_labels_out = NULL;
    Mat labels_out;

    const char* keywords[] = { "labels_out", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|O:ximgproc_SuperpixelLSC.getLabels", (char**)keywords, &pyobj_labels_out) &&
        pyopencv_to(pyobj_labels_out, labels_out, ArgInfo("labels_out", 1)) )
    {
        ERRWRAP2(_self_->getLabels(labels_out));
        return pyopencv_from(labels_out);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_labels_out = NULL;
    UMat labels_out;

    const char* keywords[] = { "labels_out", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|O:ximgproc_SuperpixelLSC.getLabels", (char**)keywords, &pyobj_labels_out) &&
        pyopencv_to(pyobj_labels_out, labels_out, ArgInfo("labels_out", 1)) )
    {
        ERRWRAP2(_self_->getLabels(labels_out));
        return pyopencv_from(labels_out);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_ximgproc_SuperpixelLSC_getNumberOfSuperpixels(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_SuperpixelLSC_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_SuperpixelLSC' or its derivative)");
    cv::ximgproc::SuperpixelLSC* _self_ = dynamic_cast<cv::ximgproc::SuperpixelLSC*>(((pyopencv_ximgproc_SuperpixelLSC_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getNumberOfSuperpixels());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_ximgproc_SuperpixelLSC_iterate(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_SuperpixelLSC_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_SuperpixelLSC' or its derivative)");
    cv::ximgproc::SuperpixelLSC* _self_ = dynamic_cast<cv::ximgproc::SuperpixelLSC*>(((pyopencv_ximgproc_SuperpixelLSC_t*)self)->v.get());
    int num_iterations=10;

    const char* keywords[] = { "num_iterations", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|i:ximgproc_SuperpixelLSC.iterate", (char**)keywords, &num_iterations) )
    {
        ERRWRAP2(_self_->iterate(num_iterations));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_ximgproc_SuperpixelLSC_methods[] =
{
    {"enforceLabelConnectivity", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_SuperpixelLSC_enforceLabelConnectivity, METH_VARARGS | METH_KEYWORDS, "enforceLabelConnectivity([, min_element_size]) -> None"},
    {"getLabelContourMask", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_SuperpixelLSC_getLabelContourMask, METH_VARARGS | METH_KEYWORDS, "getLabelContourMask([, image[, thick_line]]) -> image"},
    {"getLabels", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_SuperpixelLSC_getLabels, METH_VARARGS | METH_KEYWORDS, "getLabels([, labels_out]) -> labels_out"},
    {"getNumberOfSuperpixels", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_SuperpixelLSC_getNumberOfSuperpixels, METH_VARARGS | METH_KEYWORDS, "getNumberOfSuperpixels() -> retval"},
    {"iterate", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_SuperpixelLSC_iterate, METH_VARARGS | METH_KEYWORDS, "iterate([, num_iterations]) -> None"},

    {NULL,          NULL}
};

static void pyopencv_ximgproc_SuperpixelLSC_specials(void)
{
    pyopencv_ximgproc_SuperpixelLSC_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_ximgproc_SuperpixelLSC_Type.tp_dealloc = pyopencv_ximgproc_SuperpixelLSC_dealloc;
    pyopencv_ximgproc_SuperpixelLSC_Type.tp_repr = pyopencv_ximgproc_SuperpixelLSC_repr;
    pyopencv_ximgproc_SuperpixelLSC_Type.tp_getset = pyopencv_ximgproc_SuperpixelLSC_getseters;
    pyopencv_ximgproc_SuperpixelLSC_Type.tp_methods = pyopencv_ximgproc_SuperpixelLSC_methods;
}

static PyObject* pyopencv_ximgproc_SuperpixelSEEDS_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<ximgproc_SuperpixelSEEDS %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_ximgproc_SuperpixelSEEDS_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_ximgproc_ximgproc_SuperpixelSEEDS_getLabelContourMask(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_SuperpixelSEEDS_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_SuperpixelSEEDS' or its derivative)");
    cv::ximgproc::SuperpixelSEEDS* _self_ = dynamic_cast<cv::ximgproc::SuperpixelSEEDS*>(((pyopencv_ximgproc_SuperpixelSEEDS_t*)self)->v.get());
    {
    PyObject* pyobj_image = NULL;
    Mat image;
    bool thick_line=false;

    const char* keywords[] = { "image", "thick_line", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|Ob:ximgproc_SuperpixelSEEDS.getLabelContourMask", (char**)keywords, &pyobj_image, &thick_line) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 1)) )
    {
        ERRWRAP2(_self_->getLabelContourMask(image, thick_line));
        return pyopencv_from(image);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    bool thick_line=false;

    const char* keywords[] = { "image", "thick_line", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|Ob:ximgproc_SuperpixelSEEDS.getLabelContourMask", (char**)keywords, &pyobj_image, &thick_line) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 1)) )
    {
        ERRWRAP2(_self_->getLabelContourMask(image, thick_line));
        return pyopencv_from(image);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_ximgproc_SuperpixelSEEDS_getLabels(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_SuperpixelSEEDS_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_SuperpixelSEEDS' or its derivative)");
    cv::ximgproc::SuperpixelSEEDS* _self_ = dynamic_cast<cv::ximgproc::SuperpixelSEEDS*>(((pyopencv_ximgproc_SuperpixelSEEDS_t*)self)->v.get());
    {
    PyObject* pyobj_labels_out = NULL;
    Mat labels_out;

    const char* keywords[] = { "labels_out", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|O:ximgproc_SuperpixelSEEDS.getLabels", (char**)keywords, &pyobj_labels_out) &&
        pyopencv_to(pyobj_labels_out, labels_out, ArgInfo("labels_out", 1)) )
    {
        ERRWRAP2(_self_->getLabels(labels_out));
        return pyopencv_from(labels_out);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_labels_out = NULL;
    UMat labels_out;

    const char* keywords[] = { "labels_out", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|O:ximgproc_SuperpixelSEEDS.getLabels", (char**)keywords, &pyobj_labels_out) &&
        pyopencv_to(pyobj_labels_out, labels_out, ArgInfo("labels_out", 1)) )
    {
        ERRWRAP2(_self_->getLabels(labels_out));
        return pyopencv_from(labels_out);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_ximgproc_SuperpixelSEEDS_getNumberOfSuperpixels(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_SuperpixelSEEDS_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_SuperpixelSEEDS' or its derivative)");
    cv::ximgproc::SuperpixelSEEDS* _self_ = dynamic_cast<cv::ximgproc::SuperpixelSEEDS*>(((pyopencv_ximgproc_SuperpixelSEEDS_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getNumberOfSuperpixels());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_ximgproc_SuperpixelSEEDS_iterate(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_SuperpixelSEEDS_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_SuperpixelSEEDS' or its derivative)");
    cv::ximgproc::SuperpixelSEEDS* _self_ = dynamic_cast<cv::ximgproc::SuperpixelSEEDS*>(((pyopencv_ximgproc_SuperpixelSEEDS_t*)self)->v.get());
    {
    PyObject* pyobj_img = NULL;
    Mat img;
    int num_iterations=4;

    const char* keywords[] = { "img", "num_iterations", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|i:ximgproc_SuperpixelSEEDS.iterate", (char**)keywords, &pyobj_img, &num_iterations) &&
        pyopencv_to(pyobj_img, img, ArgInfo("img", 0)) )
    {
        ERRWRAP2(_self_->iterate(img, num_iterations));
        Py_RETURN_NONE;
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_img = NULL;
    UMat img;
    int num_iterations=4;

    const char* keywords[] = { "img", "num_iterations", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|i:ximgproc_SuperpixelSEEDS.iterate", (char**)keywords, &pyobj_img, &num_iterations) &&
        pyopencv_to(pyobj_img, img, ArgInfo("img", 0)) )
    {
        ERRWRAP2(_self_->iterate(img, num_iterations));
        Py_RETURN_NONE;
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_ximgproc_SuperpixelSEEDS_methods[] =
{
    {"getLabelContourMask", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_SuperpixelSEEDS_getLabelContourMask, METH_VARARGS | METH_KEYWORDS, "getLabelContourMask([, image[, thick_line]]) -> image"},
    {"getLabels", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_SuperpixelSEEDS_getLabels, METH_VARARGS | METH_KEYWORDS, "getLabels([, labels_out]) -> labels_out"},
    {"getNumberOfSuperpixels", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_SuperpixelSEEDS_getNumberOfSuperpixels, METH_VARARGS | METH_KEYWORDS, "getNumberOfSuperpixels() -> retval"},
    {"iterate", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_SuperpixelSEEDS_iterate, METH_VARARGS | METH_KEYWORDS, "iterate(img[, num_iterations]) -> None"},

    {NULL,          NULL}
};

static void pyopencv_ximgproc_SuperpixelSEEDS_specials(void)
{
    pyopencv_ximgproc_SuperpixelSEEDS_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_ximgproc_SuperpixelSEEDS_Type.tp_dealloc = pyopencv_ximgproc_SuperpixelSEEDS_dealloc;
    pyopencv_ximgproc_SuperpixelSEEDS_Type.tp_repr = pyopencv_ximgproc_SuperpixelSEEDS_repr;
    pyopencv_ximgproc_SuperpixelSEEDS_Type.tp_getset = pyopencv_ximgproc_SuperpixelSEEDS_getseters;
    pyopencv_ximgproc_SuperpixelSEEDS_Type.tp_methods = pyopencv_ximgproc_SuperpixelSEEDS_methods;
}

static PyObject* pyopencv_ximgproc_segmentation_GraphSegmentation_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<ximgproc_segmentation_GraphSegmentation %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_ximgproc_segmentation_GraphSegmentation_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_ximgproc_segmentation_ximgproc_segmentation_GraphSegmentation_getK(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc::segmentation;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_segmentation_GraphSegmentation_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_segmentation_GraphSegmentation' or its derivative)");
    cv::ximgproc::segmentation::GraphSegmentation* _self_ = dynamic_cast<cv::ximgproc::segmentation::GraphSegmentation*>(((pyopencv_ximgproc_segmentation_GraphSegmentation_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getK());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_segmentation_ximgproc_segmentation_GraphSegmentation_getMinSize(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc::segmentation;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_segmentation_GraphSegmentation_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_segmentation_GraphSegmentation' or its derivative)");
    cv::ximgproc::segmentation::GraphSegmentation* _self_ = dynamic_cast<cv::ximgproc::segmentation::GraphSegmentation*>(((pyopencv_ximgproc_segmentation_GraphSegmentation_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getMinSize());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_segmentation_ximgproc_segmentation_GraphSegmentation_getSigma(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc::segmentation;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_segmentation_GraphSegmentation_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_segmentation_GraphSegmentation' or its derivative)");
    cv::ximgproc::segmentation::GraphSegmentation* _self_ = dynamic_cast<cv::ximgproc::segmentation::GraphSegmentation*>(((pyopencv_ximgproc_segmentation_GraphSegmentation_t*)self)->v.get());
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getSigma());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_segmentation_ximgproc_segmentation_GraphSegmentation_processImage(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc::segmentation;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_segmentation_GraphSegmentation_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_segmentation_GraphSegmentation' or its derivative)");
    cv::ximgproc::segmentation::GraphSegmentation* _self_ = dynamic_cast<cv::ximgproc::segmentation::GraphSegmentation*>(((pyopencv_ximgproc_segmentation_GraphSegmentation_t*)self)->v.get());
    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;

    const char* keywords[] = { "src", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:ximgproc_segmentation_GraphSegmentation.processImage", (char**)keywords, &pyobj_src, &pyobj_dst) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(_self_->processImage(src, dst));
        return pyopencv_from(dst);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;

    const char* keywords[] = { "src", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:ximgproc_segmentation_GraphSegmentation.processImage", (char**)keywords, &pyobj_src, &pyobj_dst) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(_self_->processImage(src, dst));
        return pyopencv_from(dst);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_segmentation_ximgproc_segmentation_GraphSegmentation_setK(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc::segmentation;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_segmentation_GraphSegmentation_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_segmentation_GraphSegmentation' or its derivative)");
    cv::ximgproc::segmentation::GraphSegmentation* _self_ = dynamic_cast<cv::ximgproc::segmentation::GraphSegmentation*>(((pyopencv_ximgproc_segmentation_GraphSegmentation_t*)self)->v.get());
    float k=0.f;

    const char* keywords[] = { "k", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:ximgproc_segmentation_GraphSegmentation.setK", (char**)keywords, &k) )
    {
        ERRWRAP2(_self_->setK(k));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_segmentation_ximgproc_segmentation_GraphSegmentation_setMinSize(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc::segmentation;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_segmentation_GraphSegmentation_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_segmentation_GraphSegmentation' or its derivative)");
    cv::ximgproc::segmentation::GraphSegmentation* _self_ = dynamic_cast<cv::ximgproc::segmentation::GraphSegmentation*>(((pyopencv_ximgproc_segmentation_GraphSegmentation_t*)self)->v.get());
    int min_size=0;

    const char* keywords[] = { "min_size", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:ximgproc_segmentation_GraphSegmentation.setMinSize", (char**)keywords, &min_size) )
    {
        ERRWRAP2(_self_->setMinSize(min_size));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_segmentation_ximgproc_segmentation_GraphSegmentation_setSigma(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc::segmentation;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_segmentation_GraphSegmentation_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_segmentation_GraphSegmentation' or its derivative)");
    cv::ximgproc::segmentation::GraphSegmentation* _self_ = dynamic_cast<cv::ximgproc::segmentation::GraphSegmentation*>(((pyopencv_ximgproc_segmentation_GraphSegmentation_t*)self)->v.get());
    double sigma=0;

    const char* keywords[] = { "sigma", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:ximgproc_segmentation_GraphSegmentation.setSigma", (char**)keywords, &sigma) )
    {
        ERRWRAP2(_self_->setSigma(sigma));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_ximgproc_segmentation_GraphSegmentation_methods[] =
{
    {"getK", (PyCFunction)pyopencv_cv_ximgproc_segmentation_ximgproc_segmentation_GraphSegmentation_getK, METH_VARARGS | METH_KEYWORDS, "getK() -> retval"},
    {"getMinSize", (PyCFunction)pyopencv_cv_ximgproc_segmentation_ximgproc_segmentation_GraphSegmentation_getMinSize, METH_VARARGS | METH_KEYWORDS, "getMinSize() -> retval"},
    {"getSigma", (PyCFunction)pyopencv_cv_ximgproc_segmentation_ximgproc_segmentation_GraphSegmentation_getSigma, METH_VARARGS | METH_KEYWORDS, "getSigma() -> retval"},
    {"processImage", (PyCFunction)pyopencv_cv_ximgproc_segmentation_ximgproc_segmentation_GraphSegmentation_processImage, METH_VARARGS | METH_KEYWORDS, "processImage(src[, dst]) -> dst"},
    {"setK", (PyCFunction)pyopencv_cv_ximgproc_segmentation_ximgproc_segmentation_GraphSegmentation_setK, METH_VARARGS | METH_KEYWORDS, "setK(k) -> None"},
    {"setMinSize", (PyCFunction)pyopencv_cv_ximgproc_segmentation_ximgproc_segmentation_GraphSegmentation_setMinSize, METH_VARARGS | METH_KEYWORDS, "setMinSize(min_size) -> None"},
    {"setSigma", (PyCFunction)pyopencv_cv_ximgproc_segmentation_ximgproc_segmentation_GraphSegmentation_setSigma, METH_VARARGS | METH_KEYWORDS, "setSigma(sigma) -> None"},

    {NULL,          NULL}
};

static void pyopencv_ximgproc_segmentation_GraphSegmentation_specials(void)
{
    pyopencv_ximgproc_segmentation_GraphSegmentation_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_ximgproc_segmentation_GraphSegmentation_Type.tp_dealloc = pyopencv_ximgproc_segmentation_GraphSegmentation_dealloc;
    pyopencv_ximgproc_segmentation_GraphSegmentation_Type.tp_repr = pyopencv_ximgproc_segmentation_GraphSegmentation_repr;
    pyopencv_ximgproc_segmentation_GraphSegmentation_Type.tp_getset = pyopencv_ximgproc_segmentation_GraphSegmentation_getseters;
    pyopencv_ximgproc_segmentation_GraphSegmentation_Type.tp_methods = pyopencv_ximgproc_segmentation_GraphSegmentation_methods;
}

static PyObject* pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategy_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<ximgproc_segmentation_SelectiveSearchSegmentationStrategy %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategy_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_ximgproc_segmentation_ximgproc_segmentation_SelectiveSearchSegmentationStrategy_get(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc::segmentation;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategy_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_segmentation_SelectiveSearchSegmentationStrategy' or its derivative)");
    cv::ximgproc::segmentation::SelectiveSearchSegmentationStrategy* _self_ = dynamic_cast<cv::ximgproc::segmentation::SelectiveSearchSegmentationStrategy*>(((pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategy_t*)self)->v.get());
    int r1=0;
    int r2=0;
    float retval;

    const char* keywords[] = { "r1", "r2", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "ii:ximgproc_segmentation_SelectiveSearchSegmentationStrategy.get", (char**)keywords, &r1, &r2) )
    {
        ERRWRAP2(retval = _self_->get(r1, r2));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_segmentation_ximgproc_segmentation_SelectiveSearchSegmentationStrategy_merge(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc::segmentation;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategy_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_segmentation_SelectiveSearchSegmentationStrategy' or its derivative)");
    cv::ximgproc::segmentation::SelectiveSearchSegmentationStrategy* _self_ = dynamic_cast<cv::ximgproc::segmentation::SelectiveSearchSegmentationStrategy*>(((pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategy_t*)self)->v.get());
    int r1=0;
    int r2=0;

    const char* keywords[] = { "r1", "r2", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "ii:ximgproc_segmentation_SelectiveSearchSegmentationStrategy.merge", (char**)keywords, &r1, &r2) )
    {
        ERRWRAP2(_self_->merge(r1, r2));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_segmentation_ximgproc_segmentation_SelectiveSearchSegmentationStrategy_setImage(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc::segmentation;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategy_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_segmentation_SelectiveSearchSegmentationStrategy' or its derivative)");
    cv::ximgproc::segmentation::SelectiveSearchSegmentationStrategy* _self_ = dynamic_cast<cv::ximgproc::segmentation::SelectiveSearchSegmentationStrategy*>(((pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategy_t*)self)->v.get());
    {
    PyObject* pyobj_img = NULL;
    Mat img;
    PyObject* pyobj_regions = NULL;
    Mat regions;
    PyObject* pyobj_sizes = NULL;
    Mat sizes;
    int image_id=-1;

    const char* keywords[] = { "img", "regions", "sizes", "image_id", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OOO|i:ximgproc_segmentation_SelectiveSearchSegmentationStrategy.setImage", (char**)keywords, &pyobj_img, &pyobj_regions, &pyobj_sizes, &image_id) &&
        pyopencv_to(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to(pyobj_regions, regions, ArgInfo("regions", 0)) &&
        pyopencv_to(pyobj_sizes, sizes, ArgInfo("sizes", 0)) )
    {
        ERRWRAP2(_self_->setImage(img, regions, sizes, image_id));
        Py_RETURN_NONE;
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_img = NULL;
    UMat img;
    PyObject* pyobj_regions = NULL;
    UMat regions;
    PyObject* pyobj_sizes = NULL;
    UMat sizes;
    int image_id=-1;

    const char* keywords[] = { "img", "regions", "sizes", "image_id", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OOO|i:ximgproc_segmentation_SelectiveSearchSegmentationStrategy.setImage", (char**)keywords, &pyobj_img, &pyobj_regions, &pyobj_sizes, &image_id) &&
        pyopencv_to(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to(pyobj_regions, regions, ArgInfo("regions", 0)) &&
        pyopencv_to(pyobj_sizes, sizes, ArgInfo("sizes", 0)) )
    {
        ERRWRAP2(_self_->setImage(img, regions, sizes, image_id));
        Py_RETURN_NONE;
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategy_methods[] =
{
    {"get", (PyCFunction)pyopencv_cv_ximgproc_segmentation_ximgproc_segmentation_SelectiveSearchSegmentationStrategy_get, METH_VARARGS | METH_KEYWORDS, "get(r1, r2) -> retval"},
    {"merge", (PyCFunction)pyopencv_cv_ximgproc_segmentation_ximgproc_segmentation_SelectiveSearchSegmentationStrategy_merge, METH_VARARGS | METH_KEYWORDS, "merge(r1, r2) -> None"},
    {"setImage", (PyCFunction)pyopencv_cv_ximgproc_segmentation_ximgproc_segmentation_SelectiveSearchSegmentationStrategy_setImage, METH_VARARGS | METH_KEYWORDS, "setImage(img, regions, sizes[, image_id]) -> None"},

    {NULL,          NULL}
};

static void pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategy_specials(void)
{
    pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategy_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategy_Type.tp_dealloc = pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategy_dealloc;
    pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategy_Type.tp_repr = pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategy_repr;
    pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategy_Type.tp_getset = pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategy_getseters;
    pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategy_Type.tp_methods = pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategy_methods;
}

static PyObject* pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyColor_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<ximgproc_segmentation_SelectiveSearchSegmentationStrategyColor %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyColor_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyColor_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyColor_specials(void)
{
    pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyColor_Type.tp_base = &pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategy_Type;
    pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyColor_Type.tp_dealloc = pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyColor_dealloc;
    pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyColor_Type.tp_repr = pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyColor_repr;
    pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyColor_Type.tp_getset = pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyColor_getseters;
    pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyColor_Type.tp_methods = pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyColor_methods;
}

static PyObject* pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategySize_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<ximgproc_segmentation_SelectiveSearchSegmentationStrategySize %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategySize_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategySize_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategySize_specials(void)
{
    pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategySize_Type.tp_base = &pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategy_Type;
    pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategySize_Type.tp_dealloc = pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategySize_dealloc;
    pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategySize_Type.tp_repr = pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategySize_repr;
    pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategySize_Type.tp_getset = pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategySize_getseters;
    pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategySize_Type.tp_methods = pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategySize_methods;
}

static PyObject* pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyTexture_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<ximgproc_segmentation_SelectiveSearchSegmentationStrategyTexture %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyTexture_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyTexture_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyTexture_specials(void)
{
    pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyTexture_Type.tp_base = &pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategy_Type;
    pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyTexture_Type.tp_dealloc = pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyTexture_dealloc;
    pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyTexture_Type.tp_repr = pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyTexture_repr;
    pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyTexture_Type.tp_getset = pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyTexture_getseters;
    pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyTexture_Type.tp_methods = pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyTexture_methods;
}

static PyObject* pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyFill_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<ximgproc_segmentation_SelectiveSearchSegmentationStrategyFill %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyFill_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyFill_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyFill_specials(void)
{
    pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyFill_Type.tp_base = &pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategy_Type;
    pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyFill_Type.tp_dealloc = pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyFill_dealloc;
    pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyFill_Type.tp_repr = pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyFill_repr;
    pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyFill_Type.tp_getset = pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyFill_getseters;
    pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyFill_Type.tp_methods = pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyFill_methods;
}

static PyObject* pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyMultiple_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<ximgproc_segmentation_SelectiveSearchSegmentationStrategyMultiple %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyMultiple_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_ximgproc_segmentation_ximgproc_segmentation_SelectiveSearchSegmentationStrategyMultiple_addStrategy(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc::segmentation;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyMultiple_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_segmentation_SelectiveSearchSegmentationStrategyMultiple' or its derivative)");
    cv::ximgproc::segmentation::SelectiveSearchSegmentationStrategyMultiple* _self_ = dynamic_cast<cv::ximgproc::segmentation::SelectiveSearchSegmentationStrategyMultiple*>(((pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyMultiple_t*)self)->v.get());
    PyObject* pyobj_g = NULL;
    Ptr<SelectiveSearchSegmentationStrategy> g;
    float weight=0.f;

    const char* keywords[] = { "g", "weight", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "Of:ximgproc_segmentation_SelectiveSearchSegmentationStrategyMultiple.addStrategy", (char**)keywords, &pyobj_g, &weight) &&
        pyopencv_to(pyobj_g, g, ArgInfo("g", 0)) )
    {
        ERRWRAP2(_self_->addStrategy(g, weight));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_segmentation_ximgproc_segmentation_SelectiveSearchSegmentationStrategyMultiple_clearStrategies(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc::segmentation;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyMultiple_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_segmentation_SelectiveSearchSegmentationStrategyMultiple' or its derivative)");
    cv::ximgproc::segmentation::SelectiveSearchSegmentationStrategyMultiple* _self_ = dynamic_cast<cv::ximgproc::segmentation::SelectiveSearchSegmentationStrategyMultiple*>(((pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyMultiple_t*)self)->v.get());

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(_self_->clearStrategies());
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyMultiple_methods[] =
{
    {"addStrategy", (PyCFunction)pyopencv_cv_ximgproc_segmentation_ximgproc_segmentation_SelectiveSearchSegmentationStrategyMultiple_addStrategy, METH_VARARGS | METH_KEYWORDS, "addStrategy(g, weight) -> None"},
    {"clearStrategies", (PyCFunction)pyopencv_cv_ximgproc_segmentation_ximgproc_segmentation_SelectiveSearchSegmentationStrategyMultiple_clearStrategies, METH_VARARGS | METH_KEYWORDS, "clearStrategies() -> None"},

    {NULL,          NULL}
};

static void pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyMultiple_specials(void)
{
    pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyMultiple_Type.tp_base = &pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategy_Type;
    pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyMultiple_Type.tp_dealloc = pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyMultiple_dealloc;
    pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyMultiple_Type.tp_repr = pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyMultiple_repr;
    pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyMultiple_Type.tp_getset = pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyMultiple_getseters;
    pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyMultiple_Type.tp_methods = pyopencv_ximgproc_segmentation_SelectiveSearchSegmentationStrategyMultiple_methods;
}

static PyObject* pyopencv_ximgproc_segmentation_SelectiveSearchSegmentation_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<ximgproc_segmentation_SelectiveSearchSegmentation %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_ximgproc_segmentation_SelectiveSearchSegmentation_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_ximgproc_segmentation_ximgproc_segmentation_SelectiveSearchSegmentation_addGraphSegmentation(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc::segmentation;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_segmentation_SelectiveSearchSegmentation_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_segmentation_SelectiveSearchSegmentation' or its derivative)");
    cv::ximgproc::segmentation::SelectiveSearchSegmentation* _self_ = dynamic_cast<cv::ximgproc::segmentation::SelectiveSearchSegmentation*>(((pyopencv_ximgproc_segmentation_SelectiveSearchSegmentation_t*)self)->v.get());
    PyObject* pyobj_g = NULL;
    Ptr<GraphSegmentation> g;

    const char* keywords[] = { "g", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:ximgproc_segmentation_SelectiveSearchSegmentation.addGraphSegmentation", (char**)keywords, &pyobj_g) &&
        pyopencv_to(pyobj_g, g, ArgInfo("g", 0)) )
    {
        ERRWRAP2(_self_->addGraphSegmentation(g));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_segmentation_ximgproc_segmentation_SelectiveSearchSegmentation_addImage(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc::segmentation;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_segmentation_SelectiveSearchSegmentation_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_segmentation_SelectiveSearchSegmentation' or its derivative)");
    cv::ximgproc::segmentation::SelectiveSearchSegmentation* _self_ = dynamic_cast<cv::ximgproc::segmentation::SelectiveSearchSegmentation*>(((pyopencv_ximgproc_segmentation_SelectiveSearchSegmentation_t*)self)->v.get());
    {
    PyObject* pyobj_img = NULL;
    Mat img;

    const char* keywords[] = { "img", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:ximgproc_segmentation_SelectiveSearchSegmentation.addImage", (char**)keywords, &pyobj_img) &&
        pyopencv_to(pyobj_img, img, ArgInfo("img", 0)) )
    {
        ERRWRAP2(_self_->addImage(img));
        Py_RETURN_NONE;
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_img = NULL;
    UMat img;

    const char* keywords[] = { "img", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:ximgproc_segmentation_SelectiveSearchSegmentation.addImage", (char**)keywords, &pyobj_img) &&
        pyopencv_to(pyobj_img, img, ArgInfo("img", 0)) )
    {
        ERRWRAP2(_self_->addImage(img));
        Py_RETURN_NONE;
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_segmentation_ximgproc_segmentation_SelectiveSearchSegmentation_addStrategy(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc::segmentation;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_segmentation_SelectiveSearchSegmentation_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_segmentation_SelectiveSearchSegmentation' or its derivative)");
    cv::ximgproc::segmentation::SelectiveSearchSegmentation* _self_ = dynamic_cast<cv::ximgproc::segmentation::SelectiveSearchSegmentation*>(((pyopencv_ximgproc_segmentation_SelectiveSearchSegmentation_t*)self)->v.get());
    PyObject* pyobj_s = NULL;
    Ptr<SelectiveSearchSegmentationStrategy> s;

    const char* keywords[] = { "s", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:ximgproc_segmentation_SelectiveSearchSegmentation.addStrategy", (char**)keywords, &pyobj_s) &&
        pyopencv_to(pyobj_s, s, ArgInfo("s", 0)) )
    {
        ERRWRAP2(_self_->addStrategy(s));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_segmentation_ximgproc_segmentation_SelectiveSearchSegmentation_clearGraphSegmentations(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc::segmentation;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_segmentation_SelectiveSearchSegmentation_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_segmentation_SelectiveSearchSegmentation' or its derivative)");
    cv::ximgproc::segmentation::SelectiveSearchSegmentation* _self_ = dynamic_cast<cv::ximgproc::segmentation::SelectiveSearchSegmentation*>(((pyopencv_ximgproc_segmentation_SelectiveSearchSegmentation_t*)self)->v.get());

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(_self_->clearGraphSegmentations());
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_segmentation_ximgproc_segmentation_SelectiveSearchSegmentation_clearImages(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc::segmentation;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_segmentation_SelectiveSearchSegmentation_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_segmentation_SelectiveSearchSegmentation' or its derivative)");
    cv::ximgproc::segmentation::SelectiveSearchSegmentation* _self_ = dynamic_cast<cv::ximgproc::segmentation::SelectiveSearchSegmentation*>(((pyopencv_ximgproc_segmentation_SelectiveSearchSegmentation_t*)self)->v.get());

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(_self_->clearImages());
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_segmentation_ximgproc_segmentation_SelectiveSearchSegmentation_clearStrategies(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc::segmentation;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_segmentation_SelectiveSearchSegmentation_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_segmentation_SelectiveSearchSegmentation' or its derivative)");
    cv::ximgproc::segmentation::SelectiveSearchSegmentation* _self_ = dynamic_cast<cv::ximgproc::segmentation::SelectiveSearchSegmentation*>(((pyopencv_ximgproc_segmentation_SelectiveSearchSegmentation_t*)self)->v.get());

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(_self_->clearStrategies());
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_segmentation_ximgproc_segmentation_SelectiveSearchSegmentation_process(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc::segmentation;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_segmentation_SelectiveSearchSegmentation_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_segmentation_SelectiveSearchSegmentation' or its derivative)");
    cv::ximgproc::segmentation::SelectiveSearchSegmentation* _self_ = dynamic_cast<cv::ximgproc::segmentation::SelectiveSearchSegmentation*>(((pyopencv_ximgproc_segmentation_SelectiveSearchSegmentation_t*)self)->v.get());
    PyObject* pyobj_rects = NULL;
    vector_Rect rects;

    const char* keywords[] = { "rects", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:ximgproc_segmentation_SelectiveSearchSegmentation.process", (char**)keywords, &pyobj_rects) &&
        pyopencv_to(pyobj_rects, rects, ArgInfo("rects", 0)) )
    {
        ERRWRAP2(_self_->process(rects));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_segmentation_ximgproc_segmentation_SelectiveSearchSegmentation_setBaseImage(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc::segmentation;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_segmentation_SelectiveSearchSegmentation_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_segmentation_SelectiveSearchSegmentation' or its derivative)");
    cv::ximgproc::segmentation::SelectiveSearchSegmentation* _self_ = dynamic_cast<cv::ximgproc::segmentation::SelectiveSearchSegmentation*>(((pyopencv_ximgproc_segmentation_SelectiveSearchSegmentation_t*)self)->v.get());
    {
    PyObject* pyobj_img = NULL;
    Mat img;

    const char* keywords[] = { "img", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:ximgproc_segmentation_SelectiveSearchSegmentation.setBaseImage", (char**)keywords, &pyobj_img) &&
        pyopencv_to(pyobj_img, img, ArgInfo("img", 0)) )
    {
        ERRWRAP2(_self_->setBaseImage(img));
        Py_RETURN_NONE;
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_img = NULL;
    UMat img;

    const char* keywords[] = { "img", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:ximgproc_segmentation_SelectiveSearchSegmentation.setBaseImage", (char**)keywords, &pyobj_img) &&
        pyopencv_to(pyobj_img, img, ArgInfo("img", 0)) )
    {
        ERRWRAP2(_self_->setBaseImage(img));
        Py_RETURN_NONE;
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_segmentation_ximgproc_segmentation_SelectiveSearchSegmentation_switchToSelectiveSearchFast(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc::segmentation;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_segmentation_SelectiveSearchSegmentation_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_segmentation_SelectiveSearchSegmentation' or its derivative)");
    cv::ximgproc::segmentation::SelectiveSearchSegmentation* _self_ = dynamic_cast<cv::ximgproc::segmentation::SelectiveSearchSegmentation*>(((pyopencv_ximgproc_segmentation_SelectiveSearchSegmentation_t*)self)->v.get());
    int base_k=150;
    int inc_k=150;
    float sigma=0.8f;

    const char* keywords[] = { "base_k", "inc_k", "sigma", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|iif:ximgproc_segmentation_SelectiveSearchSegmentation.switchToSelectiveSearchFast", (char**)keywords, &base_k, &inc_k, &sigma) )
    {
        ERRWRAP2(_self_->switchToSelectiveSearchFast(base_k, inc_k, sigma));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_segmentation_ximgproc_segmentation_SelectiveSearchSegmentation_switchToSelectiveSearchQuality(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc::segmentation;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_segmentation_SelectiveSearchSegmentation_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_segmentation_SelectiveSearchSegmentation' or its derivative)");
    cv::ximgproc::segmentation::SelectiveSearchSegmentation* _self_ = dynamic_cast<cv::ximgproc::segmentation::SelectiveSearchSegmentation*>(((pyopencv_ximgproc_segmentation_SelectiveSearchSegmentation_t*)self)->v.get());
    int base_k=150;
    int inc_k=150;
    float sigma=0.8f;

    const char* keywords[] = { "base_k", "inc_k", "sigma", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|iif:ximgproc_segmentation_SelectiveSearchSegmentation.switchToSelectiveSearchQuality", (char**)keywords, &base_k, &inc_k, &sigma) )
    {
        ERRWRAP2(_self_->switchToSelectiveSearchQuality(base_k, inc_k, sigma));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_segmentation_ximgproc_segmentation_SelectiveSearchSegmentation_switchToSingleStrategy(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc::segmentation;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_segmentation_SelectiveSearchSegmentation_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_segmentation_SelectiveSearchSegmentation' or its derivative)");
    cv::ximgproc::segmentation::SelectiveSearchSegmentation* _self_ = dynamic_cast<cv::ximgproc::segmentation::SelectiveSearchSegmentation*>(((pyopencv_ximgproc_segmentation_SelectiveSearchSegmentation_t*)self)->v.get());
    int k=200;
    float sigma=0.8f;

    const char* keywords[] = { "k", "sigma", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|if:ximgproc_segmentation_SelectiveSearchSegmentation.switchToSingleStrategy", (char**)keywords, &k, &sigma) )
    {
        ERRWRAP2(_self_->switchToSingleStrategy(k, sigma));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_ximgproc_segmentation_SelectiveSearchSegmentation_methods[] =
{
    {"addGraphSegmentation", (PyCFunction)pyopencv_cv_ximgproc_segmentation_ximgproc_segmentation_SelectiveSearchSegmentation_addGraphSegmentation, METH_VARARGS | METH_KEYWORDS, "addGraphSegmentation(g) -> None"},
    {"addImage", (PyCFunction)pyopencv_cv_ximgproc_segmentation_ximgproc_segmentation_SelectiveSearchSegmentation_addImage, METH_VARARGS | METH_KEYWORDS, "addImage(img) -> None"},
    {"addStrategy", (PyCFunction)pyopencv_cv_ximgproc_segmentation_ximgproc_segmentation_SelectiveSearchSegmentation_addStrategy, METH_VARARGS | METH_KEYWORDS, "addStrategy(s) -> None"},
    {"clearGraphSegmentations", (PyCFunction)pyopencv_cv_ximgproc_segmentation_ximgproc_segmentation_SelectiveSearchSegmentation_clearGraphSegmentations, METH_VARARGS | METH_KEYWORDS, "clearGraphSegmentations() -> None"},
    {"clearImages", (PyCFunction)pyopencv_cv_ximgproc_segmentation_ximgproc_segmentation_SelectiveSearchSegmentation_clearImages, METH_VARARGS | METH_KEYWORDS, "clearImages() -> None"},
    {"clearStrategies", (PyCFunction)pyopencv_cv_ximgproc_segmentation_ximgproc_segmentation_SelectiveSearchSegmentation_clearStrategies, METH_VARARGS | METH_KEYWORDS, "clearStrategies() -> None"},
    {"process", (PyCFunction)pyopencv_cv_ximgproc_segmentation_ximgproc_segmentation_SelectiveSearchSegmentation_process, METH_VARARGS | METH_KEYWORDS, "process(rects) -> None"},
    {"setBaseImage", (PyCFunction)pyopencv_cv_ximgproc_segmentation_ximgproc_segmentation_SelectiveSearchSegmentation_setBaseImage, METH_VARARGS | METH_KEYWORDS, "setBaseImage(img) -> None"},
    {"switchToSelectiveSearchFast", (PyCFunction)pyopencv_cv_ximgproc_segmentation_ximgproc_segmentation_SelectiveSearchSegmentation_switchToSelectiveSearchFast, METH_VARARGS | METH_KEYWORDS, "switchToSelectiveSearchFast([, base_k[, inc_k[, sigma]]]) -> None"},
    {"switchToSelectiveSearchQuality", (PyCFunction)pyopencv_cv_ximgproc_segmentation_ximgproc_segmentation_SelectiveSearchSegmentation_switchToSelectiveSearchQuality, METH_VARARGS | METH_KEYWORDS, "switchToSelectiveSearchQuality([, base_k[, inc_k[, sigma]]]) -> None"},
    {"switchToSingleStrategy", (PyCFunction)pyopencv_cv_ximgproc_segmentation_ximgproc_segmentation_SelectiveSearchSegmentation_switchToSingleStrategy, METH_VARARGS | METH_KEYWORDS, "switchToSingleStrategy([, k[, sigma]]) -> None"},

    {NULL,          NULL}
};

static void pyopencv_ximgproc_segmentation_SelectiveSearchSegmentation_specials(void)
{
    pyopencv_ximgproc_segmentation_SelectiveSearchSegmentation_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_ximgproc_segmentation_SelectiveSearchSegmentation_Type.tp_dealloc = pyopencv_ximgproc_segmentation_SelectiveSearchSegmentation_dealloc;
    pyopencv_ximgproc_segmentation_SelectiveSearchSegmentation_Type.tp_repr = pyopencv_ximgproc_segmentation_SelectiveSearchSegmentation_repr;
    pyopencv_ximgproc_segmentation_SelectiveSearchSegmentation_Type.tp_getset = pyopencv_ximgproc_segmentation_SelectiveSearchSegmentation_getseters;
    pyopencv_ximgproc_segmentation_SelectiveSearchSegmentation_Type.tp_methods = pyopencv_ximgproc_segmentation_SelectiveSearchSegmentation_methods;
}

static PyObject* pyopencv_ximgproc_SuperpixelSLIC_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<ximgproc_SuperpixelSLIC %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_ximgproc_SuperpixelSLIC_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_ximgproc_ximgproc_SuperpixelSLIC_enforceLabelConnectivity(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_SuperpixelSLIC_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_SuperpixelSLIC' or its derivative)");
    cv::ximgproc::SuperpixelSLIC* _self_ = dynamic_cast<cv::ximgproc::SuperpixelSLIC*>(((pyopencv_ximgproc_SuperpixelSLIC_t*)self)->v.get());
    int min_element_size=25;

    const char* keywords[] = { "min_element_size", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|i:ximgproc_SuperpixelSLIC.enforceLabelConnectivity", (char**)keywords, &min_element_size) )
    {
        ERRWRAP2(_self_->enforceLabelConnectivity(min_element_size));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_ximgproc_SuperpixelSLIC_getLabelContourMask(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_SuperpixelSLIC_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_SuperpixelSLIC' or its derivative)");
    cv::ximgproc::SuperpixelSLIC* _self_ = dynamic_cast<cv::ximgproc::SuperpixelSLIC*>(((pyopencv_ximgproc_SuperpixelSLIC_t*)self)->v.get());
    {
    PyObject* pyobj_image = NULL;
    Mat image;
    bool thick_line=true;

    const char* keywords[] = { "image", "thick_line", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|Ob:ximgproc_SuperpixelSLIC.getLabelContourMask", (char**)keywords, &pyobj_image, &thick_line) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 1)) )
    {
        ERRWRAP2(_self_->getLabelContourMask(image, thick_line));
        return pyopencv_from(image);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    bool thick_line=true;

    const char* keywords[] = { "image", "thick_line", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|Ob:ximgproc_SuperpixelSLIC.getLabelContourMask", (char**)keywords, &pyobj_image, &thick_line) &&
        pyopencv_to(pyobj_image, image, ArgInfo("image", 1)) )
    {
        ERRWRAP2(_self_->getLabelContourMask(image, thick_line));
        return pyopencv_from(image);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_ximgproc_SuperpixelSLIC_getLabels(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_SuperpixelSLIC_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_SuperpixelSLIC' or its derivative)");
    cv::ximgproc::SuperpixelSLIC* _self_ = dynamic_cast<cv::ximgproc::SuperpixelSLIC*>(((pyopencv_ximgproc_SuperpixelSLIC_t*)self)->v.get());
    {
    PyObject* pyobj_labels_out = NULL;
    Mat labels_out;

    const char* keywords[] = { "labels_out", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|O:ximgproc_SuperpixelSLIC.getLabels", (char**)keywords, &pyobj_labels_out) &&
        pyopencv_to(pyobj_labels_out, labels_out, ArgInfo("labels_out", 1)) )
    {
        ERRWRAP2(_self_->getLabels(labels_out));
        return pyopencv_from(labels_out);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_labels_out = NULL;
    UMat labels_out;

    const char* keywords[] = { "labels_out", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|O:ximgproc_SuperpixelSLIC.getLabels", (char**)keywords, &pyobj_labels_out) &&
        pyopencv_to(pyobj_labels_out, labels_out, ArgInfo("labels_out", 1)) )
    {
        ERRWRAP2(_self_->getLabels(labels_out));
        return pyopencv_from(labels_out);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_ximgproc_SuperpixelSLIC_getNumberOfSuperpixels(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_SuperpixelSLIC_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_SuperpixelSLIC' or its derivative)");
    cv::ximgproc::SuperpixelSLIC* _self_ = dynamic_cast<cv::ximgproc::SuperpixelSLIC*>(((pyopencv_ximgproc_SuperpixelSLIC_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getNumberOfSuperpixels());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_ximgproc_SuperpixelSLIC_iterate(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_SuperpixelSLIC_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_SuperpixelSLIC' or its derivative)");
    cv::ximgproc::SuperpixelSLIC* _self_ = dynamic_cast<cv::ximgproc::SuperpixelSLIC*>(((pyopencv_ximgproc_SuperpixelSLIC_t*)self)->v.get());
    int num_iterations=10;

    const char* keywords[] = { "num_iterations", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|i:ximgproc_SuperpixelSLIC.iterate", (char**)keywords, &num_iterations) )
    {
        ERRWRAP2(_self_->iterate(num_iterations));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_ximgproc_SuperpixelSLIC_methods[] =
{
    {"enforceLabelConnectivity", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_SuperpixelSLIC_enforceLabelConnectivity, METH_VARARGS | METH_KEYWORDS, "enforceLabelConnectivity([, min_element_size]) -> None"},
    {"getLabelContourMask", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_SuperpixelSLIC_getLabelContourMask, METH_VARARGS | METH_KEYWORDS, "getLabelContourMask([, image[, thick_line]]) -> image"},
    {"getLabels", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_SuperpixelSLIC_getLabels, METH_VARARGS | METH_KEYWORDS, "getLabels([, labels_out]) -> labels_out"},
    {"getNumberOfSuperpixels", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_SuperpixelSLIC_getNumberOfSuperpixels, METH_VARARGS | METH_KEYWORDS, "getNumberOfSuperpixels() -> retval"},
    {"iterate", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_SuperpixelSLIC_iterate, METH_VARARGS | METH_KEYWORDS, "iterate([, num_iterations]) -> None"},

    {NULL,          NULL}
};

static void pyopencv_ximgproc_SuperpixelSLIC_specials(void)
{
    pyopencv_ximgproc_SuperpixelSLIC_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_ximgproc_SuperpixelSLIC_Type.tp_dealloc = pyopencv_ximgproc_SuperpixelSLIC_dealloc;
    pyopencv_ximgproc_SuperpixelSLIC_Type.tp_repr = pyopencv_ximgproc_SuperpixelSLIC_repr;
    pyopencv_ximgproc_SuperpixelSLIC_Type.tp_getset = pyopencv_ximgproc_SuperpixelSLIC_getseters;
    pyopencv_ximgproc_SuperpixelSLIC_Type.tp_methods = pyopencv_ximgproc_SuperpixelSLIC_methods;
}

static PyObject* pyopencv_ximgproc_SparseMatchInterpolator_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<ximgproc_SparseMatchInterpolator %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_ximgproc_SparseMatchInterpolator_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_ximgproc_ximgproc_SparseMatchInterpolator_interpolate(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_SparseMatchInterpolator_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_SparseMatchInterpolator' or its derivative)");
    cv::ximgproc::SparseMatchInterpolator* _self_ = dynamic_cast<cv::ximgproc::SparseMatchInterpolator*>(((pyopencv_ximgproc_SparseMatchInterpolator_t*)self)->v.get());
    {
    PyObject* pyobj_from_image = NULL;
    Mat from_image;
    PyObject* pyobj_from_points = NULL;
    Mat from_points;
    PyObject* pyobj_to_image = NULL;
    Mat to_image;
    PyObject* pyobj_to_points = NULL;
    Mat to_points;
    PyObject* pyobj_dense_flow = NULL;
    Mat dense_flow;

    const char* keywords[] = { "from_image", "from_points", "to_image", "to_points", "dense_flow", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OOOO|O:ximgproc_SparseMatchInterpolator.interpolate", (char**)keywords, &pyobj_from_image, &pyobj_from_points, &pyobj_to_image, &pyobj_to_points, &pyobj_dense_flow) &&
        pyopencv_to(pyobj_from_image, from_image, ArgInfo("from_image", 0)) &&
        pyopencv_to(pyobj_from_points, from_points, ArgInfo("from_points", 0)) &&
        pyopencv_to(pyobj_to_image, to_image, ArgInfo("to_image", 0)) &&
        pyopencv_to(pyobj_to_points, to_points, ArgInfo("to_points", 0)) &&
        pyopencv_to(pyobj_dense_flow, dense_flow, ArgInfo("dense_flow", 1)) )
    {
        ERRWRAP2(_self_->interpolate(from_image, from_points, to_image, to_points, dense_flow));
        return pyopencv_from(dense_flow);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_from_image = NULL;
    UMat from_image;
    PyObject* pyobj_from_points = NULL;
    UMat from_points;
    PyObject* pyobj_to_image = NULL;
    UMat to_image;
    PyObject* pyobj_to_points = NULL;
    UMat to_points;
    PyObject* pyobj_dense_flow = NULL;
    UMat dense_flow;

    const char* keywords[] = { "from_image", "from_points", "to_image", "to_points", "dense_flow", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OOOO|O:ximgproc_SparseMatchInterpolator.interpolate", (char**)keywords, &pyobj_from_image, &pyobj_from_points, &pyobj_to_image, &pyobj_to_points, &pyobj_dense_flow) &&
        pyopencv_to(pyobj_from_image, from_image, ArgInfo("from_image", 0)) &&
        pyopencv_to(pyobj_from_points, from_points, ArgInfo("from_points", 0)) &&
        pyopencv_to(pyobj_to_image, to_image, ArgInfo("to_image", 0)) &&
        pyopencv_to(pyobj_to_points, to_points, ArgInfo("to_points", 0)) &&
        pyopencv_to(pyobj_dense_flow, dense_flow, ArgInfo("dense_flow", 1)) )
    {
        ERRWRAP2(_self_->interpolate(from_image, from_points, to_image, to_points, dense_flow));
        return pyopencv_from(dense_flow);
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_ximgproc_SparseMatchInterpolator_methods[] =
{
    {"interpolate", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_SparseMatchInterpolator_interpolate, METH_VARARGS | METH_KEYWORDS, "interpolate(from_image, from_points, to_image, to_points[, dense_flow]) -> dense_flow"},

    {NULL,          NULL}
};

static void pyopencv_ximgproc_SparseMatchInterpolator_specials(void)
{
    pyopencv_ximgproc_SparseMatchInterpolator_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_ximgproc_SparseMatchInterpolator_Type.tp_dealloc = pyopencv_ximgproc_SparseMatchInterpolator_dealloc;
    pyopencv_ximgproc_SparseMatchInterpolator_Type.tp_repr = pyopencv_ximgproc_SparseMatchInterpolator_repr;
    pyopencv_ximgproc_SparseMatchInterpolator_Type.tp_getset = pyopencv_ximgproc_SparseMatchInterpolator_getseters;
    pyopencv_ximgproc_SparseMatchInterpolator_Type.tp_methods = pyopencv_ximgproc_SparseMatchInterpolator_methods;
}

static PyObject* pyopencv_ximgproc_EdgeAwareInterpolator_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<ximgproc_EdgeAwareInterpolator %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_ximgproc_EdgeAwareInterpolator_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_ximgproc_ximgproc_EdgeAwareInterpolator_getFGSLambda(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_EdgeAwareInterpolator_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_EdgeAwareInterpolator' or its derivative)");
    cv::ximgproc::EdgeAwareInterpolator* _self_ = dynamic_cast<cv::ximgproc::EdgeAwareInterpolator*>(((pyopencv_ximgproc_EdgeAwareInterpolator_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getFGSLambda());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_ximgproc_EdgeAwareInterpolator_getFGSSigma(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_EdgeAwareInterpolator_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_EdgeAwareInterpolator' or its derivative)");
    cv::ximgproc::EdgeAwareInterpolator* _self_ = dynamic_cast<cv::ximgproc::EdgeAwareInterpolator*>(((pyopencv_ximgproc_EdgeAwareInterpolator_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getFGSSigma());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_ximgproc_EdgeAwareInterpolator_getK(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_EdgeAwareInterpolator_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_EdgeAwareInterpolator' or its derivative)");
    cv::ximgproc::EdgeAwareInterpolator* _self_ = dynamic_cast<cv::ximgproc::EdgeAwareInterpolator*>(((pyopencv_ximgproc_EdgeAwareInterpolator_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getK());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_ximgproc_EdgeAwareInterpolator_getLambda(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_EdgeAwareInterpolator_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_EdgeAwareInterpolator' or its derivative)");
    cv::ximgproc::EdgeAwareInterpolator* _self_ = dynamic_cast<cv::ximgproc::EdgeAwareInterpolator*>(((pyopencv_ximgproc_EdgeAwareInterpolator_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getLambda());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_ximgproc_EdgeAwareInterpolator_getSigma(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_EdgeAwareInterpolator_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_EdgeAwareInterpolator' or its derivative)");
    cv::ximgproc::EdgeAwareInterpolator* _self_ = dynamic_cast<cv::ximgproc::EdgeAwareInterpolator*>(((pyopencv_ximgproc_EdgeAwareInterpolator_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getSigma());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_ximgproc_EdgeAwareInterpolator_getUsePostProcessing(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_EdgeAwareInterpolator_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_EdgeAwareInterpolator' or its derivative)");
    cv::ximgproc::EdgeAwareInterpolator* _self_ = dynamic_cast<cv::ximgproc::EdgeAwareInterpolator*>(((pyopencv_ximgproc_EdgeAwareInterpolator_t*)self)->v.get());
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getUsePostProcessing());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_ximgproc_EdgeAwareInterpolator_setFGSLambda(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_EdgeAwareInterpolator_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_EdgeAwareInterpolator' or its derivative)");
    cv::ximgproc::EdgeAwareInterpolator* _self_ = dynamic_cast<cv::ximgproc::EdgeAwareInterpolator*>(((pyopencv_ximgproc_EdgeAwareInterpolator_t*)self)->v.get());
    float _lambda=0.f;

    const char* keywords[] = { "_lambda", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:ximgproc_EdgeAwareInterpolator.setFGSLambda", (char**)keywords, &_lambda) )
    {
        ERRWRAP2(_self_->setFGSLambda(_lambda));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_ximgproc_EdgeAwareInterpolator_setFGSSigma(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_EdgeAwareInterpolator_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_EdgeAwareInterpolator' or its derivative)");
    cv::ximgproc::EdgeAwareInterpolator* _self_ = dynamic_cast<cv::ximgproc::EdgeAwareInterpolator*>(((pyopencv_ximgproc_EdgeAwareInterpolator_t*)self)->v.get());
    float _sigma=0.f;

    const char* keywords[] = { "_sigma", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:ximgproc_EdgeAwareInterpolator.setFGSSigma", (char**)keywords, &_sigma) )
    {
        ERRWRAP2(_self_->setFGSSigma(_sigma));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_ximgproc_EdgeAwareInterpolator_setK(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_EdgeAwareInterpolator_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_EdgeAwareInterpolator' or its derivative)");
    cv::ximgproc::EdgeAwareInterpolator* _self_ = dynamic_cast<cv::ximgproc::EdgeAwareInterpolator*>(((pyopencv_ximgproc_EdgeAwareInterpolator_t*)self)->v.get());
    int _k=0;

    const char* keywords[] = { "_k", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:ximgproc_EdgeAwareInterpolator.setK", (char**)keywords, &_k) )
    {
        ERRWRAP2(_self_->setK(_k));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_ximgproc_EdgeAwareInterpolator_setLambda(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_EdgeAwareInterpolator_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_EdgeAwareInterpolator' or its derivative)");
    cv::ximgproc::EdgeAwareInterpolator* _self_ = dynamic_cast<cv::ximgproc::EdgeAwareInterpolator*>(((pyopencv_ximgproc_EdgeAwareInterpolator_t*)self)->v.get());
    float _lambda=0.f;

    const char* keywords[] = { "_lambda", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:ximgproc_EdgeAwareInterpolator.setLambda", (char**)keywords, &_lambda) )
    {
        ERRWRAP2(_self_->setLambda(_lambda));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_ximgproc_EdgeAwareInterpolator_setSigma(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_EdgeAwareInterpolator_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_EdgeAwareInterpolator' or its derivative)");
    cv::ximgproc::EdgeAwareInterpolator* _self_ = dynamic_cast<cv::ximgproc::EdgeAwareInterpolator*>(((pyopencv_ximgproc_EdgeAwareInterpolator_t*)self)->v.get());
    float _sigma=0.f;

    const char* keywords[] = { "_sigma", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:ximgproc_EdgeAwareInterpolator.setSigma", (char**)keywords, &_sigma) )
    {
        ERRWRAP2(_self_->setSigma(_sigma));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_ximgproc_EdgeAwareInterpolator_setUsePostProcessing(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_EdgeAwareInterpolator_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_EdgeAwareInterpolator' or its derivative)");
    cv::ximgproc::EdgeAwareInterpolator* _self_ = dynamic_cast<cv::ximgproc::EdgeAwareInterpolator*>(((pyopencv_ximgproc_EdgeAwareInterpolator_t*)self)->v.get());
    bool _use_post_proc=0;

    const char* keywords[] = { "_use_post_proc", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "b:ximgproc_EdgeAwareInterpolator.setUsePostProcessing", (char**)keywords, &_use_post_proc) )
    {
        ERRWRAP2(_self_->setUsePostProcessing(_use_post_proc));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_ximgproc_EdgeAwareInterpolator_methods[] =
{
    {"getFGSLambda", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_EdgeAwareInterpolator_getFGSLambda, METH_VARARGS | METH_KEYWORDS, "getFGSLambda() -> retval"},
    {"getFGSSigma", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_EdgeAwareInterpolator_getFGSSigma, METH_VARARGS | METH_KEYWORDS, "getFGSSigma() -> retval"},
    {"getK", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_EdgeAwareInterpolator_getK, METH_VARARGS | METH_KEYWORDS, "getK() -> retval"},
    {"getLambda", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_EdgeAwareInterpolator_getLambda, METH_VARARGS | METH_KEYWORDS, "getLambda() -> retval"},
    {"getSigma", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_EdgeAwareInterpolator_getSigma, METH_VARARGS | METH_KEYWORDS, "getSigma() -> retval"},
    {"getUsePostProcessing", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_EdgeAwareInterpolator_getUsePostProcessing, METH_VARARGS | METH_KEYWORDS, "getUsePostProcessing() -> retval"},
    {"setFGSLambda", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_EdgeAwareInterpolator_setFGSLambda, METH_VARARGS | METH_KEYWORDS, "setFGSLambda(_lambda) -> None"},
    {"setFGSSigma", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_EdgeAwareInterpolator_setFGSSigma, METH_VARARGS | METH_KEYWORDS, "setFGSSigma(_sigma) -> None"},
    {"setK", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_EdgeAwareInterpolator_setK, METH_VARARGS | METH_KEYWORDS, "setK(_k) -> None"},
    {"setLambda", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_EdgeAwareInterpolator_setLambda, METH_VARARGS | METH_KEYWORDS, "setLambda(_lambda) -> None"},
    {"setSigma", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_EdgeAwareInterpolator_setSigma, METH_VARARGS | METH_KEYWORDS, "setSigma(_sigma) -> None"},
    {"setUsePostProcessing", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_EdgeAwareInterpolator_setUsePostProcessing, METH_VARARGS | METH_KEYWORDS, "setUsePostProcessing(_use_post_proc) -> None"},

    {NULL,          NULL}
};

static void pyopencv_ximgproc_EdgeAwareInterpolator_specials(void)
{
    pyopencv_ximgproc_EdgeAwareInterpolator_Type.tp_base = &pyopencv_ximgproc_SparseMatchInterpolator_Type;
    pyopencv_ximgproc_EdgeAwareInterpolator_Type.tp_dealloc = pyopencv_ximgproc_EdgeAwareInterpolator_dealloc;
    pyopencv_ximgproc_EdgeAwareInterpolator_Type.tp_repr = pyopencv_ximgproc_EdgeAwareInterpolator_repr;
    pyopencv_ximgproc_EdgeAwareInterpolator_Type.tp_getset = pyopencv_ximgproc_EdgeAwareInterpolator_getseters;
    pyopencv_ximgproc_EdgeAwareInterpolator_Type.tp_methods = pyopencv_ximgproc_EdgeAwareInterpolator_methods;
}

static PyObject* pyopencv_ximgproc_RFFeatureGetter_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<ximgproc_RFFeatureGetter %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_ximgproc_RFFeatureGetter_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_ximgproc_ximgproc_RFFeatureGetter_getFeatures(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_RFFeatureGetter_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_RFFeatureGetter' or its derivative)");
    cv::ximgproc::RFFeatureGetter* _self_ = dynamic_cast<cv::ximgproc::RFFeatureGetter*>(((pyopencv_ximgproc_RFFeatureGetter_t*)self)->v.get());
    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_features = NULL;
    Mat features;
    int gnrmRad=0;
    int gsmthRad=0;
    int shrink=0;
    int outNum=0;
    int gradNum=0;

    const char* keywords[] = { "src", "features", "gnrmRad", "gsmthRad", "shrink", "outNum", "gradNum", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OOiiiii:ximgproc_RFFeatureGetter.getFeatures", (char**)keywords, &pyobj_src, &pyobj_features, &gnrmRad, &gsmthRad, &shrink, &outNum, &gradNum) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_features, features, ArgInfo("features", 0)) )
    {
        ERRWRAP2(_self_->getFeatures(src, features, gnrmRad, gsmthRad, shrink, outNum, gradNum));
        Py_RETURN_NONE;
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_features = NULL;
    Mat features;
    int gnrmRad=0;
    int gsmthRad=0;
    int shrink=0;
    int outNum=0;
    int gradNum=0;

    const char* keywords[] = { "src", "features", "gnrmRad", "gsmthRad", "shrink", "outNum", "gradNum", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OOiiiii:ximgproc_RFFeatureGetter.getFeatures", (char**)keywords, &pyobj_src, &pyobj_features, &gnrmRad, &gsmthRad, &shrink, &outNum, &gradNum) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_features, features, ArgInfo("features", 0)) )
    {
        ERRWRAP2(_self_->getFeatures(src, features, gnrmRad, gsmthRad, shrink, outNum, gradNum));
        Py_RETURN_NONE;
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_ximgproc_RFFeatureGetter_methods[] =
{
    {"getFeatures", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_RFFeatureGetter_getFeatures, METH_VARARGS | METH_KEYWORDS, "getFeatures(src, features, gnrmRad, gsmthRad, shrink, outNum, gradNum) -> None"},

    {NULL,          NULL}
};

static void pyopencv_ximgproc_RFFeatureGetter_specials(void)
{
    pyopencv_ximgproc_RFFeatureGetter_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_ximgproc_RFFeatureGetter_Type.tp_dealloc = pyopencv_ximgproc_RFFeatureGetter_dealloc;
    pyopencv_ximgproc_RFFeatureGetter_Type.tp_repr = pyopencv_ximgproc_RFFeatureGetter_repr;
    pyopencv_ximgproc_RFFeatureGetter_Type.tp_getset = pyopencv_ximgproc_RFFeatureGetter_getseters;
    pyopencv_ximgproc_RFFeatureGetter_Type.tp_methods = pyopencv_ximgproc_RFFeatureGetter_methods;
}

static PyObject* pyopencv_ximgproc_StructuredEdgeDetection_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<ximgproc_StructuredEdgeDetection %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_ximgproc_StructuredEdgeDetection_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_ximgproc_ximgproc_StructuredEdgeDetection_detectEdges(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::ximgproc;

    if(!PyObject_TypeCheck(self, &pyopencv_ximgproc_StructuredEdgeDetection_Type))
        return failmsgp("Incorrect type of self (must be 'ximgproc_StructuredEdgeDetection' or its derivative)");
    cv::ximgproc::StructuredEdgeDetection* _self_ = dynamic_cast<cv::ximgproc::StructuredEdgeDetection*>(((pyopencv_ximgproc_StructuredEdgeDetection_t*)self)->v.get());
    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;

    const char* keywords[] = { "src", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:ximgproc_StructuredEdgeDetection.detectEdges", (char**)keywords, &pyobj_src, &pyobj_dst) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(_self_->detectEdges(src, dst));
        return pyopencv_from(dst);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;

    const char* keywords[] = { "src", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:ximgproc_StructuredEdgeDetection.detectEdges", (char**)keywords, &pyobj_src, &pyobj_dst) &&
        pyopencv_to(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(_self_->detectEdges(src, dst));
        return pyopencv_from(dst);
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_ximgproc_StructuredEdgeDetection_methods[] =
{
    {"detectEdges", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_StructuredEdgeDetection_detectEdges, METH_VARARGS | METH_KEYWORDS, "detectEdges(src[, dst]) -> dst"},

    {NULL,          NULL}
};

static void pyopencv_ximgproc_StructuredEdgeDetection_specials(void)
{
    pyopencv_ximgproc_StructuredEdgeDetection_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_ximgproc_StructuredEdgeDetection_Type.tp_dealloc = pyopencv_ximgproc_StructuredEdgeDetection_dealloc;
    pyopencv_ximgproc_StructuredEdgeDetection_Type.tp_repr = pyopencv_ximgproc_StructuredEdgeDetection_repr;
    pyopencv_ximgproc_StructuredEdgeDetection_Type.tp_getset = pyopencv_ximgproc_StructuredEdgeDetection_getseters;
    pyopencv_ximgproc_StructuredEdgeDetection_Type.tp_methods = pyopencv_ximgproc_StructuredEdgeDetection_methods;
}

static PyObject* pyopencv_aruco_DetectorParameters_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<aruco_DetectorParameters %p>", self);
    return PyString_FromString(str);
}


static PyObject* pyopencv_aruco_DetectorParameters_get_adaptiveThreshConstant(pyopencv_aruco_DetectorParameters_t* p, void *closure)
{
    return pyopencv_from(p->v->adaptiveThreshConstant);
}

static int pyopencv_aruco_DetectorParameters_set_adaptiveThreshConstant(pyopencv_aruco_DetectorParameters_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the adaptiveThreshConstant attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->adaptiveThreshConstant) ? 0 : -1;
}

static PyObject* pyopencv_aruco_DetectorParameters_get_adaptiveThreshWinSizeMax(pyopencv_aruco_DetectorParameters_t* p, void *closure)
{
    return pyopencv_from(p->v->adaptiveThreshWinSizeMax);
}

static int pyopencv_aruco_DetectorParameters_set_adaptiveThreshWinSizeMax(pyopencv_aruco_DetectorParameters_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the adaptiveThreshWinSizeMax attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->adaptiveThreshWinSizeMax) ? 0 : -1;
}

static PyObject* pyopencv_aruco_DetectorParameters_get_adaptiveThreshWinSizeMin(pyopencv_aruco_DetectorParameters_t* p, void *closure)
{
    return pyopencv_from(p->v->adaptiveThreshWinSizeMin);
}

static int pyopencv_aruco_DetectorParameters_set_adaptiveThreshWinSizeMin(pyopencv_aruco_DetectorParameters_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the adaptiveThreshWinSizeMin attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->adaptiveThreshWinSizeMin) ? 0 : -1;
}

static PyObject* pyopencv_aruco_DetectorParameters_get_adaptiveThreshWinSizeStep(pyopencv_aruco_DetectorParameters_t* p, void *closure)
{
    return pyopencv_from(p->v->adaptiveThreshWinSizeStep);
}

static int pyopencv_aruco_DetectorParameters_set_adaptiveThreshWinSizeStep(pyopencv_aruco_DetectorParameters_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the adaptiveThreshWinSizeStep attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->adaptiveThreshWinSizeStep) ? 0 : -1;
}

static PyObject* pyopencv_aruco_DetectorParameters_get_cornerRefinementMaxIterations(pyopencv_aruco_DetectorParameters_t* p, void *closure)
{
    return pyopencv_from(p->v->cornerRefinementMaxIterations);
}

static int pyopencv_aruco_DetectorParameters_set_cornerRefinementMaxIterations(pyopencv_aruco_DetectorParameters_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the cornerRefinementMaxIterations attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->cornerRefinementMaxIterations) ? 0 : -1;
}

static PyObject* pyopencv_aruco_DetectorParameters_get_cornerRefinementMinAccuracy(pyopencv_aruco_DetectorParameters_t* p, void *closure)
{
    return pyopencv_from(p->v->cornerRefinementMinAccuracy);
}

static int pyopencv_aruco_DetectorParameters_set_cornerRefinementMinAccuracy(pyopencv_aruco_DetectorParameters_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the cornerRefinementMinAccuracy attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->cornerRefinementMinAccuracy) ? 0 : -1;
}

static PyObject* pyopencv_aruco_DetectorParameters_get_cornerRefinementWinSize(pyopencv_aruco_DetectorParameters_t* p, void *closure)
{
    return pyopencv_from(p->v->cornerRefinementWinSize);
}

static int pyopencv_aruco_DetectorParameters_set_cornerRefinementWinSize(pyopencv_aruco_DetectorParameters_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the cornerRefinementWinSize attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->cornerRefinementWinSize) ? 0 : -1;
}

static PyObject* pyopencv_aruco_DetectorParameters_get_doCornerRefinement(pyopencv_aruco_DetectorParameters_t* p, void *closure)
{
    return pyopencv_from(p->v->doCornerRefinement);
}

static int pyopencv_aruco_DetectorParameters_set_doCornerRefinement(pyopencv_aruco_DetectorParameters_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the doCornerRefinement attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->doCornerRefinement) ? 0 : -1;
}

static PyObject* pyopencv_aruco_DetectorParameters_get_errorCorrectionRate(pyopencv_aruco_DetectorParameters_t* p, void *closure)
{
    return pyopencv_from(p->v->errorCorrectionRate);
}

static int pyopencv_aruco_DetectorParameters_set_errorCorrectionRate(pyopencv_aruco_DetectorParameters_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the errorCorrectionRate attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->errorCorrectionRate) ? 0 : -1;
}

static PyObject* pyopencv_aruco_DetectorParameters_get_markerBorderBits(pyopencv_aruco_DetectorParameters_t* p, void *closure)
{
    return pyopencv_from(p->v->markerBorderBits);
}

static int pyopencv_aruco_DetectorParameters_set_markerBorderBits(pyopencv_aruco_DetectorParameters_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the markerBorderBits attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->markerBorderBits) ? 0 : -1;
}

static PyObject* pyopencv_aruco_DetectorParameters_get_maxErroneousBitsInBorderRate(pyopencv_aruco_DetectorParameters_t* p, void *closure)
{
    return pyopencv_from(p->v->maxErroneousBitsInBorderRate);
}

static int pyopencv_aruco_DetectorParameters_set_maxErroneousBitsInBorderRate(pyopencv_aruco_DetectorParameters_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the maxErroneousBitsInBorderRate attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->maxErroneousBitsInBorderRate) ? 0 : -1;
}

static PyObject* pyopencv_aruco_DetectorParameters_get_maxMarkerPerimeterRate(pyopencv_aruco_DetectorParameters_t* p, void *closure)
{
    return pyopencv_from(p->v->maxMarkerPerimeterRate);
}

static int pyopencv_aruco_DetectorParameters_set_maxMarkerPerimeterRate(pyopencv_aruco_DetectorParameters_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the maxMarkerPerimeterRate attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->maxMarkerPerimeterRate) ? 0 : -1;
}

static PyObject* pyopencv_aruco_DetectorParameters_get_minCornerDistanceRate(pyopencv_aruco_DetectorParameters_t* p, void *closure)
{
    return pyopencv_from(p->v->minCornerDistanceRate);
}

static int pyopencv_aruco_DetectorParameters_set_minCornerDistanceRate(pyopencv_aruco_DetectorParameters_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the minCornerDistanceRate attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->minCornerDistanceRate) ? 0 : -1;
}

static PyObject* pyopencv_aruco_DetectorParameters_get_minDistanceToBorder(pyopencv_aruco_DetectorParameters_t* p, void *closure)
{
    return pyopencv_from(p->v->minDistanceToBorder);
}

static int pyopencv_aruco_DetectorParameters_set_minDistanceToBorder(pyopencv_aruco_DetectorParameters_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the minDistanceToBorder attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->minDistanceToBorder) ? 0 : -1;
}

static PyObject* pyopencv_aruco_DetectorParameters_get_minMarkerDistanceRate(pyopencv_aruco_DetectorParameters_t* p, void *closure)
{
    return pyopencv_from(p->v->minMarkerDistanceRate);
}

static int pyopencv_aruco_DetectorParameters_set_minMarkerDistanceRate(pyopencv_aruco_DetectorParameters_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the minMarkerDistanceRate attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->minMarkerDistanceRate) ? 0 : -1;
}

static PyObject* pyopencv_aruco_DetectorParameters_get_minMarkerPerimeterRate(pyopencv_aruco_DetectorParameters_t* p, void *closure)
{
    return pyopencv_from(p->v->minMarkerPerimeterRate);
}

static int pyopencv_aruco_DetectorParameters_set_minMarkerPerimeterRate(pyopencv_aruco_DetectorParameters_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the minMarkerPerimeterRate attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->minMarkerPerimeterRate) ? 0 : -1;
}

static PyObject* pyopencv_aruco_DetectorParameters_get_minOtsuStdDev(pyopencv_aruco_DetectorParameters_t* p, void *closure)
{
    return pyopencv_from(p->v->minOtsuStdDev);
}

static int pyopencv_aruco_DetectorParameters_set_minOtsuStdDev(pyopencv_aruco_DetectorParameters_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the minOtsuStdDev attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->minOtsuStdDev) ? 0 : -1;
}

static PyObject* pyopencv_aruco_DetectorParameters_get_perspectiveRemoveIgnoredMarginPerCell(pyopencv_aruco_DetectorParameters_t* p, void *closure)
{
    return pyopencv_from(p->v->perspectiveRemoveIgnoredMarginPerCell);
}

static int pyopencv_aruco_DetectorParameters_set_perspectiveRemoveIgnoredMarginPerCell(pyopencv_aruco_DetectorParameters_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the perspectiveRemoveIgnoredMarginPerCell attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->perspectiveRemoveIgnoredMarginPerCell) ? 0 : -1;
}

static PyObject* pyopencv_aruco_DetectorParameters_get_perspectiveRemovePixelPerCell(pyopencv_aruco_DetectorParameters_t* p, void *closure)
{
    return pyopencv_from(p->v->perspectiveRemovePixelPerCell);
}

static int pyopencv_aruco_DetectorParameters_set_perspectiveRemovePixelPerCell(pyopencv_aruco_DetectorParameters_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the perspectiveRemovePixelPerCell attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->perspectiveRemovePixelPerCell) ? 0 : -1;
}

static PyObject* pyopencv_aruco_DetectorParameters_get_polygonalApproxAccuracyRate(pyopencv_aruco_DetectorParameters_t* p, void *closure)
{
    return pyopencv_from(p->v->polygonalApproxAccuracyRate);
}

static int pyopencv_aruco_DetectorParameters_set_polygonalApproxAccuracyRate(pyopencv_aruco_DetectorParameters_t* p, PyObject *value, void *closure)
{
    if (value == NULL)
    {
        PyErr_SetString(PyExc_TypeError, "Cannot delete the polygonalApproxAccuracyRate attribute");
        return -1;
    }
    return pyopencv_to(value, p->v->polygonalApproxAccuracyRate) ? 0 : -1;
}


static PyGetSetDef pyopencv_aruco_DetectorParameters_getseters[] =
{
    {(char*)"adaptiveThreshConstant", (getter)pyopencv_aruco_DetectorParameters_get_adaptiveThreshConstant, (setter)pyopencv_aruco_DetectorParameters_set_adaptiveThreshConstant, (char*)"adaptiveThreshConstant", NULL},
    {(char*)"adaptiveThreshWinSizeMax", (getter)pyopencv_aruco_DetectorParameters_get_adaptiveThreshWinSizeMax, (setter)pyopencv_aruco_DetectorParameters_set_adaptiveThreshWinSizeMax, (char*)"adaptiveThreshWinSizeMax", NULL},
    {(char*)"adaptiveThreshWinSizeMin", (getter)pyopencv_aruco_DetectorParameters_get_adaptiveThreshWinSizeMin, (setter)pyopencv_aruco_DetectorParameters_set_adaptiveThreshWinSizeMin, (char*)"adaptiveThreshWinSizeMin", NULL},
    {(char*)"adaptiveThreshWinSizeStep", (getter)pyopencv_aruco_DetectorParameters_get_adaptiveThreshWinSizeStep, (setter)pyopencv_aruco_DetectorParameters_set_adaptiveThreshWinSizeStep, (char*)"adaptiveThreshWinSizeStep", NULL},
    {(char*)"cornerRefinementMaxIterations", (getter)pyopencv_aruco_DetectorParameters_get_cornerRefinementMaxIterations, (setter)pyopencv_aruco_DetectorParameters_set_cornerRefinementMaxIterations, (char*)"cornerRefinementMaxIterations", NULL},
    {(char*)"cornerRefinementMinAccuracy", (getter)pyopencv_aruco_DetectorParameters_get_cornerRefinementMinAccuracy, (setter)pyopencv_aruco_DetectorParameters_set_cornerRefinementMinAccuracy, (char*)"cornerRefinementMinAccuracy", NULL},
    {(char*)"cornerRefinementWinSize", (getter)pyopencv_aruco_DetectorParameters_get_cornerRefinementWinSize, (setter)pyopencv_aruco_DetectorParameters_set_cornerRefinementWinSize, (char*)"cornerRefinementWinSize", NULL},
    {(char*)"doCornerRefinement", (getter)pyopencv_aruco_DetectorParameters_get_doCornerRefinement, (setter)pyopencv_aruco_DetectorParameters_set_doCornerRefinement, (char*)"doCornerRefinement", NULL},
    {(char*)"errorCorrectionRate", (getter)pyopencv_aruco_DetectorParameters_get_errorCorrectionRate, (setter)pyopencv_aruco_DetectorParameters_set_errorCorrectionRate, (char*)"errorCorrectionRate", NULL},
    {(char*)"markerBorderBits", (getter)pyopencv_aruco_DetectorParameters_get_markerBorderBits, (setter)pyopencv_aruco_DetectorParameters_set_markerBorderBits, (char*)"markerBorderBits", NULL},
    {(char*)"maxErroneousBitsInBorderRate", (getter)pyopencv_aruco_DetectorParameters_get_maxErroneousBitsInBorderRate, (setter)pyopencv_aruco_DetectorParameters_set_maxErroneousBitsInBorderRate, (char*)"maxErroneousBitsInBorderRate", NULL},
    {(char*)"maxMarkerPerimeterRate", (getter)pyopencv_aruco_DetectorParameters_get_maxMarkerPerimeterRate, (setter)pyopencv_aruco_DetectorParameters_set_maxMarkerPerimeterRate, (char*)"maxMarkerPerimeterRate", NULL},
    {(char*)"minCornerDistanceRate", (getter)pyopencv_aruco_DetectorParameters_get_minCornerDistanceRate, (setter)pyopencv_aruco_DetectorParameters_set_minCornerDistanceRate, (char*)"minCornerDistanceRate", NULL},
    {(char*)"minDistanceToBorder", (getter)pyopencv_aruco_DetectorParameters_get_minDistanceToBorder, (setter)pyopencv_aruco_DetectorParameters_set_minDistanceToBorder, (char*)"minDistanceToBorder", NULL},
    {(char*)"minMarkerDistanceRate", (getter)pyopencv_aruco_DetectorParameters_get_minMarkerDistanceRate, (setter)pyopencv_aruco_DetectorParameters_set_minMarkerDistanceRate, (char*)"minMarkerDistanceRate", NULL},
    {(char*)"minMarkerPerimeterRate", (getter)pyopencv_aruco_DetectorParameters_get_minMarkerPerimeterRate, (setter)pyopencv_aruco_DetectorParameters_set_minMarkerPerimeterRate, (char*)"minMarkerPerimeterRate", NULL},
    {(char*)"minOtsuStdDev", (getter)pyopencv_aruco_DetectorParameters_get_minOtsuStdDev, (setter)pyopencv_aruco_DetectorParameters_set_minOtsuStdDev, (char*)"minOtsuStdDev", NULL},
    {(char*)"perspectiveRemoveIgnoredMarginPerCell", (getter)pyopencv_aruco_DetectorParameters_get_perspectiveRemoveIgnoredMarginPerCell, (setter)pyopencv_aruco_DetectorParameters_set_perspectiveRemoveIgnoredMarginPerCell, (char*)"perspectiveRemoveIgnoredMarginPerCell", NULL},
    {(char*)"perspectiveRemovePixelPerCell", (getter)pyopencv_aruco_DetectorParameters_get_perspectiveRemovePixelPerCell, (setter)pyopencv_aruco_DetectorParameters_set_perspectiveRemovePixelPerCell, (char*)"perspectiveRemovePixelPerCell", NULL},
    {(char*)"polygonalApproxAccuracyRate", (getter)pyopencv_aruco_DetectorParameters_get_polygonalApproxAccuracyRate, (setter)pyopencv_aruco_DetectorParameters_set_polygonalApproxAccuracyRate, (char*)"polygonalApproxAccuracyRate", NULL},
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_aruco_DetectorParameters_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_aruco_DetectorParameters_specials(void)
{
    pyopencv_aruco_DetectorParameters_Type.tp_base = NULL;
    pyopencv_aruco_DetectorParameters_Type.tp_dealloc = pyopencv_aruco_DetectorParameters_dealloc;
    pyopencv_aruco_DetectorParameters_Type.tp_repr = pyopencv_aruco_DetectorParameters_repr;
    pyopencv_aruco_DetectorParameters_Type.tp_getset = pyopencv_aruco_DetectorParameters_getseters;
    pyopencv_aruco_DetectorParameters_Type.tp_methods = pyopencv_aruco_DetectorParameters_methods;
}

static PyObject* pyopencv_aruco_Board_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<aruco_Board %p>", self);
    return PyString_FromString(str);
}


static PyObject* pyopencv_aruco_Board_get_dictionary(pyopencv_aruco_Board_t* p, void *closure)
{
    return pyopencv_from(p->v->dictionary);
}

static PyObject* pyopencv_aruco_Board_get_ids(pyopencv_aruco_Board_t* p, void *closure)
{
    return pyopencv_from(p->v->ids);
}

static PyObject* pyopencv_aruco_Board_get_objPoints(pyopencv_aruco_Board_t* p, void *closure)
{
    return pyopencv_from(p->v->objPoints);
}


static PyGetSetDef pyopencv_aruco_Board_getseters[] =
{
    {(char*)"dictionary", (getter)pyopencv_aruco_Board_get_dictionary, NULL, (char*)"dictionary", NULL},
    {(char*)"ids", (getter)pyopencv_aruco_Board_get_ids, NULL, (char*)"ids", NULL},
    {(char*)"objPoints", (getter)pyopencv_aruco_Board_get_objPoints, NULL, (char*)"objPoints", NULL},
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_aruco_Board_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_aruco_Board_specials(void)
{
    pyopencv_aruco_Board_Type.tp_base = NULL;
    pyopencv_aruco_Board_Type.tp_dealloc = pyopencv_aruco_Board_dealloc;
    pyopencv_aruco_Board_Type.tp_repr = pyopencv_aruco_Board_repr;
    pyopencv_aruco_Board_Type.tp_getset = pyopencv_aruco_Board_getseters;
    pyopencv_aruco_Board_Type.tp_methods = pyopencv_aruco_Board_methods;
}

static PyObject* pyopencv_aruco_GridBoard_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<aruco_GridBoard %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_aruco_GridBoard_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_aruco_aruco_GridBoard_draw(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::aruco;

    if(!PyObject_TypeCheck(self, &pyopencv_aruco_GridBoard_Type))
        return failmsgp("Incorrect type of self (must be 'aruco_GridBoard' or its derivative)");
    cv::aruco::GridBoard* _self_ = ((pyopencv_aruco_GridBoard_t*)self)->v.get();
    {
    PyObject* pyobj_outSize = NULL;
    Size outSize;
    PyObject* pyobj_img = NULL;
    Mat img;
    int marginSize=0;
    int borderBits=1;

    const char* keywords[] = { "outSize", "img", "marginSize", "borderBits", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|Oii:aruco_GridBoard.draw", (char**)keywords, &pyobj_outSize, &pyobj_img, &marginSize, &borderBits) &&
        pyopencv_to(pyobj_outSize, outSize, ArgInfo("outSize", 0)) &&
        pyopencv_to(pyobj_img, img, ArgInfo("img", 1)) )
    {
        ERRWRAP2(_self_->draw(outSize, img, marginSize, borderBits));
        return pyopencv_from(img);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_outSize = NULL;
    Size outSize;
    PyObject* pyobj_img = NULL;
    UMat img;
    int marginSize=0;
    int borderBits=1;

    const char* keywords[] = { "outSize", "img", "marginSize", "borderBits", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|Oii:aruco_GridBoard.draw", (char**)keywords, &pyobj_outSize, &pyobj_img, &marginSize, &borderBits) &&
        pyopencv_to(pyobj_outSize, outSize, ArgInfo("outSize", 0)) &&
        pyopencv_to(pyobj_img, img, ArgInfo("img", 1)) )
    {
        ERRWRAP2(_self_->draw(outSize, img, marginSize, borderBits));
        return pyopencv_from(img);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_aruco_aruco_GridBoard_getGridSize(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::aruco;

    if(!PyObject_TypeCheck(self, &pyopencv_aruco_GridBoard_Type))
        return failmsgp("Incorrect type of self (must be 'aruco_GridBoard' or its derivative)");
    cv::aruco::GridBoard* _self_ = ((pyopencv_aruco_GridBoard_t*)self)->v.get();
    Size retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getGridSize());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_aruco_aruco_GridBoard_getMarkerLength(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::aruco;

    if(!PyObject_TypeCheck(self, &pyopencv_aruco_GridBoard_Type))
        return failmsgp("Incorrect type of self (must be 'aruco_GridBoard' or its derivative)");
    cv::aruco::GridBoard* _self_ = ((pyopencv_aruco_GridBoard_t*)self)->v.get();
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getMarkerLength());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_aruco_aruco_GridBoard_getMarkerSeparation(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::aruco;

    if(!PyObject_TypeCheck(self, &pyopencv_aruco_GridBoard_Type))
        return failmsgp("Incorrect type of self (must be 'aruco_GridBoard' or its derivative)");
    cv::aruco::GridBoard* _self_ = ((pyopencv_aruco_GridBoard_t*)self)->v.get();
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getMarkerSeparation());
        return pyopencv_from(retval);
    }

    return NULL;
}



static PyMethodDef pyopencv_aruco_GridBoard_methods[] =
{
    {"draw", (PyCFunction)pyopencv_cv_aruco_aruco_GridBoard_draw, METH_VARARGS | METH_KEYWORDS, "draw(outSize[, img[, marginSize[, borderBits]]]) -> img"},
    {"getGridSize", (PyCFunction)pyopencv_cv_aruco_aruco_GridBoard_getGridSize, METH_VARARGS | METH_KEYWORDS, "getGridSize() -> retval"},
    {"getMarkerLength", (PyCFunction)pyopencv_cv_aruco_aruco_GridBoard_getMarkerLength, METH_VARARGS | METH_KEYWORDS, "getMarkerLength() -> retval"},
    {"getMarkerSeparation", (PyCFunction)pyopencv_cv_aruco_aruco_GridBoard_getMarkerSeparation, METH_VARARGS | METH_KEYWORDS, "getMarkerSeparation() -> retval"},

    {NULL,          NULL}
};

static void pyopencv_aruco_GridBoard_specials(void)
{
    pyopencv_aruco_GridBoard_Type.tp_base = &pyopencv_aruco_Board_Type;
    pyopencv_aruco_GridBoard_Type.tp_dealloc = pyopencv_aruco_GridBoard_dealloc;
    pyopencv_aruco_GridBoard_Type.tp_repr = pyopencv_aruco_GridBoard_repr;
    pyopencv_aruco_GridBoard_Type.tp_getset = pyopencv_aruco_GridBoard_getseters;
    pyopencv_aruco_GridBoard_Type.tp_methods = pyopencv_aruco_GridBoard_methods;
}

static PyObject* pyopencv_aruco_CharucoBoard_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<aruco_CharucoBoard %p>", self);
    return PyString_FromString(str);
}


static PyObject* pyopencv_aruco_CharucoBoard_get_chessboardCorners(pyopencv_aruco_CharucoBoard_t* p, void *closure)
{
    return pyopencv_from(p->v->chessboardCorners);
}

static PyObject* pyopencv_aruco_CharucoBoard_get_nearestMarkerCorners(pyopencv_aruco_CharucoBoard_t* p, void *closure)
{
    return pyopencv_from(p->v->nearestMarkerCorners);
}

static PyObject* pyopencv_aruco_CharucoBoard_get_nearestMarkerIdx(pyopencv_aruco_CharucoBoard_t* p, void *closure)
{
    return pyopencv_from(p->v->nearestMarkerIdx);
}


static PyGetSetDef pyopencv_aruco_CharucoBoard_getseters[] =
{
    {(char*)"chessboardCorners", (getter)pyopencv_aruco_CharucoBoard_get_chessboardCorners, NULL, (char*)"chessboardCorners", NULL},
    {(char*)"nearestMarkerCorners", (getter)pyopencv_aruco_CharucoBoard_get_nearestMarkerCorners, NULL, (char*)"nearestMarkerCorners", NULL},
    {(char*)"nearestMarkerIdx", (getter)pyopencv_aruco_CharucoBoard_get_nearestMarkerIdx, NULL, (char*)"nearestMarkerIdx", NULL},
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_aruco_aruco_CharucoBoard_draw(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::aruco;

    if(!PyObject_TypeCheck(self, &pyopencv_aruco_CharucoBoard_Type))
        return failmsgp("Incorrect type of self (must be 'aruco_CharucoBoard' or its derivative)");
    cv::aruco::CharucoBoard* _self_ = ((pyopencv_aruco_CharucoBoard_t*)self)->v.get();
    {
    PyObject* pyobj_outSize = NULL;
    Size outSize;
    PyObject* pyobj_img = NULL;
    Mat img;
    int marginSize=0;
    int borderBits=1;

    const char* keywords[] = { "outSize", "img", "marginSize", "borderBits", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|Oii:aruco_CharucoBoard.draw", (char**)keywords, &pyobj_outSize, &pyobj_img, &marginSize, &borderBits) &&
        pyopencv_to(pyobj_outSize, outSize, ArgInfo("outSize", 0)) &&
        pyopencv_to(pyobj_img, img, ArgInfo("img", 1)) )
    {
        ERRWRAP2(_self_->draw(outSize, img, marginSize, borderBits));
        return pyopencv_from(img);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_outSize = NULL;
    Size outSize;
    PyObject* pyobj_img = NULL;
    UMat img;
    int marginSize=0;
    int borderBits=1;

    const char* keywords[] = { "outSize", "img", "marginSize", "borderBits", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|Oii:aruco_CharucoBoard.draw", (char**)keywords, &pyobj_outSize, &pyobj_img, &marginSize, &borderBits) &&
        pyopencv_to(pyobj_outSize, outSize, ArgInfo("outSize", 0)) &&
        pyopencv_to(pyobj_img, img, ArgInfo("img", 1)) )
    {
        ERRWRAP2(_self_->draw(outSize, img, marginSize, borderBits));
        return pyopencv_from(img);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_aruco_aruco_CharucoBoard_getChessboardSize(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::aruco;

    if(!PyObject_TypeCheck(self, &pyopencv_aruco_CharucoBoard_Type))
        return failmsgp("Incorrect type of self (must be 'aruco_CharucoBoard' or its derivative)");
    cv::aruco::CharucoBoard* _self_ = ((pyopencv_aruco_CharucoBoard_t*)self)->v.get();
    Size retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getChessboardSize());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_aruco_aruco_CharucoBoard_getMarkerLength(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::aruco;

    if(!PyObject_TypeCheck(self, &pyopencv_aruco_CharucoBoard_Type))
        return failmsgp("Incorrect type of self (must be 'aruco_CharucoBoard' or its derivative)");
    cv::aruco::CharucoBoard* _self_ = ((pyopencv_aruco_CharucoBoard_t*)self)->v.get();
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getMarkerLength());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_aruco_aruco_CharucoBoard_getSquareLength(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::aruco;

    if(!PyObject_TypeCheck(self, &pyopencv_aruco_CharucoBoard_Type))
        return failmsgp("Incorrect type of self (must be 'aruco_CharucoBoard' or its derivative)");
    cv::aruco::CharucoBoard* _self_ = ((pyopencv_aruco_CharucoBoard_t*)self)->v.get();
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getSquareLength());
        return pyopencv_from(retval);
    }

    return NULL;
}



static PyMethodDef pyopencv_aruco_CharucoBoard_methods[] =
{
    {"draw", (PyCFunction)pyopencv_cv_aruco_aruco_CharucoBoard_draw, METH_VARARGS | METH_KEYWORDS, "draw(outSize[, img[, marginSize[, borderBits]]]) -> img"},
    {"getChessboardSize", (PyCFunction)pyopencv_cv_aruco_aruco_CharucoBoard_getChessboardSize, METH_VARARGS | METH_KEYWORDS, "getChessboardSize() -> retval"},
    {"getMarkerLength", (PyCFunction)pyopencv_cv_aruco_aruco_CharucoBoard_getMarkerLength, METH_VARARGS | METH_KEYWORDS, "getMarkerLength() -> retval"},
    {"getSquareLength", (PyCFunction)pyopencv_cv_aruco_aruco_CharucoBoard_getSquareLength, METH_VARARGS | METH_KEYWORDS, "getSquareLength() -> retval"},

    {NULL,          NULL}
};

static void pyopencv_aruco_CharucoBoard_specials(void)
{
    pyopencv_aruco_CharucoBoard_Type.tp_base = &pyopencv_aruco_Board_Type;
    pyopencv_aruco_CharucoBoard_Type.tp_dealloc = pyopencv_aruco_CharucoBoard_dealloc;
    pyopencv_aruco_CharucoBoard_Type.tp_repr = pyopencv_aruco_CharucoBoard_repr;
    pyopencv_aruco_CharucoBoard_Type.tp_getset = pyopencv_aruco_CharucoBoard_getseters;
    pyopencv_aruco_CharucoBoard_Type.tp_methods = pyopencv_aruco_CharucoBoard_methods;
}

static PyObject* pyopencv_aruco_Dictionary_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<aruco_Dictionary %p>", self);
    return PyString_FromString(str);
}


static PyObject* pyopencv_aruco_Dictionary_get_bytesList(pyopencv_aruco_Dictionary_t* p, void *closure)
{
    return pyopencv_from(p->v->bytesList);
}

static PyObject* pyopencv_aruco_Dictionary_get_markerSize(pyopencv_aruco_Dictionary_t* p, void *closure)
{
    return pyopencv_from(p->v->markerSize);
}

static PyObject* pyopencv_aruco_Dictionary_get_maxCorrectionBits(pyopencv_aruco_Dictionary_t* p, void *closure)
{
    return pyopencv_from(p->v->maxCorrectionBits);
}


static PyGetSetDef pyopencv_aruco_Dictionary_getseters[] =
{
    {(char*)"bytesList", (getter)pyopencv_aruco_Dictionary_get_bytesList, NULL, (char*)"bytesList", NULL},
    {(char*)"markerSize", (getter)pyopencv_aruco_Dictionary_get_markerSize, NULL, (char*)"markerSize", NULL},
    {(char*)"maxCorrectionBits", (getter)pyopencv_aruco_Dictionary_get_maxCorrectionBits, NULL, (char*)"maxCorrectionBits", NULL},
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_aruco_aruco_Dictionary_drawMarker(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::aruco;

    if(!PyObject_TypeCheck(self, &pyopencv_aruco_Dictionary_Type))
        return failmsgp("Incorrect type of self (must be 'aruco_Dictionary' or its derivative)");
    cv::aruco::Dictionary* _self_ = ((pyopencv_aruco_Dictionary_t*)self)->v.get();
    {
    int id=0;
    int sidePixels=0;
    PyObject* pyobj__img = NULL;
    Mat _img;
    int borderBits=1;

    const char* keywords[] = { "id", "sidePixels", "_img", "borderBits", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "ii|Oi:aruco_Dictionary.drawMarker", (char**)keywords, &id, &sidePixels, &pyobj__img, &borderBits) &&
        pyopencv_to(pyobj__img, _img, ArgInfo("_img", 1)) )
    {
        ERRWRAP2(_self_->drawMarker(id, sidePixels, _img, borderBits));
        return pyopencv_from(_img);
    }
    }
    PyErr_Clear();

    {
    int id=0;
    int sidePixels=0;
    PyObject* pyobj__img = NULL;
    UMat _img;
    int borderBits=1;

    const char* keywords[] = { "id", "sidePixels", "_img", "borderBits", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "ii|Oi:aruco_Dictionary.drawMarker", (char**)keywords, &id, &sidePixels, &pyobj__img, &borderBits) &&
        pyopencv_to(pyobj__img, _img, ArgInfo("_img", 1)) )
    {
        ERRWRAP2(_self_->drawMarker(id, sidePixels, _img, borderBits));
        return pyopencv_from(_img);
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_aruco_Dictionary_methods[] =
{
    {"drawMarker", (PyCFunction)pyopencv_cv_aruco_aruco_Dictionary_drawMarker, METH_VARARGS | METH_KEYWORDS, "drawMarker(id, sidePixels[, _img[, borderBits]]) -> _img"},

    {NULL,          NULL}
};

static void pyopencv_aruco_Dictionary_specials(void)
{
    pyopencv_aruco_Dictionary_Type.tp_base = NULL;
    pyopencv_aruco_Dictionary_Type.tp_dealloc = pyopencv_aruco_Dictionary_dealloc;
    pyopencv_aruco_Dictionary_Type.tp_repr = pyopencv_aruco_Dictionary_repr;
    pyopencv_aruco_Dictionary_Type.tp_getset = pyopencv_aruco_Dictionary_getseters;
    pyopencv_aruco_Dictionary_Type.tp_methods = pyopencv_aruco_Dictionary_methods;
}

static PyObject* pyopencv_optflow_VariationalRefinement_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<optflow_VariationalRefinement %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_optflow_VariationalRefinement_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_optflow_optflow_VariationalRefinement_calcUV(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::optflow;

    if(!PyObject_TypeCheck(self, &pyopencv_optflow_VariationalRefinement_Type))
        return failmsgp("Incorrect type of self (must be 'optflow_VariationalRefinement' or its derivative)");
    cv::optflow::VariationalRefinement* _self_ = dynamic_cast<cv::optflow::VariationalRefinement*>(((pyopencv_optflow_VariationalRefinement_t*)self)->v.get());
    {
    PyObject* pyobj_I0 = NULL;
    Mat I0;
    PyObject* pyobj_I1 = NULL;
    Mat I1;
    PyObject* pyobj_flow_u = NULL;
    Mat flow_u;
    PyObject* pyobj_flow_v = NULL;
    Mat flow_v;

    const char* keywords[] = { "I0", "I1", "flow_u", "flow_v", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OOOO:optflow_VariationalRefinement.calcUV", (char**)keywords, &pyobj_I0, &pyobj_I1, &pyobj_flow_u, &pyobj_flow_v) &&
        pyopencv_to(pyobj_I0, I0, ArgInfo("I0", 0)) &&
        pyopencv_to(pyobj_I1, I1, ArgInfo("I1", 0)) &&
        pyopencv_to(pyobj_flow_u, flow_u, ArgInfo("flow_u", 1)) &&
        pyopencv_to(pyobj_flow_v, flow_v, ArgInfo("flow_v", 1)) )
    {
        ERRWRAP2(_self_->calcUV(I0, I1, flow_u, flow_v));
        return Py_BuildValue("(NN)", pyopencv_from(flow_u), pyopencv_from(flow_v));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_I0 = NULL;
    UMat I0;
    PyObject* pyobj_I1 = NULL;
    UMat I1;
    PyObject* pyobj_flow_u = NULL;
    UMat flow_u;
    PyObject* pyobj_flow_v = NULL;
    UMat flow_v;

    const char* keywords[] = { "I0", "I1", "flow_u", "flow_v", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OOOO:optflow_VariationalRefinement.calcUV", (char**)keywords, &pyobj_I0, &pyobj_I1, &pyobj_flow_u, &pyobj_flow_v) &&
        pyopencv_to(pyobj_I0, I0, ArgInfo("I0", 0)) &&
        pyopencv_to(pyobj_I1, I1, ArgInfo("I1", 0)) &&
        pyopencv_to(pyobj_flow_u, flow_u, ArgInfo("flow_u", 1)) &&
        pyopencv_to(pyobj_flow_v, flow_v, ArgInfo("flow_v", 1)) )
    {
        ERRWRAP2(_self_->calcUV(I0, I1, flow_u, flow_v));
        return Py_BuildValue("(NN)", pyopencv_from(flow_u), pyopencv_from(flow_v));
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_optflow_optflow_VariationalRefinement_getAlpha(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::optflow;

    if(!PyObject_TypeCheck(self, &pyopencv_optflow_VariationalRefinement_Type))
        return failmsgp("Incorrect type of self (must be 'optflow_VariationalRefinement' or its derivative)");
    cv::optflow::VariationalRefinement* _self_ = dynamic_cast<cv::optflow::VariationalRefinement*>(((pyopencv_optflow_VariationalRefinement_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getAlpha());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_optflow_optflow_VariationalRefinement_getDelta(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::optflow;

    if(!PyObject_TypeCheck(self, &pyopencv_optflow_VariationalRefinement_Type))
        return failmsgp("Incorrect type of self (must be 'optflow_VariationalRefinement' or its derivative)");
    cv::optflow::VariationalRefinement* _self_ = dynamic_cast<cv::optflow::VariationalRefinement*>(((pyopencv_optflow_VariationalRefinement_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getDelta());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_optflow_optflow_VariationalRefinement_getFixedPointIterations(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::optflow;

    if(!PyObject_TypeCheck(self, &pyopencv_optflow_VariationalRefinement_Type))
        return failmsgp("Incorrect type of self (must be 'optflow_VariationalRefinement' or its derivative)");
    cv::optflow::VariationalRefinement* _self_ = dynamic_cast<cv::optflow::VariationalRefinement*>(((pyopencv_optflow_VariationalRefinement_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getFixedPointIterations());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_optflow_optflow_VariationalRefinement_getGamma(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::optflow;

    if(!PyObject_TypeCheck(self, &pyopencv_optflow_VariationalRefinement_Type))
        return failmsgp("Incorrect type of self (must be 'optflow_VariationalRefinement' or its derivative)");
    cv::optflow::VariationalRefinement* _self_ = dynamic_cast<cv::optflow::VariationalRefinement*>(((pyopencv_optflow_VariationalRefinement_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getGamma());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_optflow_optflow_VariationalRefinement_getOmega(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::optflow;

    if(!PyObject_TypeCheck(self, &pyopencv_optflow_VariationalRefinement_Type))
        return failmsgp("Incorrect type of self (must be 'optflow_VariationalRefinement' or its derivative)");
    cv::optflow::VariationalRefinement* _self_ = dynamic_cast<cv::optflow::VariationalRefinement*>(((pyopencv_optflow_VariationalRefinement_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getOmega());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_optflow_optflow_VariationalRefinement_getSorIterations(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::optflow;

    if(!PyObject_TypeCheck(self, &pyopencv_optflow_VariationalRefinement_Type))
        return failmsgp("Incorrect type of self (must be 'optflow_VariationalRefinement' or its derivative)");
    cv::optflow::VariationalRefinement* _self_ = dynamic_cast<cv::optflow::VariationalRefinement*>(((pyopencv_optflow_VariationalRefinement_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getSorIterations());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_optflow_optflow_VariationalRefinement_setAlpha(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::optflow;

    if(!PyObject_TypeCheck(self, &pyopencv_optflow_VariationalRefinement_Type))
        return failmsgp("Incorrect type of self (must be 'optflow_VariationalRefinement' or its derivative)");
    cv::optflow::VariationalRefinement* _self_ = dynamic_cast<cv::optflow::VariationalRefinement*>(((pyopencv_optflow_VariationalRefinement_t*)self)->v.get());
    float val=0.f;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:optflow_VariationalRefinement.setAlpha", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setAlpha(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_optflow_optflow_VariationalRefinement_setDelta(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::optflow;

    if(!PyObject_TypeCheck(self, &pyopencv_optflow_VariationalRefinement_Type))
        return failmsgp("Incorrect type of self (must be 'optflow_VariationalRefinement' or its derivative)");
    cv::optflow::VariationalRefinement* _self_ = dynamic_cast<cv::optflow::VariationalRefinement*>(((pyopencv_optflow_VariationalRefinement_t*)self)->v.get());
    float val=0.f;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:optflow_VariationalRefinement.setDelta", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setDelta(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_optflow_optflow_VariationalRefinement_setFixedPointIterations(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::optflow;

    if(!PyObject_TypeCheck(self, &pyopencv_optflow_VariationalRefinement_Type))
        return failmsgp("Incorrect type of self (must be 'optflow_VariationalRefinement' or its derivative)");
    cv::optflow::VariationalRefinement* _self_ = dynamic_cast<cv::optflow::VariationalRefinement*>(((pyopencv_optflow_VariationalRefinement_t*)self)->v.get());
    int val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:optflow_VariationalRefinement.setFixedPointIterations", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setFixedPointIterations(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_optflow_optflow_VariationalRefinement_setGamma(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::optflow;

    if(!PyObject_TypeCheck(self, &pyopencv_optflow_VariationalRefinement_Type))
        return failmsgp("Incorrect type of self (must be 'optflow_VariationalRefinement' or its derivative)");
    cv::optflow::VariationalRefinement* _self_ = dynamic_cast<cv::optflow::VariationalRefinement*>(((pyopencv_optflow_VariationalRefinement_t*)self)->v.get());
    float val=0.f;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:optflow_VariationalRefinement.setGamma", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setGamma(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_optflow_optflow_VariationalRefinement_setOmega(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::optflow;

    if(!PyObject_TypeCheck(self, &pyopencv_optflow_VariationalRefinement_Type))
        return failmsgp("Incorrect type of self (must be 'optflow_VariationalRefinement' or its derivative)");
    cv::optflow::VariationalRefinement* _self_ = dynamic_cast<cv::optflow::VariationalRefinement*>(((pyopencv_optflow_VariationalRefinement_t*)self)->v.get());
    float val=0.f;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:optflow_VariationalRefinement.setOmega", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setOmega(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_optflow_optflow_VariationalRefinement_setSorIterations(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::optflow;

    if(!PyObject_TypeCheck(self, &pyopencv_optflow_VariationalRefinement_Type))
        return failmsgp("Incorrect type of self (must be 'optflow_VariationalRefinement' or its derivative)");
    cv::optflow::VariationalRefinement* _self_ = dynamic_cast<cv::optflow::VariationalRefinement*>(((pyopencv_optflow_VariationalRefinement_t*)self)->v.get());
    int val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:optflow_VariationalRefinement.setSorIterations", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setSorIterations(val));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_optflow_VariationalRefinement_methods[] =
{
    {"calcUV", (PyCFunction)pyopencv_cv_optflow_optflow_VariationalRefinement_calcUV, METH_VARARGS | METH_KEYWORDS, "calcUV(I0, I1, flow_u, flow_v) -> flow_u, flow_v"},
    {"getAlpha", (PyCFunction)pyopencv_cv_optflow_optflow_VariationalRefinement_getAlpha, METH_VARARGS | METH_KEYWORDS, "getAlpha() -> retval"},
    {"getDelta", (PyCFunction)pyopencv_cv_optflow_optflow_VariationalRefinement_getDelta, METH_VARARGS | METH_KEYWORDS, "getDelta() -> retval"},
    {"getFixedPointIterations", (PyCFunction)pyopencv_cv_optflow_optflow_VariationalRefinement_getFixedPointIterations, METH_VARARGS | METH_KEYWORDS, "getFixedPointIterations() -> retval"},
    {"getGamma", (PyCFunction)pyopencv_cv_optflow_optflow_VariationalRefinement_getGamma, METH_VARARGS | METH_KEYWORDS, "getGamma() -> retval"},
    {"getOmega", (PyCFunction)pyopencv_cv_optflow_optflow_VariationalRefinement_getOmega, METH_VARARGS | METH_KEYWORDS, "getOmega() -> retval"},
    {"getSorIterations", (PyCFunction)pyopencv_cv_optflow_optflow_VariationalRefinement_getSorIterations, METH_VARARGS | METH_KEYWORDS, "getSorIterations() -> retval"},
    {"setAlpha", (PyCFunction)pyopencv_cv_optflow_optflow_VariationalRefinement_setAlpha, METH_VARARGS | METH_KEYWORDS, "setAlpha(val) -> None"},
    {"setDelta", (PyCFunction)pyopencv_cv_optflow_optflow_VariationalRefinement_setDelta, METH_VARARGS | METH_KEYWORDS, "setDelta(val) -> None"},
    {"setFixedPointIterations", (PyCFunction)pyopencv_cv_optflow_optflow_VariationalRefinement_setFixedPointIterations, METH_VARARGS | METH_KEYWORDS, "setFixedPointIterations(val) -> None"},
    {"setGamma", (PyCFunction)pyopencv_cv_optflow_optflow_VariationalRefinement_setGamma, METH_VARARGS | METH_KEYWORDS, "setGamma(val) -> None"},
    {"setOmega", (PyCFunction)pyopencv_cv_optflow_optflow_VariationalRefinement_setOmega, METH_VARARGS | METH_KEYWORDS, "setOmega(val) -> None"},
    {"setSorIterations", (PyCFunction)pyopencv_cv_optflow_optflow_VariationalRefinement_setSorIterations, METH_VARARGS | METH_KEYWORDS, "setSorIterations(val) -> None"},

    {NULL,          NULL}
};

static void pyopencv_optflow_VariationalRefinement_specials(void)
{
    pyopencv_optflow_VariationalRefinement_Type.tp_base = &pyopencv_DenseOpticalFlow_Type;
    pyopencv_optflow_VariationalRefinement_Type.tp_dealloc = pyopencv_optflow_VariationalRefinement_dealloc;
    pyopencv_optflow_VariationalRefinement_Type.tp_repr = pyopencv_optflow_VariationalRefinement_repr;
    pyopencv_optflow_VariationalRefinement_Type.tp_getset = pyopencv_optflow_VariationalRefinement_getseters;
    pyopencv_optflow_VariationalRefinement_Type.tp_methods = pyopencv_optflow_VariationalRefinement_methods;
}

static PyObject* pyopencv_optflow_DISOpticalFlow_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<optflow_DISOpticalFlow %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_optflow_DISOpticalFlow_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_optflow_optflow_DISOpticalFlow_getFinestScale(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::optflow;

    if(!PyObject_TypeCheck(self, &pyopencv_optflow_DISOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'optflow_DISOpticalFlow' or its derivative)");
    cv::optflow::DISOpticalFlow* _self_ = dynamic_cast<cv::optflow::DISOpticalFlow*>(((pyopencv_optflow_DISOpticalFlow_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getFinestScale());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_optflow_optflow_DISOpticalFlow_getGradientDescentIterations(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::optflow;

    if(!PyObject_TypeCheck(self, &pyopencv_optflow_DISOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'optflow_DISOpticalFlow' or its derivative)");
    cv::optflow::DISOpticalFlow* _self_ = dynamic_cast<cv::optflow::DISOpticalFlow*>(((pyopencv_optflow_DISOpticalFlow_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getGradientDescentIterations());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_optflow_optflow_DISOpticalFlow_getPatchSize(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::optflow;

    if(!PyObject_TypeCheck(self, &pyopencv_optflow_DISOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'optflow_DISOpticalFlow' or its derivative)");
    cv::optflow::DISOpticalFlow* _self_ = dynamic_cast<cv::optflow::DISOpticalFlow*>(((pyopencv_optflow_DISOpticalFlow_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getPatchSize());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_optflow_optflow_DISOpticalFlow_getPatchStride(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::optflow;

    if(!PyObject_TypeCheck(self, &pyopencv_optflow_DISOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'optflow_DISOpticalFlow' or its derivative)");
    cv::optflow::DISOpticalFlow* _self_ = dynamic_cast<cv::optflow::DISOpticalFlow*>(((pyopencv_optflow_DISOpticalFlow_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getPatchStride());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_optflow_optflow_DISOpticalFlow_getUseMeanNormalization(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::optflow;

    if(!PyObject_TypeCheck(self, &pyopencv_optflow_DISOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'optflow_DISOpticalFlow' or its derivative)");
    cv::optflow::DISOpticalFlow* _self_ = dynamic_cast<cv::optflow::DISOpticalFlow*>(((pyopencv_optflow_DISOpticalFlow_t*)self)->v.get());
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getUseMeanNormalization());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_optflow_optflow_DISOpticalFlow_getUseSpatialPropagation(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::optflow;

    if(!PyObject_TypeCheck(self, &pyopencv_optflow_DISOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'optflow_DISOpticalFlow' or its derivative)");
    cv::optflow::DISOpticalFlow* _self_ = dynamic_cast<cv::optflow::DISOpticalFlow*>(((pyopencv_optflow_DISOpticalFlow_t*)self)->v.get());
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getUseSpatialPropagation());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_optflow_optflow_DISOpticalFlow_getVariationalRefinementAlpha(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::optflow;

    if(!PyObject_TypeCheck(self, &pyopencv_optflow_DISOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'optflow_DISOpticalFlow' or its derivative)");
    cv::optflow::DISOpticalFlow* _self_ = dynamic_cast<cv::optflow::DISOpticalFlow*>(((pyopencv_optflow_DISOpticalFlow_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getVariationalRefinementAlpha());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_optflow_optflow_DISOpticalFlow_getVariationalRefinementDelta(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::optflow;

    if(!PyObject_TypeCheck(self, &pyopencv_optflow_DISOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'optflow_DISOpticalFlow' or its derivative)");
    cv::optflow::DISOpticalFlow* _self_ = dynamic_cast<cv::optflow::DISOpticalFlow*>(((pyopencv_optflow_DISOpticalFlow_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getVariationalRefinementDelta());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_optflow_optflow_DISOpticalFlow_getVariationalRefinementGamma(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::optflow;

    if(!PyObject_TypeCheck(self, &pyopencv_optflow_DISOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'optflow_DISOpticalFlow' or its derivative)");
    cv::optflow::DISOpticalFlow* _self_ = dynamic_cast<cv::optflow::DISOpticalFlow*>(((pyopencv_optflow_DISOpticalFlow_t*)self)->v.get());
    float retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getVariationalRefinementGamma());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_optflow_optflow_DISOpticalFlow_getVariationalRefinementIterations(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::optflow;

    if(!PyObject_TypeCheck(self, &pyopencv_optflow_DISOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'optflow_DISOpticalFlow' or its derivative)");
    cv::optflow::DISOpticalFlow* _self_ = dynamic_cast<cv::optflow::DISOpticalFlow*>(((pyopencv_optflow_DISOpticalFlow_t*)self)->v.get());
    int retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getVariationalRefinementIterations());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_optflow_optflow_DISOpticalFlow_setFinestScale(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::optflow;

    if(!PyObject_TypeCheck(self, &pyopencv_optflow_DISOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'optflow_DISOpticalFlow' or its derivative)");
    cv::optflow::DISOpticalFlow* _self_ = dynamic_cast<cv::optflow::DISOpticalFlow*>(((pyopencv_optflow_DISOpticalFlow_t*)self)->v.get());
    int val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:optflow_DISOpticalFlow.setFinestScale", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setFinestScale(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_optflow_optflow_DISOpticalFlow_setGradientDescentIterations(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::optflow;

    if(!PyObject_TypeCheck(self, &pyopencv_optflow_DISOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'optflow_DISOpticalFlow' or its derivative)");
    cv::optflow::DISOpticalFlow* _self_ = dynamic_cast<cv::optflow::DISOpticalFlow*>(((pyopencv_optflow_DISOpticalFlow_t*)self)->v.get());
    int val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:optflow_DISOpticalFlow.setGradientDescentIterations", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setGradientDescentIterations(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_optflow_optflow_DISOpticalFlow_setPatchSize(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::optflow;

    if(!PyObject_TypeCheck(self, &pyopencv_optflow_DISOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'optflow_DISOpticalFlow' or its derivative)");
    cv::optflow::DISOpticalFlow* _self_ = dynamic_cast<cv::optflow::DISOpticalFlow*>(((pyopencv_optflow_DISOpticalFlow_t*)self)->v.get());
    int val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:optflow_DISOpticalFlow.setPatchSize", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setPatchSize(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_optflow_optflow_DISOpticalFlow_setPatchStride(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::optflow;

    if(!PyObject_TypeCheck(self, &pyopencv_optflow_DISOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'optflow_DISOpticalFlow' or its derivative)");
    cv::optflow::DISOpticalFlow* _self_ = dynamic_cast<cv::optflow::DISOpticalFlow*>(((pyopencv_optflow_DISOpticalFlow_t*)self)->v.get());
    int val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:optflow_DISOpticalFlow.setPatchStride", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setPatchStride(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_optflow_optflow_DISOpticalFlow_setUseMeanNormalization(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::optflow;

    if(!PyObject_TypeCheck(self, &pyopencv_optflow_DISOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'optflow_DISOpticalFlow' or its derivative)");
    cv::optflow::DISOpticalFlow* _self_ = dynamic_cast<cv::optflow::DISOpticalFlow*>(((pyopencv_optflow_DISOpticalFlow_t*)self)->v.get());
    bool val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "b:optflow_DISOpticalFlow.setUseMeanNormalization", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setUseMeanNormalization(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_optflow_optflow_DISOpticalFlow_setUseSpatialPropagation(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::optflow;

    if(!PyObject_TypeCheck(self, &pyopencv_optflow_DISOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'optflow_DISOpticalFlow' or its derivative)");
    cv::optflow::DISOpticalFlow* _self_ = dynamic_cast<cv::optflow::DISOpticalFlow*>(((pyopencv_optflow_DISOpticalFlow_t*)self)->v.get());
    bool val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "b:optflow_DISOpticalFlow.setUseSpatialPropagation", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setUseSpatialPropagation(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_optflow_optflow_DISOpticalFlow_setVariationalRefinementAlpha(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::optflow;

    if(!PyObject_TypeCheck(self, &pyopencv_optflow_DISOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'optflow_DISOpticalFlow' or its derivative)");
    cv::optflow::DISOpticalFlow* _self_ = dynamic_cast<cv::optflow::DISOpticalFlow*>(((pyopencv_optflow_DISOpticalFlow_t*)self)->v.get());
    float val=0.f;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:optflow_DISOpticalFlow.setVariationalRefinementAlpha", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setVariationalRefinementAlpha(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_optflow_optflow_DISOpticalFlow_setVariationalRefinementDelta(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::optflow;

    if(!PyObject_TypeCheck(self, &pyopencv_optflow_DISOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'optflow_DISOpticalFlow' or its derivative)");
    cv::optflow::DISOpticalFlow* _self_ = dynamic_cast<cv::optflow::DISOpticalFlow*>(((pyopencv_optflow_DISOpticalFlow_t*)self)->v.get());
    float val=0.f;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:optflow_DISOpticalFlow.setVariationalRefinementDelta", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setVariationalRefinementDelta(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_optflow_optflow_DISOpticalFlow_setVariationalRefinementGamma(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::optflow;

    if(!PyObject_TypeCheck(self, &pyopencv_optflow_DISOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'optflow_DISOpticalFlow' or its derivative)");
    cv::optflow::DISOpticalFlow* _self_ = dynamic_cast<cv::optflow::DISOpticalFlow*>(((pyopencv_optflow_DISOpticalFlow_t*)self)->v.get());
    float val=0.f;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "f:optflow_DISOpticalFlow.setVariationalRefinementGamma", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setVariationalRefinementGamma(val));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_optflow_optflow_DISOpticalFlow_setVariationalRefinementIterations(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::optflow;

    if(!PyObject_TypeCheck(self, &pyopencv_optflow_DISOpticalFlow_Type))
        return failmsgp("Incorrect type of self (must be 'optflow_DISOpticalFlow' or its derivative)");
    cv::optflow::DISOpticalFlow* _self_ = dynamic_cast<cv::optflow::DISOpticalFlow*>(((pyopencv_optflow_DISOpticalFlow_t*)self)->v.get());
    int val=0;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "i:optflow_DISOpticalFlow.setVariationalRefinementIterations", (char**)keywords, &val) )
    {
        ERRWRAP2(_self_->setVariationalRefinementIterations(val));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_optflow_DISOpticalFlow_methods[] =
{
    {"getFinestScale", (PyCFunction)pyopencv_cv_optflow_optflow_DISOpticalFlow_getFinestScale, METH_VARARGS | METH_KEYWORDS, "getFinestScale() -> retval"},
    {"getGradientDescentIterations", (PyCFunction)pyopencv_cv_optflow_optflow_DISOpticalFlow_getGradientDescentIterations, METH_VARARGS | METH_KEYWORDS, "getGradientDescentIterations() -> retval"},
    {"getPatchSize", (PyCFunction)pyopencv_cv_optflow_optflow_DISOpticalFlow_getPatchSize, METH_VARARGS | METH_KEYWORDS, "getPatchSize() -> retval"},
    {"getPatchStride", (PyCFunction)pyopencv_cv_optflow_optflow_DISOpticalFlow_getPatchStride, METH_VARARGS | METH_KEYWORDS, "getPatchStride() -> retval"},
    {"getUseMeanNormalization", (PyCFunction)pyopencv_cv_optflow_optflow_DISOpticalFlow_getUseMeanNormalization, METH_VARARGS | METH_KEYWORDS, "getUseMeanNormalization() -> retval"},
    {"getUseSpatialPropagation", (PyCFunction)pyopencv_cv_optflow_optflow_DISOpticalFlow_getUseSpatialPropagation, METH_VARARGS | METH_KEYWORDS, "getUseSpatialPropagation() -> retval"},
    {"getVariationalRefinementAlpha", (PyCFunction)pyopencv_cv_optflow_optflow_DISOpticalFlow_getVariationalRefinementAlpha, METH_VARARGS | METH_KEYWORDS, "getVariationalRefinementAlpha() -> retval"},
    {"getVariationalRefinementDelta", (PyCFunction)pyopencv_cv_optflow_optflow_DISOpticalFlow_getVariationalRefinementDelta, METH_VARARGS | METH_KEYWORDS, "getVariationalRefinementDelta() -> retval"},
    {"getVariationalRefinementGamma", (PyCFunction)pyopencv_cv_optflow_optflow_DISOpticalFlow_getVariationalRefinementGamma, METH_VARARGS | METH_KEYWORDS, "getVariationalRefinementGamma() -> retval"},
    {"getVariationalRefinementIterations", (PyCFunction)pyopencv_cv_optflow_optflow_DISOpticalFlow_getVariationalRefinementIterations, METH_VARARGS | METH_KEYWORDS, "getVariationalRefinementIterations() -> retval"},
    {"setFinestScale", (PyCFunction)pyopencv_cv_optflow_optflow_DISOpticalFlow_setFinestScale, METH_VARARGS | METH_KEYWORDS, "setFinestScale(val) -> None"},
    {"setGradientDescentIterations", (PyCFunction)pyopencv_cv_optflow_optflow_DISOpticalFlow_setGradientDescentIterations, METH_VARARGS | METH_KEYWORDS, "setGradientDescentIterations(val) -> None"},
    {"setPatchSize", (PyCFunction)pyopencv_cv_optflow_optflow_DISOpticalFlow_setPatchSize, METH_VARARGS | METH_KEYWORDS, "setPatchSize(val) -> None"},
    {"setPatchStride", (PyCFunction)pyopencv_cv_optflow_optflow_DISOpticalFlow_setPatchStride, METH_VARARGS | METH_KEYWORDS, "setPatchStride(val) -> None"},
    {"setUseMeanNormalization", (PyCFunction)pyopencv_cv_optflow_optflow_DISOpticalFlow_setUseMeanNormalization, METH_VARARGS | METH_KEYWORDS, "setUseMeanNormalization(val) -> None"},
    {"setUseSpatialPropagation", (PyCFunction)pyopencv_cv_optflow_optflow_DISOpticalFlow_setUseSpatialPropagation, METH_VARARGS | METH_KEYWORDS, "setUseSpatialPropagation(val) -> None"},
    {"setVariationalRefinementAlpha", (PyCFunction)pyopencv_cv_optflow_optflow_DISOpticalFlow_setVariationalRefinementAlpha, METH_VARARGS | METH_KEYWORDS, "setVariationalRefinementAlpha(val) -> None"},
    {"setVariationalRefinementDelta", (PyCFunction)pyopencv_cv_optflow_optflow_DISOpticalFlow_setVariationalRefinementDelta, METH_VARARGS | METH_KEYWORDS, "setVariationalRefinementDelta(val) -> None"},
    {"setVariationalRefinementGamma", (PyCFunction)pyopencv_cv_optflow_optflow_DISOpticalFlow_setVariationalRefinementGamma, METH_VARARGS | METH_KEYWORDS, "setVariationalRefinementGamma(val) -> None"},
    {"setVariationalRefinementIterations", (PyCFunction)pyopencv_cv_optflow_optflow_DISOpticalFlow_setVariationalRefinementIterations, METH_VARARGS | METH_KEYWORDS, "setVariationalRefinementIterations(val) -> None"},

    {NULL,          NULL}
};

static void pyopencv_optflow_DISOpticalFlow_specials(void)
{
    pyopencv_optflow_DISOpticalFlow_Type.tp_base = &pyopencv_DenseOpticalFlow_Type;
    pyopencv_optflow_DISOpticalFlow_Type.tp_dealloc = pyopencv_optflow_DISOpticalFlow_dealloc;
    pyopencv_optflow_DISOpticalFlow_Type.tp_repr = pyopencv_optflow_DISOpticalFlow_repr;
    pyopencv_optflow_DISOpticalFlow_Type.tp_getset = pyopencv_optflow_DISOpticalFlow_getseters;
    pyopencv_optflow_DISOpticalFlow_Type.tp_methods = pyopencv_optflow_DISOpticalFlow_methods;
}

static PyObject* pyopencv_optflow_PCAPrior_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<optflow_PCAPrior %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_optflow_PCAPrior_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_optflow_PCAPrior_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_optflow_PCAPrior_specials(void)
{
    pyopencv_optflow_PCAPrior_Type.tp_base = NULL;
    pyopencv_optflow_PCAPrior_Type.tp_dealloc = pyopencv_optflow_PCAPrior_dealloc;
    pyopencv_optflow_PCAPrior_Type.tp_repr = pyopencv_optflow_PCAPrior_repr;
    pyopencv_optflow_PCAPrior_Type.tp_getset = pyopencv_optflow_PCAPrior_getseters;
    pyopencv_optflow_PCAPrior_Type.tp_methods = pyopencv_optflow_PCAPrior_methods;
}

static PyObject* pyopencv_optflow_OpticalFlowPCAFlow_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<optflow_OpticalFlowPCAFlow %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_optflow_OpticalFlowPCAFlow_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_optflow_OpticalFlowPCAFlow_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_optflow_OpticalFlowPCAFlow_specials(void)
{
    pyopencv_optflow_OpticalFlowPCAFlow_Type.tp_base = &pyopencv_DenseOpticalFlow_Type;
    pyopencv_optflow_OpticalFlowPCAFlow_Type.tp_dealloc = pyopencv_optflow_OpticalFlowPCAFlow_dealloc;
    pyopencv_optflow_OpticalFlowPCAFlow_Type.tp_repr = pyopencv_optflow_OpticalFlowPCAFlow_repr;
    pyopencv_optflow_OpticalFlowPCAFlow_Type.tp_getset = pyopencv_optflow_OpticalFlowPCAFlow_getseters;
    pyopencv_optflow_OpticalFlowPCAFlow_Type.tp_methods = pyopencv_optflow_OpticalFlowPCAFlow_methods;
}

static PyObject* pyopencv_optflow_GPCPatchDescriptor_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<optflow_GPCPatchDescriptor %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_optflow_GPCPatchDescriptor_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_optflow_GPCPatchDescriptor_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_optflow_GPCPatchDescriptor_specials(void)
{
    pyopencv_optflow_GPCPatchDescriptor_Type.tp_base = NULL;
    pyopencv_optflow_GPCPatchDescriptor_Type.tp_dealloc = pyopencv_optflow_GPCPatchDescriptor_dealloc;
    pyopencv_optflow_GPCPatchDescriptor_Type.tp_repr = pyopencv_optflow_GPCPatchDescriptor_repr;
    pyopencv_optflow_GPCPatchDescriptor_Type.tp_getset = pyopencv_optflow_GPCPatchDescriptor_getseters;
    pyopencv_optflow_GPCPatchDescriptor_Type.tp_methods = pyopencv_optflow_GPCPatchDescriptor_methods;
}

static PyObject* pyopencv_optflow_GPCPatchSample_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<optflow_GPCPatchSample %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_optflow_GPCPatchSample_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_optflow_GPCPatchSample_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_optflow_GPCPatchSample_specials(void)
{
    pyopencv_optflow_GPCPatchSample_Type.tp_base = NULL;
    pyopencv_optflow_GPCPatchSample_Type.tp_dealloc = pyopencv_optflow_GPCPatchSample_dealloc;
    pyopencv_optflow_GPCPatchSample_Type.tp_repr = pyopencv_optflow_GPCPatchSample_repr;
    pyopencv_optflow_GPCPatchSample_Type.tp_getset = pyopencv_optflow_GPCPatchSample_getseters;
    pyopencv_optflow_GPCPatchSample_Type.tp_methods = pyopencv_optflow_GPCPatchSample_methods;
}

static PyObject* pyopencv_optflow_GPCTrainingSamples_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<optflow_GPCTrainingSamples %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_optflow_GPCTrainingSamples_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_optflow_GPCTrainingSamples_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_optflow_GPCTrainingSamples_specials(void)
{
    pyopencv_optflow_GPCTrainingSamples_Type.tp_base = NULL;
    pyopencv_optflow_GPCTrainingSamples_Type.tp_dealloc = pyopencv_optflow_GPCTrainingSamples_dealloc;
    pyopencv_optflow_GPCTrainingSamples_Type.tp_repr = pyopencv_optflow_GPCTrainingSamples_repr;
    pyopencv_optflow_GPCTrainingSamples_Type.tp_getset = pyopencv_optflow_GPCTrainingSamples_getseters;
    pyopencv_optflow_GPCTrainingSamples_Type.tp_methods = pyopencv_optflow_GPCTrainingSamples_methods;
}

static PyObject* pyopencv_optflow_GPCTree_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<optflow_GPCTree %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_optflow_GPCTree_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_optflow_GPCTree_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_optflow_GPCTree_specials(void)
{
    pyopencv_optflow_GPCTree_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_optflow_GPCTree_Type.tp_dealloc = pyopencv_optflow_GPCTree_dealloc;
    pyopencv_optflow_GPCTree_Type.tp_repr = pyopencv_optflow_GPCTree_repr;
    pyopencv_optflow_GPCTree_Type.tp_getset = pyopencv_optflow_GPCTree_getseters;
    pyopencv_optflow_GPCTree_Type.tp_methods = pyopencv_optflow_GPCTree_methods;
}

static PyObject* pyopencv_optflow_GPCDetails_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<optflow_GPCDetails %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_optflow_GPCDetails_getseters[] =
{
    {NULL}  /* Sentinel */
};



static PyMethodDef pyopencv_optflow_GPCDetails_methods[] =
{

    {NULL,          NULL}
};

static void pyopencv_optflow_GPCDetails_specials(void)
{
    pyopencv_optflow_GPCDetails_Type.tp_base = NULL;
    pyopencv_optflow_GPCDetails_Type.tp_dealloc = pyopencv_optflow_GPCDetails_dealloc;
    pyopencv_optflow_GPCDetails_Type.tp_repr = pyopencv_optflow_GPCDetails_repr;
    pyopencv_optflow_GPCDetails_Type.tp_getset = pyopencv_optflow_GPCDetails_getseters;
    pyopencv_optflow_GPCDetails_Type.tp_methods = pyopencv_optflow_GPCDetails_methods;
}

static PyObject* pyopencv_phase_unwrapping_HistogramPhaseUnwrapping_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<phase_unwrapping_HistogramPhaseUnwrapping %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_phase_unwrapping_HistogramPhaseUnwrapping_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_phase_unwrapping_phase_unwrapping_HistogramPhaseUnwrapping_getInverseReliabilityMap(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::phase_unwrapping;

    if(!PyObject_TypeCheck(self, &pyopencv_phase_unwrapping_HistogramPhaseUnwrapping_Type))
        return failmsgp("Incorrect type of self (must be 'phase_unwrapping_HistogramPhaseUnwrapping' or its derivative)");
    cv::phase_unwrapping::HistogramPhaseUnwrapping* _self_ = dynamic_cast<cv::phase_unwrapping::HistogramPhaseUnwrapping*>(((pyopencv_phase_unwrapping_HistogramPhaseUnwrapping_t*)self)->v.get());
    {
    PyObject* pyobj_reliabilityMap = NULL;
    Mat reliabilityMap;

    const char* keywords[] = { "reliabilityMap", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|O:phase_unwrapping_HistogramPhaseUnwrapping.getInverseReliabilityMap", (char**)keywords, &pyobj_reliabilityMap) &&
        pyopencv_to(pyobj_reliabilityMap, reliabilityMap, ArgInfo("reliabilityMap", 1)) )
    {
        ERRWRAP2(_self_->getInverseReliabilityMap(reliabilityMap));
        return pyopencv_from(reliabilityMap);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_reliabilityMap = NULL;
    UMat reliabilityMap;

    const char* keywords[] = { "reliabilityMap", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|O:phase_unwrapping_HistogramPhaseUnwrapping.getInverseReliabilityMap", (char**)keywords, &pyobj_reliabilityMap) &&
        pyopencv_to(pyobj_reliabilityMap, reliabilityMap, ArgInfo("reliabilityMap", 1)) )
    {
        ERRWRAP2(_self_->getInverseReliabilityMap(reliabilityMap));
        return pyopencv_from(reliabilityMap);
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_phase_unwrapping_HistogramPhaseUnwrapping_methods[] =
{
    {"getInverseReliabilityMap", (PyCFunction)pyopencv_cv_phase_unwrapping_phase_unwrapping_HistogramPhaseUnwrapping_getInverseReliabilityMap, METH_VARARGS | METH_KEYWORDS, "getInverseReliabilityMap([, reliabilityMap]) -> reliabilityMap"},

    {NULL,          NULL}
};

static void pyopencv_phase_unwrapping_HistogramPhaseUnwrapping_specials(void)
{
    pyopencv_phase_unwrapping_HistogramPhaseUnwrapping_Type.tp_base = &pyopencv_phase_unwrapping_PhaseUnwrapping_Type;
    pyopencv_phase_unwrapping_HistogramPhaseUnwrapping_Type.tp_dealloc = pyopencv_phase_unwrapping_HistogramPhaseUnwrapping_dealloc;
    pyopencv_phase_unwrapping_HistogramPhaseUnwrapping_Type.tp_repr = pyopencv_phase_unwrapping_HistogramPhaseUnwrapping_repr;
    pyopencv_phase_unwrapping_HistogramPhaseUnwrapping_Type.tp_getset = pyopencv_phase_unwrapping_HistogramPhaseUnwrapping_getseters;
    pyopencv_phase_unwrapping_HistogramPhaseUnwrapping_Type.tp_methods = pyopencv_phase_unwrapping_HistogramPhaseUnwrapping_methods;
}

static PyObject* pyopencv_phase_unwrapping_PhaseUnwrapping_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<phase_unwrapping_PhaseUnwrapping %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_phase_unwrapping_PhaseUnwrapping_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_phase_unwrapping_phase_unwrapping_PhaseUnwrapping_unwrapPhaseMap(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::phase_unwrapping;

    if(!PyObject_TypeCheck(self, &pyopencv_phase_unwrapping_PhaseUnwrapping_Type))
        return failmsgp("Incorrect type of self (must be 'phase_unwrapping_PhaseUnwrapping' or its derivative)");
    cv::phase_unwrapping::PhaseUnwrapping* _self_ = dynamic_cast<cv::phase_unwrapping::PhaseUnwrapping*>(((pyopencv_phase_unwrapping_PhaseUnwrapping_t*)self)->v.get());
    {
    PyObject* pyobj_wrappedPhaseMap = NULL;
    Mat wrappedPhaseMap;
    PyObject* pyobj_unwrappedPhaseMap = NULL;
    Mat unwrappedPhaseMap;
    PyObject* pyobj_shadowMask = NULL;
    Mat shadowMask;

    const char* keywords[] = { "wrappedPhaseMap", "unwrappedPhaseMap", "shadowMask", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|OO:phase_unwrapping_PhaseUnwrapping.unwrapPhaseMap", (char**)keywords, &pyobj_wrappedPhaseMap, &pyobj_unwrappedPhaseMap, &pyobj_shadowMask) &&
        pyopencv_to(pyobj_wrappedPhaseMap, wrappedPhaseMap, ArgInfo("wrappedPhaseMap", 0)) &&
        pyopencv_to(pyobj_unwrappedPhaseMap, unwrappedPhaseMap, ArgInfo("unwrappedPhaseMap", 1)) &&
        pyopencv_to(pyobj_shadowMask, shadowMask, ArgInfo("shadowMask", 0)) )
    {
        ERRWRAP2(_self_->unwrapPhaseMap(wrappedPhaseMap, unwrappedPhaseMap, shadowMask));
        return pyopencv_from(unwrappedPhaseMap);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_wrappedPhaseMap = NULL;
    UMat wrappedPhaseMap;
    PyObject* pyobj_unwrappedPhaseMap = NULL;
    UMat unwrappedPhaseMap;
    PyObject* pyobj_shadowMask = NULL;
    UMat shadowMask;

    const char* keywords[] = { "wrappedPhaseMap", "unwrappedPhaseMap", "shadowMask", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|OO:phase_unwrapping_PhaseUnwrapping.unwrapPhaseMap", (char**)keywords, &pyobj_wrappedPhaseMap, &pyobj_unwrappedPhaseMap, &pyobj_shadowMask) &&
        pyopencv_to(pyobj_wrappedPhaseMap, wrappedPhaseMap, ArgInfo("wrappedPhaseMap", 0)) &&
        pyopencv_to(pyobj_unwrappedPhaseMap, unwrappedPhaseMap, ArgInfo("unwrappedPhaseMap", 1)) &&
        pyopencv_to(pyobj_shadowMask, shadowMask, ArgInfo("shadowMask", 0)) )
    {
        ERRWRAP2(_self_->unwrapPhaseMap(wrappedPhaseMap, unwrappedPhaseMap, shadowMask));
        return pyopencv_from(unwrappedPhaseMap);
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_phase_unwrapping_PhaseUnwrapping_methods[] =
{
    {"unwrapPhaseMap", (PyCFunction)pyopencv_cv_phase_unwrapping_phase_unwrapping_PhaseUnwrapping_unwrapPhaseMap, METH_VARARGS | METH_KEYWORDS, "unwrapPhaseMap(wrappedPhaseMap[, unwrappedPhaseMap[, shadowMask]]) -> unwrappedPhaseMap"},

    {NULL,          NULL}
};

static void pyopencv_phase_unwrapping_PhaseUnwrapping_specials(void)
{
    pyopencv_phase_unwrapping_PhaseUnwrapping_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_phase_unwrapping_PhaseUnwrapping_Type.tp_dealloc = pyopencv_phase_unwrapping_PhaseUnwrapping_dealloc;
    pyopencv_phase_unwrapping_PhaseUnwrapping_Type.tp_repr = pyopencv_phase_unwrapping_PhaseUnwrapping_repr;
    pyopencv_phase_unwrapping_PhaseUnwrapping_Type.tp_getset = pyopencv_phase_unwrapping_PhaseUnwrapping_getseters;
    pyopencv_phase_unwrapping_PhaseUnwrapping_Type.tp_methods = pyopencv_phase_unwrapping_PhaseUnwrapping_methods;
}

static PyObject* pyopencv_Stitcher_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<Stitcher %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_Stitcher_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_Stitcher_composePanorama(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_Stitcher_Type))
        return failmsgp("Incorrect type of self (must be 'Stitcher' or its derivative)");
    cv::Stitcher* _self_ = ((pyopencv_Stitcher_t*)self)->v.get();
    {
    PyObject* pyobj_pano = NULL;
    Mat pano;
    Status retval;

    const char* keywords[] = { "pano", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|O:Stitcher.composePanorama", (char**)keywords, &pyobj_pano) &&
        pyopencv_to(pyobj_pano, pano, ArgInfo("pano", 1)) )
    {
        ERRWRAP2(retval = _self_->composePanorama(pano));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(pano));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_pano = NULL;
    UMat pano;
    Status retval;

    const char* keywords[] = { "pano", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|O:Stitcher.composePanorama", (char**)keywords, &pyobj_pano) &&
        pyopencv_to(pyobj_pano, pano, ArgInfo("pano", 1)) )
    {
        ERRWRAP2(retval = _self_->composePanorama(pano));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(pano));
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_Stitcher_compositingResol(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_Stitcher_Type))
        return failmsgp("Incorrect type of self (must be 'Stitcher' or its derivative)");
    cv::Stitcher* _self_ = ((pyopencv_Stitcher_t*)self)->v.get();
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->compositingResol());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_Stitcher_estimateTransform(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_Stitcher_Type))
        return failmsgp("Incorrect type of self (must be 'Stitcher' or its derivative)");
    cv::Stitcher* _self_ = ((pyopencv_Stitcher_t*)self)->v.get();
    {
    PyObject* pyobj_images = NULL;
    vector_Mat images;
    Status retval;

    const char* keywords[] = { "images", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:Stitcher.estimateTransform", (char**)keywords, &pyobj_images) &&
        pyopencv_to(pyobj_images, images, ArgInfo("images", 0)) )
    {
        ERRWRAP2(retval = _self_->estimateTransform(images));
        return pyopencv_from(retval);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_images = NULL;
    vector_Mat images;
    Status retval;

    const char* keywords[] = { "images", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O:Stitcher.estimateTransform", (char**)keywords, &pyobj_images) &&
        pyopencv_to(pyobj_images, images, ArgInfo("images", 0)) )
    {
        ERRWRAP2(retval = _self_->estimateTransform(images));
        return pyopencv_from(retval);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_Stitcher_panoConfidenceThresh(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_Stitcher_Type))
        return failmsgp("Incorrect type of self (must be 'Stitcher' or its derivative)");
    cv::Stitcher* _self_ = ((pyopencv_Stitcher_t*)self)->v.get();
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->panoConfidenceThresh());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_Stitcher_registrationResol(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_Stitcher_Type))
        return failmsgp("Incorrect type of self (must be 'Stitcher' or its derivative)");
    cv::Stitcher* _self_ = ((pyopencv_Stitcher_t*)self)->v.get();
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->registrationResol());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_Stitcher_seamEstimationResol(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_Stitcher_Type))
        return failmsgp("Incorrect type of self (must be 'Stitcher' or its derivative)");
    cv::Stitcher* _self_ = ((pyopencv_Stitcher_t*)self)->v.get();
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->seamEstimationResol());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_Stitcher_setCompositingResol(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_Stitcher_Type))
        return failmsgp("Incorrect type of self (must be 'Stitcher' or its derivative)");
    cv::Stitcher* _self_ = ((pyopencv_Stitcher_t*)self)->v.get();
    double resol_mpx=0;

    const char* keywords[] = { "resol_mpx", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:Stitcher.setCompositingResol", (char**)keywords, &resol_mpx) )
    {
        ERRWRAP2(_self_->setCompositingResol(resol_mpx));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_Stitcher_setPanoConfidenceThresh(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_Stitcher_Type))
        return failmsgp("Incorrect type of self (must be 'Stitcher' or its derivative)");
    cv::Stitcher* _self_ = ((pyopencv_Stitcher_t*)self)->v.get();
    double conf_thresh=0;

    const char* keywords[] = { "conf_thresh", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:Stitcher.setPanoConfidenceThresh", (char**)keywords, &conf_thresh) )
    {
        ERRWRAP2(_self_->setPanoConfidenceThresh(conf_thresh));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_Stitcher_setRegistrationResol(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_Stitcher_Type))
        return failmsgp("Incorrect type of self (must be 'Stitcher' or its derivative)");
    cv::Stitcher* _self_ = ((pyopencv_Stitcher_t*)self)->v.get();
    double resol_mpx=0;

    const char* keywords[] = { "resol_mpx", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:Stitcher.setRegistrationResol", (char**)keywords, &resol_mpx) )
    {
        ERRWRAP2(_self_->setRegistrationResol(resol_mpx));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_Stitcher_setSeamEstimationResol(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_Stitcher_Type))
        return failmsgp("Incorrect type of self (must be 'Stitcher' or its derivative)");
    cv::Stitcher* _self_ = ((pyopencv_Stitcher_t*)self)->v.get();
    double resol_mpx=0;

    const char* keywords[] = { "resol_mpx", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "d:Stitcher.setSeamEstimationResol", (char**)keywords, &resol_mpx) )
    {
        ERRWRAP2(_self_->setSeamEstimationResol(resol_mpx));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_Stitcher_setWaveCorrection(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_Stitcher_Type))
        return failmsgp("Incorrect type of self (must be 'Stitcher' or its derivative)");
    cv::Stitcher* _self_ = ((pyopencv_Stitcher_t*)self)->v.get();
    bool flag=0;

    const char* keywords[] = { "flag", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "b:Stitcher.setWaveCorrection", (char**)keywords, &flag) )
    {
        ERRWRAP2(_self_->setWaveCorrection(flag));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_Stitcher_stitch(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_Stitcher_Type))
        return failmsgp("Incorrect type of self (must be 'Stitcher' or its derivative)");
    cv::Stitcher* _self_ = ((pyopencv_Stitcher_t*)self)->v.get();
    {
    PyObject* pyobj_images = NULL;
    vector_Mat images;
    PyObject* pyobj_pano = NULL;
    Mat pano;
    Status retval;

    const char* keywords[] = { "images", "pano", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:Stitcher.stitch", (char**)keywords, &pyobj_images, &pyobj_pano) &&
        pyopencv_to(pyobj_images, images, ArgInfo("images", 0)) &&
        pyopencv_to(pyobj_pano, pano, ArgInfo("pano", 1)) )
    {
        ERRWRAP2(retval = _self_->stitch(images, pano));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(pano));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_images = NULL;
    vector_Mat images;
    PyObject* pyobj_pano = NULL;
    UMat pano;
    Status retval;

    const char* keywords[] = { "images", "pano", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|O:Stitcher.stitch", (char**)keywords, &pyobj_images, &pyobj_pano) &&
        pyopencv_to(pyobj_images, images, ArgInfo("images", 0)) &&
        pyopencv_to(pyobj_pano, pano, ArgInfo("pano", 1)) )
    {
        ERRWRAP2(retval = _self_->stitch(images, pano));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(pano));
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_Stitcher_waveCorrection(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_Stitcher_Type))
        return failmsgp("Incorrect type of self (must be 'Stitcher' or its derivative)");
    cv::Stitcher* _self_ = ((pyopencv_Stitcher_t*)self)->v.get();
    bool retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->waveCorrection());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_Stitcher_workScale(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv;

    if(!PyObject_TypeCheck(self, &pyopencv_Stitcher_Type))
        return failmsgp("Incorrect type of self (must be 'Stitcher' or its derivative)");
    cv::Stitcher* _self_ = ((pyopencv_Stitcher_t*)self)->v.get();
    double retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->workScale());
        return pyopencv_from(retval);
    }

    return NULL;
}



static PyMethodDef pyopencv_Stitcher_methods[] =
{
    {"composePanorama", (PyCFunction)pyopencv_cv_Stitcher_composePanorama, METH_VARARGS | METH_KEYWORDS, "composePanorama([, pano]) -> retval, pano"},
    {"compositingResol", (PyCFunction)pyopencv_cv_Stitcher_compositingResol, METH_VARARGS | METH_KEYWORDS, "compositingResol() -> retval"},
    {"estimateTransform", (PyCFunction)pyopencv_cv_Stitcher_estimateTransform, METH_VARARGS | METH_KEYWORDS, "estimateTransform(images) -> retval"},
    {"panoConfidenceThresh", (PyCFunction)pyopencv_cv_Stitcher_panoConfidenceThresh, METH_VARARGS | METH_KEYWORDS, "panoConfidenceThresh() -> retval"},
    {"registrationResol", (PyCFunction)pyopencv_cv_Stitcher_registrationResol, METH_VARARGS | METH_KEYWORDS, "registrationResol() -> retval"},
    {"seamEstimationResol", (PyCFunction)pyopencv_cv_Stitcher_seamEstimationResol, METH_VARARGS | METH_KEYWORDS, "seamEstimationResol() -> retval"},
    {"setCompositingResol", (PyCFunction)pyopencv_cv_Stitcher_setCompositingResol, METH_VARARGS | METH_KEYWORDS, "setCompositingResol(resol_mpx) -> None"},
    {"setPanoConfidenceThresh", (PyCFunction)pyopencv_cv_Stitcher_setPanoConfidenceThresh, METH_VARARGS | METH_KEYWORDS, "setPanoConfidenceThresh(conf_thresh) -> None"},
    {"setRegistrationResol", (PyCFunction)pyopencv_cv_Stitcher_setRegistrationResol, METH_VARARGS | METH_KEYWORDS, "setRegistrationResol(resol_mpx) -> None"},
    {"setSeamEstimationResol", (PyCFunction)pyopencv_cv_Stitcher_setSeamEstimationResol, METH_VARARGS | METH_KEYWORDS, "setSeamEstimationResol(resol_mpx) -> None"},
    {"setWaveCorrection", (PyCFunction)pyopencv_cv_Stitcher_setWaveCorrection, METH_VARARGS | METH_KEYWORDS, "setWaveCorrection(flag) -> None"},
    {"stitch", (PyCFunction)pyopencv_cv_Stitcher_stitch, METH_VARARGS | METH_KEYWORDS, "stitch(images[, pano]) -> retval, pano"},
    {"waveCorrection", (PyCFunction)pyopencv_cv_Stitcher_waveCorrection, METH_VARARGS | METH_KEYWORDS, "waveCorrection() -> retval"},
    {"workScale", (PyCFunction)pyopencv_cv_Stitcher_workScale, METH_VARARGS | METH_KEYWORDS, "workScale() -> retval"},

    {NULL,          NULL}
};

static void pyopencv_Stitcher_specials(void)
{
    pyopencv_Stitcher_Type.tp_base = NULL;
    pyopencv_Stitcher_Type.tp_dealloc = pyopencv_Stitcher_dealloc;
    pyopencv_Stitcher_Type.tp_repr = pyopencv_Stitcher_repr;
    pyopencv_Stitcher_Type.tp_getset = pyopencv_Stitcher_getseters;
    pyopencv_Stitcher_Type.tp_methods = pyopencv_Stitcher_methods;
}

static PyObject* pyopencv_structured_light_GrayCodePattern_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<structured_light_GrayCodePattern %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_structured_light_GrayCodePattern_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_structured_light_structured_light_GrayCodePattern_getImagesForShadowMasks(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::structured_light;

    if(!PyObject_TypeCheck(self, &pyopencv_structured_light_GrayCodePattern_Type))
        return failmsgp("Incorrect type of self (must be 'structured_light_GrayCodePattern' or its derivative)");
    cv::structured_light::GrayCodePattern* _self_ = dynamic_cast<cv::structured_light::GrayCodePattern*>(((pyopencv_structured_light_GrayCodePattern_t*)self)->v.get());
    {
    PyObject* pyobj_blackImage = NULL;
    Mat blackImage;
    PyObject* pyobj_whiteImage = NULL;
    Mat whiteImage;

    const char* keywords[] = { "blackImage", "whiteImage", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO:structured_light_GrayCodePattern.getImagesForShadowMasks", (char**)keywords, &pyobj_blackImage, &pyobj_whiteImage) &&
        pyopencv_to(pyobj_blackImage, blackImage, ArgInfo("blackImage", 1)) &&
        pyopencv_to(pyobj_whiteImage, whiteImage, ArgInfo("whiteImage", 1)) )
    {
        ERRWRAP2(_self_->getImagesForShadowMasks(blackImage, whiteImage));
        return Py_BuildValue("(NN)", pyopencv_from(blackImage), pyopencv_from(whiteImage));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_blackImage = NULL;
    UMat blackImage;
    PyObject* pyobj_whiteImage = NULL;
    UMat whiteImage;

    const char* keywords[] = { "blackImage", "whiteImage", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO:structured_light_GrayCodePattern.getImagesForShadowMasks", (char**)keywords, &pyobj_blackImage, &pyobj_whiteImage) &&
        pyopencv_to(pyobj_blackImage, blackImage, ArgInfo("blackImage", 1)) &&
        pyopencv_to(pyobj_whiteImage, whiteImage, ArgInfo("whiteImage", 1)) )
    {
        ERRWRAP2(_self_->getImagesForShadowMasks(blackImage, whiteImage));
        return Py_BuildValue("(NN)", pyopencv_from(blackImage), pyopencv_from(whiteImage));
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_structured_light_structured_light_GrayCodePattern_getNumberOfPatternImages(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::structured_light;

    if(!PyObject_TypeCheck(self, &pyopencv_structured_light_GrayCodePattern_Type))
        return failmsgp("Incorrect type of self (must be 'structured_light_GrayCodePattern' or its derivative)");
    cv::structured_light::GrayCodePattern* _self_ = dynamic_cast<cv::structured_light::GrayCodePattern*>(((pyopencv_structured_light_GrayCodePattern_t*)self)->v.get());
    size_t retval;

    if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = _self_->getNumberOfPatternImages());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_structured_light_structured_light_GrayCodePattern_getProjPixel(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::structured_light;

    if(!PyObject_TypeCheck(self, &pyopencv_structured_light_GrayCodePattern_Type))
        return failmsgp("Incorrect type of self (must be 'structured_light_GrayCodePattern' or its derivative)");
    cv::structured_light::GrayCodePattern* _self_ = dynamic_cast<cv::structured_light::GrayCodePattern*>(((pyopencv_structured_light_GrayCodePattern_t*)self)->v.get());
    {
    PyObject* pyobj_patternImages = NULL;
    vector_Mat patternImages;
    int x=0;
    int y=0;
    PyObject* pyobj_projPix = NULL;
    Point projPix;
    bool retval;

    const char* keywords[] = { "patternImages", "x", "y", "projPix", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OiiO:structured_light_GrayCodePattern.getProjPixel", (char**)keywords, &pyobj_patternImages, &x, &y, &pyobj_projPix) &&
        pyopencv_to(pyobj_patternImages, patternImages, ArgInfo("patternImages", 0)) &&
        pyopencv_to(pyobj_projPix, projPix, ArgInfo("projPix", 0)) )
    {
        ERRWRAP2(retval = _self_->getProjPixel(patternImages, x, y, projPix));
        return pyopencv_from(retval);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_patternImages = NULL;
    vector_Mat patternImages;
    int x=0;
    int y=0;
    PyObject* pyobj_projPix = NULL;
    Point projPix;
    bool retval;

    const char* keywords[] = { "patternImages", "x", "y", "projPix", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OiiO:structured_light_GrayCodePattern.getProjPixel", (char**)keywords, &pyobj_patternImages, &x, &y, &pyobj_projPix) &&
        pyopencv_to(pyobj_patternImages, patternImages, ArgInfo("patternImages", 0)) &&
        pyopencv_to(pyobj_projPix, projPix, ArgInfo("projPix", 0)) )
    {
        ERRWRAP2(retval = _self_->getProjPixel(patternImages, x, y, projPix));
        return pyopencv_from(retval);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_structured_light_structured_light_GrayCodePattern_setBlackThreshold(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::structured_light;

    if(!PyObject_TypeCheck(self, &pyopencv_structured_light_GrayCodePattern_Type))
        return failmsgp("Incorrect type of self (must be 'structured_light_GrayCodePattern' or its derivative)");
    cv::structured_light::GrayCodePattern* _self_ = dynamic_cast<cv::structured_light::GrayCodePattern*>(((pyopencv_structured_light_GrayCodePattern_t*)self)->v.get());
    size_t value=0;

    const char* keywords[] = { "value", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "I:structured_light_GrayCodePattern.setBlackThreshold", (char**)keywords, &value) )
    {
        ERRWRAP2(_self_->setBlackThreshold(value));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_structured_light_structured_light_GrayCodePattern_setWhiteThreshold(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::structured_light;

    if(!PyObject_TypeCheck(self, &pyopencv_structured_light_GrayCodePattern_Type))
        return failmsgp("Incorrect type of self (must be 'structured_light_GrayCodePattern' or its derivative)");
    cv::structured_light::GrayCodePattern* _self_ = dynamic_cast<cv::structured_light::GrayCodePattern*>(((pyopencv_structured_light_GrayCodePattern_t*)self)->v.get());
    size_t value=0;

    const char* keywords[] = { "value", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "I:structured_light_GrayCodePattern.setWhiteThreshold", (char**)keywords, &value) )
    {
        ERRWRAP2(_self_->setWhiteThreshold(value));
        Py_RETURN_NONE;
    }

    return NULL;
}



static PyMethodDef pyopencv_structured_light_GrayCodePattern_methods[] =
{
    {"getImagesForShadowMasks", (PyCFunction)pyopencv_cv_structured_light_structured_light_GrayCodePattern_getImagesForShadowMasks, METH_VARARGS | METH_KEYWORDS, "getImagesForShadowMasks(blackImage, whiteImage) -> blackImage, whiteImage"},
    {"getNumberOfPatternImages", (PyCFunction)pyopencv_cv_structured_light_structured_light_GrayCodePattern_getNumberOfPatternImages, METH_VARARGS | METH_KEYWORDS, "getNumberOfPatternImages() -> retval"},
    {"getProjPixel", (PyCFunction)pyopencv_cv_structured_light_structured_light_GrayCodePattern_getProjPixel, METH_VARARGS | METH_KEYWORDS, "getProjPixel(patternImages, x, y, projPix) -> retval"},
    {"setBlackThreshold", (PyCFunction)pyopencv_cv_structured_light_structured_light_GrayCodePattern_setBlackThreshold, METH_VARARGS | METH_KEYWORDS, "setBlackThreshold(value) -> None"},
    {"setWhiteThreshold", (PyCFunction)pyopencv_cv_structured_light_structured_light_GrayCodePattern_setWhiteThreshold, METH_VARARGS | METH_KEYWORDS, "setWhiteThreshold(value) -> None"},

    {NULL,          NULL}
};

static void pyopencv_structured_light_GrayCodePattern_specials(void)
{
    pyopencv_structured_light_GrayCodePattern_Type.tp_base = &pyopencv_structured_light_StructuredLightPattern_Type;
    pyopencv_structured_light_GrayCodePattern_Type.tp_dealloc = pyopencv_structured_light_GrayCodePattern_dealloc;
    pyopencv_structured_light_GrayCodePattern_Type.tp_repr = pyopencv_structured_light_GrayCodePattern_repr;
    pyopencv_structured_light_GrayCodePattern_Type.tp_getset = pyopencv_structured_light_GrayCodePattern_getseters;
    pyopencv_structured_light_GrayCodePattern_Type.tp_methods = pyopencv_structured_light_GrayCodePattern_methods;
}

static PyObject* pyopencv_structured_light_SinusoidalPattern_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<structured_light_SinusoidalPattern %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_structured_light_SinusoidalPattern_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_structured_light_structured_light_SinusoidalPattern_computeDataModulationTerm(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::structured_light;

    if(!PyObject_TypeCheck(self, &pyopencv_structured_light_SinusoidalPattern_Type))
        return failmsgp("Incorrect type of self (must be 'structured_light_SinusoidalPattern' or its derivative)");
    cv::structured_light::SinusoidalPattern* _self_ = dynamic_cast<cv::structured_light::SinusoidalPattern*>(((pyopencv_structured_light_SinusoidalPattern_t*)self)->v.get());
    {
    PyObject* pyobj_patternImages = NULL;
    vector_Mat patternImages;
    PyObject* pyobj_dataModulationTerm = NULL;
    Mat dataModulationTerm;
    PyObject* pyobj_shadowMask = NULL;
    Mat shadowMask;

    const char* keywords[] = { "patternImages", "shadowMask", "dataModulationTerm", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|O:structured_light_SinusoidalPattern.computeDataModulationTerm", (char**)keywords, &pyobj_patternImages, &pyobj_shadowMask, &pyobj_dataModulationTerm) &&
        pyopencv_to(pyobj_patternImages, patternImages, ArgInfo("patternImages", 0)) &&
        pyopencv_to(pyobj_dataModulationTerm, dataModulationTerm, ArgInfo("dataModulationTerm", 1)) &&
        pyopencv_to(pyobj_shadowMask, shadowMask, ArgInfo("shadowMask", 0)) )
    {
        ERRWRAP2(_self_->computeDataModulationTerm(patternImages, dataModulationTerm, shadowMask));
        return pyopencv_from(dataModulationTerm);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_patternImages = NULL;
    vector_Mat patternImages;
    PyObject* pyobj_dataModulationTerm = NULL;
    UMat dataModulationTerm;
    PyObject* pyobj_shadowMask = NULL;
    UMat shadowMask;

    const char* keywords[] = { "patternImages", "shadowMask", "dataModulationTerm", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|O:structured_light_SinusoidalPattern.computeDataModulationTerm", (char**)keywords, &pyobj_patternImages, &pyobj_shadowMask, &pyobj_dataModulationTerm) &&
        pyopencv_to(pyobj_patternImages, patternImages, ArgInfo("patternImages", 0)) &&
        pyopencv_to(pyobj_dataModulationTerm, dataModulationTerm, ArgInfo("dataModulationTerm", 1)) &&
        pyopencv_to(pyobj_shadowMask, shadowMask, ArgInfo("shadowMask", 0)) )
    {
        ERRWRAP2(_self_->computeDataModulationTerm(patternImages, dataModulationTerm, shadowMask));
        return pyopencv_from(dataModulationTerm);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_structured_light_structured_light_SinusoidalPattern_computePhaseMap(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::structured_light;

    if(!PyObject_TypeCheck(self, &pyopencv_structured_light_SinusoidalPattern_Type))
        return failmsgp("Incorrect type of self (must be 'structured_light_SinusoidalPattern' or its derivative)");
    cv::structured_light::SinusoidalPattern* _self_ = dynamic_cast<cv::structured_light::SinusoidalPattern*>(((pyopencv_structured_light_SinusoidalPattern_t*)self)->v.get());
    {
    PyObject* pyobj_patternImages = NULL;
    vector_Mat patternImages;
    PyObject* pyobj_wrappedPhaseMap = NULL;
    Mat wrappedPhaseMap;
    PyObject* pyobj_shadowMask = NULL;
    Mat shadowMask;
    PyObject* pyobj_fundamental = NULL;
    Mat fundamental;

    const char* keywords[] = { "patternImages", "wrappedPhaseMap", "shadowMask", "fundamental", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|OOO:structured_light_SinusoidalPattern.computePhaseMap", (char**)keywords, &pyobj_patternImages, &pyobj_wrappedPhaseMap, &pyobj_shadowMask, &pyobj_fundamental) &&
        pyopencv_to(pyobj_patternImages, patternImages, ArgInfo("patternImages", 0)) &&
        pyopencv_to(pyobj_wrappedPhaseMap, wrappedPhaseMap, ArgInfo("wrappedPhaseMap", 1)) &&
        pyopencv_to(pyobj_shadowMask, shadowMask, ArgInfo("shadowMask", 1)) &&
        pyopencv_to(pyobj_fundamental, fundamental, ArgInfo("fundamental", 0)) )
    {
        ERRWRAP2(_self_->computePhaseMap(patternImages, wrappedPhaseMap, shadowMask, fundamental));
        return Py_BuildValue("(NN)", pyopencv_from(wrappedPhaseMap), pyopencv_from(shadowMask));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_patternImages = NULL;
    vector_Mat patternImages;
    PyObject* pyobj_wrappedPhaseMap = NULL;
    UMat wrappedPhaseMap;
    PyObject* pyobj_shadowMask = NULL;
    UMat shadowMask;
    PyObject* pyobj_fundamental = NULL;
    UMat fundamental;

    const char* keywords[] = { "patternImages", "wrappedPhaseMap", "shadowMask", "fundamental", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|OOO:structured_light_SinusoidalPattern.computePhaseMap", (char**)keywords, &pyobj_patternImages, &pyobj_wrappedPhaseMap, &pyobj_shadowMask, &pyobj_fundamental) &&
        pyopencv_to(pyobj_patternImages, patternImages, ArgInfo("patternImages", 0)) &&
        pyopencv_to(pyobj_wrappedPhaseMap, wrappedPhaseMap, ArgInfo("wrappedPhaseMap", 1)) &&
        pyopencv_to(pyobj_shadowMask, shadowMask, ArgInfo("shadowMask", 1)) &&
        pyopencv_to(pyobj_fundamental, fundamental, ArgInfo("fundamental", 0)) )
    {
        ERRWRAP2(_self_->computePhaseMap(patternImages, wrappedPhaseMap, shadowMask, fundamental));
        return Py_BuildValue("(NN)", pyopencv_from(wrappedPhaseMap), pyopencv_from(shadowMask));
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_structured_light_structured_light_SinusoidalPattern_findProCamMatches(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::structured_light;

    if(!PyObject_TypeCheck(self, &pyopencv_structured_light_SinusoidalPattern_Type))
        return failmsgp("Incorrect type of self (must be 'structured_light_SinusoidalPattern' or its derivative)");
    cv::structured_light::SinusoidalPattern* _self_ = dynamic_cast<cv::structured_light::SinusoidalPattern*>(((pyopencv_structured_light_SinusoidalPattern_t*)self)->v.get());
    {
    PyObject* pyobj_projUnwrappedPhaseMap = NULL;
    Mat projUnwrappedPhaseMap;
    PyObject* pyobj_camUnwrappedPhaseMap = NULL;
    Mat camUnwrappedPhaseMap;
    PyObject* pyobj_matches = NULL;
    vector_Mat matches;

    const char* keywords[] = { "projUnwrappedPhaseMap", "camUnwrappedPhaseMap", "matches", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|O:structured_light_SinusoidalPattern.findProCamMatches", (char**)keywords, &pyobj_projUnwrappedPhaseMap, &pyobj_camUnwrappedPhaseMap, &pyobj_matches) &&
        pyopencv_to(pyobj_projUnwrappedPhaseMap, projUnwrappedPhaseMap, ArgInfo("projUnwrappedPhaseMap", 0)) &&
        pyopencv_to(pyobj_camUnwrappedPhaseMap, camUnwrappedPhaseMap, ArgInfo("camUnwrappedPhaseMap", 0)) &&
        pyopencv_to(pyobj_matches, matches, ArgInfo("matches", 1)) )
    {
        ERRWRAP2(_self_->findProCamMatches(projUnwrappedPhaseMap, camUnwrappedPhaseMap, matches));
        return pyopencv_from(matches);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_projUnwrappedPhaseMap = NULL;
    UMat projUnwrappedPhaseMap;
    PyObject* pyobj_camUnwrappedPhaseMap = NULL;
    UMat camUnwrappedPhaseMap;
    PyObject* pyobj_matches = NULL;
    vector_Mat matches;

    const char* keywords[] = { "projUnwrappedPhaseMap", "camUnwrappedPhaseMap", "matches", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|O:structured_light_SinusoidalPattern.findProCamMatches", (char**)keywords, &pyobj_projUnwrappedPhaseMap, &pyobj_camUnwrappedPhaseMap, &pyobj_matches) &&
        pyopencv_to(pyobj_projUnwrappedPhaseMap, projUnwrappedPhaseMap, ArgInfo("projUnwrappedPhaseMap", 0)) &&
        pyopencv_to(pyobj_camUnwrappedPhaseMap, camUnwrappedPhaseMap, ArgInfo("camUnwrappedPhaseMap", 0)) &&
        pyopencv_to(pyobj_matches, matches, ArgInfo("matches", 1)) )
    {
        ERRWRAP2(_self_->findProCamMatches(projUnwrappedPhaseMap, camUnwrappedPhaseMap, matches));
        return pyopencv_from(matches);
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_structured_light_structured_light_SinusoidalPattern_unwrapPhaseMap(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::structured_light;

    if(!PyObject_TypeCheck(self, &pyopencv_structured_light_SinusoidalPattern_Type))
        return failmsgp("Incorrect type of self (must be 'structured_light_SinusoidalPattern' or its derivative)");
    cv::structured_light::SinusoidalPattern* _self_ = dynamic_cast<cv::structured_light::SinusoidalPattern*>(((pyopencv_structured_light_SinusoidalPattern_t*)self)->v.get());
    {
    PyObject* pyobj_wrappedPhaseMap = NULL;
    vector_Mat wrappedPhaseMap;
    PyObject* pyobj_unwrappedPhaseMap = NULL;
    Mat unwrappedPhaseMap;
    PyObject* pyobj_camSize = NULL;
    Size camSize;
    PyObject* pyobj_shadowMask = NULL;
    Mat shadowMask;

    const char* keywords[] = { "wrappedPhaseMap", "camSize", "unwrappedPhaseMap", "shadowMask", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|OO:structured_light_SinusoidalPattern.unwrapPhaseMap", (char**)keywords, &pyobj_wrappedPhaseMap, &pyobj_camSize, &pyobj_unwrappedPhaseMap, &pyobj_shadowMask) &&
        pyopencv_to(pyobj_wrappedPhaseMap, wrappedPhaseMap, ArgInfo("wrappedPhaseMap", 0)) &&
        pyopencv_to(pyobj_unwrappedPhaseMap, unwrappedPhaseMap, ArgInfo("unwrappedPhaseMap", 1)) &&
        pyopencv_to(pyobj_camSize, camSize, ArgInfo("camSize", 0)) &&
        pyopencv_to(pyobj_shadowMask, shadowMask, ArgInfo("shadowMask", 0)) )
    {
        ERRWRAP2(_self_->unwrapPhaseMap(wrappedPhaseMap, unwrappedPhaseMap, camSize, shadowMask));
        return pyopencv_from(unwrappedPhaseMap);
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_wrappedPhaseMap = NULL;
    vector_Mat wrappedPhaseMap;
    PyObject* pyobj_unwrappedPhaseMap = NULL;
    UMat unwrappedPhaseMap;
    PyObject* pyobj_camSize = NULL;
    Size camSize;
    PyObject* pyobj_shadowMask = NULL;
    UMat shadowMask;

    const char* keywords[] = { "wrappedPhaseMap", "camSize", "unwrappedPhaseMap", "shadowMask", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "OO|OO:structured_light_SinusoidalPattern.unwrapPhaseMap", (char**)keywords, &pyobj_wrappedPhaseMap, &pyobj_camSize, &pyobj_unwrappedPhaseMap, &pyobj_shadowMask) &&
        pyopencv_to(pyobj_wrappedPhaseMap, wrappedPhaseMap, ArgInfo("wrappedPhaseMap", 0)) &&
        pyopencv_to(pyobj_unwrappedPhaseMap, unwrappedPhaseMap, ArgInfo("unwrappedPhaseMap", 1)) &&
        pyopencv_to(pyobj_camSize, camSize, ArgInfo("camSize", 0)) &&
        pyopencv_to(pyobj_shadowMask, shadowMask, ArgInfo("shadowMask", 0)) )
    {
        ERRWRAP2(_self_->unwrapPhaseMap(wrappedPhaseMap, unwrappedPhaseMap, camSize, shadowMask));
        return pyopencv_from(unwrappedPhaseMap);
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_structured_light_SinusoidalPattern_methods[] =
{
    {"computeDataModulationTerm", (PyCFunction)pyopencv_cv_structured_light_structured_light_SinusoidalPattern_computeDataModulationTerm, METH_VARARGS | METH_KEYWORDS, "computeDataModulationTerm(patternImages, shadowMask[, dataModulationTerm]) -> dataModulationTerm"},
    {"computePhaseMap", (PyCFunction)pyopencv_cv_structured_light_structured_light_SinusoidalPattern_computePhaseMap, METH_VARARGS | METH_KEYWORDS, "computePhaseMap(patternImages[, wrappedPhaseMap[, shadowMask[, fundamental]]]) -> wrappedPhaseMap, shadowMask"},
    {"findProCamMatches", (PyCFunction)pyopencv_cv_structured_light_structured_light_SinusoidalPattern_findProCamMatches, METH_VARARGS | METH_KEYWORDS, "findProCamMatches(projUnwrappedPhaseMap, camUnwrappedPhaseMap[, matches]) -> matches"},
    {"unwrapPhaseMap", (PyCFunction)pyopencv_cv_structured_light_structured_light_SinusoidalPattern_unwrapPhaseMap, METH_VARARGS | METH_KEYWORDS, "unwrapPhaseMap(wrappedPhaseMap, camSize[, unwrappedPhaseMap[, shadowMask]]) -> unwrappedPhaseMap"},

    {NULL,          NULL}
};

static void pyopencv_structured_light_SinusoidalPattern_specials(void)
{
    pyopencv_structured_light_SinusoidalPattern_Type.tp_base = &pyopencv_structured_light_StructuredLightPattern_Type;
    pyopencv_structured_light_SinusoidalPattern_Type.tp_dealloc = pyopencv_structured_light_SinusoidalPattern_dealloc;
    pyopencv_structured_light_SinusoidalPattern_Type.tp_repr = pyopencv_structured_light_SinusoidalPattern_repr;
    pyopencv_structured_light_SinusoidalPattern_Type.tp_getset = pyopencv_structured_light_SinusoidalPattern_getseters;
    pyopencv_structured_light_SinusoidalPattern_Type.tp_methods = pyopencv_structured_light_SinusoidalPattern_methods;
}

static PyObject* pyopencv_structured_light_StructuredLightPattern_repr(PyObject* self)
{
    char str[1000];
    sprintf(str, "<structured_light_StructuredLightPattern %p>", self);
    return PyString_FromString(str);
}



static PyGetSetDef pyopencv_structured_light_StructuredLightPattern_getseters[] =
{
    {NULL}  /* Sentinel */
};

static PyObject* pyopencv_cv_structured_light_structured_light_StructuredLightPattern_decode(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::structured_light;

    if(!PyObject_TypeCheck(self, &pyopencv_structured_light_StructuredLightPattern_Type))
        return failmsgp("Incorrect type of self (must be 'structured_light_StructuredLightPattern' or its derivative)");
    cv::structured_light::StructuredLightPattern* _self_ = dynamic_cast<cv::structured_light::StructuredLightPattern*>(((pyopencv_structured_light_StructuredLightPattern_t*)self)->v.get());
    {
    PyObject* pyobj_patternImages = NULL;
    vector_Mat patternImages;
    PyObject* pyobj_disparityMap = NULL;
    Mat disparityMap;
    PyObject* pyobj_blackImages = NULL;
    vector_Mat blackImages;
    PyObject* pyobj_whiteImages = NULL;
    vector_Mat whiteImages;
    int flags=DECODE_3D_UNDERWORLD;
    bool retval;

    const char* keywords[] = { "patternImages", "disparityMap", "blackImages", "whiteImages", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|OOOi:structured_light_StructuredLightPattern.decode", (char**)keywords, &pyobj_patternImages, &pyobj_disparityMap, &pyobj_blackImages, &pyobj_whiteImages, &flags) &&
        pyopencv_to(pyobj_patternImages, patternImages, ArgInfo("patternImages", 0)) &&
        pyopencv_to(pyobj_disparityMap, disparityMap, ArgInfo("disparityMap", 1)) &&
        pyopencv_to(pyobj_blackImages, blackImages, ArgInfo("blackImages", 0)) &&
        pyopencv_to(pyobj_whiteImages, whiteImages, ArgInfo("whiteImages", 0)) )
    {
        ERRWRAP2(retval = _self_->decode(patternImages, disparityMap, blackImages, whiteImages, flags));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(disparityMap));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_patternImages = NULL;
    vector_Mat patternImages;
    PyObject* pyobj_disparityMap = NULL;
    UMat disparityMap;
    PyObject* pyobj_blackImages = NULL;
    vector_Mat blackImages;
    PyObject* pyobj_whiteImages = NULL;
    vector_Mat whiteImages;
    int flags=DECODE_3D_UNDERWORLD;
    bool retval;

    const char* keywords[] = { "patternImages", "disparityMap", "blackImages", "whiteImages", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "O|OOOi:structured_light_StructuredLightPattern.decode", (char**)keywords, &pyobj_patternImages, &pyobj_disparityMap, &pyobj_blackImages, &pyobj_whiteImages, &flags) &&
        pyopencv_to(pyobj_patternImages, patternImages, ArgInfo("patternImages", 0)) &&
        pyopencv_to(pyobj_disparityMap, disparityMap, ArgInfo("disparityMap", 1)) &&
        pyopencv_to(pyobj_blackImages, blackImages, ArgInfo("blackImages", 0)) &&
        pyopencv_to(pyobj_whiteImages, whiteImages, ArgInfo("whiteImages", 0)) )
    {
        ERRWRAP2(retval = _self_->decode(patternImages, disparityMap, blackImages, whiteImages, flags));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(disparityMap));
    }
    }

    return NULL;
}

static PyObject* pyopencv_cv_structured_light_structured_light_StructuredLightPattern_generate(PyObject* self, PyObject* args, PyObject* kw)
{
    using namespace cv::structured_light;

    if(!PyObject_TypeCheck(self, &pyopencv_structured_light_StructuredLightPattern_Type))
        return failmsgp("Incorrect type of self (must be 'structured_light_StructuredLightPattern' or its derivative)");
    cv::structured_light::StructuredLightPattern* _self_ = dynamic_cast<cv::structured_light::StructuredLightPattern*>(((pyopencv_structured_light_StructuredLightPattern_t*)self)->v.get());
    {
    PyObject* pyobj_patternImages = NULL;
    vector_Mat patternImages;
    bool retval;

    const char* keywords[] = { "patternImages", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|O:structured_light_StructuredLightPattern.generate", (char**)keywords, &pyobj_patternImages) &&
        pyopencv_to(pyobj_patternImages, patternImages, ArgInfo("patternImages", 1)) )
    {
        ERRWRAP2(retval = _self_->generate(patternImages));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(patternImages));
    }
    }
    PyErr_Clear();

    {
    PyObject* pyobj_patternImages = NULL;
    vector_Mat patternImages;
    bool retval;

    const char* keywords[] = { "patternImages", NULL };
    if( PyArg_ParseTupleAndKeywords(args, kw, "|O:structured_light_StructuredLightPattern.generate", (char**)keywords, &pyobj_patternImages) &&
        pyopencv_to(pyobj_patternImages, patternImages, ArgInfo("patternImages", 1)) )
    {
        ERRWRAP2(retval = _self_->generate(patternImages));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(patternImages));
    }
    }

    return NULL;
}



static PyMethodDef pyopencv_structured_light_StructuredLightPattern_methods[] =
{
    {"decode", (PyCFunction)pyopencv_cv_structured_light_structured_light_StructuredLightPattern_decode, METH_VARARGS | METH_KEYWORDS, "decode(patternImages[, disparityMap[, blackImages[, whiteImages[, flags]]]]) -> retval, disparityMap"},
    {"generate", (PyCFunction)pyopencv_cv_structured_light_structured_light_StructuredLightPattern_generate, METH_VARARGS | METH_KEYWORDS, "generate([, patternImages]) -> retval, patternImages"},

    {NULL,          NULL}
};

static void pyopencv_structured_light_StructuredLightPattern_specials(void)
{
    pyopencv_structured_light_StructuredLightPattern_Type.tp_base = &pyopencv_Algorithm_Type;
    pyopencv_structured_light_StructuredLightPattern_Type.tp_dealloc = pyopencv_structured_light_StructuredLightPattern_dealloc;
    pyopencv_structured_light_StructuredLightPattern_Type.tp_repr = pyopencv_structured_light_StructuredLightPattern_repr;
    pyopencv_structured_light_StructuredLightPattern_Type.tp_getset = pyopencv_structured_light_StructuredLightPattern_getseters;
    pyopencv_structured_light_StructuredLightPattern_Type.tp_methods = pyopencv_structured_light_StructuredLightPattern_methods;
}
