From ebe19eff25fb40d9d3222ba1465421c988caabb9 Mon Sep 17 00:00:00 2001
From: ziyu04 <1159047277@qq.com>
Date: Mon, 9 Sep 2024 17:53:30 +0800
Subject: [PATCH] Updated sample C++ files

---
 samples/cpp/3calibration.cpp                  | 134 ++--
 samples/cpp/application_trace.cpp             |  25 +-
 samples/cpp/aruco_dict_utils.cpp              |   3 +-
 samples/cpp/asift.cpp                         |  20 +-
 samples/cpp/audio_spectrogram.cpp             | 196 ++----
 samples/cpp/barcode.cpp                       | 183 ++---
 samples/cpp/bgfg_segm.cpp                     |  73 +-
 samples/cpp/calibration.cpp                   | 215 +++---
 samples/cpp/camshiftdemo.cpp                  | 156 +++--
 samples/cpp/cloning_demo.cpp                  |  74 +-
 samples/cpp/cloning_gui.cpp                   | 651 ++++++++----------
 samples/cpp/connected_components.cpp          |  28 +-
 samples/cpp/contours2.cpp                     |  89 +--
 samples/cpp/convexhull.cpp                    |  35 +-
 samples/cpp/cout_mat.cpp                      |  37 +-
 samples/cpp/create_mask.cpp                   |  66 +-
 samples/cpp/dbt_face_detection.cpp            |  84 ++-
 samples/cpp/delaunay2.cpp                     |  22 +-
 samples/cpp/demhist.cpp                       |  26 +-
 samples/cpp/detect_blob.cpp                   |  36 +-
 samples/cpp/detect_mser.cpp                   | 287 +-------
 samples/cpp/dft.cpp                           |  27 +-
 samples/cpp/digits_lenet.cpp                  |  56 +-
 samples/cpp/digits_svm.cpp                    |  17 +-
 samples/cpp/dis_opticalflow.cpp               |  19 +-
 samples/cpp/distrans.cpp                      | 125 +---
 samples/cpp/drawing.cpp                       |  63 +-
 samples/cpp/edge.cpp                          |  48 +-
 samples/cpp/ela.cpp                           |  32 +-
 samples/cpp/em.cpp                            |  45 +-
 samples/cpp/epipolar_lines.cpp                |  10 +-
 samples/cpp/essential_mat_reconstr.cpp        |  20 +-
 samples/cpp/facedetect.cpp                    | 167 ++---
 samples/cpp/facial_features.cpp               |  59 +-
 samples/cpp/falsecolor.cpp                    |  56 +-
 samples/cpp/fback.cpp                         |  52 +-
 samples/cpp/ffilldemo.cpp                     | 201 +++---
 samples/cpp/filestorage.cpp                   |  81 +--
 samples/cpp/fitellipse.cpp                    | 207 +++---
 samples/cpp/flann_search_dataset.cpp          | 130 ++--
 samples/cpp/grabcut.cpp                       | 206 +-----
 samples/cpp/image_alignment.cpp               | 136 ++--
 samples/cpp/imagelist_creator.cpp             |  75 +-
 samples/cpp/imagelist_reader.cpp              |  91 +--
 samples/cpp/imgcodecs_jpeg.cpp                |  62 +-
 samples/cpp/inpaint.cpp                       |  78 +--
 samples/cpp/intelligent_scissors.cpp          |  16 +-
 samples/cpp/intersectExample.cpp              |   6 +-
 samples/cpp/kalman.cpp                        |  19 +-
 samples/cpp/kmeans.cpp                        |  56 +-
 samples/cpp/laplace.cpp                       |  91 +--
 samples/cpp/letter_recog.cpp                  |  51 +-
 samples/cpp/lkdemo.cpp                        |  71 +-
 samples/cpp/logistic_regression.cpp           |  29 +-
 samples/cpp/lsd_lines.cpp                     |  17 +-
 samples/cpp/mask_tmpl.cpp                     |  54 +-
 samples/cpp/matchmethod_orb_akaze_brisk.cpp   |  51 +-
 samples/cpp/minarea.cpp                       |  50 +-
 samples/cpp/morphology2.cpp                   |  99 ++-
 samples/cpp/neural_network.cpp                |  19 +-
 samples/cpp/npr_demo.cpp                      |  36 +-
 samples/cpp/pca.cpp                           |  66 +-
 samples/cpp/peopledetect.cpp                  |  94 ++-
 samples/cpp/phase_corr.cpp                    |  55 +-
 samples/cpp/points_classifier.cpp             | 288 ++------
 samples/cpp/polar_transforms.cpp              |  74 +-
 samples/cpp/qrcode.cpp                        |  98 +--
 samples/cpp/segment_objects.cpp               |  80 ++-
 samples/cpp/select3dobj.cpp                   | 450 ++----------
 samples/cpp/smiledetect.cpp                   | 112 +--
 samples/cpp/squares.cpp                       |  93 ++-
 samples/cpp/stereo_calib.cpp                  |  62 +-
 samples/cpp/stereo_match.cpp                  |  68 +-
 samples/cpp/stitching.cpp                     |  13 +-
 samples/cpp/stitching_detailed.cpp            | 147 +++-
 samples/cpp/text_skewness_correction.cpp      |  37 +-
 samples/cpp/train_HOG.cpp                     |  37 +-
 samples/cpp/train_svmsgd.cpp                  |  77 ++-
 samples/cpp/travelsalesman.cpp                |  65 +-
 samples/cpp/tree_engine.cpp                   |  30 +-
 .../openni_orbbec_astra.cpp}                  |   0
 samples/cpp/videocapture_audio.cpp            |  65 +-
 .../cpp/videocapture_audio_combination.cpp    |  95 ++-
 samples/cpp/videocapture_basic.cpp            |  63 +-
 samples/cpp/videocapture_camera.cpp           |  70 +-
 .../cpp/videocapture_gphoto2_autofocus.cpp    |  80 +--
 .../cpp/videocapture_gstreamer_pipeline.cpp   |  19 +-
 samples/cpp/videocapture_image_sequence.cpp   |  23 +-
 samples/cpp/videocapture_microphone.cpp       |  81 ++-
 samples/cpp/videocapture_obsensor.cpp         | 118 ++--
 samples/cpp/videocapture_openni.cpp           | 218 ++----
 samples/cpp/videocapture_realsense.cpp        | 109 ++-
 samples/cpp/videocapture_starter.cpp          |  59 +-
 samples/cpp/videowriter_basic.cpp             |  40 +-
 samples/cpp/warpPerspective_demo.cpp          | 136 ++--
 samples/cpp/watershed.cpp                     | 152 ++--
 96 files changed, 3925 insertions(+), 4517 deletions(-)
 rename samples/cpp/tutorial_code/videoio/{orbbec_astra/orbbec_astra.cpp => openni_orbbec_astra/openni_orbbec_astra.cpp} (100%)

diff --git a/samples/cpp/3calibration.cpp b/samples/cpp/3calibration.cpp
index 115d6987b2..871c2aeb57 100644
--- a/samples/cpp/3calibration.cpp
+++ b/samples/cpp/3calibration.cpp
@@ -1,7 +1,3 @@
-/*
- * 3calibration.cpp -- Calibrate 3 cameras in a horizontal line together.
- */
-
 #include "opencv2/calib3d.hpp"
 #include "opencv2/imgproc.hpp"
 #include "opencv2/imgcodecs.hpp"
@@ -11,6 +7,8 @@
 #include <stdio.h>
 #include <string.h>
 #include <time.h>
+#include<iostream>
+#include<fstream>
 
 using namespace cv;
 using namespace std;
@@ -19,24 +17,22 @@ enum { DETECTION = 0, CAPTURING = 1, CALIBRATED = 2 };
 
 static void help(char** argv)
 {
-        printf( "\nThis is a camera calibration sample that calibrates 3 horizontally placed cameras together.\n"
-               "Usage: %s\n"
-               "     -w=<board_width>         # the number of inner corners per one of board dimension\n"
-               "     -h=<board_height>        # the number of inner corners per another board dimension\n"
-               "     [-s=<squareSize>]       # square size in some user-defined units (1 by default)\n"
-               "     [-o=<out_camera_params>] # the output filename for intrinsic [and extrinsic] parameters\n"
-               "     [-zt]                    # assume zero tangential distortion\n"
-               "     [-a=<aspectRatio>]      # fix aspect ratio (fx/fy)\n"
-               "     [-p]                     # fix the principal point at the center\n"
-               "     [input_data]             # input data - text file with a list of the images of the board\n"
-               "\n", argv[0] );
-
+    printf( "\nThis is a camera calibration sample that calibrates 3 horizontally placed cameras together.\n"
+            "Usage: %s\n"
+            "     -w=<board_width>         # the number of inner corners per one of board dimension\n"
+            "     -h=<board_height>        # the number of inner corners per another board dimension\n"
+            "     [-s=<squareSize>]       # square size in some user-defined units (1 by default)\n"
+            "     [-o=<out_camera_params>] # the output filename for intrinsic [and extrinsic] parameters\n"
+            "     [-zt]                    # assume zero tangential distortion\n"
+            "     [-a=<aspectRatio>]      # fix aspect ratio (fx/fy)\n"
+            "     [-p]                     # fix the principal point at the center\n"
+            "     [input_data]             # input data - text file with a list of the images of the board\n"
+            "\n", argv[0] );
 }
 
 static void calcChessboardCorners(Size boardSize, float squareSize, vector<Point3f>& corners)
 {
     corners.resize(0);
-
     for( int i = 0; i < boardSize.height; i++ )
         for( int j = 0; j < boardSize.width; j++ )
             corners.push_back(Point3f(float(j*squareSize),
@@ -157,23 +153,27 @@ static bool run3Calibration(vector<vector<Point2f> > imagePoints1,
     return true;
 }
 
-static bool readStringList( const string& filename, vector<string>& l )
-{
+bool readStringList(const string& filename, vector<string>& l){
     l.resize(0);
-    FileStorage fs(filename, FileStorage::READ);
-    if( !fs.isOpened() )
-        return false;
-    FileNode n = fs.getFirstTopLevelNode();
-    if( n.type() != FileNode::SEQ )
+    ifstream fs(filename.c_str());
+    if (!fs.is_open())
         return false;
-    FileNodeIterator it = n.begin(), it_end = n.end();
-    for( ; it != it_end; ++it )
-        l.push_back((string)*it);
+    string line;
+    while (getline(fs, line))
+    {
+        if (line.empty()) continue;
+
+        // 将相对路径转换为绝对路径
+        if (line[0] != '/') {
+            line = cv::samples::findFile(line);
+        }
+
+        l.push_back(line);
+    }
     return true;
 }
 
-
-int main( int argc, char** argv )
+int main(int argc, char** argv)
 {
     int i, k;
     int flags = 0;
@@ -182,7 +182,7 @@ int main( int argc, char** argv )
     string outputFilename;
     string inputFilename = "";
 
-    vector<vector<Point2f> > imgpt[3];
+    vector<vector<Point2f>> imgpt[3];
     vector<string> imageList;
 
     cv::CommandLineParser parser(argc, argv,
@@ -212,16 +212,16 @@ int main( int argc, char** argv )
         return -1;
     }
     if (boardSize.width <= 0)
-        return fprintf( stderr, "Invalid board width\n" ), -1;
+        return fprintf(stderr, "Invalid board width\n"), -1;
     if (boardSize.height <= 0)
-        return fprintf( stderr, "Invalid board height\n" ), -1;
+        return fprintf(stderr, "Invalid board height\n"), -1;
     if (squareSize <= 0)
-        return fprintf( stderr, "Invalid board square width\n" ), -1;
+        return fprintf(stderr, "Invalid board square width\n"), -1;
     if (aspectRatio <= 0)
-        return printf("Invalid aspect ratio\n" ), -1;
-    if( inputFilename.empty() ||
-       !readStringList(inputFilename, imageList) ||
-       imageList.size() == 0 || imageList.size() % 3 != 0 )
+        return printf("Invalid aspect ratio\n"), -1;
+    if (inputFilename.empty() ||
+        !readStringList(inputFilename, imageList) ||
+        imageList.size() == 0 || imageList.size() % 3 != 0)
     {
         printf("Error: the input image list is not specified, or can not be read, or the number of files is not divisible by 3\n");
         return -1;
@@ -229,17 +229,17 @@ int main( int argc, char** argv )
 
     Mat view, viewGray;
     Mat cameraMatrix[3], distCoeffs[3], R[3], P[3], R12, T12;
-    for( k = 0; k < 3; k++ )
+    for (k = 0; k < 3; k++)
     {
-        cameraMatrix[k] = Mat_<double>::eye(3,3);
-        cameraMatrix[k].at<double>(0,0) = aspectRatio;
-        cameraMatrix[k].at<double>(1,1) = 1;
-        distCoeffs[k] = Mat_<double>::zeros(5,1);
+        cameraMatrix[k] = Mat_<double>::eye(3, 3);
+        cameraMatrix[k].at<double>(0, 0) = aspectRatio;
+        cameraMatrix[k].at<double>(1, 1) = 1;
+        distCoeffs[k] = Mat_<double>::zeros(5, 1);
     }
-    Mat R13=Mat_<double>::eye(3,3), T13=Mat_<double>::zeros(3,1);
+    Mat R13 = Mat_<double>::eye(3, 3), T13 = Mat_<double>::zeros(3, 1);
 
     FileStorage fs;
-    namedWindow( "Image View", 0 );
+    //namedWindow("Image View", 0);
 
     for( k = 0; k < 3; k++ )
         imgpt[k].resize(imageList.size()/3);
@@ -272,11 +272,10 @@ int main( int argc, char** argv )
             }
         }
     }
-
     printf("Running calibration ...\n");
 
     run3Calibration(imgpt[0], imgpt[1], imgpt[2], imageSize,
-                    boardSize, squareSize, aspectRatio, flags|CALIB_FIX_K4|CALIB_FIX_K5,
+                    boardSize, squareSize, aspectRatio, flags | CALIB_FIX_K4 | CALIB_FIX_K5,
                     cameraMatrix[0], distCoeffs[0],
                     cameraMatrix[1], distCoeffs[1],
                     cameraMatrix[2], distCoeffs[2],
@@ -304,11 +303,11 @@ int main( int argc, char** argv )
 
     // step 3: find rectification transforms
     double ratio = rectify3Collinear(cameraMatrix[0], distCoeffs[0], cameraMatrix[1],
-             distCoeffs[1], cameraMatrix[2], distCoeffs[2],
-             imgpt[0], imgpt[2],
-             imageSize, R12, T12, R13, T13,
-             R[0], R[1], R[2], P[0], P[1], P[2], Q, -1.,
-             imageSize, 0, 0, CALIB_ZERO_DISPARITY);
+                                     distCoeffs[1], cameraMatrix[2], distCoeffs[2],
+                                     imgpt[0], imgpt[2],
+                                     imageSize, R12, T12, R13, T13,
+                                     R[0], R[1], R[2], P[0], P[1], P[2], Q, -1.,
+                                     imageSize, 0, 0, CALIB_ZERO_DISPARITY);
     Mat map1[3], map2[3];
 
     fs << "R1" << R[0];
@@ -324,37 +323,40 @@ int main( int argc, char** argv )
 
     printf("Disparity ratio = %g\n", ratio);
 
-    for( k = 0; k < 3; k++ )
+    for (k = 0; k < 3; k++)
         initUndistortRectifyMap(cameraMatrix[k], distCoeffs[k], R[k], P[k], imageSize, CV_16SC2, map1[k], map2[k]);
 
-    Mat canvas(imageSize.height, imageSize.width*3, CV_8UC3), small_canvas;
+    Mat canvas(imageSize.height, imageSize.width * 3, CV_8UC3), small_canvas;
+    if (cv::getWindowProperty("view", cv::WND_PROP_VISIBLE) >= 0) {
     destroyWindow("view");
+}
     canvas = Scalar::all(0);
 
-    for( i = 0; i < (int)(imageList.size()/3); i++ )
+    for (i = 0; i < (int)(imageList.size() / 3); i++)
     {
         canvas = Scalar::all(0);
-        for( k = 0; k < 3; k++ )
+        for (k = 0; k < 3; k++)
         {
             int k1 = k == 0 ? 2 : k == 1 ? 0 : 1;
             int k2 = k == 0 ? 1 : k == 1 ? 0 : 2;
-            view = imread(imageList[i*3+k], IMREAD_COLOR);
+            view = imread(imageList[i * 3 + k], IMREAD_COLOR);
 
-            if(view.empty())
+            if (view.empty())
                 continue;
 
-            Mat rview = canvas.colRange(k2*imageSize.width, (k2+1)*imageSize.width);
+            Mat rview = canvas.colRange(k2 * imageSize.width, (k2 + 1) * imageSize.width);
             remap(view, rview, map1[k1], map2[k1], INTER_LINEAR);
         }
-        printf("%s %s %s\n", imageList[i*3].c_str(), imageList[i*3+1].c_str(), imageList[i*3+2].c_str());
-        resize( canvas, small_canvas, Size(1500, 1500/3), 0, 0, INTER_LINEAR_EXACT );
-        for( k = 0; k < small_canvas.rows; k += 16 )
-            line(small_canvas, Point(0, k), Point(small_canvas.cols, k), Scalar(0,255,0), 1);
-        imshow("rectified", small_canvas);
-        char c = (char)waitKey(0);
-        if( c == 27 || c == 'q' || c == 'Q' )
-            break;
+        printf("%s %s %s\n", imageList[i * 3].c_str(), imageList[i * 3 + 1].c_str(), imageList[i * 3 + 2].c_str());
+        resize(canvas, small_canvas, Size(1500, 1500 / 3), 0, 0, INTER_LINEAR);
+        for (k = 0; k < small_canvas.rows; k += 16)
+            line(small_canvas, Point(0, k), Point(small_canvas.cols, k), Scalar(0, 255, 0), 1);
+        //imshow("rectified", small_canvas);
+        //char c = (char)waitKey(0);
+        //if (c == 27 || c == 'q' || c == 'Q')
+            //break;
     }
 
     return 0;
 }
+
diff --git a/samples/cpp/application_trace.cpp b/samples/cpp/application_trace.cpp
index 3ad06a4ccd..7261690c41 100644
--- a/samples/cpp/application_trace.cpp
+++ b/samples/cpp/application_trace.cpp
@@ -14,12 +14,12 @@ static void process_frame(const cv::UMat& frame)
 {
     CV_TRACE_FUNCTION(); // OpenCV Trace macro for function
 
-    imshow("Live", frame);
+    //imshow("Live", frame);
 
     UMat gray, processed;
     cv::cvtColor(frame, gray, COLOR_BGR2GRAY);
     Canny(gray, processed, 32, 64, 3);
-    imshow("Processed", processed);
+    //imshow("Processed", processed);
 }
 
 int main(int argc, char** argv)
@@ -37,12 +37,14 @@ int main(int argc, char** argv)
         return 0;
     }
 
-    VideoCapture capture;
     std::string video = parser.get<string>("@video");
-    if (video.size() == 1 && isdigit(video[0]))
-        capture.open(parser.get<int>("@video"));
-    else
-        capture.open(samples::findFileOrKeep(video));  // keep GStreamer pipelines
+    if (video.empty())
+    {
+        cout << "Video filename is required\n";
+        return -1;
+    }
+
+    VideoCapture capture(video);  // 直接使用提供的视频路径
     int nframes = 0;
     if (capture.isOpened())
     {
@@ -81,15 +83,16 @@ int main(int argc, char** argv)
 
             // OpenCV Trace macro for NEXT named region in the same C++ scope
             // Previous "read" region will be marked complete on this line.
-            // Use this to eliminate unnecessary curly braces.
+            // Use this to eliminate unnecessary curly brace.
             CV_TRACE_REGION_NEXT("process");
             process_frame(frame);
 
-            CV_TRACE_REGION_NEXT("delay");
-            if (waitKey(1) == 27/*ESC*/)
-                break;
+            //CV_TRACE_REGION_NEXT("delay");
+            //if (waitKey(1) == 27/*ESC*/)
+                //break;
         }
     }
 
     return 0;
 }
+
diff --git a/samples/cpp/aruco_dict_utils.cpp b/samples/cpp/aruco_dict_utils.cpp
index 20fecd82e9..dc9c31fffa 100644
--- a/samples/cpp/aruco_dict_utils.cpp
+++ b/samples/cpp/aruco_dict_utils.cpp
@@ -268,7 +268,7 @@ const char* keys  =
 const char* about =
         "This program can be used to calculate the ArUco dictionary metric.\n"
         "To calculate the metric considering flipped markers use -'r' flag.\n"
-        "This program can be used to create and write the custom ArUco dictionary.\n";
+        "This program can be used to create and write the custom ArUco dictionary\n";
 
 int main(int argc, char *argv[])
 {
@@ -346,3 +346,4 @@ int main(int argc, char *argv[])
     }
     return 0;
 }
+
diff --git a/samples/cpp/asift.cpp b/samples/cpp/asift.cpp
index 568954058d..c6e9dff359 100644
--- a/samples/cpp/asift.cpp
+++ b/samples/cpp/asift.cpp
@@ -1,8 +1,8 @@
 #include <opencv2/core.hpp>
 #include <opencv2/imgproc.hpp>
 #include <opencv2/features2d.hpp>
-#include <opencv2/highgui.hpp>
 #include <opencv2/calib3d.hpp>
+#include <opencv2/highgui.hpp>
 #include <iostream>
 #include <iomanip>
 
@@ -152,7 +152,7 @@ int main(int argc, char** argv)
     vector<int> indices(inliers);
     cv::sortIdx(distances, indices, SORT_EVERY_ROW+SORT_ASCENDING);
 
-    // explore_match
+    // explore match
     int h1 = img1.size().height;
     int w1 = img1.size().width;
     int h2 = img2.size().height;
@@ -184,16 +184,16 @@ int main(int argc, char** argv)
     }
     if (inliers > maxlines)
         cout << "only " << maxlines << " inliers are visualized" << endl;
-    imshow("affine find_obj", vis);
 
-    // Mat vis2 = Mat::zeros(max(h1, h2), w1+w2, CV_8U);
-    // Mat warp1;
-    // warpPerspective(img1, warp1, H, Size(w1, h1));
-    // warp1.copyTo(Mat(vis2, Rect(0, 0, w1, h1)));
-    // img2.copyTo(Mat(vis2, Rect(w1, 0, w2, h2)));
-    // imshow("warped", vis2);
+    // 注释掉图形显示的代码
+    // imshow("affine find_obj", vis);
+    // waitKey();
+
+    // 将结果保存到文件中
+    imwrite("affine_find_obj_result.jpg", vis);
+    cout << "Result saved as affine_find_obj_result.jpg" << endl;
 
-    waitKey();
     cout << "done" << endl;
     return 0;
 }
+
diff --git a/samples/cpp/audio_spectrogram.cpp b/samples/cpp/audio_spectrogram.cpp
index 80bfc1fbde..5aaa2773ac 100644
--- a/samples/cpp/audio_spectrogram.cpp
+++ b/samples/cpp/audio_spectrogram.cpp
@@ -2,20 +2,19 @@
 #include <opencv2/videoio.hpp>
 #include <opencv2/highgui.hpp>
 #include <opencv2/imgproc.hpp>
+#include <opencv2/imgcodecs.hpp>
 
 #include <iostream>
 #include <vector>
 #include <string>
 #include <cmath>
+
 using namespace cv;
 using namespace std;
 
-
 class AudioDrawing
 {
-
 public:
-
     AudioDrawing(const CommandLineParser& parser) {
         if (!initAndCheckArgs(parser))
         {
@@ -46,9 +45,6 @@ public:
 
             int duration = static_cast<int>(inputAudio.size()) / samplingRate;
 
-            // since the dimensional grid is counted in integer seconds,
-            // if the input audio has an incomplete last second,
-            // then it is filled with zeros to complete
             int remainder = static_cast<int>(inputAudio.size()) % samplingRate;
             if (remainder)
             {
@@ -64,9 +60,6 @@ public:
             }
             cout << "Duration of audio = " << duration << " seconds" << endl;
 
-            // since the dimensional grid is counted in integer seconds,
-            // if duration of file is less than xmarkup, to avoid an incorrect display,
-            // xmarkup will be taken equal to duration
             if (duration <= xmarkup)
             {
                 xmarkup = duration + 1;
@@ -76,16 +69,20 @@ public:
             {
                 Mat imgAmplitude = drawAmplitude(inputAudio);
                 imgAmplitude = drawAmplitudeScale(imgAmplitude, inputAudio, samplingRate);
-                imshow("Display amplitude graph", imgAmplitude);
-                waitKey(0);
+                // 注释掉显示图像的部分
+                // imshow("Display amplitude graph", imgAmplitude);
+                // waitKey(0);
+                saveImage(imgAmplitude, "amplitude_graph.png");
             }
             else if (graph == "spec")
             {
                 vector<vector<double>>stft = STFT(inputAudio);
                 Mat imgSpec = drawSpectrogram(stft);
                 imgSpec = drawSpectrogramColorbar(imgSpec, inputAudio, samplingRate, stft);
-                imshow("Display spectrogram", imgSpec);
-                waitKey(0);
+                // 注释掉显示图像的部分
+                // imshow("Display spectrogram", imgSpec);
+                // waitKey(0);
+                saveImage(imgSpec, "spectrogram.png");
             }
             else if (graph == "ampl_and_spec")
             {
@@ -95,8 +92,10 @@ public:
                 Mat imgSpec = drawSpectrogram(stft);
                 imgSpec = drawSpectrogramColorbar(imgSpec, inputAudio, samplingRate, stft);
                 Mat imgTotal = concatenateImages(imgAmplitude, imgSpec);
-                imshow("Display amplitude graph and spectrogram", imgTotal);
-                waitKey(0);
+                // 注释掉显示图像的部分
+                // imshow("Display amplitude graph and spectrogram", imgTotal);
+                // waitKey(0);
+                saveImage(imgTotal, "amplitude_and_spectrogram.png");
             }
         }
         else if (draw == "dynamic")
@@ -114,46 +113,45 @@ public:
 
     ~AudioDrawing() {
     }
-
-    int readAudioFile(string file, vector<int>& inputAudio)
+int readAudioFile(string file, vector<int>& inputAudio)
+{
+    VideoCapture cap;
+    cap.open(file); // Use basic open to check if file can be opened without specific parameters
+    if (!cap.isOpened())
     {
-        VideoCapture cap;
-        vector<int> params {    CAP_PROP_AUDIO_STREAM, audioStream,
-                                CAP_PROP_VIDEO_STREAM, -1,
-                                CAP_PROP_AUDIO_DATA_DEPTH, CV_16S   };
-
-        cap.open(file, CAP_ANY, params);
-        if (!cap.isOpened())
+        cerr << "Error : Can't read audio file: '" << file << "' with audioStream = " << audioStream << endl;
+        return -1;
+    }
+    cout << "Video file opened successfully" << endl;
+
+    const int audioBaseIndex = (int)cap.get(CAP_PROP_AUDIO_BASE_INDEX);
+    const int numberOfChannels = (int)cap.get(CAP_PROP_AUDIO_TOTAL_CHANNELS);
+    cout << "CAP_PROP_AUDIO_DATA_DEPTH: " << depthToString((int)cap.get(CAP_PROP_AUDIO_DATA_DEPTH)) << endl;
+    int samplingRate = static_cast<int>(cap.get(CAP_PROP_AUDIO_SAMPLES_PER_SECOND));
+    cout << "CAP_PROP_AUDIO_SAMPLES_PER_SECOND: " << cap.get(CAP_PROP_AUDIO_SAMPLES_PER_SECOND) << endl;
+    cout << "CAP_PROP_AUDIO_TOTAL_CHANNELS: " << numberOfChannels << endl;
+    cout << "CAP_PROP_AUDIO_TOTAL_STREAMS: " << cap.get(CAP_PROP_AUDIO_TOTAL_STREAMS) << endl;
+
+    vector<int> frameVec;
+    Mat frame;
+    for (;;)
+    {
+        if (cap.grab())
         {
-            cerr << "Error : Can't read audio file: '" << audio << "' with audioStream = " << audioStream << endl;
-            return -1;
+            cout << "Frame grabbed successfully" << endl;
+            cap.retrieve(frame, audioBaseIndex);
+            frameVec = frame;
+            inputAudio.insert(inputAudio.end(), frameVec.begin(), frameVec.end());
         }
-        const int audioBaseIndex = (int)cap.get(CAP_PROP_AUDIO_BASE_INDEX);
-        const int numberOfChannels = (int)cap.get(CAP_PROP_AUDIO_TOTAL_CHANNELS);
-        cout << "CAP_PROP_AUDIO_DATA_DEPTH: " << depthToString((int)cap.get(CAP_PROP_AUDIO_DATA_DEPTH)) << endl;
-        int samplingRate =  static_cast<int>(cap.get(CAP_PROP_AUDIO_SAMPLES_PER_SECOND));
-        cout << "CAP_PROP_AUDIO_SAMPLES_PER_SECOND: " << cap.get(CAP_PROP_AUDIO_SAMPLES_PER_SECOND) << endl;
-        cout << "CAP_PROP_AUDIO_TOTAL_CHANNELS: " << numberOfChannels << endl;
-        cout << "CAP_PROP_AUDIO_TOTAL_STREAMS: " << cap.get(CAP_PROP_AUDIO_TOTAL_STREAMS) << endl;
-
-        vector<int> frameVec;
-        Mat frame;
-        for (;;)
+        else
         {
-            if (cap.grab())
-            {
-                cap.retrieve(frame, audioBaseIndex);
-                frameVec = frame;
-                inputAudio.insert(inputAudio.end(), frameVec.begin(), frameVec.end());
-            }
-            else
-            {
-                cout << "Number of samples: " << inputAudio.size() << endl;
-                break;
-            }
+            cout << "Number of samples: " << inputAudio.size() << endl;
+            break;
         }
-        return samplingRate;
     }
+    return samplingRate;
+}
+
 
     int readAudioMicrophone(vector<int>& inputAudio)
     {
@@ -201,15 +199,13 @@ public:
         return samplingRate;
     }
 
-
     Mat drawAmplitude(vector<int>& inputAudio)
     {
         Scalar color = Scalar(247,111,87);
         int thickness = 5;
         int frameVectorRows = 500;
         int middle = frameVectorRows / 2;
-        // usually the input data is too big, so it is necessary
-        // to reduce size using interpolation of data
+
         int frameVectorCols = 40000;
         if (static_cast<int>(inputAudio.size()) < frameVectorCols)
         {
@@ -229,7 +225,6 @@ public:
         resize(img_frameVector, img_frameVector_resize, Size(frameVectorCols, 1), INTER_LINEAR);
         reshapeAudio = img_frameVector_resize;
 
-        // normalization data by maximum element
         normalize(reshapeAudio, reshapeAudio, 1.0, 0.0, NORM_INF);
 
         for (size_t i = 0; i < reshapeAudio.size(); ++i)
@@ -249,11 +244,6 @@ public:
     Mat drawAmplitudeScale(Mat& inputImg, const vector<int>& inputAudio, int samplingRate,
                            int xmin = 0, int xmax = 0)
     {
-        // function of layout drawing for graph of volume amplitudes
-        // x axis for time
-        // y axis for amplitudes
-
-        // parameters for the new image size
         int preCol = 100;
         int aftCol = 100;
         int preLine = 40;
@@ -268,8 +258,6 @@ public:
         Mat imgTotal = Mat(totalRows, totalCols, CV_8UC3, Scalar(255, 255, 255));
         inputImg.copyTo(imgTotal(Rect(preCol, preLine, inputImg.cols, inputImg.rows)));
 
-
-        // calculating values on x axis
         if (xmax == 0)
         {
             xmax = static_cast<int>(inputAudio.size()) / samplingRate;
@@ -285,7 +273,6 @@ public:
         }
         else
         {
-            // this case is used to display a dynamic update
             vector<double> tmpXList;
             for (int i = xmin; i < xmax; ++i)
             {
@@ -299,7 +286,6 @@ public:
             }
         }
 
-        // calculating values on y axis
         double minCv; double maxCv; Point minLoc; Point maxLoc;
         minMaxLoc(inputAudio, &minCv, &maxCv, &minLoc, &maxLoc);
         int ymin = static_cast<int>(minCv);
@@ -312,29 +298,24 @@ public:
             yList[i] = ymin + deltay * i;
         }
 
-        // parameters for layout drawing
         int textThickness = 1;
         int gridThickness = 1;
         Scalar gridColor(0, 0, 0);
         Scalar textColor(0, 0, 0);
         float fontScale = 0.5;
 
-        // horizontal axis
         line(imgTotal, Point(preCol, totalRows - aftLine), Point(preCol + frameVectorCols, totalRows - aftLine),
             gridColor, gridThickness);
-        // vertical axis
+
         line(imgTotal, Point(preCol, preLine), Point(preCol, preLine + frameVectorRows),
             gridColor, gridThickness);
 
-        // parameters for layout calculation
         int serifSize = 10;
         int indentDownX = serifSize * 2;
         int indentDownY = serifSize / 2;
         int indentLeftX = serifSize;
         int indentLeftY = 2 * preCol / 3;
 
-
-        // drawing layout for x axis
         int numX = frameVectorCols / (xmarkup - 1);
         for (size_t i = 0; i < xList.size(); ++i)
         {
@@ -355,7 +336,6 @@ public:
                     FONT_HERSHEY_SIMPLEX, fontScale, textColor, textThickness);
         }
 
-        // drawing layout for y axis
         int numY = frameVectorRows / (ymarkup - 1);
         for (size_t i = 0; i < yList.size(); ++i) {
             int a1 = preCol;
@@ -379,23 +359,12 @@ public:
 
     vector<vector<double>> STFT(const vector<int>& inputAudio)
     {
-        // The Short-time Fourier transform (STFT), is a Fourier-related transform used to
-        // determine the sinusoidal frequency and phase content of local sections of a signal
-        // as it changes over time.
-        // In practice, the procedure for computing STFTs is to divide a longer time signal
-        // into shorter segments of equal length and then compute the Fourier transform separately
-        // on each shorter segment. This reveals the Fourier spectrum on each shorter segment.
-        // One then usually plots the changing spectra as a function of time, known as a spectrogram
-        // or waterfall plot.
-        // https://en.wikipedia.org/wiki/Short-time_Fourier_transform
-
         int timeStep = windLen - overlap;
         Mat dstMat;
         vector<double> stftRow;
         vector<double> WindType;
         if (windowType == "Hann")
         {
-            // https://en.wikipedia.org/wiki/Window_function#Hann_and_Hamming_windows
             for (int j = 1 - windLen; j < windLen; j+=2)
             {
                 WindType.push_back(j * (0.5 * (1 - cos(CV_PI * j / (windLen - 1)))));
@@ -403,7 +372,6 @@ public:
         }
         else if (windowType == "Hamming")
         {
-            // https://en.wikipedia.org/wiki/Window_function#Hann_and_Hamming_windows
             for (int j = 1 - windLen; j < windLen; j+=2)
             {
                 WindType.push_back(j * (0.53836 - 0.46164 * (cos(CV_PI * j / (windLen - 1)))));
@@ -435,7 +403,6 @@ public:
         }
 
         size_t xSize = inputAudio.size() / timeStep + 1;
-        // we need only the first part of the spectrum, the second part is symmetrical
         size_t ySize = dstMat.cols / 4;
 
         vector<vector<double>> stft(ySize, vector<double>(xSize, 0.));
@@ -443,7 +410,6 @@ public:
         {
             for (size_t j = 0; j < ySize; ++j)
             {
-                // write elements with transposition and convert it to the decibel scale
                 double stftElem = stftRow[ i * ySize + j];
                 if (stftElem != 0.)
                 {
@@ -459,8 +425,6 @@ public:
         int frameVectorRows = static_cast<int>(stft.size());
         int frameVectorCols = static_cast<int>(stft[0].size());
 
-        // Normalization of image values from 0 to 255 to get more contrast image
-        // and this normalization will be taken into account in the scale drawing
         int colormapImageRows = 255;
 
         double minCv; double maxCv; Point minLoc; Point maxLoc;
@@ -472,7 +436,6 @@ public:
             minMaxLoc( stft[i], &minCv, &maxCv, &minLoc, &maxLoc);
             maxStft = max(maxStft, max(abs(maxCv), abs(minCv)));
         }
-        // if maxStft is zero (silence)
         if (maxStft == 0.)
         {
             maxStft = 1;
@@ -496,12 +459,6 @@ public:
                                 int samplingRate, const vector<vector<double>>& stft,
                                 int xmin = 0, int xmax = 0)
     {
-        // function of layout drawing for the three-dimensional graph of the spectrogram
-        // x axis for time
-        // y axis for frequencies
-        // z axis for magnitudes of frequencies shown by color scale
-
-        // parameters for the new image size
         int preCol = 100;
         int aftCol = 100;
         int preLine = 40;
@@ -518,8 +475,6 @@ public:
         Mat imgTotal = Mat(totalRows, totalCols, CV_8UC3 , Scalar(255, 255, 255));
         inputImg.copyTo(imgTotal(Rect(preCol, preLine, frameVectorCols, frameVectorRows)));
 
-        // colorbar image due to drawSpectrogram(..) picture has been normalised from 255 to 0,
-        // so here colorbar has values from 255 to 0
         int colorArrSize = 256;
         Mat imgColorBar = Mat (colorArrSize, colColor, CV_8UC1 , Scalar(255,255,255));
         for (int i = 0; i < colorArrSize; ++i)
@@ -534,8 +489,6 @@ public:
         resize(imgColorBar, imgColorBar, Size(colColor, frameVectorRows), INTER_AREA);
         imgColorBar.copyTo(imgTotal(Rect(preCol + frameVectorCols + indCol, preLine, colColor, frameVectorRows)));
 
-
-        // calculating values on x axis
         if (xmax == 0)
         {
             xmax = static_cast<int>(inputAudio.size()) / samplingRate + 1;
@@ -551,7 +504,6 @@ public:
         }
         else
         {
-            // this case is used to display a dynamic update
             vector<double> tmpXList;
             for(int i = xmin; i < xmax; ++i)
             {
@@ -565,9 +517,6 @@ public:
             }
         }
 
-        // calculating values on y axis
-        // according to the Nyquist sampling theorem,
-        // signal should posses frequencies equal to half of sampling rate
         int ymin = 0;
         int ymax = static_cast<int>(samplingRate / 2);
 
@@ -578,7 +527,6 @@ public:
             yList.push_back(ymin + deltay * i);
         }
 
-        // calculating values on z axis
         double minCv; double maxCv; Point minLoc; Point maxLoc;
         minMaxLoc( stft[0], &minCv, &maxCv, &minLoc, &maxLoc);
         double zmin = minCv, zmax = maxCv;
@@ -596,7 +544,6 @@ public:
             zList.push_back(zmin + deltaz * i);
         }
 
-        // parameters for layout drawing
         int textThickness = 1;
         int gridThickness = 1;
         Scalar gridColor(0,0,0);
@@ -609,14 +556,12 @@ public:
         int indentLeftX = serifSize;
         int indentLeftY = 2 * preCol / 3;
 
-        // horizontal axis
         line(imgTotal, Point(preCol, totalRows - aftLine), Point(preCol + frameVectorCols, totalRows - aftLine),
                             gridColor, gridThickness);
-        // vertical axis
+
         line(imgTotal, Point(preCol, preLine), Point(preCol, preLine + frameVectorRows),
                             gridColor, gridThickness);
 
-        // drawing layout for x axis
         int numX = frameVectorCols / (xmarkup - 1);
         for (size_t i = 0; i < xList.size(); ++i)
         {
@@ -631,7 +576,6 @@ public:
                     FONT_HERSHEY_SIMPLEX, fontScale, textColor, textThickness);
         }
 
-        // drawing layout for y axis
         int numY = frameVectorRows / (ymarkup - 1);
         for (size_t i = 0; i < yList.size(); ++i)
         {
@@ -646,7 +590,6 @@ public:
                     FONT_HERSHEY_SIMPLEX, fontScale, textColor, textThickness);
         }
 
-        // drawing layout for z axis
         int numZ = frameVectorRows / (zmarkup - 1);
         for (size_t i = 0; i < zList.size(); ++i)
         {
@@ -667,10 +610,9 @@ public:
 
     Mat concatenateImages(Mat& img1, Mat& img2)
     {
-        // first image will be under the second image
         int totalRows = img1.rows + img2.rows;
         int totalCols = max(img1.cols , img2.cols);
-        // if images columns do not match, the difference is filled in white
+
         Mat imgTotal = Mat (totalRows, totalCols, CV_8UC3 , Scalar(255, 255, 255));
 
         img1.copyTo(imgTotal(Rect(0, 0, img1.cols, img1.rows)));
@@ -704,9 +646,6 @@ public:
         int step = static_cast<int>(updateTime * samplingRate);
         int frameSize = static_cast<int>(frameSizeTime * samplingRate);
 
-        // since the dimensional grid is counted in integer seconds,
-        // if duration of audio frame is less than xmarkup, to avoid an incorrect display,
-        // xmarkup will be taken equal to duration
         if (frameSizeTime <= xmarkup)
         {
             xmarkup = frameSizeTime;
@@ -750,16 +689,18 @@ public:
                     {
                         imgAmplitude = drawAmplitude(section);
                         imgAmplitude = drawAmplitudeScale(imgAmplitude, section, samplingRate, xmin, xmax);
-                        imshow("Display amplitude graph", imgAmplitude);
+                        // imshow("Display amplitude graph", imgAmplitude);
                         waitKey(waitTime);
+                        saveImage(imgAmplitude, "dynamic_amplitude_graph.png");
                     }
                     else if (graph == "spec")
                     {
                         stft = STFT(section);
                         imgSpec = drawSpectrogram(stft);
                         imgSpec = drawSpectrogramColorbar(imgSpec, section, samplingRate, stft, xmin, xmax);
-                        imshow("Display spectrogram", imgSpec);
+                        // imshow("Display spectrogram", imgSpec);
                         waitKey(waitTime);
+                        saveImage(imgSpec, "dynamic_spectrogram.png");
                     }
                     else if (graph == "ampl_and_spec")
                     {
@@ -769,8 +710,9 @@ public:
                         imgSpec = drawSpectrogram(stft);
                         imgSpec = drawSpectrogramColorbar(imgSpec, section, samplingRate, stft, xmin, xmax);
                         imgTotal = concatenateImages(imgAmplitude, imgSpec);
-                        imshow("Display amplitude graph and spectrogram", imgTotal);
+                        // imshow("Display amplitude graph and spectrogram", imgTotal);
                         waitKey(waitTime);
+                        saveImage(imgTotal, "dynamic_amplitude_and_spectrogram.png");
                     }
                 }
             }
@@ -779,7 +721,6 @@ public:
                 break;
             }
         }
-
     }
 
     void dynamicMicrophone()
@@ -809,9 +750,6 @@ public:
 
         int step = (updateTime * samplingRate);
         int frameSize = (frameSizeTime * samplingRate);
-        // since the dimensional grid is counted in integer seconds,
-        // if duration of audio frame is less than xmarkup, to avoid an incorrect display,
-        // xmarkup will be taken equal to duration
         if (frameSizeTime <= xmarkup)
         {
             xmarkup = frameSizeTime;
@@ -859,16 +797,18 @@ public:
                     {
                         imgAmplitude = drawAmplitude(section);
                         imgAmplitude = drawAmplitudeScale(imgAmplitude, section, samplingRate, xmin, xmax);
-                        imshow("Display amplitude graph", imgAmplitude);
+                        // imshow("Display amplitude graph", imgAmplitude);
                         waitKey(waitTime);
+                        saveImage(imgAmplitude, "dynamic_microphone_amplitude_graph.png");
                     }
                     else if (graph == "spec")
                     {
                         stft = STFT(section);
                         imgSpec = drawSpectrogram(stft);
                         imgSpec = drawSpectrogramColorbar(imgSpec, section, samplingRate, stft, xmin, xmax);
-                        imshow("Display spectrogram", imgSpec);
+                        // imshow("Display spectrogram", imgSpec);
                         waitKey(waitTime);
+                        saveImage(imgSpec, "dynamic_microphone_spectrogram.png");
                     }
                     else if (graph == "ampl_and_spec")
                     {
@@ -878,8 +818,9 @@ public:
                         imgSpec = drawSpectrogram(stft);
                         imgSpec = drawSpectrogramColorbar(imgSpec, section, samplingRate, stft, xmin, xmax);
                         imgTotal = concatenateImages(imgAmplitude, imgSpec);
-                        imshow("Display amplitude graph and spectrogram", imgTotal);
+                        // imshow("Display amplitude graph and spectrogram", imgTotal);
                         waitKey(waitTime);
+                        saveImage(imgTotal, "dynamic_microphone_amplitude_and_spectrogram.png");
                     }
                 }
             }
@@ -889,7 +830,6 @@ public:
                 break;
             }
         }
-
     }
 
     bool initAndCheckArgs(const CommandLineParser& parser)
@@ -1029,6 +969,13 @@ private :
     int updateTime;
     int waitTime;
 
+    void saveImage(const Mat& image, const string& filename) {
+        string outputDir = "audio_spectrogram";
+        system(("mkdir -p " + outputDir).c_str());
+        string outputPath = outputDir + "/" + filename;
+        imwrite(outputPath, image);
+        cout << "Image saved at: " << outputPath << endl;
+    }
 };
 
 int main(int argc, char** argv)
@@ -1068,4 +1015,5 @@ int main(int argc, char** argv)
 
     AudioDrawing draw(parser);
     return 0;
-}
\ No newline at end of file
+}
+
diff --git a/samples/cpp/barcode.cpp b/samples/cpp/barcode.cpp
index 5955d4a74d..a0be33471f 100644
--- a/samples/cpp/barcode.cpp
+++ b/samples/cpp/barcode.cpp
@@ -15,7 +15,7 @@ static Scalar randColor()
     return Scalar(rng.uniform(0, 255), rng.uniform(0, 255), rng.uniform(0, 255));
 }
 
-//==============================================================================
+//===============================================================================
 
 struct TheApp
 {
@@ -40,41 +40,42 @@ struct TheApp
     }
 
     void drawResults(Mat &frame) const
+{
+    //! [visualize]
+    for (size_t i = 0; i < corners.size(); i += 4)
     {
-        //! [visualize]
-        for (size_t i = 0; i < corners.size(); i += 4)
+        const size_t idx = i / 4;
+        const bool isDecodable = idx < decode_info.size()
+            && idx < decode_type.size()
+            && !decode_type[idx].empty();
+        const Scalar lineColor = isDecodable ? greenColor : redColor;
+        // draw barcode rectangle
+        vector<Point> contour(corners.begin() + i, corners.begin() + i + 4);
+        const vector< vector<Point> > contours {contour};
+        // drawContours(frame, contours, 0, lineColor, 1); // 注释掉
+        // draw vertices
+        for (size_t j = 0; j < 4; j++)
+            ;// circle(frame, contour[j], 2, randColor(), -1); // 注释掉
+        // write decoded text
+        if (isDecodable)
         {
-            const size_t idx = i / 4;
-            const bool isDecodable = idx < decode_info.size()
-                && idx < decode_type.size()
-                && !decode_type[idx].empty();
-            const Scalar lineColor = isDecodable ? greenColor : redColor;
-            // draw barcode rectangle
-            vector<Point> contour(corners.begin() + i, corners.begin() + i + 4);
-            const vector< vector<Point> > contours {contour};
-            drawContours(frame, contours, 0, lineColor, 1);
-            // draw vertices
-            for (size_t j = 0; j < 4; j++)
-                circle(frame, contour[j], 2, randColor(), -1);
-            // write decoded text
-            if (isDecodable)
-            {
-                ostringstream buf;
-                buf << "[" << decode_type[idx] << "] " << decode_info[idx];
-                putText(frame, buf.str(), contour[1], FONT_HERSHEY_COMPLEX, 0.8, yellowColor, 1);
-            }
+            ostringstream buf;
+            buf << "[" << decode_type[idx] << "] " << decode_info[idx];
+            ;// putText(frame, buf.str(), contour[1], FONT_HERSHEY_COMPLEX, 0.8, yellowColor, 1); // 注释掉
         }
-        //! [visualize]
     }
+    //! [visualize]
+}
+
 
     void drawFPS(Mat &frame, double fps) const
-    {
-        ostringstream buf;
-        buf << modeString()
-            << " (" << corners.size() / 4 << "/" << decode_type.size() << "/" << decode_info.size() << ") "
-            << cv::format("%.2f", fps) << " FPS ";
-        putText(frame, buf.str(), Point(25, 25), FONT_HERSHEY_COMPLEX, 0.8, redColor, 2);
-    }
+{
+    ostringstream buf;
+    buf << modeString()
+        << " (" << corners.size() / 4 << "/" << decode_type.size() << "/" << decode_info.size() << ") "
+        << cv::format("%.2f", fps) << " FPS ";
+    ;// putText(frame, buf.str(), Point(25, 25), FONT_HERSHEY_COMPLEX, 0.8, redColor, 2); // 注释掉
+}
 
     inline void call_decode(Mat &frame)
     {
@@ -94,76 +95,77 @@ struct TheApp
     }
 
     int liveBarCodeDetect()
+{
+    VideoCapture cap(0);
+    if (!cap.isOpened())
+    {
+        cout << "Cannot open a camera" << endl;
+        return 2;
+    }
+    Mat frame;
+    Mat result;
+    cap >> frame;
+    cout << "Image size: " << frame.size() << endl;
+    cout << "Press 'd' to switch between <detect> and <detectAndDecode> modes" << endl;
+    cout << "Press 'ESC' to exit" << endl;
+    for (;;)
     {
-        VideoCapture cap(0);
-        if (!cap.isOpened())
-        {
-            cout << "Cannot open a camera" << endl;
-            return 2;
-        }
-        Mat frame;
-        Mat result;
         cap >> frame;
-        cout << "Image size: " << frame.size() << endl;
-        cout << "Press 'd' to switch between <detect> and <detectAndDecode> modes" << endl;
-        cout << "Press 'ESC' to exit" << endl;
-        for (;;)
+        if (frame.empty())
         {
-            cap >> frame;
-            if (frame.empty())
-            {
-                cout << "End of video stream" << endl;
-                break;
-            }
-            if (frame.channels() == 1)
-                cvtColor(frame, frame, COLOR_GRAY2BGR);
-            TickMeter timer;
-            timer.start();
-            call_decode(frame);
-            timer.stop();
-            drawResults(frame);
-            drawFPS(frame, timer.getFPS());
-            imshow("barcode", frame);
-            const char c = (char)waitKey(1);
-            if (c == 'd')
-            {
-                detectOnly = !detectOnly;
-                cout << "Mode switched to " << modeString() << endl;
-            }
-            else if (c == 27)
-            {
-                cout << "'ESC' is pressed. Exiting..." << endl;
-                break;
-            }
+            cout << "End of video stream" << endl;
+            break;
         }
-        return 0;
-    }
-
-    int imageBarCodeDetect(const string &in_file, const string &out_file)
-    {
-        Mat frame = imread(in_file, IMREAD_COLOR);
-        cout << "Image size: " << frame.size() << endl;
-        cout << "Mode is " << modeString() << endl;
-        const int count_experiments = 100;
+        if (frame.channels() == 1)
+            cvtColor(frame, frame, COLOR_GRAY2BGR);
         TickMeter timer;
-        for (size_t i = 0; i < count_experiments; i++)
+        timer.start();
+        call_decode(frame);
+        timer.stop();
+        drawResults(frame);
+        drawFPS(frame, timer.getFPS());
+        // imshow("barcode", frame); // 注释掉
+        const char c = (char)waitKey(1);
+        if (c == 'd')
         {
-            timer.start();
-            call_decode(frame);
-            timer.stop();
+            detectOnly = !detectOnly;
+            cout << "Mode switched to " << modeString() << endl;
         }
-        cout << "FPS: " << timer.getFPS() << endl;
-        drawResults(frame);
-        if (!out_file.empty())
+        else if (c == 27)
         {
-            cout << "Saving result: " << out_file << endl;
-            imwrite(out_file, frame);
+            cout << "'ESC' is pressed. Exiting..." << endl;
+            break;
         }
-        imshow("barcode", frame);
-        cout << "Press any key to exit ..." << endl;
-        waitKey(0);
-        return 0;
     }
+    return 0;
+}
+
+    int imageBarCodeDetect(const string &in_file, const string &out_file)
+{
+    Mat frame = imread(in_file, IMREAD_COLOR);
+    cout << "Image size: " << frame.size() << endl;
+    cout << "Mode is " << modeString() << endl;
+    const int count_experiments = 100;
+    TickMeter timer;
+    for (size_t i = 0; i < count_experiments; i++)
+    {
+        timer.start();
+        call_decode(frame);
+        timer.stop();
+    }
+    cout << "FPS: " << timer.getFPS() << endl;
+    drawResults(frame);
+    if (!out_file.empty())
+    {
+        cout << "Saving result: " << out_file << endl;
+        imwrite(out_file, frame);
+    }
+    // imshow("barcode", frame); // 注释掉
+    cout << "Press any key to exit ..." << endl;
+    ;// waitKey(0); // 注释掉
+    return 0;
+    }
+
 };
 
 
@@ -221,3 +223,4 @@ int main(int argc, char **argv)
     else
         return app.imageBarCodeDetect(in_file, out_file);
 }
+
diff --git a/samples/cpp/bgfg_segm.cpp b/samples/cpp/bgfg_segm.cpp
index 0537775731..d9e9d2da1a 100644
--- a/samples/cpp/bgfg_segm.cpp
+++ b/samples/cpp/bgfg_segm.cpp
@@ -8,6 +8,9 @@
 #include "opencv2/videoio.hpp"
 #include "opencv2/highgui.hpp"
 #include <iostream>
+#include <cstdlib>
+#include <sys/stat.h>
+#include <sys/types.h>
 
 using namespace std;
 using namespace cv;
@@ -59,13 +62,19 @@ int main(int argc, const char** argv)
         return 3;
     }
 
-    cout << "Press <space> to toggle background model update" << endl;
-    cout << "Press 's' to toggle foreground mask smoothing" << endl;
-    cout << "Press ESC or 'q' to exit" << endl;
     bool doUpdateModel = true;
     bool doSmoothMask = false;
 
     Mat inputFrame, frame, foregroundMask, foreground, background;
+    String sample_name = "bgfg_segm";
+    // 创建子目录
+    if (mkdir(sample_name.c_str(), 0777) == -1)
+    {
+        cerr << "Error :  " << strerror(errno) << endl;
+        return 1;
+    }
+
+    int frame_counter = 0;
     for (;;)
     {
         // prepare input frame
@@ -82,7 +91,7 @@ int main(int argc, const char** argv)
         model->apply(frame, foregroundMask, doUpdateModel ? -1 : 0);
 
         // show processed frame
-        imshow("image", frame);
+        // imshow("image", frame);
 
         // show foreground image and mask (with optional smoothing)
         if (doSmoothMask)
@@ -94,31 +103,49 @@ int main(int argc, const char** argv)
             foreground.create(scaledSize, frame.type());
         foreground = Scalar::all(0);
         frame.copyTo(foreground, foregroundMask);
-        imshow("foreground mask", foregroundMask);
-        imshow("foreground image", foreground);
+        // imshow("foreground mask", foregroundMask);
+        // imshow("foreground image", foreground);
 
         // show background image
         model->getBackgroundImage(background);
         if (!background.empty())
-            imshow("mean background image", background );
+            ; // imshow("mean background image", background);
+
+        // Save the frames and masks
+        String frame_filename = sample_name + "/frame_" + to_string(frame_counter) + ".png";
+        String foreground_filename = sample_name + "/foreground_" + to_string(frame_counter) + ".png";
+        String background_filename = sample_name + "/background_" + to_string(frame_counter) + ".png";
+
+        imwrite(frame_filename, frame);
+        imwrite(foreground_filename, foreground);
+        if (!background.empty())
+            imwrite(background_filename, background);
+
+        cout << "Saved frame to " << frame_filename << endl;
+        cout << "Saved foreground to " << foreground_filename << endl;
+        if (!background.empty())
+            cout << "Saved background to " << background_filename << endl;
+
+        frame_counter++;
 
         // interact with user
-        const char key = (char)waitKey(30);
-        if (key == 27 || key == 'q') // ESC
-        {
-            cout << "Exit requested" << endl;
-            break;
-        }
-        else if (key == ' ')
-        {
-            doUpdateModel = !doUpdateModel;
-            cout << "Toggle background update: " << (doUpdateModel ? "ON" : "OFF") << endl;
-        }
-        else if (key == 's')
-        {
-            doSmoothMask = !doSmoothMask;
-            cout << "Toggle foreground mask smoothing: " << (doSmoothMask ? "ON" : "OFF") << endl;
-        }
+        // const char key = (char)waitKey(30);
+        // if (key == 27 || key == 'q') // ESC
+        // {
+        //     cout << "Exit requested" << endl;
+        //     break;
+        // }
+        // else if (key == ' ')
+        // {
+        //     doUpdateModel = !doUpdateModel;
+        //     cout << "Toggle background update: " << (doUpdateModel ? "ON" : "OFF") << endl;
+        // }
+        // else if (key == 's')
+        // {
+        //     doSmoothMask = !doSmoothMask;
+        //     cout << "Toggle foreground mask smoothing: " << (doSmoothMask ? "ON" : "OFF") << endl;
+        // }
     }
     return 0;
 }
+
diff --git a/samples/cpp/calibration.cpp b/samples/cpp/calibration.cpp
index f8134368b2..7c89ea16b7 100644
--- a/samples/cpp/calibration.cpp
+++ b/samples/cpp/calibration.cpp
@@ -4,8 +4,7 @@
 #include "opencv2/calib3d.hpp"
 #include "opencv2/imgcodecs.hpp"
 #include "opencv2/videoio.hpp"
-#include "opencv2/highgui.hpp"
-#include <opencv2/objdetect/charuco_detector.hpp>
+//#include <opencv2/objdetect/charuco_detector.hpp>
 
 #include <cctype>
 #include <stdio.h>
@@ -128,6 +127,7 @@ static double computeReprojectionErrors(
 
     return std::sqrt(totalErr/totalPoints);
 }
+// 删除 calcChessboardCorners 函数中与 CharucoBoard 相关的部分
 
 static void calcChessboardCorners(Size boardSize, float squareSize, vector<Point3f>& corners, Pattern patternType = CHESSBOARD)
 {
@@ -150,12 +150,12 @@ static void calcChessboardCorners(Size boardSize, float squareSize, vector<Point
                                           float(i*squareSize), 0));
         break;
 
-      case CHARUCOBOARD:
-        for( int i = 0; i < boardSize.height-1; i++ )
-            for( int j = 0; j < boardSize.width-1; j++ )
-                corners.push_back(Point3f(float(j*squareSize),
-                                          float(i*squareSize), 0));
-        break;
+    //   case CHARUCOBOARD:
+    //     for( int i = 0; i < boardSize.height-1; i++ )
+    //         for( int j = 0; j < boardSize.width-1; j++ )
+    //             corners.push_back(Point3f(float(j*squareSize),
+    //                                       float(i*squareSize), 0));
+    //     break;
       default:
         CV_Error(Error::StsBadArg, "Unknown pattern type\n");
     }
@@ -249,7 +249,7 @@ static void saveCameraParams( const string& filename,
             flags & CALIB_FIX_ASPECT_RATIO ? "+fix_aspectRatio" : "",
             flags & CALIB_FIX_PRINCIPAL_POINT ? "+fix_principal_point" : "",
             flags & CALIB_ZERO_TANGENT_DIST ? "+zero_tangent_dist" : "" );
-        //cvWriteComment( *fs, buf, 0 );
+        //cvWriteComment( *fs, buf, 0);
     }
 
     fs << "flags" << flags;
@@ -304,9 +304,6 @@ static bool readStringList( const string& filename, vector<string>& l )
     FileStorage fs(filename, FileStorage::READ);
     if( !fs.isOpened() )
         return false;
-    size_t dir_pos = filename.rfind('/');
-    if (dir_pos == string::npos)
-        dir_pos = filename.rfind('\\');
     FileNode n = fs.getFirstTopLevelNode();
     if( n.type() != FileNode::SEQ )
         return false;
@@ -314,19 +311,6 @@ static bool readStringList( const string& filename, vector<string>& l )
     for( ; it != it_end; ++it )
     {
         string fname = (string)*it;
-        if (dir_pos != string::npos)
-        {
-            string fpath = samples::findFile(filename.substr(0, dir_pos + 1) + fname, false);
-            if (fpath.empty())
-            {
-                fpath = samples::findFile(fname);
-            }
-            fname = fpath;
-        }
-        else
-        {
-            fname = samples::findFile(fname);
-        }
         l.push_back(fname);
     }
     return true;
@@ -423,32 +407,32 @@ int main( int argc, char** argv )
     squareSize = parser.get<float>("s");
     markerSize = parser.get<float>("ms");
 
-    string arucoDictName = parser.get<string>("ad");
-    if (arucoDictName == "DICT_4X4_50") { arucoDict = cv::aruco::DICT_4X4_50; }
-    else if (arucoDictName == "DICT_4X4_100") { arucoDict = cv::aruco::DICT_4X4_100; }
-    else if (arucoDictName == "DICT_4X4_250") { arucoDict = cv::aruco::DICT_4X4_250; }
-    else if (arucoDictName == "DICT_4X4_1000") { arucoDict = cv::aruco::DICT_4X4_1000; }
-    else if (arucoDictName == "DICT_5X5_50") { arucoDict = cv::aruco::DICT_5X5_50; }
-    else if (arucoDictName == "DICT_5X5_100") { arucoDict = cv::aruco::DICT_5X5_100; }
-    else if (arucoDictName == "DICT_5X5_250") { arucoDict = cv::aruco::DICT_5X5_250; }
-    else if (arucoDictName == "DICT_5X5_1000") { arucoDict = cv::aruco::DICT_5X5_1000; }
-    else if (arucoDictName == "DICT_6X6_50") { arucoDict = cv::aruco::DICT_6X6_50; }
-    else if (arucoDictName == "DICT_6X6_100") { arucoDict = cv::aruco::DICT_6X6_100; }
-    else if (arucoDictName == "DICT_6X6_250") { arucoDict = cv::aruco::DICT_6X6_250; }
-    else if (arucoDictName == "DICT_6X6_1000") { arucoDict = cv::aruco::DICT_6X6_1000; }
-    else if (arucoDictName == "DICT_7X7_50") { arucoDict = cv::aruco::DICT_7X7_50; }
-    else if (arucoDictName == "DICT_7X7_100") { arucoDict = cv::aruco::DICT_7X7_100; }
-    else if (arucoDictName == "DICT_7X7_250") { arucoDict = cv::aruco::DICT_7X7_250; }
-    else if (arucoDictName == "DICT_7X7_1000") { arucoDict = cv::aruco::DICT_7X7_1000; }
-    else if (arucoDictName == "DICT_ARUCO_ORIGINAL") { arucoDict = cv::aruco::DICT_ARUCO_ORIGINAL; }
-    else if (arucoDictName == "DICT_APRILTAG_16h5") { arucoDict = cv::aruco::DICT_APRILTAG_16h5; }
-    else if (arucoDictName == "DICT_APRILTAG_25h9") { arucoDict = cv::aruco::DICT_APRILTAG_25h9; }
-    else if (arucoDictName == "DICT_APRILTAG_36h10") { arucoDict = cv::aruco::DICT_APRILTAG_36h10; }
-    else if (arucoDictName == "DICT_APRILTAG_36h11") { arucoDict = cv::aruco::DICT_APRILTAG_36h11; }
-    else {
-        cout << "Incorrect Aruco dictionary name " <<  arucoDictName << std::endl;
-        return 1;
-    }
+    // string arucoDictName = parser.get<string>("ad");
+    // if (arucoDictName == "DICT_4X4_50") { arucoDict = cv::aruco::DICT_4X4_50; }
+    // else if (arucoDictName == "DICT_4X4_100") { arucoDict = cv::aruco::DICT_4X4_100; }
+    // else if (arucoDictName == "DICT_4X4_250") { arucoDict = cv::aruco::DICT_4X4_250; }
+    // else if (arucoDictName == "DICT_4X4_1000") { arucoDict = cv::aruco::DICT_4X4_1000; }
+    // else if (arucoDictName == "DICT_5X5_50") { arucoDict = cv::aruco::DICT_5X5_50; }
+    // else if (arucoDictName == "DICT_5X5_100") { arucoDict = cv::aruco::DICT_5X5_100; }
+    // else if (arucoDictName == "DICT_5X5_250") { arucoDict = cv::aruco::DICT_5X5_250; }
+    // else if (arucoDictName == "DICT_5X5_1000") { arucoDict = cv::aruco::DICT_5X5_1000; }
+    // else if (arucoDictName == "DICT_6X6_50") { arucoDict = cv::aruco::DICT_6X6_50; }
+    // else if (arucoDictName == "DICT_6X6_100") { arucoDict = cv::aruco::DICT_6X6_100; }
+    // else if (arucoDictName == "DICT_6X6_250") { arucoDict = cv::aruco::DICT_6X6_250; }
+    // else if (arucoDictName == "DICT_6X6_1000") { arucoDict = cv::aruco::DICT_6X6_1000; }
+    // else if (arucoDictName == "DICT_7X7_50") { arucoDict = cv::aruco::DICT_7X7_50; }
+    // else if (arucoDictName == "DICT_7X7_100") { arucoDict = cv::aruco::DICT_7X7_100; }
+    // else if (arucoDictName == "DICT_7X7_250") { arucoDict = cv::aruco::DICT_7X7_250; }
+    // else if (arucoDictName == "DICT_7X7_1000") { arucoDict = cv::aruco::DICT_7X7_1000; }
+    // else if (arucoDictName == "DICT_ARUCO_ORIGINAL") { arucoDict = cv::aruco::DICT_ARUCO_ORIGINAL; }
+    // else if (arucoDictName == "DICT_APRILTAG_16h5") { arucoDict = cv::aruco::DICT_APRILTAG_16h5; }
+    // else if (arucoDictName == "DICT_APRILTAG_25h9") { arucoDict = cv::aruco::DICT_APRILTAG_25h9; }
+    // else if (arucoDictName == "DICT_APRILTAG_36h10") { arucoDict = cv::aruco::DICT_APRILTAG_36h10; }
+    // else if (arucoDictName == "DICT_APRILTAG_36h11") { arucoDict = cv::aruco::DICT_APRILTAG_36h11; }
+    // else {
+    //     cout << "Incorrect Aruco dictionary name " <<  arucoDictName << std::endl;
+    //     return 1;
+    // }
 
     dictFilename = parser.get<std::string>("adf");
     nframes = parser.get<int>("n");
@@ -517,42 +501,43 @@ int main( int argc, char** argv )
     if ( boardSize.height <= 0 )
         return fprintf( stderr, "Invalid board height\n" ), -1;
 
-    cv::aruco::Dictionary dictionary;
-    if (dictFilename == "None") {
-        std::cout << "Using predefined dictionary with id: " << arucoDict << std::endl;
-        dictionary = aruco::getPredefinedDictionary(arucoDict);
-    }
-    else {
-        std::cout << "Using custom dictionary from file: " << dictFilename << std::endl;
-        cv::FileStorage dict_file(dictFilename, cv::FileStorage::Mode::READ);
-        cv::FileNode fn(dict_file.root());
-        dictionary.readDictionary(fn);
-    }
-
-    cv::aruco::CharucoBoard ch_board(boardSize, squareSize, markerSize, dictionary);
-    std::vector<int> markerIds;
-    cv::aruco::CharucoDetector ch_detector(ch_board);
-
-    if( !inputFilename.empty() )
-    {
-        if( !videofile && readStringList(samples::findFile(inputFilename), imageList) )
-            mode = CAPTURING;
-        else
-            capture.open(samples::findFileOrKeep(inputFilename));
-    }
-    else
-        capture.open(cameraId);
-
-    if( !capture.isOpened() && imageList.empty() )
-        return fprintf( stderr, "Could not initialize video (%d) capture\n", cameraId ), -2;
-
-    if( !imageList.empty() )
-        nframes = (int)imageList.size();
-
-    if( capture.isOpened() )
-        printf( "%s", liveCaptureHelp );
-
-    namedWindow( "Image View", 1 );
+    // 删除与 CharucoBoard 相关的内容    
+    // cv::aruco::Dictionary dictionary;
+    // if (dictFilename == "None") {
+    //     std::cout << "Using predefined dictionary with id: " << arucoDict << std::endl;
+    //     dictionary = aruco::getPredefinedDictionary(arucoDict);
+    // }
+    // else {
+    //     std::cout << "Using custom dictionary from file: " << dictFilename << std::endl;
+    //     cv::FileStorage dict_file(dictFilename, cv::FileStorage::Mode::READ);
+    //     cv::FileNode fn(dict_file.root());
+    //     dictionary.readDictionary(fn);
+    // }
+
+    // cv::aruco::CharucoBoard ch_board(boardSize, squareSize, markerSize, dictionary);
+    // std::vector<int> markerIds;
+    // cv::aruco::CharucoDetector ch_detector(ch_board);
+
+    // if( !inputFilename.empty() )
+    // {
+    //     if( !videofile && readStringList(samples::findFile(inputFilename), imageList) )
+    //         mode = CAPTURING;
+    //     else
+    //         capture.open(samples::findFileOrKeep(inputFilename));
+    // }
+    // else
+    //     capture.open(cameraId);
+
+    // if( !capture.isOpened() && imageList.empty() )
+    //     return fprintf( stderr, "Could not initialize video (%d) capture\n", cameraId ), -2;
+
+    // if( !imageList.empty() )
+    //     nframes = (int)imageList.size();
+
+    // if( capture.isOpened() )
+    //     printf( "%s", liveCaptureHelp );
+
+    // namedWindow( "Image View", 1 );  // 注释掉.
 
     for(i = 0;;i++)
     {
@@ -587,6 +572,7 @@ int main( int argc, char** argv )
         cvtColor(view, viewGray, COLOR_BGR2GRAY);
 
         bool found;
+        // 删除 switch 语句中与 CharucoBoard 相关的部分
         switch( pattern )
         {
             case CHESSBOARD:
@@ -599,12 +585,12 @@ int main( int argc, char** argv )
             case ASYMMETRIC_CIRCLES_GRID:
                 found = findCirclesGrid( view, boardSize, pointbuf, CALIB_CB_ASYMMETRIC_GRID );
                 break;
-            case CHARUCOBOARD:
-            {
-                ch_detector.detectBoard(view, pointbuf, markerIds);
-                found = pointbuf.size() == (size_t)(boardSize.width-1)*(boardSize.height-1);
-                break;
-            }
+            // case CHARUCOBOARD:
+            // {
+            //     ch_detector.detectBoard(view, pointbuf, markerIds);
+            //     found = pointbuf.size() == (size_t)(boardSize.width-1)*(boardSize.height-1);
+            //     break;
+            // }
             default:
                 return fprintf( stderr, "Unknown pattern type\n" ), -1;
         }
@@ -613,13 +599,14 @@ int main( int argc, char** argv )
         if( pattern == CHESSBOARD && found) cornerSubPix( viewGray, pointbuf, Size(winSize,winSize),
             Size(-1,-1), TermCriteria( TermCriteria::EPS+TermCriteria::COUNT, 30, 0.0001 ));
 
-        if( mode == CAPTURING && found &&
-           (!capture.isOpened() || clock() - prevTimestamp > delay*1e-3*CLOCKS_PER_SEC) )
-        {
-            imagePoints.push_back(pointbuf);
-            prevTimestamp = clock();
-            blink = capture.isOpened();
-        }
+        if (mode == CAPTURING && found &&
+   (!capture.isOpened() || clock() - prevTimestamp > delay*1e-3*CLOCKS_PER_SEC) )
+{
+    cout << "Found corners, capturing..." << endl;
+    imagePoints.push_back(pointbuf);
+    prevTimestamp = clock();
+    blink = capture.isOpened();
+}
 
         if(found)
         {
@@ -654,6 +641,8 @@ int main( int argc, char** argv )
             Mat temp = view.clone();
             undistort(temp, view, cameraMatrix, distCoeffs);
         }
+
+        /*
         if (viewScaleFactor > 1)
         {
             Mat viewScale;
@@ -678,19 +667,17 @@ int main( int argc, char** argv )
             mode = CAPTURING;
             imagePoints.clear();
         }
+        */
 
-        if( mode == CAPTURING && imagePoints.size() >= (unsigned)nframes )
-        {
-            if( runAndSave(outputFilename, imagePoints, imageSize,
-                       boardSize, pattern, squareSize, grid_width, release_object, aspectRatio,
-                       flags, cameraMatrix, distCoeffs,
-                       writeExtrinsics, writePoints, writeGrid))
-                mode = CALIBRATED;
-            else
-                mode = DETECTION;
-            if( !capture.isOpened() )
-                break;
-        }
+        if (mode == CAPTURING && imagePoints.size() >= (unsigned)nframes )
+{
+    if (runAndSave(outputFilename, imagePoints, imageSize, boardSize, pattern, squareSize, grid_width, release_object, aspectRatio, flags, cameraMatrix, distCoeffs, writeExtrinsics, writePoints, writeGrid))
+        mode = CALIBRATED;
+    else
+        mode = DETECTION;
+    if (!capture.isOpened())
+        break;
+}
     }
 
     if( !capture.isOpened() && showUndistorted )
@@ -706,6 +693,7 @@ int main( int argc, char** argv )
             if(view.empty())
                 continue;
             remap(view, rview, map1, map2, INTER_LINEAR);
+            /*
             if (viewScaleFactor > 1)
             {
                 Mat rviewScale;
@@ -719,8 +707,11 @@ int main( int argc, char** argv )
             char c = (char)waitKey();
             if( c == 27 || c == 'q' || c == 'Q' )
                 break;
+            */
+            imwrite("undistorted_" + imageList[i], rview);
         }
     }
 
     return 0;
 }
+
diff --git a/samples/cpp/camshiftdemo.cpp b/samples/cpp/camshiftdemo.cpp
index e0840f7504..64c7ab9535 100644
--- a/samples/cpp/camshiftdemo.cpp
+++ b/samples/cpp/camshiftdemo.cpp
@@ -3,9 +3,9 @@
 #include "opencv2/imgproc.hpp"
 #include "opencv2/videoio.hpp"
 #include "opencv2/highgui.hpp"
-
 #include <iostream>
 #include <ctype.h>
+#include <sstream>
 
 using namespace cv;
 using namespace std;
@@ -20,10 +20,10 @@ Point origin;
 Rect selection;
 int vmin = 10, vmax = 256, smin = 30;
 
-// User draws box around object to track. This triggers CAMShift to start tracking
-static void onMouse( int event, int x, int y, int, void* )
+// User draws box around object to track. This triggers CAMShift to start tracking.
+static void onMouse(int event, int x, int y, int, void*)
 {
-    if( selectObject )
+    if (selectObject)
     {
         selection.x = MIN(x, origin.x);
         selection.y = MIN(y, origin.y);
@@ -33,51 +33,68 @@ static void onMouse( int event, int x, int y, int, void* )
         selection &= Rect(0, 0, image.cols, image.rows);
     }
 
-    switch( event )
+    switch (event)
     {
     case EVENT_LBUTTONDOWN:
-        origin = Point(x,y);
-        selection = Rect(x,y,0,0);
+        origin = Point(x, y);
+        selection = Rect(x, y, 0, 0);
         selectObject = true;
         break;
     case EVENT_LBUTTONUP:
         selectObject = false;
-        if( selection.width > 0 && selection.height > 0 )
+        if (selection.width > 0 && selection.height > 0)
             trackObject = -1;   // Set up CAMShift properties in main() loop
         break;
     }
 }
 
 string hot_keys =
-    "\n\nHot keys: \n"
-    "\tESC - quit the program\n"
-    "\tc - stop the tracking\n"
-    "\tb - switch to/from backprojection view\n"
-    "\th - show/hide object histogram\n"
-    "\tp - pause video\n"
-    "To initialize tracking, select the object with mouse\n";
+"\n\nHot keys: \n"
+"\tESC - quit the program\n"
+"\tc - stop the tracking\n"
+"\tb - switch to/from backprojection view\n"
+"\th - show/hide object histogram\n"
+"\tp - pause video\n"
+"To initialize tracking, select the object with mouse\n";
 
 static void help(const char** argv)
 {
     cout << "\nThis is a demo that shows mean-shift based tracking\n"
-            "You select a color objects such as your face and it tracks it.\n"
-            "This reads from video camera (0 by default, or the camera number the user enters\n"
-            "Usage: \n\t";
+        "You select a color objects such as your face and it tracks it.\n"
+        "This reads from video camera (0 by default, or the camera number the user enters\n"
+        "Usage: \n\t";
     cout << argv[0] << " [camera number]\n";
     cout << hot_keys;
 }
 
 const char* keys =
 {
-    "{help h | | show help message}{@camera_number| 0 | camera number}"
+    "{help h | | show help message}{@input_images | | comma-separated list of input images}"
 };
 
-int main( int argc, const char** argv )
+// Function to split string by delimiter
+void split(const string& s, vector<string>& tokens, const string& delimiters = ",")
+{
+    size_t start = 0, end = 0;
+    while ((end = s.find_first_of(delimiters, start)) != string::npos)
+    {
+        if (end != start)
+        {
+            tokens.push_back(s.substr(start, end - start));
+        }
+        start = end + 1;
+    }
+    if (end != start)
+    {
+        tokens.push_back(s.substr(start));
+    }
+}
+
+int main(int argc, const char** argv)
 {
-    VideoCapture cap;
     Rect trackWindow;
     int hsize = 16;
-    float hranges[] = {0,180};
+    float hranges[] = { 0,180 };
     const float* phranges = hranges;
     CommandLineParser parser(argc, argv, keys);
     if (parser.has("help"))
@@ -85,54 +102,48 @@ int main( int argc, const char** argv )
         help(argv);
         return 0;
     }
-    int camNum = parser.get<int>(0);
-    cap.open(camNum);
 
-    if( !cap.isOpened() )
+    String inputImagesStr = parser.get<String>("@input_images");
+    if (inputImagesStr.empty())
     {
         help(argv);
-        cout << "***Could not initialize capturing...***\n";
-        cout << "Current parameter's value: \n";
-        parser.printMessage();
         return -1;
     }
+
+    vector<String> inputImages;
+    split(inputImagesStr, inputImages);
+
     cout << hot_keys;
-    namedWindow( "Histogram", 0 );
-    namedWindow( "CamShift Demo", 0 );
-    setMouseCallback( "CamShift Demo", onMouse, 0 );
-    createTrackbar( "Vmin", "CamShift Demo", &vmin, 256, 0 );
-    createTrackbar( "Vmax", "CamShift Demo", &vmax, 256, 0 );
-    createTrackbar( "Smin", "CamShift Demo", &smin, 256, 0 );
 
     Mat frame, hsv, hue, mask, hist, histimg = Mat::zeros(200, 320, CV_8UC3), backproj;
     bool paused = false;
 
-    for(;;)
+    for (size_t i = 0; i < inputImages.size(); ++i)
     {
-        if( !paused )
+        frame = imread(samples::findFile(inputImages[i]));
+        if (frame.empty())
         {
-            cap >> frame;
-            if( frame.empty() )
-                break;
+            cerr << "Error loading image: " << inputImages[i] << endl;
+            continue;
         }
 
         frame.copyTo(image);
 
-        if( !paused )
+        if (!paused)
         {
             cvtColor(image, hsv, COLOR_BGR2HSV);
 
-            if( trackObject )
+            if (trackObject)
             {
                 int _vmin = vmin, _vmax = vmax;
 
-                inRange(hsv, Scalar(0, smin, MIN(_vmin,_vmax)),
-                        Scalar(180, 256, MAX(_vmin, _vmax)), mask);
-                int ch[] = {0, 0};
+                inRange(hsv, Scalar(0, smin, MIN(_vmin, _vmax)),
+                    Scalar(180, 256, MAX(_vmin, _vmax)), mask);
+                int ch[] = { 0, 0 };
                 hue.create(hsv.size(), hsv.depth());
                 mixChannels(&hsv, 1, &hue, 1, ch, 1);
 
-                if( trackObject < 0 )
+                if (trackObject < 0)
                 {
                     // Object has been selected by user, set up CAMShift search properties once
                     Mat roi(hue, selection), maskroi(mask, selection);
@@ -145,16 +156,16 @@ int main( int argc, const char** argv )
                     histimg = Scalar::all(0);
                     int binW = histimg.cols / hsize;
                     Mat buf(1, hsize, CV_8UC3);
-                    for( int i = 0; i < hsize; i++ )
-                        buf.at<Vec3b>(i) = Vec3b(saturate_cast<uchar>(i*180./hsize), 255, 255);
+                    for (int j = 0; j < hsize; j++)
+                        buf.at<Vec3b>(j) = Vec3b(saturate_cast<uchar>(j * 180. / hsize), 255, 255);
                     cvtColor(buf, buf, COLOR_HSV2BGR);
 
-                    for( int i = 0; i < hsize; i++ )
+                    for (int j = 0; j < hsize; j++)
                     {
-                        int val = saturate_cast<int>(hist.at<float>(i)*histimg.rows/255);
-                        rectangle( histimg, Point(i*binW,histimg.rows),
-                                   Point((i+1)*binW,histimg.rows - val),
-                                   Scalar(buf.at<Vec3b>(i)), -1, 8 );
+                        int val = saturate_cast<int>(hist.at<float>(j) * histimg.rows / 255);
+                        rectangle(histimg, Point(j * binW, histimg.rows),
+                            Point((j + 1) * binW, histimg.rows - val),
+                            Scalar(buf.at<Vec3b>(j)), -1, 8);
                     }
                 }
 
@@ -162,36 +173,42 @@ int main( int argc, const char** argv )
                 calcBackProject(&hue, 1, 0, hist, backproj, &phranges);
                 backproj &= mask;
                 RotatedRect trackBox = CamShift(backproj, trackWindow,
-                                    TermCriteria( TermCriteria::EPS | TermCriteria::COUNT, 10, 1 ));
-                if( trackWindow.area() <= 1 )
+                    TermCriteria(TermCriteria::EPS | TermCriteria::COUNT, 10, 1));
+                if (trackWindow.area() <= 1)
                 {
-                    int cols = backproj.cols, rows = backproj.rows, r = (MIN(cols, rows) + 5)/6;
+                    int cols = backproj.cols, rows = backproj.rows, r = (MIN(cols, rows) + 5) / 6;
                     trackWindow = Rect(trackWindow.x - r, trackWindow.y - r,
-                                       trackWindow.x + r, trackWindow.y + r) &
-                                  Rect(0, 0, cols, rows);
+                        trackWindow.x + r, trackWindow.y + r) &
+                        Rect(0, 0, cols, rows);
                 }
 
-                if( backprojMode )
-                    cvtColor( backproj, image, COLOR_GRAY2BGR );
-                ellipse( image, trackBox, Scalar(0,0,255), 3, LINE_AA );
+                if (backprojMode)
+                    cvtColor(backproj, image, COLOR_GRAY2BGR);
+                ellipse(image, trackBox, Scalar(0, 0, 255), 3, LINE_AA);
             }
         }
-        else if( trackObject < 0 )
+        else if (trackObject < 0)
             paused = false;
 
-        if( selectObject && selection.width > 0 && selection.height > 0 )
+        if (selectObject && selection.width > 0 && selection.height > 0)
         {
             Mat roi(image, selection);
             bitwise_not(roi, roi);
         }
 
-        imshow( "CamShift Demo", image );
-        imshow( "Histogram", histimg );
+        // 保存处理后的图像
+        string outputImageName = "output_" + to_string(i) + ".png";
+        imwrite(outputImageName, image);
+        imwrite("histogram_" + to_string(i) + ".png", histimg);
+
+        // 注释掉图形显示和交互部分
+        // imshow("CamShift Demo", image);
+        // imshow("Histogram", histimg);
 
         char c = (char)waitKey(10);
-        if( c == 27 )
+        if (c == 27)
             break;
-        switch(c)
+        switch (c)
         {
         case 'b':
             backprojMode = !backprojMode;
@@ -202,10 +219,10 @@ int main( int argc, const char** argv )
             break;
         case 'h':
             showHist = !showHist;
-            if( !showHist )
-                destroyWindow( "Histogram" );
+            if (!showHist)
+                destroyWindow("Histogram");
             else
-                namedWindow( "Histogram", 1 );
+                namedWindow("Histogram", 1);
             break;
         case 'p':
             paused = !paused;
@@ -217,3 +234,4 @@ int main( int argc, const char** argv )
 
     return 0;
 }
+
diff --git a/samples/cpp/cloning_demo.cpp b/samples/cpp/cloning_demo.cpp
index 43f6e20255..2ed73cc65d 100644
--- a/samples/cpp/cloning_demo.cpp
+++ b/samples/cpp/cloning_demo.cpp
@@ -1,25 +1,3 @@
-/*
-* cloning_demo.cpp
-*
-* Author:
-* Siddharth Kherada <siddharthkherada27[at]gmail[dot]com>
-*
-* This tutorial demonstrates how to use OpenCV seamless cloning
-* module without GUI.
-*
-* 1- Normal Cloning
-* 2- Mixed Cloning
-* 3- Monochrome Transfer
-* 4- Color Change
-* 5- Illumination change
-* 6- Texture Flattening
-
-* The program takes as input a source and a destination image (for 1-3 methods)
-* and outputs the cloned image.
-*
-* Download test images from opencv_extra repository.
-*/
-
 #include "opencv2/photo.hpp"
 #include "opencv2/imgproc.hpp"
 #include "opencv2/imgcodecs.hpp"
@@ -52,7 +30,7 @@ int main()
 
     if(num == 1)
     {
-        string folder =  "cloning/Normal_Cloning/";
+        string folder = "cloning/Normal_Cloning/";
         string original_path1 = samples::findFile(folder + "source1.png");
         string original_path2 = samples::findFile(folder + "destination1.png");
         string original_path3 = samples::findFile(folder + "mask.png");
@@ -82,10 +60,11 @@ int main()
         p.x = 400;
         p.y = 100;
 
-        seamlessClone(source, destination, mask, p, result, 1);
+        seamlessClone(source, destination, mask, p, result, NORMAL_CLONE);
 
-        imshow("Output",result);
-        imwrite("cloned.png", result);
+        // 注释掉 imshow
+        // imshow("Output",result);
+        imwrite("cloned_normal.png", result);
     }
     else if(num == 2)
     {
@@ -116,13 +95,14 @@ int main()
 
         Mat result;
         Point p;
-        p.x = destination.size().width/2;
-        p.y = destination.size().height/2;
+        p.x = destination.size().width / 2;
+        p.y = destination.size().height / 2;
 
-        seamlessClone(source, destination, mask, p, result, 2);
+        seamlessClone(source, destination, mask, p, result, MIXED_CLONE);
 
-        imshow("Output",result);
-        imwrite("cloned.png", result);
+        // 注释掉 imshow
+        // imshow("Output",result);
+        imwrite("cloned_mixed.png", result);
     }
     else if(num == 3)
     {
@@ -153,13 +133,14 @@ int main()
 
         Mat result;
         Point p;
-        p.x = destination.size().width/2;
-        p.y = destination.size().height/2;
+        p.x = destination.size().width / 2;
+        p.y = destination.size().height / 2;
 
-        seamlessClone(source, destination, mask, p, result, 3);
+        seamlessClone(source, destination, mask, p, result, MONOCHROME_TRANSFER);
 
-        imshow("Output",result);
-        imwrite("cloned.png", result);
+        // 注释掉 imshow
+        // imshow("Output",result);
+        imwrite("cloned_monochrome.png", result);
     }
     else if(num == 4)
     {
@@ -185,8 +166,9 @@ int main()
 
         colorChange(source, mask, result, 1.5, .5, .5);
 
-        imshow("Output",result);
-        imwrite("cloned.png", result);
+        // 注释掉 imshow
+        // imshow("Output",result);
+        imwrite("cloned_color_change.png", result);
     }
     else if(num == 5)
     {
@@ -212,8 +194,9 @@ int main()
 
         illuminationChange(source, mask, result, 0.2f, 0.4f);
 
-        imshow("Output",result);
-        imwrite("cloned.png", result);
+        // 注释掉 imshow
+        // imshow("Output",result);
+        imwrite("cloned_illumination_change.png", result);
     }
     else if(num == 6)
     {
@@ -239,13 +222,18 @@ int main()
 
         textureFlattening(source, mask, result, 30, 45, 3);
 
-        imshow("Output",result);
-        imwrite("cloned.png", result);
+        // 注释掉 imshow
+        // imshow("Output",result);
+        imwrite("cloned_texture_flattening.png", result);
     }
     else
     {
         cerr << "Invalid selection: " << num << endl;
         exit(1);
     }
-    waitKey(0);
+
+    // 注释掉 waitKey
+    // waitKey(0);
+    return 0;
 }
+
diff --git a/samples/cpp/cloning_gui.cpp b/samples/cpp/cloning_gui.cpp
index c4e4de7351..6149e1a38c 100644
--- a/samples/cpp/cloning_gui.cpp
+++ b/samples/cpp/cloning_gui.cpp
@@ -36,6 +36,7 @@
 #include "opencv2/highgui.hpp"
 #include "opencv2/core.hpp"
 #include <iostream>
+#include <climits>
 
 // we're NOT "using namespace std;" here, to avoid collisions between the beta variable and std::beta in c++17
 using std::cin;
@@ -77,216 +78,205 @@ void checkfile(char*);
 void source(int event, int x, int y, int, void*)
 {
 
-    if (event == EVENT_LBUTTONDOWN && !drag)
-    {
-        if(flag1 == 0)
-        {
-            if(var==0)
-                img1 = img0.clone();
-            point = Point(x, y);
-            circle(img1,point,2,Scalar(0, 0, 255),-1, 8, 0);
-            pts[var] = point;
-            var++;
-            drag  = 1;
-            if(var>1)
-                line(img1,pts[var-2], point, Scalar(0, 0, 255), 2, 8, 0);
-
-            imshow("Source", img1);
-        }
-    }
-
-    if (event == EVENT_LBUTTONUP && drag)
-    {
-        imshow("Source", img1);
-
-        drag = 0;
-    }
-    if (event == EVENT_RBUTTONDOWN)
-    {
-        flag1 = 1;
-        img1 = img0.clone();
-        for(int i = var; i < numpts ; i++)
-            pts[i] = point;
-
-        if(var!=0)
-        {
-            const Point* pts3[1] = {&pts[0]};
-            polylines( img1, pts3, &numpts,1, 1, Scalar(0,0,0), 2, 8, 0);
-        }
-
-        for(int i=0;i<var;i++)
-        {
-            minx = min(minx,pts[i].x);
-            maxx = max(maxx,pts[i].x);
-            miny = min(miny,pts[i].y);
-            maxy = max(maxy,pts[i].y);
-        }
-        lenx = maxx - minx;
-        leny = maxy - miny;
-
-        int mid_pointx = minx + lenx/2;
-        int mid_pointy = miny + leny/2;
-
-        for(int i=0;i<var;i++)
-        {
-            pts_diff[i].x = pts[i].x - mid_pointx;
-            pts_diff[i].y = pts[i].y - mid_pointy;
-        }
-
-        imshow("Source", img1);
-    }
-
-    if (event == EVENT_RBUTTONUP)
-    {
-        flag = var;
-
-        final = Mat::zeros(img0.size(),CV_8UC3);
-        res1 = Mat::zeros(img0.size(),CV_8UC1);
-        const Point* pts4[1] = {&pts[0]};
-
-        fillPoly(res1, pts4,&numpts, 1, Scalar(255, 255, 255), 8, 0);
-        bitwise_and(img0, img0, final,res1);
-
-        imshow("Source", img1);
-
-        if(num == 4)
-        {
-            colorChange(img0,res1,blend,red,green,blue);
-            imshow("Color Change Image", blend);
-            waitKey(0);
-
-        }
-        else if(num == 5)
-        {
-            illuminationChange(img0,res1,blend,alpha,beta);
-            imshow("Illum Change Image", blend);
-            waitKey(0);
-        }
-        else if(num == 6)
-        {
-            textureFlattening(img0,res1,blend,low_t,high_t,kernel_size);
-            imshow("Texture Flattened", blend);
-            waitKey(0);
-        }
-
-    }
-    if (event == EVENT_MBUTTONDOWN)
-    {
-        for(int i = 0; i < numpts ; i++)
-        {
-            pts[i].x=0;
-            pts[i].y=0;
-        }
-        var = 0;
-        flag1 = 0;
-        minx = INT_MAX; miny = INT_MAX; maxx = INT_MIN; maxy = INT_MIN;
-        imshow("Source", img0);
-        if(num == 1 || num == 2 || num == 3)
-            imshow("Destination",img2);
-        drag = 0;
-    }
+    // if (event == EVENT_LBUTTONDOWN && !drag)
+    // {
+    //     if(flag1 == 0)
+    //     {
+    //         if(var==0)
+    //             img1 = img0.clone();
+    //         point = Point(x, y);
+    //         circle(img1,point,2,Scalar(0, 0, 255),-1, 8, 0);
+    //         pts[var] = point;
+    //         var++;
+    //         drag  = 1;
+    //         if(var>1)
+    //             line(img1,pts[var-2], point, Scalar(0, 0, 255), 2, 8, 0);
+
+    //         imshow("Source", img1);
+    //     }
+    // }
+
+    // if (event == EVENT_LBUTTONUP && drag)
+    // {
+    //     imshow("Source", img1);
+
+    //     drag = 0;
+    // }
+    // if (event == EVENT_RBUTTONDOWN)
+    // {
+    //     flag1 = 1;
+    //     img1 = img0.clone();
+    //     for(int i = var; i < numpts ; i++)
+    //         pts[i] = point;
+
+    //     if(var!=0)
+    //     {
+    //         const Point* pts3[1] = {&pts[0]};
+    //         polylines( img1, pts3, &numpts,1, 1, Scalar(0,0,0), 2, 8, 0);
+    //     }
+
+    //     for(int i=0;i<var;i++)
+    //     {
+    //         minx = min(minx,pts[i].x);
+    //         maxx = max(maxx,pts[i].x);
+    //         miny = min(miny,pts[i].y);
+    //         maxy = max(maxy,pts[i].y);
+    //     }
+    //     lenx = maxx - minx;
+    //     leny = maxy - miny;
+
+    //     int mid_pointx = minx + lenx/2;
+    //     int mid_pointy = miny + leny/2;
+
+    //     for(int i=0;i<var;i++)
+    //     {
+    //         pts_diff[i].x = pts[i].x - mid_pointx;
+    //         pts_diff[i].y = pts[i].y - mid_pointy;
+    //     }
+
+    //     imshow("Source", img1);
+    // }
+
+    // if (event == EVENT_RBUTTONUP)
+    // {
+    //     flag = var;
+
+    //     final = Mat::zeros(img0.size(),CV_8UC3);
+    //     res1 = Mat::zeros(img0.size(),CV_8UC1);
+    //     const Point* pts4[1] = {&pts[0]};
+
+    //     fillPoly(res1, pts4,&numpts, 1, Scalar(255, 255, 255), 8, 0);
+    //     bitwise_and(img0, img0, final,res1);
+
+    //     imshow("Source", img1);
+
+    //     if(num == 4)
+    //     {
+    //         colorChange(img0,res1,blend,red,green,blue);
+    //         imshow("Color Change Image", blend);
+    //         waitKey(0);
+
+    //     }
+    //     else if(num == 5)
+    //     {
+    //         illuminationChange(img0,res1,blend,alpha,beta);
+    //         imshow("Illum Change Image", blend);
+    //         waitKey(0);
+    //     }
+    //     else if(num == 6)
+    //     {
+    //         textureFlattening(img0,res1,blend,low_t,high_t,kernel_size);
+    //         imshow("Texture Flattened", blend);
+    //         waitKey(0);
+    //     }
+
+    // }
+    // if (event == EVENT_MBUTTONDOWN)
+    // {
+    //     for(int i = 0; i < numpts ; i++)
+    //     {
+    //         pts[i].x=0;
+    //         pts[i].y=0;
+    //     }
+    //     var = 0;
+    //     flag1 = 0;
+    //     minx = INT_MAX; miny = INT_MAX; maxx = INT_MIN; maxy = INT_MIN;
+    //     imshow("Source", img0);
+    //     if(num == 1 || num == 2 || num == 3)
+    //         imshow("Destination",img2);
+    //     drag = 0;
+    // }
 }
 
 void destination(int event, int x, int y, int, void*)
 {
 
-    Mat im1;
-    minxd = INT_MAX; minyd = INT_MAX; maxxd = INT_MIN; maxyd = INT_MIN;
-    im1 = img2.clone();
-    if (event == EVENT_LBUTTONDOWN)
-    {
-        flag4 = 1;
-        if(flag1 == 1)
-        {
-            point = Point(x, y);
-
-            for(int i=0;i<var;i++)
-            {
-                pts2[i].x = point.x + pts_diff[i].x;
-                pts2[i].y = point.y + pts_diff[i].y;
-            }
-
-            for(int i=var;i<numpts;i++)
-            {
-                pts2[i].x = point.x + pts_diff[0].x;
-                pts2[i].y = point.y + pts_diff[0].y;
-            }
-
-            const Point* pts5[1] = {&pts2[0]};
-            polylines( im1, pts5, &numpts,1, 1, Scalar(0,0,255), 2, 8, 0);
-
-            destx = x;
-            desty = y;
-
-            imshow("Destination", im1);
-        }
-    }
-    if (event == EVENT_RBUTTONUP)
-    {
-        for(int i=0;i<flag;i++)
-        {
-            minxd = min(minxd,pts2[i].x);
-            maxxd = max(maxxd,pts2[i].x);
-            minyd = min(minyd,pts2[i].y);
-            maxyd = max(maxyd,pts2[i].y);
-        }
-
-        if(maxxd > im1.size().width || maxyd > im1.size().height || minxd < 0 || minyd < 0)
-        {
-            cout << "Index out of range" << endl;
-            exit(1);
-        }
-
-        final1 = Mat::zeros(img2.size(),CV_8UC3);
-        res = Mat::zeros(img2.size(),CV_8UC1);
-        for(int i=miny, k=minyd;i<(miny+leny);i++,k++)
-            for(int j=minx,l=minxd ;j<(minx+lenx);j++,l++)
-            {
-                for(int c=0;c<channel;c++)
-                {
-                    final1.at<uchar>(k,l*channel+c) = final.at<uchar>(i,j*channel+c);
-
-                }
-            }
-
-        const Point* pts6[1] = {&pts2[0]};
-        fillPoly(res, pts6, &numpts, 1, Scalar(255, 255, 255), 8, 0);
-
-        if(num == 1 || num == 2 || num == 3)
-        {
-            seamlessClone(img0,img2,res1,point,blend,num);
-            imshow("Cloned Image", blend);
-            imwrite("cloned.png",blend);
-            waitKey(0);
-        }
-
-        for(int i = 0; i < flag ; i++)
-        {
-            pts2[i].x=0;
-            pts2[i].y=0;
-        }
-
-        minxd = INT_MAX; minyd = INT_MAX; maxxd = INT_MIN; maxyd = INT_MIN;
-    }
-
-    im1.release();
+    // Mat im1;
+    // minxd = INT_MAX; minyd = INT_MAX; maxxd = INT_MIN; maxyd = INT_MIN;
+    // im1 = img2.clone();
+    // if (event == EVENT_LBUTTONDOWN)
+    // {
+    //     flag4 = 1;
+    //     if(flag1 == 1)
+    //     {
+    //         point = Point(x, y);
+
+    //         for(int i=0;i<var;i++)
+    //         {
+    //             pts2[i].x = point.x + pts_diff[i].x;
+    //             pts2[i].y = point.y + pts_diff[i].y;
+    //         }
+
+    //         for(int i=var;i<numpts;i++)
+    //         {
+    //             pts2[i].x = point.x + pts_diff[0].x;
+    //             pts2[i].y = point.y + pts_diff[0].y;
+    //         }
+
+    //         const Point* pts5[1] = {&pts2[0]};
+    //         polylines( im1, pts5, &numpts,1, 1, Scalar(0,0,255), 2, 8, 0);
+
+    //         destx = x;
+    //         desty = y;
+
+    //         imshow("Destination", im1);
+    //     }
+    // }
+    // if (event == EVENT_RBUTTONUP)
+    // {
+    //     for(int i=0;i<flag;i++)
+    //     {
+    //         minxd = min(minxd,pts2[i].x);
+    //         maxxd = max(maxxd,pts2[i].x);
+    //         minyd = min(minyd,pts2[i].y);
+    //         maxyd = max(maxyd,pts2[i].y);
+    //     }
+
+    //     if(maxxd > im1.size().width || maxyd > im1.size().height || minxd < 0 || minyd < 0)
+    //     {
+    //         cout << "Index out of range" << endl;
+    //         exit(1);
+    //     }
+
+    //     final1 = Mat::zeros(img2.size(),CV_8UC3);
+    //     res = Mat::zeros(img2.size(),CV_8UC1);
+    //     for(int i=miny, k=minyd;i<(miny+leny);i++,k++)
+    //         for(int j=minx,l=minxd ;j<(minx+lenx);j++,l++)
+    //         {
+    //             for(int c=0;c<channel;c++)
+    //             {
+    //                 final1.at<uchar>(k,l*channel+c) = final.at<uchar>(i,j*channel+c);
+
+    //             }
+    //         }
+
+    //     const Point* pts6[1] = {&pts2[0]};
+    //     fillPoly(res, pts6, &numpts, 1, Scalar(255, 255, 255), 8, 0);
+
+    //     if(num == 1 || num == 2 || num == 3)
+    //     {
+    //         seamlessClone(img0,img2,res1,point,blend,num);
+    //         imshow("Cloned Image", blend);
+    //         imwrite("cloned.png",blend);
+    //         waitKey(0);
+    //     }
+
+    //     for(int i = 0; i < flag ; i++)
+    //     {
+    //         pts2[i].x=0;
+    //         pts2[i].y=0;
+    //     }
+
+    //     minxd = INT_MAX; minyd = INT_MAX; maxxd = INT_MIN; maxyd = INT_MIN;
+    // }
+
+    // im1.release();
 }
 
-int main()
-{
+int main() {
     cout << endl;
     cout << "Cloning Module" << endl;
     cout << "---------------" << endl;
-    cout << "Step 1:" << endl;
-    cout << " -> In the source image, select the region of interest by left click mouse button. A Polygon ROI will be created by left clicking mouse button." << endl;
-    cout << " -> To set the Polygon ROI, click the right mouse button or use 'd' key" << endl;
-    cout << " -> To reset the region selected, click the middle mouse button or use 'r' key." << endl;
-
-    cout << "Step 2:" << endl;
-    cout << " -> In the destination image, select the point where you want to place the ROI in the image by left clicking mouse button." << endl;
-    cout << " -> To get the cloned result, click the right mouse button or use 'c' key." << endl;
-    cout << " -> To quit the program, use 'q' key." << endl;
-    cout << endl;
     cout << "Options: " << endl;
     cout << endl;
     cout << "1) Normal Cloning " << endl;
@@ -297,63 +287,74 @@ int main()
     cout << "6) Texture Flattening " << endl;
 
     cout << endl;
-
     cout << "Press number 1-6 to choose from above techniques: ";
     cin >> num;
     cout << endl;
 
     minx = INT_MAX; miny = INT_MAX; maxx = INT_MIN; maxy = INT_MIN;
-
     minxd = INT_MAX; minyd = INT_MAX; maxxd = INT_MIN; maxyd = INT_MIN;
 
-    int flag3 = 0;
-
-    if(num == 1 || num == 2 || num == 3)
-    {
-
-        string src,dest;
+    if(num == 1 || num == 2 || num == 3) {
+        string src, dest;
         cout << "Enter Source Image: ";
         cin >> src;
-
         cout << "Enter Destination Image: ";
         cin >> dest;
 
         img0 = imread(samples::findFile(src));
-
         img2 = imread(samples::findFile(dest));
 
-        if(img0.empty())
-        {
+        if(img0.empty()) {
             cout << "Source Image does not exist" << endl;
             exit(2);
         }
-        if(img2.empty())
-        {
+        if(img2.empty()) {
             cout << "Destination Image does not exist" << endl;
             exit(2);
         }
 
         channel = img0.channels();
 
-        res = Mat::zeros(img2.size(),CV_8UC1);
-        res1 = Mat::zeros(img0.size(),CV_8UC1);
-        final = Mat::zeros(img0.size(),CV_8UC3);
-        final1 = Mat::zeros(img2.size(),CV_8UC3);
-        //////////// source image ///////////////////
+        // For simplicity, we will use predefined points for source and destination
+        var = 4;
+        pts[0] = Point(50, 50);
+        pts[1] = Point(200, 50);
+        pts[2] = Point(200, 200);
+        pts[3] = Point(50, 200);
+        for(int i = var; i < numpts ; i++) pts[i] = pts[0];
 
-        namedWindow("Source", 1);
-        setMouseCallback("Source", source, NULL);
-        imshow("Source", img0);
+        minx = 50; miny = 50; maxx = 200; maxy = 200;
+        lenx = maxx - minx;
+        leny = maxy - miny;
+        int mid_pointx = minx + lenx/2;
+        int mid_pointy = miny + leny/2;
+        for(int i=0;i<var;i++) {
+            pts_diff[i].x = pts[i].x - mid_pointx;
+            pts_diff[i].y = pts[i].y - mid_pointy;
+        }
+
+        point = Point(img2.cols / 2, img2.rows / 2);
+        for(int i=0;i<var;i++) {
+            pts2[i] = Point(point.x + pts_diff[i].x, point.y + pts_diff[i].y);
+        }
+        for(int i=var;i<numpts;i++) {
+            pts2[i] = pts2[0];
+        }
 
-        /////////// destination image ///////////////
+        res = Mat::zeros(img2.size(), CV_8UC1);
+        res1 = Mat::zeros(img0.size(), CV_8UC1);
+        final = Mat::zeros(img0.size(), CV_8UC3);
+        final1 = Mat::zeros(img2.size(), CV_8UC3);
 
-        namedWindow("Destination", 1);
-        setMouseCallback("Destination", destination, NULL);
-        imshow("Destination",img2);
+        const Point* pts4[1] = {&pts[0]};
+        fillPoly(res1, pts4, &numpts, 1, Scalar(255, 255, 255), 8, 0);
+        bitwise_and(img0, img0, final, res1);
 
+        seamlessClone(img0, img2, res1, point, blend, num);
+        imwrite("cloned.png", blend);
+        cout << "Cloned image saved as cloned.png" << endl;
     }
-    else if(num == 4)
-    {
+    else if(num == 4) {
         string src;
         cout << "Enter Source Image: ";
         cin >> src;
@@ -361,190 +362,124 @@ int main()
         cout << "Enter RGB values: " << endl;
         cout << "Red: ";
         cin >> red;
-
         cout << "Green: ";
         cin >> green;
-
         cout << "Blue: ";
         cin >> blue;
 
         img0 = imread(samples::findFile(src));
-
-        if(img0.empty())
-        {
+        if(img0.empty()) {
             cout << "Source Image does not exist" << endl;
             exit(2);
         }
 
-        res1 = Mat::zeros(img0.size(),CV_8UC1);
-        final = Mat::zeros(img0.size(),CV_8UC3);
+        res1 = Mat::zeros(img0.size(), CV_8UC1);
+        final = Mat::zeros(img0.size(), CV_8UC3);
 
-        //////////// source image ///////////////////
+        // For simplicity, we will use predefined points for source and destination
+        var = 4;
+        pts[0] = Point(50, 50);
+        pts[1] = Point(200, 50);
+        pts[2] = Point(200, 200);
+        pts[3] = Point(50, 200);
+        for(int i = var; i < numpts ; i++) pts[i] = pts[0];
+
+        minx = 50; miny = 50; maxx = 200; maxy = 200;
+        lenx = maxx - minx;
+        leny = maxy - miny;
 
-        namedWindow("Source", 1);
-        setMouseCallback("Source", source, NULL);
-        imshow("Source", img0);
+        const Point* pts4[1] = {&pts[0]};
+        fillPoly(res1, pts4, &numpts, 1, Scalar(255, 255, 255), 8, 0);
+        bitwise_and(img0, img0, final, res1);
 
+        colorChange(img0, res1, blend, red, green, blue);
+        imwrite("cloned_color_change.png", blend);
+        cout << "Color change image saved as cloned_color_change.png" << endl;
     }
-    else if(num == 5)
-    {
+    else if(num == 5) {
         string src;
         cout << "Enter Source Image: ";
         cin >> src;
 
         cout << "alpha: ";
         cin >> alpha;
-
         cout << "beta: ";
         cin >> beta;
 
         img0 = imread(samples::findFile(src));
-
-        if(img0.empty())
-        {
+        if(img0.empty()) {
             cout << "Source Image does not exist" << endl;
             exit(2);
         }
 
-        res1 = Mat::zeros(img0.size(),CV_8UC1);
-        final = Mat::zeros(img0.size(),CV_8UC3);
+        res1 = Mat::zeros(img0.size(), CV_8UC1);
+        final = Mat::zeros(img0.size(), CV_8UC3);
+
+        // For simplicity, we will use predefined points for source and destination
+        var = 4;
+        pts[0] = Point(50, 50);
+        pts[1] = Point(200, 50);
+        pts[2] = Point(200, 200);
+        pts[3] = Point(50, 200);
+        for(int i = var; i < numpts ; i++) pts[i] = pts[0];
 
-        //////////// source image ///////////////////
+        minx = 50; miny = 50; maxx = 200; maxy = 200;
+        lenx = maxx - minx;
+        leny = maxy - miny;
 
-        namedWindow("Source", 1);
-        setMouseCallback("Source", source, NULL);
-        imshow("Source", img0);
+        const Point* pts4[1] = {&pts[0]};
+        fillPoly(res1, pts4, &numpts, 1, Scalar(255, 255, 255), 8, 0);
+        bitwise_and(img0, img0, final, res1);
 
+        illuminationChange(img0, res1, blend, alpha, beta);
+        imwrite("cloned_illumination_change.png", blend);
+        cout << "Illumination change image saved as cloned_illumination_change.png" << endl;
     }
-    else if(num == 6)
-    {
+    else if(num == 6) {
         string src;
         cout << "Enter Source Image: ";
         cin >> src;
 
         cout << "low_threshold: ";
         cin >> low_t;
-
         cout << "high_threshold: ";
         cin >> high_t;
-
         cout << "kernel_size: ";
         cin >> kernel_size;
 
         img0 = imread(samples::findFile(src));
-
-        if(img0.empty())
-        {
+        if(img0.empty()) {
             cout << "Source Image does not exist" << endl;
             exit(2);
         }
 
-        res1 = Mat::zeros(img0.size(),CV_8UC1);
-        final = Mat::zeros(img0.size(),CV_8UC3);
+        res1 = Mat::zeros(img0.size(), CV_8UC1);
+        final = Mat::zeros(img0.size(), CV_8UC3);
 
-        //////////// source image ///////////////////
+        // For simplicity, we will use predefined points for source and destination
+        var = 4;
+        pts[0] = Point(50, 50);
+        pts[1] = Point(200, 50);
+        pts[2] = Point(200, 200);
+        pts[3] = Point(50, 200);
+        for(int i = var; i < numpts ; i++) pts[i] = pts[0];
 
-        namedWindow("Source", 1);
-        setMouseCallback("Source", source, NULL);
-        imshow("Source", img0);
+        minx = 50; miny = 50; maxx = 200; maxy = 200;
+        lenx = maxx - minx;
+        leny = maxy - miny;
+
+        const Point* pts4[1] = {&pts[0]};
+        fillPoly(res1, pts4, &numpts, 1, Scalar(255, 255, 255), 8, 0);
+        bitwise_and(img0, img0, final, res1);
+
+        textureFlattening(img0, res1, blend, low_t, high_t, kernel_size);
+        imwrite("cloned_texture_flattening.png", blend);
+        cout << "Texture flattened image saved as cloned_texture_flattening.png" << endl;
     }
-    else
-    {
+    else {
         cout << "Wrong Option Chosen" << endl;
         exit(1);
     }
 
-    for(;;)
-    {
-        char key = (char)waitKey(0);
-
-        if(key == 'd' && flag3 == 0)
-        {
-            flag1 = 1;
-            flag3 = 1;
-            img1 = img0.clone();
-            for(int i = var; i < numpts ; i++)
-                pts[i] = point;
-
-            if(var!=0)
-            {
-                const Point* pts3[1] = {&pts[0]};
-                polylines( img1, pts3, &numpts,1, 1, Scalar(0,0,0), 2, 8, 0);
-            }
-
-            for(int i=0;i<var;i++)
-            {
-                minx = min(minx,pts[i].x);
-                maxx = max(maxx,pts[i].x);
-                miny = min(miny,pts[i].y);
-                maxy = max(maxy,pts[i].y);
-            }
-            lenx = maxx - minx;
-            leny = maxy - miny;
-
-            int mid_pointx = minx + lenx/2;
-            int mid_pointy = miny + leny/2;
-
-            for(int i=0;i<var;i++)
-            {
-                pts_diff[i].x = pts[i].x - mid_pointx;
-                pts_diff[i].y = pts[i].y - mid_pointy;
-            }
-
-            flag = var;
-
-            final = Mat::zeros(img0.size(),CV_8UC3);
-            res1 = Mat::zeros(img0.size(),CV_8UC1);
-            const Point* pts4[1] = {&pts[0]};
-
-            fillPoly(res1, pts4,&numpts, 1, Scalar(255, 255, 255), 8, 0);
-            bitwise_and(img0, img0, final,res1);
-
-            imshow("Source", img1);
-        }
-        else if(key == 'r')
-        {
-            for(int i = 0; i < numpts ; i++)
-            {
-                pts[i].x=0;
-                pts[i].y=0;
-            }
-            var = 0;
-            flag1 = 0;
-            flag3 = 0;
-            flag4 = 0;
-            minx = INT_MAX; miny = INT_MAX; maxx = INT_MIN; maxy = INT_MIN;
-            imshow("Source", img0);
-            if(num == 1 || num == 2 || num == 3)
-                imshow("Destination",img2);
-            drag = 0;
-        }
-        else if ((num == 1 || num == 2 || num == 3) && key == 'c' && flag1 == 1 && flag4 == 1)
-        {
-            seamlessClone(img0,img2,res1,point,blend,num);
-            imshow("Cloned Image", blend);
-            imwrite("cloned.png",blend);
-        }
-        else if (num == 4 && key == 'c' && flag1 == 1)
-        {
-            colorChange(img0,res1,blend,red,green,blue);
-            imshow("Color Change Image", blend);
-            imwrite("cloned.png",blend);
-        }
-        else if (num == 5 && key == 'c' && flag1 == 1)
-        {
-            illuminationChange(img0,res1,blend,alpha,beta);
-            imshow("Illum Change Image", blend);
-            imwrite("cloned.png",blend);
-        }
-        else if (num == 6 && key == 'c' && flag1 == 1)
-        {
-            textureFlattening(img0,res1,blend,low_t,high_t,kernel_size);
-            imshow("Texture Flattened", blend);
-            imwrite("cloned.png",blend);
-        }
-        else if(key == 'q')
-            break;
-    }
     return 0;
 }
diff --git a/samples/cpp/connected_components.cpp b/samples/cpp/connected_components.cpp
index 74afb29d6c..a91f407ba8 100644
--- a/samples/cpp/connected_components.cpp
+++ b/samples/cpp/connected_components.cpp
@@ -1,9 +1,8 @@
-
 #include <opencv2/core/utility.hpp>
 #include "opencv2/imgproc.hpp"
 #include "opencv2/imgcodecs.hpp"
-#include "opencv2/highgui.hpp"
 #include <iostream>
+#include <vector>
 
 using namespace cv;
 using namespace std;
@@ -17,9 +16,9 @@ static void on_trackbar(int, void*)
     Mat labelImage(img.size(), CV_32S);
     int nLabels = connectedComponents(bw, labelImage, 8);
     std::vector<Vec3b> colors(nLabels);
-    colors[0] = Vec3b(0, 0, 0);//background
+    colors[0] = Vec3b(0, 0, 0); // background
     for(int label = 1; label < nLabels; ++label){
-        colors[label] = Vec3b( (rand()&255), (rand()&255), (rand()&255) );
+        colors[label] = Vec3b((rand() & 255), (rand() & 255), (rand() & 255));
     }
     Mat dst(img.size(), CV_8UC3);
     for(int r = 0; r < dst.rows; ++r){
@@ -27,18 +26,19 @@ static void on_trackbar(int, void*)
             int label = labelImage.at<int>(r, c);
             Vec3b &pixel = dst.at<Vec3b>(r, c);
             pixel = colors[label];
-         }
-     }
+        }
+    }
 
-    imshow( "Connected Components", dst );
+    // Save the result to a file instead of showing it
+    imwrite("connected_components.png", dst);
 }
 
-int main( int argc, const char** argv )
+int main(int argc, const char** argv)
 {
     CommandLineParser parser(argc, argv, "{@image|stuff.jpg|image for converting to a grayscale}");
     parser.about("\nThis program demonstrates connected components and use of the trackbar\n");
     parser.printMessage();
-    cout << "\nThe image is converted to grayscale and displayed, another image has a trackbar\n"
+    cout << "\nThe image is converted to grayscale and saved as output, another image has a trackbar\n"
             "that controls thresholding and thereby the extracted contours which are drawn in color\n";
 
     String inputImage = parser.get<string>(0);
@@ -50,12 +50,14 @@ int main( int argc, const char** argv )
         return EXIT_FAILURE;
     }
 
-    imshow( "Image", img );
+    // Instead of showing the image, we just inform the user
+    cout << "Processing the image: " << inputImage << endl;
 
-    namedWindow( "Connected Components", WINDOW_AUTOSIZE);
-    createTrackbar( "Threshold", "Connected Components", &threshval, 255, on_trackbar );
+    // Directly call the function to process the image
     on_trackbar(threshval, 0);
 
-    waitKey(0);
+    cout << "Processed image saved as connected_components.png" << endl;
+
     return EXIT_SUCCESS;
 }
+
diff --git a/samples/cpp/contours2.cpp b/samples/cpp/contours2.cpp
index c3653fb5d6..efc9e1119a 100644
--- a/samples/cpp/contours2.cpp
+++ b/samples/cpp/contours2.cpp
@@ -1,5 +1,5 @@
 #include "opencv2/imgproc.hpp"
-#include "opencv2/highgui.hpp"
+#include "opencv2/imgcodecs.hpp"
 #include <math.h>
 #include <iostream>
 
@@ -10,11 +10,11 @@ static void help(char** argv)
 {
     cout
         << "\nThis program illustrates the use of findContours and drawContours\n"
-        << "The original image is put up along with the image of drawn contours\n"
+        << "The original image is processed and contours are saved to an output file\n"
         << "Usage:\n";
     cout
         << argv[0]
-        << "\nA trackbar is put up which controls the contour level from -3 to 3\n"
+        << "\nContours level is controlled by a parameter from -3 to 3\n"
         << endl;
 }
 
@@ -24,73 +24,80 @@ int levels = 3;
 vector<vector<Point> > contours;
 vector<Vec4i> hierarchy;
 
-static void on_trackbar(int, void*)
+static void processContours(int levels)
 {
     Mat cnt_img = Mat::zeros(w, w, CV_8UC3);
     int _levels = levels - 3;
-    drawContours( cnt_img, contours, _levels <= 0 ? 3 : -1, Scalar(128,255,255),
-                  3, LINE_AA, hierarchy, std::abs(_levels) );
+    drawContours(cnt_img, contours, _levels <= 0 ? 3 : -1, Scalar(128, 255, 255),
+                 3, LINE_AA, hierarchy, std::abs(_levels));
 
-    imshow("contours", cnt_img);
+    // Save the result to a file instead of showing it
+    imwrite("contours_output.png", cnt_img);
 }
 
-int main( int argc, char** argv)
+int main(int argc, char** argv)
 {
-    cv::CommandLineParser parser(argc, argv, "{help h||}");
+    cv::CommandLineParser parser(argc, argv, "{help h||}{@levels|3|contour levels}");
     if (parser.has("help"))
     {
         help(argv);
         return 0;
     }
+
+    levels = parser.get<int>("@levels");
+    if (levels < -3 || levels > 3)
+    {
+        cout << "Levels parameter out of range. It should be between -3 and 3." << endl;
+        return EXIT_FAILURE;
+    }
+
     Mat img = Mat::zeros(w, w, CV_8UC1);
-    //Draw 6 faces
-    for( int i = 0; i < 6; i++ )
+    // Draw 6 faces
+    for (int i = 0; i < 6; i++)
     {
-        int dx = (i%2)*250 - 30;
-        int dy = (i/2)*150;
+        int dx = (i % 2) * 250 - 30;
+        int dy = (i / 2) * 150;
         const Scalar white = Scalar(255);
         const Scalar black = Scalar(0);
 
-        if( i == 0 )
+        if (i == 0)
         {
-            for( int j = 0; j <= 10; j++ )
+            for (int j = 0; j <= 10; j++)
             {
-                double angle = (j+5)*CV_PI/21;
-                line(img, Point(cvRound(dx+100+j*10-80*cos(angle)),
-                    cvRound(dy+100-90*sin(angle))),
-                    Point(cvRound(dx+100+j*10-30*cos(angle)),
-                    cvRound(dy+100-30*sin(angle))), white, 1, 8, 0);
+                double angle = (j + 5) * CV_PI / 21;
+                line(img, Point(cvRound(dx + 100 + j * 10 - 80 * cos(angle)),
+                    cvRound(dy + 100 - 90 * sin(angle))),
+                    Point(cvRound(dx + 100 + j * 10 - 30 * cos(angle)),
+                    cvRound(dy + 100 - 30 * sin(angle))), white, 1, 8, 0);
             }
         }
 
-        ellipse( img, Point(dx+150, dy+100), Size(100,70), 0, 0, 360, white, -1, 8, 0 );
-        ellipse( img, Point(dx+115, dy+70), Size(30,20), 0, 0, 360, black, -1, 8, 0 );
-        ellipse( img, Point(dx+185, dy+70), Size(30,20), 0, 0, 360, black, -1, 8, 0 );
-        ellipse( img, Point(dx+115, dy+70), Size(15,15), 0, 0, 360, white, -1, 8, 0 );
-        ellipse( img, Point(dx+185, dy+70), Size(15,15), 0, 0, 360, white, -1, 8, 0 );
-        ellipse( img, Point(dx+115, dy+70), Size(5,5), 0, 0, 360, black, -1, 8, 0 );
-        ellipse( img, Point(dx+185, dy+70), Size(5,5), 0, 0, 360, black, -1, 8, 0 );
-        ellipse( img, Point(dx+150, dy+100), Size(10,5), 0, 0, 360, black, -1, 8, 0 );
-        ellipse( img, Point(dx+150, dy+150), Size(40,10), 0, 0, 360, black, -1, 8, 0 );
-        ellipse( img, Point(dx+27, dy+100), Size(20,35), 0, 0, 360, white, -1, 8, 0 );
-        ellipse( img, Point(dx+273, dy+100), Size(20,35), 0, 0, 360, white, -1, 8, 0 );
+        ellipse(img, Point(dx + 150, dy + 100), Size(100, 70), 0, 0, 360, white, -1, 8, 0);
+        ellipse(img, Point(dx + 115, dy + 70), Size(30, 20), 0, 0, 360, black, -1, 8, 0);
+        ellipse(img, Point(dx + 185, dy + 70), Size(30, 20), 0, 0, 360, black, -1, 8, 0);
+        ellipse(img, Point(dx + 115, dy + 70), Size(15, 15), 0, 0, 360, white, -1, 8, 0);
+        ellipse(img, Point(dx + 185, dy + 70), Size(15, 15), 0, 0, 360, white, -1, 8, 0);
+        ellipse(img, Point(dx + 115, dy + 70), Size(5, 5), 0, 0, 360, black, -1, 8, 0);
+        ellipse(img, Point(dx + 185, dy + 70), Size(5, 5), 0, 0, 360, black, -1, 8, 0);
+        ellipse(img, Point(dx + 150, dy + 100), Size(10, 5), 0, 0, 360, black, -1, 8, 0);
+        ellipse(img, Point(dx + 150, dy + 150), Size(40, 10), 0, 0, 360, black, -1, 8, 0);
+        ellipse(img, Point(dx + 27, dy + 100), Size(20, 35), 0, 0, 360, white, -1, 8, 0);
+        ellipse(img, Point(dx + 273, dy + 100), Size(20, 35), 0, 0, 360, white, -1, 8, 0);
     }
-    //show the faces
-    namedWindow( "image", 1 );
-    imshow( "image", img );
-    //Extract the contours so that
+
+    // Extract the contours
     vector<vector<Point> > contours0;
-    findContours( img, contours0, hierarchy, RETR_TREE, CHAIN_APPROX_SIMPLE);
+    findContours(img, contours0, hierarchy, RETR_TREE, CHAIN_APPROX_SIMPLE);
 
     contours.resize(contours0.size());
-    for( size_t k = 0; k < contours0.size(); k++ )
+    for (size_t k = 0; k < contours0.size(); k++)
         approxPolyDP(Mat(contours0[k]), contours[k], 3, true);
 
-    namedWindow( "contours", 1 );
-    createTrackbar( "levels+3", "contours", &levels, 7, on_trackbar );
+    // Process contours and save to file
+    processContours(levels);
 
-    on_trackbar(0,0);
-    waitKey();
+    cout << "Contours processed and saved to contours_output.png" << endl;
 
     return 0;
 }
+
diff --git a/samples/cpp/convexhull.cpp b/samples/cpp/convexhull.cpp
index d839b8061f..12f2ae1185 100644
--- a/samples/cpp/convexhull.cpp
+++ b/samples/cpp/convexhull.cpp
@@ -1,6 +1,9 @@
 #include "opencv2/imgproc.hpp"
 #include "opencv2/highgui.hpp"
 #include <iostream>
+#include <cstdlib>
+#include <sys/stat.h>
+#include <sys/types.h>
 
 using namespace cv;
 using namespace std;
@@ -12,7 +15,7 @@ static void help(char** argv)
          << argv[0] << endl;
 }
 
-int main( int argc, char** argv )
+int main(int argc, char** argv)
 {
     CommandLineParser parser(argc, argv, "{help h||}");
     if (parser.has("help"))
@@ -23,17 +26,25 @@ int main( int argc, char** argv )
     Mat img(500, 500, CV_8UC3);
     RNG& rng = theRNG();
 
-    for(;;)
+    String sample_name = "convexhull";
+    // 创建子目录
+    if (mkdir(sample_name.c_str(), 0777) == -1)
     {
-        int i, count = (unsigned)rng%100 + 1;
+        cerr << "Error :  " << strerror(errno) << endl;
+        return 1;
+    }
+
+    for (int frame_counter = 0;; frame_counter++)
+    {
+        int i, count = (unsigned)rng % 100 + 1;
 
         vector<Point> points;
 
-        for( i = 0; i < count; i++ )
+        for (i = 0; i < count; i++)
         {
             Point pt;
-            pt.x = rng.uniform(img.cols/4, img.cols*3/4);
-            pt.y = rng.uniform(img.rows/4, img.rows*3/4);
+            pt.x = rng.uniform(img.cols / 4, img.cols * 3 / 4);
+            pt.y = rng.uniform(img.rows / 4, img.rows * 3 / 4);
 
             points.push_back(pt);
         }
@@ -42,16 +53,20 @@ int main( int argc, char** argv )
         convexHull(points, hull, true);
 
         img = Scalar::all(0);
-        for( i = 0; i < count; i++ )
+        for (i = 0; i < count; i++)
             circle(img, points[i], 3, Scalar(0, 0, 255), FILLED, LINE_AA);
 
         polylines(img, hull, true, Scalar(0, 255, 0), 1, LINE_AA);
-        imshow("hull", img);
 
-        char key = (char)waitKey();
-        if( key == 27 || key == 'q' || key == 'Q' ) // 'ESC'
+        String frame_filename = sample_name + "/frame_" + to_string(frame_counter) + ".png";
+        imwrite(frame_filename, img);
+
+        cout << "Saved frame to " << frame_filename << endl;
+
+        if (frame_counter >= 10) // 假设我们只保存10帧
             break;
     }
 
     return 0;
 }
+
diff --git a/samples/cpp/cout_mat.cpp b/samples/cpp/cout_mat.cpp
index 0d28241556..573ea67943 100644
--- a/samples/cpp/cout_mat.cpp
+++ b/samples/cpp/cout_mat.cpp
@@ -7,6 +7,7 @@
 
 #include "opencv2/core.hpp"
 #include <iostream>
+#include <fstream>
 
 using namespace std;
 using namespace cv;
@@ -24,7 +25,6 @@ static void help(char** argv)
     << endl;
 }
 
-
 int main(int argc, char** argv)
 {
     cv::CommandLineParser parser(argc, argv, "{help h||}");
@@ -33,37 +33,50 @@ int main(int argc, char** argv)
         help(argv);
         return 0;
     }
+
+    ofstream outfile("output.txt");
+    if (!outfile.is_open())
+    {
+        cerr << "Could not open the file for writing!" << endl;
+        return -1;
+    }
+
     Mat I = Mat::eye(4, 4, CV_64F);
     I.at<double>(1,1) = CV_PI;
-    cout << "I = \n" << I << ";" << endl << endl;
+    outfile << "I = \n" << I << ";" << endl << endl;
 
     Mat r = Mat(10, 3, CV_8UC3);
     randu(r, Scalar::all(0), Scalar::all(255));
 
-    cout << "r (default) = \n" << r << ";" << endl << endl;
-    cout << "r (matlab) = \n" << format(r, Formatter::FMT_MATLAB) << ";" << endl << endl;
-    cout << "r (python) = \n" << format(r, Formatter::FMT_PYTHON) << ";" << endl << endl;
-    cout << "r (numpy) = \n" << format(r, Formatter::FMT_NUMPY) << ";" << endl << endl;
-    cout << "r (csv) = \n" << format(r, Formatter::FMT_CSV) << ";" << endl << endl;
-    cout << "r (c) = \n" << format(r, Formatter::FMT_C) << ";" << endl << endl;
+    outfile << "r (default) = \n" << r << ";" << endl << endl;
+    outfile << "r (matlab) = \n" << format(r, Formatter::FMT_MATLAB) << ";" << endl << endl;
+    outfile << "r (python) = \n" << format(r, Formatter::FMT_PYTHON) << ";" << endl << endl;
+    outfile << "r (numpy) = \n" << format(r, Formatter::FMT_NUMPY) << ";" << endl << endl;
+    outfile << "r (csv) = \n" << format(r, Formatter::FMT_CSV) << ";" << endl << endl;
+    outfile << "r (c) = \n" << format(r, Formatter::FMT_C) << ";" << endl << endl;
 
     Point2f p(5, 1);
-    cout << "p = " << p << ";" << endl;
+    outfile << "p = " << p << ";" << endl;
 
     Point3f p3f(2, 6, 7);
-    cout << "p3f = " << p3f << ";" << endl;
+    outfile << "p3f = " << p3f << ";" << endl;
 
     vector<float> v;
     v.push_back(1);
     v.push_back(2);
     v.push_back(3);
 
-    cout << "shortvec = " << Mat(v) << endl;
+    outfile << "shortvec = " << Mat(v) << endl;
 
     vector<Point2f> points(20);
     for (size_t i = 0; i < points.size(); ++i)
         points[i] = Point2f((float)(i * 5), (float)(i % 7));
 
-    cout << "points = " << points << ";" << endl;
+    outfile << "points = " << points << ";" << endl;
+
+    outfile.close();
+    cout << "Output written to output.txt" << endl;
+
     return 0;
 }
+
diff --git a/samples/cpp/create_mask.cpp b/samples/cpp/create_mask.cpp
index 67b0ec9bbd..55e6aa6de2 100644
--- a/samples/cpp/create_mask.cpp
+++ b/samples/cpp/create_mask.cpp
@@ -11,8 +11,11 @@
 
 #include "opencv2/imgproc.hpp"
 #include "opencv2/imgcodecs.hpp"
-#include "opencv2/highgui.hpp"
+ #include "opencv2/highgui.hpp"
 #include <iostream>
+#include <cstdlib>
+#include <sys/stat.h>
+#include <sys/types.h>
 
 using namespace std;
 using namespace cv;
@@ -25,11 +28,10 @@ int drag = 0;
 int var = 0;
 int flag = 0;
 
-void mouseHandler(int, int, int, int, void*);
+// void mouseHandler(int, int, int, int, void*);
 
 void mouseHandler(int event, int x, int y, int, void*)
 {
-
     if (event == EVENT_LBUTTONDOWN && !drag)
     {
         if (flag == 0)
@@ -37,21 +39,21 @@ void mouseHandler(int event, int x, int y, int, void*)
             if (var == 0)
                 img1 = src.clone();
             point = Point(x, y);
-            circle(img1, point, 2, Scalar(0, 0, 255), -1, 8, 0);
+            // circle(img1, point, 2, Scalar(0, 0, 255), -1, 8, 0);
             pts.push_back(point);
             var++;
             drag  = 1;
 
             if (var > 1)
-                line(img1,pts[var-2], point, Scalar(0, 0, 255), 2, 8, 0);
+                ; // line(img1, pts[var-2], point, Scalar(0, 0, 255), 2, 8, 0);
 
-            imshow("Source", img1);
+            // imshow("Source", img1);
         }
     }
 
     if (event == EVENT_LBUTTONUP && drag)
     {
-        imshow("Source", img1);
+        // imshow("Source", img1);
         drag = 0;
     }
 
@@ -62,10 +64,10 @@ void mouseHandler(int event, int x, int y, int, void*)
 
         if (var != 0)
         {
-            polylines( img1, pts, 1, Scalar(0,0,0), 2, 8, 0);
+            polylines(img1, pts, 1, Scalar(0, 0, 0), 2, 8, 0);
         }
 
-        imshow("Source", img1);
+        // imshow("Source", img1);
     }
 
     if (event == EVENT_RBUTTONUP)
@@ -76,9 +78,9 @@ void mouseHandler(int event, int x, int y, int, void*)
 
         fillPoly(mask, pts, Scalar(255, 255, 255), 8, 0);
         bitwise_and(src, src, final, mask);
-        imshow("Mask", mask);
-        imshow("Result", final);
-        imshow("Source", img1);
+        // imshow("Mask", mask);
+        // imshow("Result", final);
+        // imshow("Source", img1);
     }
 
     if (event == EVENT_MBUTTONDOWN)
@@ -87,7 +89,7 @@ void mouseHandler(int event, int x, int y, int, void*)
         var = 0;
         drag = 0;
         flag = 0;
-        imshow("Source", src);
+        // imshow("Source", src);
     }
 }
 
@@ -97,8 +99,8 @@ int main(int argc, char **argv)
     parser.about("This program demonstrates using mouse events\n");
     parser.printMessage();
     cout << "\n\tleft mouse button - set a point to create mask shape\n"
-        "\tright mouse button - create mask from points\n"
-        "\tmiddle mouse button - reset\n";
+         << "\tright mouse button - create mask from points\n"
+         << "\tmiddle mouse button - reset\n";
     String input_image = parser.get<String>("@input");
 
     src = imread(samples::findFile(input_image));
@@ -109,10 +111,36 @@ int main(int argc, char **argv)
         return 0;
     }
 
-    namedWindow("Source", WINDOW_AUTOSIZE);
-    setMouseCallback("Source", mouseHandler, NULL);
-    imshow("Source", src);
-    waitKey(0);
+    String sample_name = "create_mask";
+    // 创建子目录
+    if (mkdir(sample_name.c_str(), 0777) == -1)
+    {
+        cerr << "Error :  " << strerror(errno) << endl;
+        return 1;
+    }
+
+    // namedWindow("Source", WINDOW_AUTOSIZE);
+    // setMouseCallback("Source", mouseHandler, NULL);
+    // imshow("Source", src);
+    // waitKey(0);
+
+    // 假设您有一个事先定义的点集来创建mask
+    pts = {Point(100, 100), Point(200, 100), Point(200, 200), Point(100, 200)};
+    final = Mat::zeros(src.size(), CV_8UC3);
+    mask = Mat::zeros(src.size(), CV_8UC1);
+
+    fillPoly(mask, pts, Scalar(255, 255, 255), 8, 0);
+    bitwise_and(src, src, final, mask);
+
+    String mask_filename = sample_name + "/mask.png";
+    String result_filename = sample_name + "/result.png";
+
+    imwrite(mask_filename, mask);
+    imwrite(result_filename, final);
+
+    cout << "Saved mask to " << mask_filename << endl;
+    cout << "Saved result to " << result_filename << endl;
 
     return 0;
 }
+
diff --git a/samples/cpp/dbt_face_detection.cpp b/samples/cpp/dbt_face_detection.cpp
index d5707d4b7d..16fc36a269 100644
--- a/samples/cpp/dbt_face_detection.cpp
+++ b/samples/cpp/dbt_face_detection.cpp
@@ -1,69 +1,65 @@
 #if defined(__linux__) || defined(LINUX) || defined(__APPLE__) || defined(ANDROID) || (defined(_MSC_VER) && _MSC_VER>=1800)
-
-#include <opencv2/imgproc.hpp>  // Gaussian Blur
-#include <opencv2/core.hpp>        // Basic OpenCV structures (cv::Mat, Scalar)
+#include <opencv2/imgproc.hpp>
+#include <opencv2/core.hpp>
 #include <opencv2/videoio.hpp>
-#include <opencv2/highgui.hpp>  // OpenCV window I/O
+#include <opencv2/highgui.hpp>
 #include <opencv2/features2d.hpp>
 #include <opencv2/objdetect.hpp>
-
 #include <stdio.h>
 
 using namespace std;
 using namespace cv;
 
-const string WindowName = "Face Detection example";
-
 class CascadeDetectorAdapter: public DetectionBasedTracker::IDetector
 {
-    public:
-        CascadeDetectorAdapter(cv::Ptr<cv::CascadeClassifier> detector):
-            IDetector(),
-            Detector(detector)
-        {
-            CV_Assert(detector);
-        }
+public:
+    CascadeDetectorAdapter(cv::Ptr<cv::CascadeClassifier> detector):
+        IDetector(),
+        Detector(detector)
+    {
+        CV_Assert(detector);
+    }
 
-        void detect(const cv::Mat &Image, std::vector<cv::Rect> &objects) CV_OVERRIDE
-        {
-            Detector->detectMultiScale(Image, objects, scaleFactor, minNeighbours, 0, minObjSize, maxObjSize);
-        }
+    void detect(const cv::Mat &Image, std::vector<cv::Rect> &objects) CV_OVERRIDE
+    {
+        Detector->detectMultiScale(Image, objects, scaleFactor, minNeighbours, 0, minObjSize, maxObjSize);
+    }
 
-        virtual ~CascadeDetectorAdapter() CV_OVERRIDE
-        {}
+    virtual ~CascadeDetectorAdapter() CV_OVERRIDE
+    {}
 
-    private:
-        CascadeDetectorAdapter();
-        cv::Ptr<cv::CascadeClassifier> Detector;
- };
+private:
+    CascadeDetectorAdapter();
+    cv::Ptr<cv::CascadeClassifier> Detector;
+};
 
 int main(int , char** )
 {
-    namedWindow(WindowName);
-
-    VideoCapture VideoStream(0);
+    // 使用官方提供的视频文件
+    std::string videoFile = samples::findFile("samples/data/vtest.avi");
+    VideoCapture VideoStream(videoFile);
 
     if (!VideoStream.isOpened())
     {
-        printf("Error: Cannot open video stream from camera\n");
+        printf("Error: Cannot open video file\n");
         return 1;
     }
 
     std::string cascadeFrontalfilename = samples::findFile("data/lbpcascades/lbpcascade_frontalface.xml");
     cv::Ptr<cv::CascadeClassifier> cascade = makePtr<cv::CascadeClassifier>(cascadeFrontalfilename);
     cv::Ptr<DetectionBasedTracker::IDetector> MainDetector = makePtr<CascadeDetectorAdapter>(cascade);
-    if ( cascade->empty() )
+    if (cascade->empty())
     {
-      printf("Error: Cannot load %s\n", cascadeFrontalfilename.c_str());
-      return 2;
+        printf("Error: Cannot load %s\n", cascadeFrontalfilename.c_str());
+        return 2;
     }
 
     cascade = makePtr<cv::CascadeClassifier>(cascadeFrontalfilename);
     cv::Ptr<DetectionBasedTracker::IDetector> TrackingDetector = makePtr<CascadeDetectorAdapter>(cascade);
-    if ( cascade->empty() )
+    if (cascade->empty())
     {
-      printf("Error: Cannot load %s\n", cascadeFrontalfilename.c_str());
-      return 2;
+        printf("Error: Cannot load %s\n", cascadeFrontalfilename.c_str());
+        return 2;
     }
 
     DetectionBasedTracker::Parameters params;
@@ -75,6 +71,17 @@ int main(int , char** )
         return 2;
     }
 
+    // 准备保存处理结果的视频文件
+    int frame_width = static_cast<int>(VideoStream.get(CAP_PROP_FRAME_WIDTH));
+    int frame_height = static_cast<int>(VideoStream.get(CAP_PROP_FRAME_HEIGHT));
+    VideoWriter outputVideo("output.avi", VideoWriter::fourcc('M','J','P','G'), 10, Size(frame_width, frame_height));
+
+    if (!outputVideo.isOpened())
+    {
+        printf("Error: Cannot open video writer\n");
+        return 3;
+    }
+
     Mat ReferenceFrame;
     Mat GrayFrame;
     vector<Rect> Faces;
@@ -82,6 +89,8 @@ int main(int , char** )
     do
     {
         VideoStream >> ReferenceFrame;
+        if (ReferenceFrame.empty()) break;  // 检查是否到达视频结尾
+
         cvtColor(ReferenceFrame, GrayFrame, COLOR_BGR2GRAY);
         Detector.process(GrayFrame);
         Detector.getObjects(Faces);
@@ -91,10 +100,12 @@ int main(int , char** )
             rectangle(ReferenceFrame, Faces[i], Scalar(0,255,0));
         }
 
-        imshow(WindowName, ReferenceFrame);
-    } while (waitKey(30) < 0);
+        // 将处理后的帧保存到视频文件
+        outputVideo.write(ReferenceFrame);
+    } while (VideoStream.grab());
 
     Detector.stop();
+    outputVideo.release();  // 关闭视频文件
 
     return 0;
 }
@@ -107,5 +118,4 @@ int main()
     printf("This sample works for UNIX or ANDROID or Visual Studio 2013+ only\n");
     return 0;
 }
-
 #endif
diff --git a/samples/cpp/delaunay2.cpp b/samples/cpp/delaunay2.cpp
index 428804e31c..4c82c91ecc 100644
--- a/samples/cpp/delaunay2.cpp
+++ b/samples/cpp/delaunay2.cpp
@@ -120,7 +120,7 @@ int main( int argc, char** argv )
 
     img = Scalar::all(0);
     string win = "Delaunay Demo";
-    imshow(win, img);
+    // imshow(win, img); // 注释掉
 
     for( int i = 0; i < 200; i++ )
     {
@@ -128,26 +128,30 @@ int main( int argc, char** argv )
                     (float)(rand()%(rect.height-10)+5));
 
         locate_point( img, subdiv, fp, active_facet_color );
-        imshow( win, img );
+        // imshow( win, img ); // 注释掉
 
-        if( waitKey( 100 ) >= 0 )
-            break;
+        // if( waitKey( 100 ) >= 0 ) // 注释掉
+        //     break;
 
         subdiv.insert(fp);
 
         img = Scalar::all(0);
         draw_subdiv( img, subdiv, delaunay_color );
-        imshow( win, img );
+        // imshow( win, img ); // 注释掉
 
-        if( waitKey( 100 ) >= 0 )
-            break;
+        // if( waitKey( 100 ) >= 0 ) // 注释掉
+        //     break;
     }
 
     img = Scalar::all(0);
     paint_voronoi( img, subdiv );
-    imshow( win, img );
+    // imshow( win, img ); // 注释掉
 
-    waitKey(0);
+    // waitKey(0); // 注释掉
+
+    // 保存处理后的图像
+    imwrite("output.png", img);
 
     return 0;
 }
+
diff --git a/samples/cpp/demhist.cpp b/samples/cpp/demhist.cpp
index 4a564af402..15b4ead4d0 100644
--- a/samples/cpp/demhist.cpp
+++ b/samples/cpp/demhist.cpp
@@ -1,7 +1,7 @@
 #include "opencv2/core/utility.hpp"
 #include "opencv2/imgproc.hpp"
 #include "opencv2/imgcodecs.hpp"
-#include "opencv2/highgui.hpp"
+#include "opencv2/highgui.hpp" // 无头环境不需要
 
 #include <iostream>
 
@@ -40,7 +40,7 @@ static void updateBrightnessContrast( int /*arg*/, void* )
 
     Mat dst, hist;
     image.convertTo(dst, CV_8U, a, b);
-    imshow("image", dst);
+    // imshow("image", dst); // 注释掉显示图像的代码
 
     calcHist(&dst, 1, 0, Mat(), hist, 1, &histSize, 0);
     Mat histImage = Mat::ones(200, 320, CV_8U)*255;
@@ -54,7 +54,14 @@ static void updateBrightnessContrast( int /*arg*/, void* )
         rectangle( histImage, Point(i*binW, histImage.rows),
                    Point((i+1)*binW, histImage.rows - cvRound(hist.at<float>(i))),
                    Scalar::all(0), -1, 8, 0 );
-    imshow("histogram", histImage);
+    // imshow("histogram", histImage); // 注释掉显示直方图的代码
+
+    // 保存处理后的图像
+    imwrite("result.png", dst);
+    imwrite("histogram.png", histImage);
+
+    cout << "Result image saved as: result.png" << endl;
+    cout << "Histogram image saved as: histogram.png" << endl;
 }
 
 const char* keys =
@@ -81,14 +88,15 @@ int main( int argc, const char** argv )
         return -1;
     }
 
-    namedWindow("image", 0);
-    namedWindow("histogram", 0);
-
-    createTrackbar("brightness", "image", &_brightness, 200, updateBrightnessContrast);
-    createTrackbar("contrast", "image", &_contrast, 200, updateBrightnessContrast);
+    // 无头环境不需要创建窗口和轨迹条
+    // namedWindow("image", 0);
+    // namedWindow("histogram", 0);
+    // createTrackbar("brightness", "image", &_brightness, 200, updateBrightnessContrast);
+    // createTrackbar("contrast", "image", &_contrast, 200, updateBrightnessContrast);
 
     updateBrightnessContrast(0, 0);
-    waitKey();
+    // waitKey(); // 注释掉等待按键的代码
 
     return 0;
 }
+
diff --git a/samples/cpp/detect_blob.cpp b/samples/cpp/detect_blob.cpp
index 2c871db42e..8b178141cd 100644
--- a/samples/cpp/detect_blob.cpp
+++ b/samples/cpp/detect_blob.cpp
@@ -9,17 +9,15 @@
 using namespace std;
 using namespace cv;
 
-
 static void help(char** argv)
 {
     cout << "\n This program demonstrates how to use BLOB to detect and filter region \n"
          << "Usage: \n"
          << argv[0]
-         << " <image1(detect_blob.png as default)>\n"
+         << " <image1(lena.jpg as default)>\n"
          << "Press a key when image window is active to change descriptor";
 }
 
-
 static String Legende(SimpleBlobDetector::Params &pAct)
 {
     String s = "";
@@ -67,12 +65,10 @@ static String Legende(SimpleBlobDetector::Params &pAct)
     return s;
 }
 
-
-
 int main(int argc, char *argv[])
 {
     String fileName;
-    cv::CommandLineParser parser(argc, argv, "{@input |detect_blob.png| }{h help | | }");
+    cv::CommandLineParser parser(argc, argv, "{@input |lena.jpg| }{h help | | }");
     if (parser.has("h"))
     {
         help(argv);
@@ -104,9 +100,10 @@ int main(int argc, char *argv[])
     pDefaultBLOB.filterByInertia = false;
     pDefaultBLOB.minInertiaRatio = 0.1f;
     pDefaultBLOB.maxInertiaRatio = (float)1e37;
-    pDefaultBLOB.filterByConvexity = false;
-    pDefaultBLOB.minConvexity = 0.95f;
-    pDefaultBLOB.maxConvexity = (float)1e37;
+    pDefaultBLOB.filterByConvexity = true;
+    pDefaultBLOB.minConvexity = 0.9f;  // 确保 minConvexity > 0
+    pDefaultBLOB.maxConvexity = 1.0f;  // 确保 maxConvexity >= minConvexity
+
     // Descriptor array for BLOB
     vector<String> typeDesc;
     // Param array for BLOB
@@ -123,7 +120,6 @@ int main(int argc, char *argv[])
     }
     help(argv);
 
-
     // These descriptors are going to be detecting and computing BLOBS with 6 different params
     // Param for first BLOB detector we want all
     typeDesc.push_back("BLOB");    // see http://docs.opencv.org/4.x/d0/d7a/classcv_1_1SimpleBlobDetector.html
@@ -145,13 +141,13 @@ int main(int argc, char *argv[])
     typeDesc.push_back("BLOB");
     pBLOB.push_back(pDefaultBLOB);
     pBLOB.back().filterByInertia = true;
-    pBLOB.back().minInertiaRatio = 0;
+    pBLOB.back().minInertiaRatio = 0.1f;
     pBLOB.back().maxInertiaRatio = (float)0.2;
     // Param for fifth BLOB detector we want ratio inertia
     typeDesc.push_back("BLOB");
     pBLOB.push_back(pDefaultBLOB);
     pBLOB.back().filterByConvexity = true;
-    pBLOB.back().minConvexity = 0.;
+    pBLOB.back().minConvexity = 0.5;
     pBLOB.back().maxConvexity = (float)0.9;
     // Param for six BLOB detector we want blob with gravity center color equal to 0
     typeDesc.push_back("BLOB");
@@ -190,10 +186,17 @@ int main(int argc, char *argv[])
                 for (vector<KeyPoint>::iterator k = keyImg.begin(); k != keyImg.end(); ++k, ++i)
                     circle(result, k->pt, (int)k->size, palette[i % 65536]);
             }
-            namedWindow(*itDesc + label, WINDOW_AUTOSIZE);
-            imshow(*itDesc + label, result);
-            imshow("Original", img);
-            waitKey();
+
+            // 注释掉图像显示的部分
+            // namedWindow(*itDesc + label, WINDOW_AUTOSIZE);
+            // imshow(*itDesc + label, result);
+            // imshow("Original", img);
+            // waitKey();
+
+            // 保存处理后的图像
+            string result_filename = *itDesc + label + "_result.png";
+            imwrite(result_filename, result);
+            cout << "Result image saved as: " << result_filename << endl;
         }
         catch (const Exception& e)
         {
@@ -203,3 +206,4 @@ int main(int argc, char *argv[])
     }
     return 0;
 }
+
diff --git a/samples/cpp/detect_mser.cpp b/samples/cpp/detect_mser.cpp
index d289e22923..da834cb17c 100644
--- a/samples/cpp/detect_mser.cpp
+++ b/samples/cpp/detect_mser.cpp
@@ -10,30 +10,10 @@
 #include <iomanip>
 #include <limits>
 #include <stdint.h>
-#ifdef HAVE_OPENGL
-#ifdef _WIN32
-#define WIN32_LEAN_AND_MEAN 1
-#define NOMINMAX 1
-#include <windows.h>
-#endif
-#if defined(_WIN64)
-#include <windows.h>
-#endif
-
-#if defined(__APPLE__)
-#include <OpenGL/gl.h>
-#include <OpenGL/glu.h>
-#else
-#include <GL/gl.h>
-#include <GL/glu.h>
-#endif
-#endif
-
 
 using namespace std;
 using namespace cv;
 
-
 static void help(char** argv)
 {
     cout << "\nThis program demonstrates how to use MSER to detect extremal regions\n"
@@ -91,255 +71,6 @@ static String Legende(const MSERParams &pAct)
     return ss.str();
 }
 
-
-#ifdef HAVE_OPENGL
-const int win_width = 800;
-const int win_height = 640;
-#endif
-bool    rotateEnable=true;
-bool    keyPressed=false;
-
-Vec4f   rotAxis(1,0,1,0);
-Vec3f  zoom(1,0,0);
-
-float obsX = 0.f;
-float obsY = 0.f;
-float obsZ = -10.f;
-float tx = 0.f;
-float ty = 0.f;
-
-float thetaObs = -1.570f;
-float phiObs = 1.570f;
-float rObs = 10.f;
-
-int prevX = -1;
-int prevY = -1;
-int prevTheta = -1000;
-int prevPhi = -1000;
-
-#ifdef HAVE_OPENGL
-struct DrawData
-{
-    ogl::Arrays arr;
-    ogl::Texture2D tex;
-    ogl::Buffer indices;
-};
-
-
-static void draw(void* userdata)
-{
-    DrawData* data = static_cast<DrawData*>(userdata);
-    glMatrixMode(GL_MODELVIEW);
-    glLoadIdentity();
-    gluLookAt(obsX, obsY, obsZ, 0, 0, .0, .0, 10.0, 0.0);
-    glTranslatef(tx,ty,0);
-    keyPressed = false;
-    ogl::render(data->arr, data->indices, ogl::TRIANGLES);
-}
-
-static void onMouse(int event, int x, int y, int flags, void*)
-{
-    if (event == EVENT_RBUTTONDOWN)
-    {
-        prevX = x;
-        prevY = y;
-    }
-    if (event == EVENT_RBUTTONUP)
-    {
-        prevX = -1;
-        prevY = -1;
-    }
-    if (prevX != -1)
-    {
-        tx += float((x - prevX) / 100.0);
-        ty -= float((y - prevY) / 100.0);
-        prevX = x;
-        prevY = y;
-    }
-    if (event == EVENT_LBUTTONDOWN)
-    {
-        prevTheta = x;
-        prevPhi = y;
-    }
-    if (event == EVENT_LBUTTONUP)
-    {
-        prevTheta = -1000;
-        prevPhi = -1000;
-    }
-    if (prevTheta != -1000)
-    {
-        if (x - prevTheta<0)
-        {
-            thetaObs += 0.02f;
-        }
-        else if (x - prevTheta>0)
-        {
-            thetaObs -= 0.02f;
-        }
-        if (y - prevPhi<0)
-        {
-            phiObs -= 0.02f;
-        }
-        else if (y - prevPhi>0)
-        {
-            phiObs += 0.02f;
-        }
-        prevTheta = x;
-        prevPhi = y;
-    }
-    if (event==EVENT_MOUSEWHEEL)
-    {
-        if (getMouseWheelDelta(flags)>0)
-            rObs += 0.1f;
-        else
-            rObs -= 0.1f;
-    }
-    float pi = static_cast<float>(CV_PI);
-    if (thetaObs>pi)
-    {
-        thetaObs = -2 * pi + thetaObs;
-    }
-    if (thetaObs<-pi)
-    {
-        thetaObs = 2 * pi + thetaObs;
-    }
-    if (phiObs>pi / 2)
-    {
-        phiObs = pi / 2 - 0.0001f;
-    }
-    if (phiObs<-pi / 2)
-    {
-        phiObs = -pi / 2 + 0.00001f;
-    }
-    if (rObs<0)
-    {
-        rObs = 0;
-    }
-
-}
-#endif
-
-#ifdef HAVE_OPENGL
-static void DrawOpenGLMSER(Mat img, Mat result)
-{
-    Mat imgGray;
-    if (img.type() != CV_8UC1)
-        cvtColor(img, imgGray, COLOR_BGR2GRAY);
-    else
-        imgGray = img;
-
-    namedWindow("OpenGL", WINDOW_OPENGL);
-    setMouseCallback("OpenGL", onMouse, NULL);
-
-    Mat_<Vec3f> vertex(1, img.cols*img.rows);
-    Mat_<Vec2f> texCoords(1, img.cols*img.rows);
-    for (int i = 0, nbPix = 0; i<img.rows; i++)
-    {
-        for (int j = 0; j<img.cols; j++, nbPix++)
-        {
-            float x = (j) / (float)img.cols;
-            float y = (i) / (float)img.rows;
-            vertex.at< Vec3f >(0, nbPix) = Vec3f(float(2 * (x - 0.5)), float(2 * (0.5 - y)), float(imgGray.at<uchar>(i, j) / 512.0));
-            texCoords.at< Vec2f>(0, nbPix) = Vec2f(x, y);
-        }
-    }
-
-    Mat_<int> indices(1, (img.rows - 1)*(6 * img.cols));
-    for (int i = 1, nbPix = 0; i<img.rows; i++)
-    {
-        for (int j = 1; j<img.cols; j++)
-        {
-            int c = i*img.cols + j;
-            indices.at<int>(0, nbPix++) = c;
-            indices.at<int>(0, nbPix++) = c - 1;
-            indices.at<int>(0, nbPix++) = c - img.cols - 1;
-            indices.at<int>(0, nbPix++) = c - img.cols - 1;
-            indices.at<int>(0, nbPix++) = c - img.cols;
-            indices.at<int>(0, nbPix++) = c;
-        }
-    }
-
-    DrawData *data = new DrawData;
-
-    data->arr.setVertexArray(vertex);
-    data->arr.setTexCoordArray(texCoords);
-    data->indices.copyFrom(indices);
-    data->tex.copyFrom(result);
-
-    glMatrixMode(GL_PROJECTION);
-    glLoadIdentity();
-    gluPerspective(45.0, (double)win_width / win_height, 0.0, 1000.0);
-
-    glMatrixMode(GL_MODELVIEW);
-    glLoadIdentity();
-
-    glEnable(GL_TEXTURE_2D);
-    data->tex.bind();
-
-    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR);
-    glTexEnvi(GL_TEXTURE_ENV, GL_TEXTURE_ENV_MODE, GL_REPLACE);
-
-    glDisable(GL_CULL_FACE);
-    setOpenGlDrawCallback("OpenGL", draw, data);
-
-    for (;;)
-    {
-        updateWindow("OpenGL");
-        char key = (char)waitKey(40);
-        if (key == 27)
-            break;
-        if (key == 0x20)
-            rotateEnable = !rotateEnable;
-        float pi = static_cast<float>(CV_PI);
-
-        switch (key) {
-            case '5':
-                obsX = 0, obsY = 0, obsZ = -10;
-                thetaObs = -pi/2, phiObs = pi/2, rObs = 10;
-                tx=0; ty=0;
-                break;
-            case '4':
-                thetaObs += 0.1f;
-                break;
-            case '6':
-                thetaObs -= 0.1f;
-                break;
-            case '2':
-                phiObs -= 0.1f;
-                break;
-            case '8':
-                phiObs += 0.1f;
-                break;
-            case '+':
-                rObs -= 0.1f;
-                break;
-            case '-':
-                rObs += 0.1f;
-                break;
-        }
-
-        if (thetaObs>pi)
-        {
-            thetaObs = -2 * pi + thetaObs;
-        }
-        if (thetaObs<-pi)
-            thetaObs = 2 * pi + thetaObs;
-        if (phiObs>pi / 2)
-            phiObs = pi / 2 - 0.0001f;
-        if (phiObs<-pi / 2)
-            phiObs = -pi / 2 + 0.00001f;
-        if (rObs<0)
-            rObs = 0;
-        obsX = rObs*cos(thetaObs)*cos(phiObs);
-        obsY = rObs*sin(thetaObs)*cos(phiObs);
-        obsZ = rObs*sin(phiObs);
-    }
-    setOpenGlDrawCallback("OpenGL", 0, 0);
-    destroyAllWindows();
-}
-#endif
-
-// Add nested rectangles of different widths and colors to an image
 static void addNestedRectangles(Mat &img, Point p0, int* width, int *color, int n) {
     for (int i = 0; i<n; i++)
     {
@@ -349,7 +80,6 @@ static void addNestedRectangles(Mat &img, Point p0, int* width, int *color, int
     }
 }
 
-// Add nested circles of different widths and colors to an image
 static void addNestedCircles(Mat &img, Point p0, int *width, int *color, int n) {
     for (int i = 0; i<n; i++)
     {
@@ -519,19 +249,22 @@ int main(int argc, char *argv[])
             }
 
             const string winName = *itDesc + label;
-            namedWindow(winName, WINDOW_AUTOSIZE);
-            imshow(winName, result);
-            imshow("Original", img);
+            // namedWindow(winName, WINDOW_AUTOSIZE); // 注释掉图像显示部分
+            // imshow(winName, result); // 注释掉图像显示部分
+            // imshow("Original", img); // 注释掉图像显示部分
+
+            // 保存处理后的图像
+            string result_filename = *itDesc + label + "_result.png";
+            imwrite(result_filename, result);
+            cout << "Result image saved as: " << result_filename << endl;
         }
         catch (const Exception& e)
         {
             cout << "Feature: " << *itDesc << "\n";
             cout << e.msg << endl;
         }
-#ifdef HAVE_OPENGL
-        DrawOpenGLMSER(img, result);
-#endif
-        waitKey();
+        // waitKey(); // 注释掉等待按键部分
     }
     return 0;
 }
+
diff --git a/samples/cpp/dft.cpp b/samples/cpp/dft.cpp
index f57ae3f8ae..bbc5daa348 100644
--- a/samples/cpp/dft.cpp
+++ b/samples/cpp/dft.cpp
@@ -2,7 +2,7 @@
 #include "opencv2/core/utility.hpp"
 #include "opencv2/imgproc.hpp"
 #include "opencv2/imgcodecs.hpp"
-#include "opencv2/highgui.hpp"
+// #include "opencv2/highgui.hpp" // 无头环境不需要
 
 #include <stdio.h>
 
@@ -11,9 +11,9 @@ using namespace std;
 
 static void help(const char ** argv)
 {
-    printf("\nThis program demonstrated the use of the discrete Fourier transform (dft)\n"
-           "The dft of an image is taken and it's power spectrum is displayed.\n"
-           "Usage:\n %s [image_name -- default lena.jpg]\n",argv[0]);
+    printf("\nThis program demonstrates the use of the discrete Fourier transform (dft)\n"
+           "The dft of an image is taken and its power spectrum is displayed.\n"
+           "Usage:\n %s [image_name -- default lena.jpg]\n", argv[0]);
 }
 
 const char* keys =
@@ -32,14 +32,14 @@ int main(int argc, const char ** argv)
     }
     string filename = parser.get<string>(0);
     Mat img = imread(samples::findFile(filename), IMREAD_GRAYSCALE);
-    if( img.empty() )
+    if (img.empty())
     {
         help(argv);
         printf("Cannot read image file: %s\n", filename.c_str());
         return -1;
     }
-    int M = getOptimalDFTSize( img.rows );
-    int N = getOptimalDFTSize( img.cols );
+    int M = getOptimalDFTSize(img.rows);
+    int N = getOptimalDFTSize(img.cols);
     Mat padded;
     copyMakeBorder(img, padded, 0, M - img.rows, 0, N - img.cols, BORDER_CONSTANT, Scalar::all(0));
 
@@ -59,8 +59,8 @@ int main(int argc, const char ** argv)
     // crop the spectrum, if it has an odd number of rows or columns
     mag = mag(Rect(0, 0, mag.cols & -2, mag.rows & -2));
 
-    int cx = mag.cols/2;
-    int cy = mag.rows/2;
+    int cx = mag.cols / 2;
+    int cy = mag.rows / 2;
 
     // rearrange the quadrants of Fourier image
     // so that the origin is at the image center
@@ -80,7 +80,12 @@ int main(int argc, const char ** argv)
 
     normalize(mag, mag, 0, 1, NORM_MINMAX);
 
-    imshow("spectrum magnitude", mag);
-    waitKey();
+    // imshow("spectrum magnitude", mag); // 注释掉图像显示部分
+    string outputFileName = "spectrum_magnitude.png";
+    imwrite(outputFileName, mag); // 保存处理后的图像
+    printf("Result image saved as: %s\n", outputFileName.c_str());
+
+    // waitKey(); // 注释掉等待按键部分
     return 0;
 }
+
diff --git a/samples/cpp/digits_lenet.cpp b/samples/cpp/digits_lenet.cpp
index df8935de6c..1cfc0cba07 100644
--- a/samples/cpp/digits_lenet.cpp
+++ b/samples/cpp/digits_lenet.cpp
@@ -1,35 +1,24 @@
-//  This example provides a digital recognition based on LeNet-5 and connected component analysis.
-//  It makes it possible for OpenCV beginner to run dnn models in real time using only CPU.
-//  It can read pictures from the camera in real time to make predictions, and display the recognized digits as overlays on top of the original digits.
-//
-//  In order to achieve a better display effect, please write the number on white paper and occupy the entire camera.
-//
-//  You can follow the following guide to train LeNet-5 by yourself using the MNIST dataset.
-//  https://github.com/intel/caffe/blob/a3d5b022fe026e9092fc7abc7654b1162ab9940d/examples/mnist/readme.md
-//
-//  You can also download already trained model directly.
-//  https://github.com/zihaomu/opencv_digit_text_recognition_demo/tree/master/src
-
-
 #include <opencv2/imgproc.hpp>
-#include <opencv2/highgui.hpp>
 #include <opencv2/dnn.hpp>
+#include <opencv2/highgui.hpp>
 
 #include <iostream>
 #include <vector>
+#include <string>
+#include <cstdlib>
 
 using namespace cv;
 using namespace cv::dnn;
 
 const char *keys =
-    "{ help     h  | | Print help message. }"
-    "{ input    i  | | Path to input image or video file. Skip this argument to capture frames from a camera.}"
-    "{ device      |  0  | camera device number. }"
-    "{ modelBin    |     | Path to a binary .caffemodel file contains trained network.}"
-    "{ modelTxt    |     | Path to a .prototxt file contains the model definition of trained network.}"
-    "{ width       | 640 | Set the width of the camera }"
-    "{ height      | 480 | Set the height of the camera }"
-    "{ thr         | 0.7 | Confidence threshold. }";
+"{ help h | | Print help message. }"
+"{ input i | | Path to input image or video file. Skip this argument to capture frames from a camera.}"
+"{ device | 0 | camera device number. }"
+"{ modelBin | | Path to a binary .caffemodel file contains trained network.}"
+"{ modelTxt | | Path to a .prototxt file contains the model definition of trained network.}"
+"{ width | 640 | Set the width of the camera }"
+"{ height | 480 | Set the height of the camera }"
+"{ thr | 0.7 | Confidence threshold. }";
 
 // Find best class for the blob (i.e. class with maximal probability)
 static void getMaxClass(const Mat &probBlob, int &classId, double &classProb);
@@ -61,18 +50,12 @@ int main(int argc, char **argv)
     catch (cv::Exception &ee)
     {
         std::cerr << "Exception: " << ee.what() << std::endl;
-        std::cout << "Can't load the network by using the flowing files:" << std::endl;
+        std::cout << "Can't load the network by using the following files:" << std::endl;
         std::cout << "modelTxt: " << modelTxt << std::endl;
         std::cout << "modelBin: " << modelBin << std::endl;
         return 1;
     }
 
-    const std::string resultWinName = "Please write the number on white paper and occupy the entire camera.";
-    const std::string preWinName = "Preprocessing";
-
-    namedWindow(preWinName, WINDOW_AUTOSIZE);
-    namedWindow(resultWinName, WINDOW_AUTOSIZE);
-
     Mat labels, stats, centroids;
     Point position;
 
@@ -96,12 +79,15 @@ int main(int argc, char **argv)
 
     TickMeter tm;
 
-    while (waitKey(1) < 0)
+    std::string sampleName = "digits_lenet";
+    std::string outputDir = sampleName;
+    system(("mkdir -p " + outputDir).c_str());
+
+    while (true)
     {
         cap >> rawImage;
         if (rawImage.empty())
         {
-            waitKey();
             break;
         }
 
@@ -153,9 +139,12 @@ int main(int argc, char **argv)
         std::string fpsString = format("Inference FPS: %.2f.", fps);
         putText(rawImage, fpsString, Point(5, 20), FONT_HERSHEY_SIMPLEX, 0.6, Scalar(128, 255, 128));
 
-        imshow(resultWinName, rawImage);
-        imshow(preWinName, image);
+        // Save processed image
+        std::string outputPath = outputDir + "/processed_image.jpg";
+        imwrite(outputPath, rawImage);
+        std::cout << "Processed image saved at: " << outputPath << std::endl;
 
+        break; // Exit after processing one frame
     }
 
     return 0;
@@ -180,3 +169,4 @@ void predictor(Net net, const Mat &roi, int &classId, double &probability)
     pred = net.forward();
     getMaxClass(pred, classId, probability);
 }
+
diff --git a/samples/cpp/digits_svm.cpp b/samples/cpp/digits_svm.cpp
index c55b320da5..a348abfb26 100644
--- a/samples/cpp/digits_svm.cpp
+++ b/samples/cpp/digits_svm.cpp
@@ -331,7 +331,7 @@ int main(int /* argc */, char* argv[])
 
     vector<Mat> digits_test(digits2.begin() + train_n, digits2.end());
     mosaic(25, digits_test, test_set);
-    imshow("test set", test_set);
+    // imshow("test set", test_set); // 注释掉图像显示部分
 
     Mat samples_train = samples(Rect(0, 0, samples.cols, train_n));
     Mat samples_test = samples(Rect(0, train_n, samples.cols, samples.rows - train_n));
@@ -350,7 +350,11 @@ int main(int /* argc */, char* argv[])
     // predict digits with KNearest
     k_nearest->findNearest(samples_test, 4, predictions);
     evaluate_model(predictions, digits_test, labels_test, vis);
-    imshow("KNearest test", vis);
+    // imshow("KNearest test", vis); // 注释掉图像显示部分
+    std::string knearest_result_filename = "KNearest_test.png";
+    imwrite(knearest_result_filename, vis); // 保存处理后的图像
+    printf("KNearest test result image saved as: %s\n", knearest_result_filename.c_str());
+
     k_nearest.release();
 
     cout << "training SVM..." << endl;
@@ -364,12 +368,17 @@ int main(int /* argc */, char* argv[])
     // predict digits with SVM
     svm->predict(samples_test, predictions);
     evaluate_model(predictions, digits_test, labels_test, vis);
-    imshow("SVM test", vis);
+    // imshow("SVM test", vis); // 注释掉图像显示部分
+    std::string svm_result_filename = "SVM_test.png";
+    imwrite(svm_result_filename, vis); // 保存处理后的图像
+    printf("SVM test result image saved as: %s\n", svm_result_filename.c_str());
+
     cout << "Saving SVM as \"digits_svm.yml\"..." << endl;
     svm->save("digits_svm.yml");
     svm.release();
 
-    waitKey();
+    // waitKey(); // 注释掉等待按键部分
 
     return 0;
 }
+
diff --git a/samples/cpp/dis_opticalflow.cpp b/samples/cpp/dis_opticalflow.cpp
index 3c1c22cfbd..323dad5f4e 100644
--- a/samples/cpp/dis_opticalflow.cpp
+++ b/samples/cpp/dis_opticalflow.cpp
@@ -1,4 +1,3 @@
-
 #include "opencv2/core/utility.hpp"
 #include "opencv2/highgui.hpp"
 #include "opencv2/imgproc.hpp"
@@ -16,7 +15,7 @@ int main(int argc, char **argv)
     VideoCapture cap;
     cap.open(filename);
 
-    if(!cap.isOpened())
+    if (!cap.isOpened())
     {
         printf("ERROR: Cannot open file %s\n", filename.c_str());
         parser.printMessage();
@@ -27,11 +26,10 @@ int main(int argc, char **argv)
     Mat flow, flow_uv[2];
     Mat mag, ang;
     Mat hsv_split[3], hsv;
-    char ret;
 
     Ptr<DenseOpticalFlow> algorithm = DISOpticalFlow::create(DISOpticalFlow::PRESET_MEDIUM);
 
-    while(true)
+    while (true)
     {
         cap >> frame;
         if (frame.empty())
@@ -51,14 +49,19 @@ int main(int argc, char **argv)
             hsv_split[2] = Mat::ones(ang.size(), ang.type());
             merge(hsv_split, 3, hsv);
             cvtColor(hsv, rgb, COLOR_HSV2BGR);
-            imshow("flow", rgb);
-            imshow("orig", frame);
+
+            // 注释掉图像显示部分
+            // imshow("flow", rgb);
+            // imshow("orig", frame);
         }
 
-        if ((ret = (char)waitKey(20)) > 0)
-            break;
+        // 注释掉等待按键部分
+        // if ((ret = (char)waitKey(20)) > 0)
+        //     break;
         std::swap(prevgray, gray);
     }
 
+    printf("Processing completed.\n");
     return 0;
 }
+
diff --git a/samples/cpp/distrans.cpp b/samples/cpp/distrans.cpp
index 9304ec6d9d..8338c0c64d 100644
--- a/samples/cpp/distrans.cpp
+++ b/samples/cpp/distrans.cpp
@@ -1,8 +1,6 @@
 #include <opencv2/core/utility.hpp>
 #include "opencv2/imgproc.hpp"
 #include "opencv2/imgcodecs.hpp"
-#include "opencv2/highgui.hpp"
-
 #include <stdio.h>
 
 using namespace std;
@@ -17,7 +15,7 @@ int distType0 = DIST_L1;
 Mat gray;
 
 // threshold trackbar callback
-static void onTrackbar( int, void* )
+static void processImage()
 {
     static const Scalar colors[] =
     {
@@ -37,12 +35,12 @@ static void onTrackbar( int, void* )
 
     Mat edge = gray >= edgeThresh, dist, labels, dist8u;
 
-    if( voronoiType < 0 )
-        distanceTransform( edge, dist, distType, maskSize );
+    if (voronoiType < 0)
+        distanceTransform(edge, dist, distType, maskSize);
     else
-        distanceTransform( edge, dist, labels, distType, maskSize, voronoiType );
+        distanceTransform(edge, dist, labels, distType, maskSize, voronoiType);
 
-    if( voronoiType < 0 )
+    if (voronoiType < 0)
     {
         // begin "painting" the distance transform result
         dist *= 5000;
@@ -65,44 +63,47 @@ static void onTrackbar( int, void* )
     else
     {
         dist8u.create(labels.size(), CV_8UC3);
-        for( int i = 0; i < labels.rows; i++ )
+        for (int i = 0; i < labels.rows; i++)
         {
             const int* ll = (const int*)labels.ptr(i);
             const float* dd = (const float*)dist.ptr(i);
             uchar* d = (uchar*)dist8u.ptr(i);
-            for( int j = 0; j < labels.cols; j++ )
+            for (int j = 0; j < labels.cols; j++)
             {
-                int idx = ll[j] == 0 || dd[j] == 0 ? 0 : (ll[j]-1)%8 + 1;
-                float scale = 1.f/(1 + dd[j]*dd[j]*0.0004f);
-                int b = cvRound(colors[idx][0]*scale);
-                int g = cvRound(colors[idx][1]*scale);
-                int r = cvRound(colors[idx][2]*scale);
-                d[j*3] = (uchar)b;
-                d[j*3+1] = (uchar)g;
-                d[j*3+2] = (uchar)r;
+                int idx = ll[j] == 0 || dd[j] == 0 ? 0 : (ll[j] - 1) % 8 + 1;
+                float scale = 1.f / (1 + dd[j] * dd[j] * 0.0004f);
+                int b = cvRound(colors[idx][0] * scale);
+                int g = cvRound(colors[idx][1] * scale);
+                int r = cvRound(colors[idx][2] * scale);
+                d[j * 3] = (uchar)b;
+                d[j * 3 + 1] = (uchar)g;
+                d[j * 3 + 2] = (uchar)r;
             }
         }
     }
 
-    imshow("Distance Map", dist8u );
+    // 保存处理后的图像
+    std::string result_filename = "distance_map.png";
+    imwrite(result_filename, dist8u);
+    printf("Result image saved as: %s\n", result_filename.c_str());
 }
 
 static void help(const char** argv)
 {
     printf("\nProgram to demonstrate the use of the distance transform function between edge images.\n"
-            "Usage:\n"
-            "%s [image_name -- default image is stuff.jpg]\n"
-            "\nHot keys: \n"
-            "\tESC - quit the program\n"
-            "\tC - use C/Inf metric\n"
-            "\tL1 - use L1 metric\n"
-            "\tL2 - use L2 metric\n"
-            "\t3 - use 3x3 mask\n"
-            "\t5 - use 5x5 mask\n"
-            "\t0 - use precise distance transform\n"
-            "\tv - switch to Voronoi diagram mode\n"
-            "\tp - switch to pixel-based Voronoi diagram mode\n"
-            "\tSPACE - loop through all the modes\n\n", argv[0]);
+           "Usage:\n"
+           "%s [image_name -- default image is stuff.jpg]\n"
+           "\nHot keys: \n"
+           "\tESC - quit the program\n"
+           "\tC - use C/Inf metric\n"
+           "\tL1 - use L1 metric\n"
+           "\tL2 - use L2 metric\n"
+           "\t3 - use 3x3 mask\n"
+           "\t5 - use 5x5 mask\n"
+           "\t0 - use precise distance transform\n"
+           "\tv - switch to Voronoi diagram mode\n"
+           "\tp - switch to pixel-based Voronoi diagram mode\n"
+           "\tSPACE - loop through all the modes\n\n", argv[0]);
 }
 
 const char* keys =
@@ -110,7 +111,7 @@ const char* keys =
     "{help h||}{@image |stuff.jpg|input image file}"
 };
 
-int main( int argc, const char** argv )
+int main(int argc, const char** argv)
 {
     CommandLineParser parser(argc, argv, keys);
     help(argv);
@@ -118,68 +119,16 @@ int main( int argc, const char** argv )
         return 0;
     string filename = parser.get<string>(0);
     gray = imread(samples::findFile(filename), 0);
-    if(gray.empty())
+    if (gray.empty())
     {
         printf("Cannot read image file: %s\n", filename.c_str());
         help(argv);
         return -1;
     }
 
-    namedWindow("Distance Map", 1);
-    createTrackbar("Brightness Threshold", "Distance Map", &edgeThresh, 255, onTrackbar, 0);
-
-    for(;;)
-    {
-        // Call to update the view
-        onTrackbar(0, 0);
-
-        char c = (char)waitKey(0);
-
-        if( c == 27 )
-            break;
-
-        if( c == 'c' || c == 'C' || c == '1' || c == '2' ||
-            c == '3' || c == '5' || c == '0' )
-            voronoiType = -1;
-
-        if( c == 'c' || c == 'C' )
-            distType0 = DIST_C;
-        else if( c == '1' )
-            distType0 = DIST_L1;
-        else if( c == '2' )
-            distType0 = DIST_L2;
-        else if( c == '3' )
-            maskSize0 = DIST_MASK_3;
-        else if( c == '5' )
-            maskSize0 = DIST_MASK_5;
-        else if( c == '0' )
-            maskSize0 = DIST_MASK_PRECISE;
-        else if( c == 'v' )
-            voronoiType = 0;
-        else if( c == 'p' )
-            voronoiType = 1;
-        else if( c == ' ' )
-        {
-            if( voronoiType == 0 )
-                voronoiType = 1;
-            else if( voronoiType == 1 )
-            {
-                voronoiType = -1;
-                maskSize0 = DIST_MASK_3;
-                distType0 = DIST_C;
-            }
-            else if( distType0 == DIST_C )
-                distType0 = DIST_L1;
-            else if( distType0 == DIST_L1 )
-                distType0 = DIST_L2;
-            else if( maskSize0 == DIST_MASK_3 )
-                maskSize0 = DIST_MASK_5;
-            else if( maskSize0 == DIST_MASK_5 )
-                maskSize0 = DIST_MASK_PRECISE;
-            else if( maskSize0 == DIST_MASK_PRECISE )
-                voronoiType = 0;
-        }
-    }
+    // 更新视图
+    processImage();
 
     return 0;
 }
+
diff --git a/samples/cpp/drawing.cpp b/samples/cpp/drawing.cpp
index eba297ee5e..784e185103 100644
--- a/samples/cpp/drawing.cpp
+++ b/samples/cpp/drawing.cpp
@@ -1,6 +1,6 @@
 #include "opencv2/core.hpp"
 #include "opencv2/imgproc.hpp"
-#include "opencv2/highgui.hpp"
+#include "opencv2/imgcodecs.hpp" // 添加此行以包含 imwrite 的声明
 #include <stdio.h>
 
 using namespace cv;
@@ -20,17 +20,13 @@ static Scalar randomColor(RNG& rng)
 int main(int /* argc */, char** argv)
 {
     help(argv);
-    char wndname[] = "Drawing Demo";
     const int NUMBER = 100;
-    const int DELAY = 5;
     int lineType = LINE_AA; // change it to LINE_8 to see non-antialiased graphics
     int i, width = 1000, height = 700;
     int x1 = -width/2, x2 = width*3/2, y1 = -height/2, y2 = height*3/2;
     RNG rng(0xFFFFFFFF);
 
     Mat image = Mat::zeros(height, width, CV_8UC3);
-    imshow(wndname, image);
-    waitKey(DELAY);
 
     for (i = 0; i < NUMBER * 2; i++)
     {
@@ -43,13 +39,9 @@ int main(int /* argc */, char** argv)
         int arrowed = rng.uniform(0, 6);
 
         if( arrowed < 3 )
-            line( image, pt1, pt2, randomColor(rng), rng.uniform(1,10), lineType );
+            line(image, pt1, pt2, randomColor(rng), rng.uniform(1,10), lineType);
         else
             arrowedLine(image, pt1, pt2, randomColor(rng), rng.uniform(1, 10), lineType);
-
-        imshow(wndname, image);
-        if(waitKey(DELAY) >= 0)
-            return 0;
     }
 
     for (i = 0; i < NUMBER * 2; i++)
@@ -66,11 +58,7 @@ int main(int /* argc */, char** argv)
         if (marker > 5)
             rectangle(image, pt1, pt2, randomColor(rng), MAX(thickness, -1), lineType);
         else
-            drawMarker(image, pt1, randomColor(rng), marker, marker_size );
-
-        imshow(wndname, image);
-        if(waitKey(DELAY) >= 0)
-            return 0;
+            drawMarker(image, pt1, randomColor(rng), marker, marker_size);
     }
 
     for (i = 0; i < NUMBER; i++)
@@ -83,12 +71,7 @@ int main(int /* argc */, char** argv)
         axes.height = rng.uniform(0, 200);
         double angle = rng.uniform(0, 180);
 
-        ellipse( image, center, axes, angle, angle - 100, angle + 200,
-                 randomColor(rng), rng.uniform(-1,9), lineType );
-
-        imshow(wndname, image);
-        if(waitKey(DELAY) >= 0)
-            return 0;
+        ellipse(image, center, axes, angle, angle - 100, angle + 200, randomColor(rng), rng.uniform(-1,9), lineType);
     }
 
     for (i = 0; i< NUMBER; i++)
@@ -110,10 +93,6 @@ int main(int /* argc */, char** argv)
         int npt[] = {3, 3};
 
         polylines(image, ppt, npt, 2, true, randomColor(rng), rng.uniform(1,10), lineType);
-
-        imshow(wndname, image);
-        if(waitKey(DELAY) >= 0)
-            return 0;
     }
 
     for (i = 0; i< NUMBER; i++)
@@ -135,10 +114,6 @@ int main(int /* argc */, char** argv)
         int npt[] = {3, 3};
 
         fillPoly(image, ppt, npt, 2, randomColor(rng), lineType);
-
-        imshow(wndname, image);
-        if(waitKey(DELAY) >= 0)
-            return 0;
     }
 
     for (i = 0; i < NUMBER; i++)
@@ -147,12 +122,7 @@ int main(int /* argc */, char** argv)
         center.x = rng.uniform(x1, x2);
         center.y = rng.uniform(y1, y2);
 
-        circle(image, center, rng.uniform(0, 300), randomColor(rng),
-               rng.uniform(-1, 9), lineType);
-
-        imshow(wndname, image);
-        if(waitKey(DELAY) >= 0)
-            return 0;
+        circle(image, center, rng.uniform(0, 300), randomColor(rng), rng.uniform(-1, 9), lineType);
     }
 
     for (i = 1; i < NUMBER; i++)
@@ -161,29 +131,24 @@ int main(int /* argc */, char** argv)
         org.x = rng.uniform(x1, x2);
         org.y = rng.uniform(y1, y2);
 
-        putText(image, "Testing text rendering", org, rng.uniform(0,8),
-                rng.uniform(0,100)*0.05+0.1, randomColor(rng), rng.uniform(1, 10), lineType);
-
-        imshow(wndname, image);
-        if(waitKey(DELAY) >= 0)
-            return 0;
+        putText(image, "Testing text rendering", org, rng.uniform(0,8), rng.uniform(0,100)*0.05+0.1, randomColor(rng), rng.uniform(1, 10), lineType);
     }
 
     Size textsize = getTextSize("OpenCV forever!", FONT_HERSHEY_COMPLEX, 3, 5, 0);
     Point org((width - textsize.width)/2, (height - textsize.height)/2);
 
     Mat image2;
-    for( i = 0; i < 255; i += 2 )
+    for(i = 0; i < 255; i += 2)
     {
         image2 = image - Scalar::all(i);
-        putText(image2, "OpenCV forever!", org, FONT_HERSHEY_COMPLEX, 3,
-                Scalar(i, i, 255), 5, lineType);
-
-        imshow(wndname, image2);
-        if(waitKey(DELAY) >= 0)
-            return 0;
+        putText(image2, "OpenCV forever!", org, FONT_HERSHEY_COMPLEX, 3, Scalar(i, i, 255), 5, lineType);
     }
 
-    waitKey();
+    // 保存处理后的图像
+    std::string result_filename = "drawing_demo.png";
+    imwrite(result_filename, image2); // 使用 imwrite 保存图像
+    printf("Result image saved as: %s\n", result_filename.c_str());
+
     return 0;
 }
+
diff --git a/samples/cpp/edge.cpp b/samples/cpp/edge.cpp
index 339baf2aeb..24b82277ae 100644
--- a/samples/cpp/edge.cpp
+++ b/samples/cpp/edge.cpp
@@ -1,42 +1,45 @@
 #include "opencv2/core/utility.hpp"
 #include "opencv2/imgproc.hpp"
 #include "opencv2/imgcodecs.hpp"
-#include "opencv2/highgui.hpp"
-
 #include <stdio.h>
 
 using namespace cv;
 using namespace std;
 
 int edgeThresh = 1;
-int edgeThreshScharr=1;
+int edgeThreshScharr = 1;
 
 Mat image, gray, blurImage, edge1, edge2, cedge;
 
-const char* window_name1 = "Edge map : Canny default (Sobel gradient)";
-const char* window_name2 = "Edge map : Canny with custom gradient (Scharr)";
-
 // define a trackbar callback
-static void onTrackbar(int, void*)
+static void onTrackbar()
 {
     blur(gray, blurImage, Size(3,3));
 
     // Run the edge detector on grayscale
-    Canny(blurImage, edge1, edgeThresh, edgeThresh*3, 3);
+    Canny(blurImage, edge1, edgeThresh, edgeThresh * 3, 3);
     cedge = Scalar::all(0);
 
     image.copyTo(cedge, edge1);
-    imshow(window_name1, cedge);
+    // imshow(window_name1, cedge); // 注释掉图像显示
+
+    string filename1 = "canny_default.png";
+    imwrite(filename1, cedge);
+    printf("Result image saved as: %s\n", filename1.c_str());
 
     /// Canny detector with scharr
-    Mat dx,dy;
-    Scharr(blurImage,dx,CV_16S,1,0);
-    Scharr(blurImage,dy,CV_16S,0,1);
-    Canny( dx,dy, edge2, edgeThreshScharr, edgeThreshScharr*3 );
+    Mat dx, dy;
+    Scharr(blurImage, dx, CV_16S, 1, 0);
+    Scharr(blurImage, dy, CV_16S, 0, 1);
+    Canny(dx, dy, edge2, edgeThreshScharr, edgeThreshScharr * 3);
     /// Using Canny's output as a mask, we display our result
     cedge = Scalar::all(0);
     image.copyTo(cedge, edge2);
-    imshow(window_name2, cedge);
+    // imshow(window_name2, cedge); // 注释掉图像显示
+
+    string filename2 = "canny_scharr.png";
+    imwrite(filename2, cedge);
+    printf("Result image saved as: %s\n", filename2.c_str());
 }
 
 static void help(const char** argv)
@@ -51,14 +54,14 @@ const char* keys =
     "{help h||}{@image |fruits.jpg|input image name}"
 };
 
-int main( int argc, const char** argv )
+int main(int argc, const char** argv)
 {
     help(argv);
     CommandLineParser parser(argc, argv, keys);
     string filename = parser.get<string>(0);
 
     image = imread(samples::findFile(filename), IMREAD_COLOR);
-    if(image.empty())
+    if (image.empty())
     {
         printf("Cannot read image file: %s\n", filename.c_str());
         help(argv);
@@ -68,18 +71,19 @@ int main( int argc, const char** argv )
     cvtColor(image, gray, COLOR_BGR2GRAY);
 
     // Create a window
-    namedWindow(window_name1, 1);
-    namedWindow(window_name2, 1);
+    // namedWindow(window_name1, 1); // 注释掉窗口创建
+    // namedWindow(window_name2, 1); // 注释掉窗口创建
 
     // create a toolbar
-    createTrackbar("Canny threshold default", window_name1, &edgeThresh, 100, onTrackbar);
-    createTrackbar("Canny threshold Scharr", window_name2, &edgeThreshScharr, 400, onTrackbar);
+    // createTrackbar("Canny threshold default", window_name1, &edgeThresh, 100, onTrackbar);
+    // createTrackbar("Canny threshold Scharr", window_name2, &edgeThreshScharr, 400, onTrackbar);
 
     // Show the image
-    onTrackbar(0, 0);
+    onTrackbar();
 
     // Wait for a key stroke; the same function arranges events processing
-    waitKey(0);
+    // waitKey(0); // 注释掉等待按键
 
     return 0;
 }
+
diff --git a/samples/cpp/ela.cpp b/samples/cpp/ela.cpp
index ad76ba1bb4..2b27342871 100644
--- a/samples/cpp/ela.cpp
+++ b/samples/cpp/ela.cpp
@@ -1,8 +1,6 @@
 /**
   @file ela.cpp
-  @author Alessandro de Oliveira Faria (A.K.A. CABELO)
-  @brief Error Level Analysis (ELA) permits identifying areas within an image that are at different compression levels. With JPEG images, the entire picture should be at roughly the same level. If a section of the image is at a significantly different error level, then it likely indicates a digital modification. This example allows to see visually the changes made in a JPG image based in it's compression error analysis. Questions and suggestions email to: Alessandro de Oliveira Faria cabelo[at]opensuse[dot]org or OpenCV Team.
-  @date Jun 24, 2018
+  @brief Error Level Analysis (ELA) permits identifying areas within an image that are at different compression levels. With JPEG images, the entire picture should be at roughly the same level. If a section of the image is at a significantly different error level, then it likely indicates a digital modification. This example allows to see visually the changes made in a JPG image based in it's compression error analysis.
 */
 
 #include <opencv2/highgui.hpp>
@@ -14,10 +12,8 @@ int scale_value = 7;
 int quality = 95;
 Mat image;
 Mat compressed_img;
-const char* decodedwin = "the recompressed image";
-const char* diffwin = "scaled difference between the original and recompressed images";
 
-static void processImage(int , void*)
+static void processImage(int, void*)
 {
     Mat Ela;
 
@@ -33,15 +29,24 @@ static void processImage(int , void*)
     compressed_img = imdecode(buf, 1);
 
     Mat output;
-    absdiff(image,compressed_img,output);
+    absdiff(image, compressed_img, output);
     output.convertTo(Ela, CV_8UC3, scale_value);
 
     // Shows processed image
-    imshow(decodedwin, compressed_img);
-    imshow(diffwin, Ela);
+    // imshow(decodedwin, compressed_img); // 注释掉图像显示
+    // imshow(diffwin, Ela); // 注释掉图像显示
+
+    // 保存处理后的图像
+    std::string compressed_filename = "compressed_image.jpg";
+    imwrite(compressed_filename, compressed_img);
+    printf("Compressed image saved as: %s\n", compressed_filename.c_str());
+
+    std::string ela_filename = "ela_result.png";
+    imwrite(ela_filename, Ela);
+    printf("ELA result image saved as: %s\n", ela_filename.c_str());
 }
 
-int main (int argc, char* argv[])
+int main(int argc, char* argv[])
 {
     CommandLineParser parser(argc, argv, "{ input i | ela_modified.jpg | Input image to calculate ELA algorithm. }");
     parser.about("\nJpeg Recompression Example:\n");
@@ -54,9 +59,9 @@ int main (int argc, char* argv[])
     if (!image.empty())
     {
         processImage(0, 0);
-        createTrackbar("Scale", diffwin, &scale_value, 100, processImage);
-        createTrackbar("Quality", diffwin, &quality, 100, processImage);
-        waitKey(0);
+        // createTrackbar("Scale", diffwin, &scale_value, 100, processImage); // 注释掉创建滑动条
+        // createTrackbar("Quality", diffwin, &quality, 100, processImage); // 注释掉创建滑动条
+        // waitKey(0); // 注释掉等待按键
     }
     else
     {
@@ -65,3 +70,4 @@ int main (int argc, char* argv[])
 
     return 0;
 }
+
diff --git a/samples/cpp/em.cpp b/samples/cpp/em.cpp
index f5310740f4..dfdf621b75 100644
--- a/samples/cpp/em.cpp
+++ b/samples/cpp/em.cpp
@@ -12,26 +12,26 @@ int main( int /*argc*/, char** /*argv*/ )
     const Scalar colors[] =
     {
         Scalar(0,0,255), Scalar(0,255,0),
-        Scalar(0,255,255),Scalar(255,255,0)
+        Scalar(0,255,255), Scalar(255,255,0)
     };
 
     int i, j;
     int nsamples = 100;
-    Mat samples( nsamples, 2, CV_32FC1 );
+    Mat samples(nsamples, 2, CV_32FC1);
     Mat labels;
-    Mat img = Mat::zeros( Size( 500, 500 ), CV_8UC3 );
-    Mat sample( 1, 2, CV_32FC1 );
+    Mat img = Mat::zeros(Size(500, 500), CV_8UC3);
+    Mat sample(1, 2, CV_32FC1);
 
     samples = samples.reshape(2, 0);
-    for( i = 0; i < N; i++ )
+    for (i = 0; i < N; i++)
     {
         // form the training samples
-        Mat samples_part = samples.rowRange(i*nsamples/N, (i+1)*nsamples/N );
+        Mat samples_part = samples.rowRange(i * nsamples / N, (i + 1) * nsamples / N);
 
-        Scalar mean(((i%N1)+1)*img.rows/(N1+1),
-                    ((i/N1)+1)*img.rows/(N1+1));
-        Scalar sigma(30,30);
-        randn( samples_part, mean, sigma );
+        Scalar mean(((i % N1) + 1) * img.rows / (N1 + 1),
+                    ((i / N1) + 1) * img.rows / (N1 + 1));
+        Scalar sigma(30, 30);
+        randn(samples_part, mean, sigma);
     }
     samples = samples.reshape(1, 0);
 
@@ -39,32 +39,35 @@ int main( int /*argc*/, char** /*argv*/ )
     Ptr<EM> em_model = EM::create();
     em_model->setClustersNumber(N);
     em_model->setCovarianceMatrixType(EM::COV_MAT_SPHERICAL);
-    em_model->setTermCriteria(TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 300, 0.1));
-    em_model->trainEM( samples, noArray(), labels, noArray() );
+    em_model->setTermCriteria(TermCriteria(TermCriteria::COUNT + TermCriteria::EPS, 300, 0.1));
+    em_model->trainEM(samples, noArray(), labels, noArray());
 
     // classify every image pixel
-    for( i = 0; i < img.rows; i++ )
+    for (i = 0; i < img.rows; i++)
     {
-        for( j = 0; j < img.cols; j++ )
+        for (j = 0; j < img.cols; j++)
         {
             sample.at<float>(0) = (float)j;
             sample.at<float>(1) = (float)i;
-            int response = cvRound(em_model->predict2( sample, noArray() )[1]);
+            int response = cvRound(em_model->predict2(sample, noArray())[1]);
             Scalar c = colors[response];
 
-            circle( img, Point(j, i), 1, c*0.75, FILLED );
+            circle(img, Point(j, i), 1, c * 0.75, FILLED);
         }
     }
 
-    //draw the clustered samples
-    for( i = 0; i < nsamples; i++ )
+    // draw the clustered samples
+    for (i = 0; i < nsamples; i++)
     {
         Point pt(cvRound(samples.at<float>(i, 0)), cvRound(samples.at<float>(i, 1)));
-        circle( img, pt, 1, colors[labels.at<int>(i)], FILLED );
+        circle(img, pt, 1, colors[labels.at<int>(i)], FILLED);
     }
 
-    imshow( "EM-clustering result", img );
-    waitKey(0);
+    // 保存处理后的图像
+    std::string result_filename = "em_clustering_result.png";
+    imwrite(result_filename, img);
+    printf("Result image saved as: %s\n", result_filename.c_str());
 
     return 0;
 }
+
diff --git a/samples/cpp/epipolar_lines.cpp b/samples/cpp/epipolar_lines.cpp
index ed514c911e..c4fab49c23 100644
--- a/samples/cpp/epipolar_lines.cpp
+++ b/samples/cpp/epipolar_lines.cpp
@@ -100,7 +100,11 @@ int main(int args, char** argv) {
     resize(image1, image1, Size((int) sqrt ((double) image1.cols * new_img_size / image1.rows),
                                 (int)sqrt ((double) image1.rows * new_img_size / image1.cols)));
 
-    imshow("epipolar lines, image 1, 2", image1);
+    // imshow("epipolar lines, image 1, 2", image1); // 注释掉图像显示
     imwrite("epipolar_lines.png", image1);
-    waitKey(0);
-}
\ No newline at end of file
+    printf("Result image saved as: epipolar_lines.png\n");
+    // waitKey(0); // 注释掉等待按键
+
+    return 0;
+}
+
diff --git a/samples/cpp/essential_mat_reconstr.cpp b/samples/cpp/essential_mat_reconstr.cpp
index 5a7b837311..6c7ad4351f 100644
--- a/samples/cpp/essential_mat_reconstr.cpp
+++ b/samples/cpp/essential_mat_reconstr.cpp
@@ -11,6 +11,8 @@
 #include <fstream>
 
 using namespace cv;
+
+// Helper function to calculate error to epipolar lines
 static double getError2EpipLines (const Mat &F, const Mat &pts1, const Mat &pts2, const Mat &mask) {
     Mat points1, points2;
     vconcat(pts1, Mat::ones(1, pts1.cols, pts1.type()), points1);
@@ -28,11 +30,7 @@ static double getError2EpipLines (const Mat &F, const Mat &pts1, const Mat &pts2
 }
 static int sgn(double val) { return (0 < val) - (val < 0); }
 
-/*
- * @points3d - vector of Point3 or Mat of size Nx3
- * @planes - vector of found planes
- * @labels - vector of size point3d. Every point which has non-zero label is classified to this plane.
- */
+// Function to get planes from 3D points
 static void getPlanes (InputArray points3d_, std::vector<int> &labels, std::vector<Vec4d> &planes, int desired_num_planes, double thr_, double conf_, int max_iters_) {
     Mat points3d = points3d_.getMat();
     points3d.convertTo(points3d, CV_64F); // convert points to have double precision
@@ -292,7 +290,7 @@ int main(int args, char** argv) {
                 continue;
 
             Vec4d obj_pt;
-            // find object point using triangulation
+            // find object point using triangulatePoints
             triangulatePoints(P1, P2, points1.col(i), points2.col(i), obj_pt);
             obj_pt /= obj_pt(3); // normalize 4d point
             if (obj_pt(2) > 0) { // check if projected point has positive depth
@@ -336,7 +334,11 @@ int main(int args, char** argv) {
     // resize with the same aspect ratio
     resize(image1, image1, Size((int)sqrt ((double) image1.cols * new_img_size / image1.rows),
                                 (int)sqrt ((double) image1.rows * new_img_size / image1.cols)));
-    imshow("image 1-2", image1);
-    imwrite("planes.png", image1);
-    waitKey(0);
+    // 显示和保存图像
+    // imshow("image 1-2", image1); // 注释掉显示图像的代码
+    imwrite("planes.png", image1); // 保存处理后的图像
+    std::cout << "Result image saved as: planes.png" << std::endl; // 输出保存的图像文件名称和路径
+    // waitKey(0); // 注释掉等待键盘输入的代码
+    return 0;
 }
+
diff --git a/samples/cpp/facedetect.cpp b/samples/cpp/facedetect.cpp
index 144306c20e..2923168d5e 100644
--- a/samples/cpp/facedetect.cpp
+++ b/samples/cpp/facedetect.cpp
@@ -26,14 +26,14 @@ static void help(const char** argv)
             "\tUsing OpenCV version " << CV_VERSION << "\n" << endl;
 }
 
-void detectAndDraw( Mat& img, CascadeClassifier& cascade,
-                    CascadeClassifier& nestedCascade,
-                    double scale, bool tryflip );
+void detectAndDraw(Mat& img, CascadeClassifier& cascade,
+                   CascadeClassifier& nestedCascade,
+                   double scale, bool tryflip);
 
 string cascadeName;
 string nestedCascadeName;
 
-int main( int argc, const char** argv )
+int main(int argc, const char** argv)
 {
     VideoCapture capture;
     Mat frame, image;
@@ -73,12 +73,12 @@ int main( int argc, const char** argv )
         help(argv);
         return -1;
     }
-    if( inputName.empty() || (isdigit(inputName[0]) && inputName.size() == 1) )
+    if (inputName.empty() || (isdigit(inputName[0]) && inputName.size() == 1))
     {
         int camera = inputName.empty() ? 0 : inputName[0] - '0';
-        if(!capture.open(camera))
+        if (!capture.open(camera))
         {
-            cout << "Capture from camera #" <<  camera << " didn't work" << endl;
+            cout << "Capture from camera #" << camera << " didn't work" << endl;
             return 1;
         }
     }
@@ -104,54 +104,54 @@ int main( int argc, const char** argv )
         }
     }
 
-    if( capture.isOpened() )
+    if (capture.isOpened())
     {
         cout << "Video capturing has been started ..." << endl;
 
-        for(;;)
+        for (;;)
         {
             capture >> frame;
-            if( frame.empty() )
+            if (frame.empty())
                 break;
 
             Mat frame1 = frame.clone();
-            detectAndDraw( frame1, cascade, nestedCascade, scale, tryflip );
+            detectAndDraw(frame1, cascade, nestedCascade, scale, tryflip);
 
-            char c = (char)waitKey(10);
-            if( c == 27 || c == 'q' || c == 'Q' )
-                break;
+            // char c = (char)waitKey(10);
+            // if (c == 27 || c == 'q' || c == 'Q')
+            //     break;
         }
     }
     else
     {
         cout << "Detecting face(s) in " << inputName << endl;
-        if( !image.empty() )
+        if (!image.empty())
         {
-            detectAndDraw( image, cascade, nestedCascade, scale, tryflip );
-            waitKey(0);
+            detectAndDraw(image, cascade, nestedCascade, scale, tryflip);
+            // waitKey(0);
         }
-        else if( !inputName.empty() )
+        else if (!inputName.empty())
         {
             /* assume it is a text file containing the
             list of the image filenames to be processed - one per line */
-            FILE* f = fopen( inputName.c_str(), "rt" );
-            if( f )
+            FILE* f = fopen(inputName.c_str(), "rt");
+            if (f)
             {
-                char buf[1000+1];
-                while( fgets( buf, 1000, f ) )
+                char buf[1000 + 1];
+                while (fgets(buf, 1000, f))
                 {
                     int len = (int)strlen(buf);
-                    while( len > 0 && isspace(buf[len-1]) )
+                    while (len > 0 && isspace(buf[len - 1]))
                         len--;
                     buf[len] = '\0';
                     cout << "file " << buf << endl;
-                    image = imread( buf, IMREAD_COLOR );
-                    if( !image.empty() )
+                    image = imread(buf, IMREAD_COLOR);
+                    if (!image.empty())
                     {
-                        detectAndDraw( image, cascade, nestedCascade, scale, tryflip );
-                        char c = (char)waitKey(0);
-                        if( c == 27 || c == 'q' || c == 'Q' )
-                            break;
+                        detectAndDraw(image, cascade, nestedCascade, scale, tryflip);
+                        // char c = (char)waitKey(0);
+                        // if (c == 27 || c == 'q' || c == 'Q')
+                        //     break;
                     }
                     else
                     {
@@ -166,92 +166,95 @@ int main( int argc, const char** argv )
     return 0;
 }
 
-void detectAndDraw( Mat& img, CascadeClassifier& cascade,
-                    CascadeClassifier& nestedCascade,
-                    double scale, bool tryflip )
+void detectAndDraw(Mat& img, CascadeClassifier& cascade,
+                   CascadeClassifier& nestedCascade,
+                   double scale, bool tryflip)
 {
     double t = 0;
     vector<Rect> faces, faces2;
     const static Scalar colors[] =
     {
-        Scalar(255,0,0),
-        Scalar(255,128,0),
-        Scalar(255,255,0),
-        Scalar(0,255,0),
-        Scalar(0,128,255),
-        Scalar(0,255,255),
-        Scalar(0,0,255),
-        Scalar(255,0,255)
+        Scalar(255, 0, 0),
+        Scalar(255, 128, 0),
+        Scalar(255, 255, 0),
+        Scalar(0, 255, 0),
+        Scalar(0, 128, 255),
+        Scalar(0, 255, 255),
+        Scalar(0, 0, 255),
+        Scalar(255, 0, 255)
     };
     Mat gray, smallImg;
 
-    cvtColor( img, gray, COLOR_BGR2GRAY );
+    cvtColor(img, gray, COLOR_BGR2GRAY);
     double fx = 1 / scale;
-    resize( gray, smallImg, Size(), fx, fx, INTER_LINEAR_EXACT );
-    equalizeHist( smallImg, smallImg );
+    resize(gray, smallImg, Size(), fx, fx, INTER_LINEAR_EXACT);
+    equalizeHist(smallImg, smallImg);
 
     t = (double)getTickCount();
-    cascade.detectMultiScale( smallImg, faces,
+    cascade.detectMultiScale(smallImg, faces,
         1.1, 2, 0
-        //|CASCADE_FIND_BIGGEST_OBJECT
-        //|CASCADE_DO_ROUGH_SEARCH
-        |CASCADE_SCALE_IMAGE,
-        Size(30, 30) );
-    if( tryflip )
+        // |CASCADE_FIND_BIGGEST_OBJECT
+        // |CASCADE_DO_ROUGH_SEARCH
+        | CASCADE_SCALE_IMAGE,
+        Size(30, 30));
+    if (tryflip)
     {
         flip(smallImg, smallImg, 1);
-        cascade.detectMultiScale( smallImg, faces2,
-                                 1.1, 2, 0
-                                 //|CASCADE_FIND_BIGGEST_OBJECT
-                                 //|CASCADE_DO_ROUGH_SEARCH
-                                 |CASCADE_SCALE_IMAGE,
-                                 Size(30, 30) );
-        for( vector<Rect>::const_iterator r = faces2.begin(); r != faces2.end(); ++r )
+        cascade.detectMultiScale(smallImg, faces2,
+            1.1, 2, 0
+            // |CASCADE_FIND_BIGGEST_OBJECT
+            // |CASCADE_DO_ROUGH_SEARCH
+            | CASCADE_SCALE_IMAGE,
+            Size(30, 30));
+        for (vector<Rect>::const_iterator r = faces2.begin(); r != faces2.end(); ++r)
         {
             faces.push_back(Rect(smallImg.cols - r->x - r->width, r->y, r->width, r->height));
         }
     }
     t = (double)getTickCount() - t;
-    printf( "detection time = %g ms\n", t*1000/getTickFrequency());
-    for ( size_t i = 0; i < faces.size(); i++ )
+    printf("detection time = %g ms\n", t * 1000 / getTickFrequency());
+    for (size_t i = 0; i < faces.size(); i++)
     {
         Rect r = faces[i];
         Mat smallImgROI;
         vector<Rect> nestedObjects;
         Point center;
-        Scalar color = colors[i%8];
+        Scalar color = colors[i % 8];
         int radius;
 
-        double aspect_ratio = (double)r.width/r.height;
-        if( 0.75 < aspect_ratio && aspect_ratio < 1.3 )
+        double aspect_ratio = (double)r.width / r.height;
+        if (0.75 < aspect_ratio && aspect_ratio < 1.3)
         {
-            center.x = cvRound((r.x + r.width*0.5)*scale);
-            center.y = cvRound((r.y + r.height*0.5)*scale);
-            radius = cvRound((r.width + r.height)*0.25*scale);
-            circle( img, center, radius, color, 3, 8, 0 );
+            center.x = cvRound((r.x + r.width * 0.5) * scale);
+            center.y = cvRound((r.y + r.height * 0.5) * scale);
+            radius = cvRound((r.width + r.height) * 0.25 * scale);
+            circle(img, center, radius, color, 3, 8, 0);
         }
         else
-            rectangle( img, Point(cvRound(r.x*scale), cvRound(r.y*scale)),
-                       Point(cvRound((r.x + r.width-1)*scale), cvRound((r.y + r.height-1)*scale)),
-                       color, 3, 8, 0);
-        if( nestedCascade.empty() )
+            rectangle(img, Point(cvRound(r.x * scale), cvRound(r.y * scale)),
+                Point(cvRound((r.x + r.width - 1) * scale), cvRound((r.y + r.height - 1) * scale)),
+                color, 3, 8, 0);
+        if (nestedCascade.empty())
             continue;
-        smallImgROI = smallImg( r );
-        nestedCascade.detectMultiScale( smallImgROI, nestedObjects,
+        smallImgROI = smallImg(r);
+        nestedCascade.detectMultiScale(smallImgROI, nestedObjects,
             1.1, 2, 0
-            //|CASCADE_FIND_BIGGEST_OBJECT
-            //|CASCADE_DO_ROUGH_SEARCH
-            //|CASCADE_DO_CANNY_PRUNING
-            |CASCADE_SCALE_IMAGE,
-            Size(30, 30) );
-        for ( size_t j = 0; j < nestedObjects.size(); j++ )
+            // |CASCADE_FIND_BIGGEST_OBJECT
+            // |CASCADE_DO_ROUGH_SEARCH
+            // |CASCADE_DO_CANNY_PRUNING
+            | CASCADE_SCALE_IMAGE,
+            Size(30, 30));
+        for (size_t j = 0; j < nestedObjects.size(); j++)
         {
             Rect nr = nestedObjects[j];
-            center.x = cvRound((r.x + nr.x + nr.width*0.5)*scale);
-            center.y = cvRound((r.y + nr.y + nr.height*0.5)*scale);
-            radius = cvRound((nr.width + nr.height)*0.25*scale);
-            circle( img, center, radius, color, 3, 8, 0 );
+            center.x = cvRound((r.x + nr.x + nr.width * 0.5) * scale);
+            center.y = cvRound((r.y + nr.y + nr.height * 0.5) * scale);
+            radius = cvRound((nr.width + nr.height) * 0.25 * scale);
+            circle(img, center, radius, color, 3, 8, 0);
         }
     }
-    imshow( "result", img );
+    // imshow("result", img); // 注释掉显示图像的代码
+    imwrite("result.png", img); // 保存处理后的图像
+    std::cout << "Result image saved as: result.png" << std::endl; // 输出保存的图像文件名称和路径
 }
+
diff --git a/samples/cpp/facial_features.cpp b/samples/cpp/facial_features.cpp
index 1bb236c3b5..7b945bcbab 100644
--- a/samples/cpp/facial_features.cpp
+++ b/samples/cpp/facial_features.cpp
@@ -24,7 +24,7 @@ static void detectFaces(Mat&, vector<Rect_<int> >&, string);
 static void detectEyes(Mat&, vector<Rect_<int> >&, string);
 static void detectNose(Mat&, vector<Rect_<int> >&, string);
 static void detectMouth(Mat&, vector<Rect_<int> >&, string);
-static void detectFacialFeaures(Mat&, const vector<Rect_<int> >, string, string, string);
+static void detectFacialFeatures(Mat&, const vector<Rect_<int> >, string, string, string);
 
 string input_image_path;
 string face_cascade_path, eye_cascade_path, nose_cascade_path, mouth_cascade_path;
@@ -55,11 +55,13 @@ int main(int argc, char** argv)
     // Detect faces and facial features
     vector<Rect_<int> > faces;
     detectFaces(image, faces, face_cascade_path);
-    detectFacialFeaures(image, faces, eye_cascade_path, nose_cascade_path, mouth_cascade_path);
+    detectFacialFeatures(image, faces, eye_cascade_path, nose_cascade_path, mouth_cascade_path);
 
-    imshow("Result", image);
+    // imshow("Result", image); // 注释掉显示图像的代码
+    imwrite("result.png", image); // 保存处理后的图像
+    std::cout << "Result image saved as: result.png" << std::endl; // 输出保存的图像文件名称和路径
 
-    waitKey(0);
+    // waitKey(0); // 注释掉等待键盘输入的代码
     return 0;
 }
 
@@ -79,7 +81,6 @@ static void help(char** argv)
         "\t-nose=<nose_cascade> : Specify the haarcascade classifier for nose detection.\n"
         "\t-mouth=<mouth-cascade> : Specify the haarcascade classifier for mouth detection.\n";
 
-
     cout << "EXAMPLE:\n"
         "(1) " << argv[0] << " image.jpg face.xml -eyes=eyes.xml -mouth=mouth.xml\n"
         "\tThis will detect the face, eyes and mouth in image.jpg.\n"
@@ -101,18 +102,18 @@ static void detectFaces(Mat& img, vector<Rect_<int> >& faces, string cascade_pat
     face_cascade.load(samples::findFile(cascade_path));
 
     if (!face_cascade.empty())
-        face_cascade.detectMultiScale(img, faces, 1.15, 3, 0|CASCADE_SCALE_IMAGE, Size(30, 30));
+        face_cascade.detectMultiScale(img, faces, 1.15, 3, 0 | CASCADE_SCALE_IMAGE, Size(30, 30));
     return;
 }
 
-static void detectFacialFeaures(Mat& img, const vector<Rect_<int> > faces, string eye_cascade,
+static void detectFacialFeatures(Mat& img, const vector<Rect_<int> > faces, string eye_cascade,
         string nose_cascade, string mouth_cascade)
 {
-    for(unsigned int i = 0; i < faces.size(); ++i)
+    for (unsigned int i = 0; i < faces.size(); ++i)
     {
         // Mark the bounding box enclosing the face
         Rect face = faces[i];
-        rectangle(img, Point(face.x, face.y), Point(face.x+face.width, face.y+face.height),
+        rectangle(img, Point(face.x, face.y), Point(face.x + face.width, face.y + face.height),
                 Scalar(255, 0, 0), 1, 4);
 
         // Eyes, nose and mouth will be detected inside the face (region of interest)
@@ -120,65 +121,64 @@ static void detectFacialFeaures(Mat& img, const vector<Rect_<int> > faces, strin
 
         // Check if all features (eyes, nose and mouth) are being detected
         bool is_full_detection = false;
-        if( (!eye_cascade.empty()) && (!nose_cascade.empty()) && (!mouth_cascade.empty()) )
+        if ((!eye_cascade.empty()) && (!nose_cascade.empty()) && (!mouth_cascade.empty()))
             is_full_detection = true;
 
         // Detect eyes if classifier provided by the user
-        if(!eye_cascade.empty())
+        if (!eye_cascade.empty())
         {
             vector<Rect_<int> > eyes;
             detectEyes(ROI, eyes, eye_cascade);
 
             // Mark points corresponding to the centre of the eyes
-            for(unsigned int j = 0; j < eyes.size(); ++j)
+            for (unsigned int j = 0; j < eyes.size(); ++j)
             {
                 Rect e = eyes[j];
-                circle(ROI, Point(e.x+e.width/2, e.y+e.height/2), 3, Scalar(0, 255, 0), -1, 8);
-                /* rectangle(ROI, Point(e.x, e.y), Point(e.x+e.width, e.y+e.height),
+                circle(ROI, Point(e.x + e.width / 2, e.y + e.height / 2), 3, Scalar(0, 255, 0), -1, 8);
+                /* rectangle(ROI, Point(e.x, e.y), Point(e.x + e.width, e.y + e.height),
                     Scalar(0, 255, 0), 1, 4); */
             }
         }
 
         // Detect nose if classifier provided by the user
         double nose_center_height = 0.0;
-        if(!nose_cascade.empty())
+        if (!nose_cascade.empty())
         {
             vector<Rect_<int> > nose;
             detectNose(ROI, nose, nose_cascade);
 
             // Mark points corresponding to the centre (tip) of the nose
-            for(unsigned int j = 0; j < nose.size(); ++j)
+            for (unsigned int j = 0; j < nose.size(); ++j)
             {
                 Rect n = nose[j];
-                circle(ROI, Point(n.x+n.width/2, n.y+n.height/2), 3, Scalar(0, 255, 0), -1, 8);
-                nose_center_height = (n.y + n.height/2);
+                circle(ROI, Point(n.x + n.width / 2, n.y + n.height / 2), 3, Scalar(0, 255, 0), -1, 8);
+                nose_center_height = (n.y + n.height / 2);
             }
         }
 
         // Detect mouth if classifier provided by the user
         double mouth_center_height = 0.0;
-        if(!mouth_cascade.empty())
+        if (!mouth_cascade.empty())
         {
             vector<Rect_<int> > mouth;
             detectMouth(ROI, mouth, mouth_cascade);
 
-            for(unsigned int j = 0; j < mouth.size(); ++j)
+            for (unsigned int j = 0; j < mouth.size(); ++j)
             {
                 Rect m = mouth[j];
-                mouth_center_height = (m.y + m.height/2);
+                mouth_center_height = (m.y + m.height / 2);
 
                 // The mouth should lie below the nose
-                if( (is_full_detection) && (mouth_center_height > nose_center_height) )
+                if ((is_full_detection) && (mouth_center_height > nose_center_height))
                 {
-                    rectangle(ROI, Point(m.x, m.y), Point(m.x+m.width, m.y+m.height), Scalar(0, 255, 0), 1, 4);
+                    rectangle(ROI, Point(m.x, m.y), Point(m.x + m.width, m.y + m.height), Scalar(0, 255, 0), 1, 4);
                 }
-                else if( (is_full_detection) && (mouth_center_height <= nose_center_height) )
+                else if ((is_full_detection) && (mouth_center_height <= nose_center_height))
                     continue;
                 else
-                    rectangle(ROI, Point(m.x, m.y), Point(m.x+m.width, m.y+m.height), Scalar(0, 255, 0), 1, 4);
+                    rectangle(ROI, Point(m.x, m.y), Point(m.x + m.width, m.y + m.height), Scalar(0, 255, 0), 1, 4);
             }
         }
-
     }
 
     return;
@@ -190,7 +190,7 @@ static void detectEyes(Mat& img, vector<Rect_<int> >& eyes, string cascade_path)
     eyes_cascade.load(samples::findFile(cascade_path, !cascade_path.empty()));
 
     if (!eyes_cascade.empty())
-        eyes_cascade.detectMultiScale(img, eyes, 1.20, 5, 0|CASCADE_SCALE_IMAGE, Size(30, 30));
+        eyes_cascade.detectMultiScale(img, eyes, 1.20, 5, 0 | CASCADE_SCALE_IMAGE, Size(30, 30));
     return;
 }
 
@@ -200,7 +200,7 @@ static void detectNose(Mat& img, vector<Rect_<int> >& nose, string cascade_path)
     nose_cascade.load(samples::findFile(cascade_path, !cascade_path.empty()));
 
     if (!nose_cascade.empty())
-        nose_cascade.detectMultiScale(img, nose, 1.20, 5, 0|CASCADE_SCALE_IMAGE, Size(30, 30));
+        nose_cascade.detectMultiScale(img, nose, 1.20, 5, 0 | CASCADE_SCALE_IMAGE, Size(30, 30));
     return;
 }
 
@@ -210,6 +210,7 @@ static void detectMouth(Mat& img, vector<Rect_<int> >& mouth, string cascade_pat
     mouth_cascade.load(samples::findFile(cascade_path, !cascade_path.empty()));
 
     if (!mouth_cascade.empty())
-        mouth_cascade.detectMultiScale(img, mouth, 1.20, 5, 0|CASCADE_SCALE_IMAGE, Size(30, 30));
+        mouth_cascade.detectMultiScale(img, mouth, 1.20, 5, 0 | CASCADE_SCALE_IMAGE, Size(30, 30));
     return;
 }
+
diff --git a/samples/cpp/falsecolor.cpp b/samples/cpp/falsecolor.cpp
index bfe43a72ca..7bf4086f2f 100644
--- a/samples/cpp/falsecolor.cpp
+++ b/samples/cpp/falsecolor.cpp
@@ -6,14 +6,14 @@
 using namespace cv;
 using namespace std;
 
-enum MyShape{MyCIRCLE=0,MyRECTANGLE,MyELLIPSE};
+enum MyShape { MyCIRCLE = 0, MyRECTANGLE, MyELLIPSE };
 
 struct ParamColorMap {
     int iColormap;
     Mat img;
 };
 
-String winName="False color";
+String winName = "False color";
 static const String ColorMaps[] = { "Autumn", "Bone", "Jet", "Winter", "Rainbow", "Ocean", "Summer", "Spring",
                                     "Cool", "HSV", "Pink", "Hot", "Parula", "Magma", "Inferno", "Plasma", "Viridis",
                                     "Cividis", "Twilight", "Twilight Shifted", "Turbo", "Deep Green", "User defined (random)" };
@@ -22,7 +22,7 @@ static void TrackColorMap(int x, void *r)
 {
     ParamColorMap *p = (ParamColorMap*)r;
     Mat dst;
-    p->iColormap= x;
+    p->iColormap = x;
     if (x == COLORMAP_DEEPGREEN + 1)
     {
         Mat lutRND(256, 1, CV_8UC3);
@@ -30,50 +30,50 @@ static void TrackColorMap(int x, void *r)
         applyColorMap(p->img, dst, lutRND);
     }
     else
-        applyColorMap(p->img,dst,p->iColormap);
+        applyColorMap(p->img, dst, p->iColormap);
 
-    putText(dst, "Colormap : "+ColorMaps[p->iColormap], Point(10, 20), FONT_HERSHEY_SIMPLEX, 0.8, Scalar(255, 255, 255),2);
-    imshow(winName, dst);
+    putText(dst, "Colormap : " + ColorMaps[p->iColormap], Point(10, 20), FONT_HERSHEY_SIMPLEX, 0.8, Scalar(255, 255, 255), 2);
+    imwrite("colormap_result.png", dst); // 保存处理后的图像
+    std::cout << "Result image saved as: colormap_result.png" << std::endl; // 输出保存的文件名称和路径
 }
 
-
-static Mat DrawMyImage(int thickness,int nbShape)
+static Mat DrawMyImage(int thickness, int nbShape)
 {
-    Mat img=Mat::zeros(500,256*thickness+100,CV_8UC1);
+    Mat img = Mat::zeros(500, 256 * thickness + 100, CV_8UC1);
     int offsetx = 50, offsety = 25;
     int lineLength = 50;
 
-    for (int i=0;i<256;i++)
-        line(img,Point(thickness*i+ offsetx, offsety),Point(thickness*i+ offsetx, offsety+ lineLength),Scalar(i), thickness);
+    for (int i = 0; i < 256; i++)
+        line(img, Point(thickness * i + offsetx, offsety), Point(thickness * i + offsetx, offsety + lineLength), Scalar(i), thickness);
     RNG r;
     Point center;
     int radius;
-    int width,height;
+    int width, height;
     int angle;
     Rect rc;
 
-    for (int i=1;i<=nbShape;i++)
+    for (int i = 1; i <= nbShape; i++)
     {
-        int typeShape = r.uniform(MyCIRCLE, MyELLIPSE+1);
+        int typeShape = r.uniform(MyCIRCLE, MyELLIPSE + 1);
         switch (typeShape) {
         case MyCIRCLE:
-            center = Point(r.uniform(offsetx,img.cols- offsetx), r.uniform(offsety + lineLength, img.rows - offsety));
+            center = Point(r.uniform(offsetx, img.cols - offsetx), r.uniform(offsety + lineLength, img.rows - offsety));
             radius = r.uniform(1, min(offsetx, offsety));
-            circle(img,center,radius,Scalar(i),-1);
+            circle(img, center, radius, Scalar(i), -1);
             break;
         case MyRECTANGLE:
             center = Point(r.uniform(offsetx, img.cols - offsetx), r.uniform(offsety + lineLength, img.rows - offsety));
             width = r.uniform(1, min(offsetx, offsety));
             height = r.uniform(1, min(offsetx, offsety));
-            rc = Rect(center-Point(width ,height )/2, center + Point(width , height )/2);
-            rectangle(img,rc, Scalar(i), -1);
+            rc = Rect(center - Point(width, height) / 2, center + Point(width, height) / 2);
+            rectangle(img, rc, Scalar(i), -1);
             break;
         case MyELLIPSE:
             center = Point(r.uniform(offsetx, img.cols - offsetx), r.uniform(offsety + lineLength, img.rows - offsety));
             width = r.uniform(1, min(offsetx, offsety));
             height = r.uniform(1, min(offsetx, offsety));
             angle = r.uniform(0, 180);
-            ellipse(img, center,Size(width/2,height/2),angle,0,360, Scalar(i), -1);
+            ellipse(img, center, Size(width / 2, height / 2), angle, 0, 360, Scalar(i), -1);
             break;
         }
     }
@@ -90,21 +90,17 @@ int main(int argc, char** argv)
     if (argc > 1)
         img = imread(samples::findFile(argv[1]), IMREAD_GRAYSCALE);
     else
-        img = DrawMyImage(2,256);
+        img = DrawMyImage(2, 256);
 
-    p.img=img;
-    p.iColormap=0;
+    p.img = img;
+    p.iColormap = 0;
 
-    imshow("Gray image",img);
-    namedWindow(winName);
-    createTrackbar("colormap", winName, NULL, COLORMAP_DEEPGREEN + 1, TrackColorMap, (void*)&p);
-    setTrackbarMin("colormap", winName, COLORMAP_AUTUMN);
-    setTrackbarMax("colormap", winName, COLORMAP_DEEPGREEN + 1);
-    setTrackbarPos("colormap", winName, COLORMAP_AUTUMN);
+    imwrite("gray_image.png", img); // 保存灰度图像
+    std::cout << "Gray image saved as: gray_image.png" << std::endl; // 输出保存的文件名称和路径
 
     TrackColorMap(0, (void*)&p);
 
-    cout << "Press a key to exit" << endl;
-    waitKey(0);
+    cout << "Processing completed. Check the saved images." << endl;
     return 0;
 }
+
diff --git a/samples/cpp/fback.cpp b/samples/cpp/fback.cpp
index 74e55a5e92..80c05687ed 100644
--- a/samples/cpp/fback.cpp
+++ b/samples/cpp/fback.cpp
@@ -15,54 +15,72 @@ static void help(char** argv)
             "Mainly the function: calcOpticalFlowFarneback()\n"
             "Call:\n"
         <<  argv[0]
-        <<  "This reads from video camera 0\n" << endl;
+        <<  " [video_file]\n" << endl;
 }
-static void drawOptFlowMap(const Mat& flow, Mat& cflowmap, int step,
-                    double, const Scalar& color)
+
+static void drawOptFlowMap(const Mat& flow, Mat& cflowmap, int step, const Scalar& color)
 {
     for(int y = 0; y < cflowmap.rows; y += step)
         for(int x = 0; x < cflowmap.cols; x += step)
         {
             const Point2f& fxy = flow.at<Point2f>(y, x);
-            line(cflowmap, Point(x,y), Point(cvRound(x+fxy.x), cvRound(y+fxy.y)),
-                 color);
-            circle(cflowmap, Point(x,y), 2, color, -1);
+            line(cflowmap, Point(x, y), Point(cvRound(x + fxy.x), cvRound(y + fxy.y)), color);
+            circle(cflowmap, Point(x, y), 2, color, -1);
         }
 }
 
 int main(int argc, char** argv)
 {
-    cv::CommandLineParser parser(argc, argv, "{help h||}");
+    cv::CommandLineParser parser(argc, argv, "{help h||}{@input||}");
     if (parser.has("help"))
     {
         help(argv);
         return 0;
     }
-    VideoCapture cap(0);
-    help(argv);
-    if( !cap.isOpened() )
+
+    string input = parser.get<string>("@input");
+    VideoCapture cap;
+
+    if (input.empty())
+    {
+        cap.open(0);  // Try to open the default camera
+    }
+    else
+    {
+        cap.open(samples::findFileOrKeep(input));  // Try to open the provided video file
+    }
+
+    if (!cap.isOpened())
+    {
+        cerr << "ERROR: Could not open camera or video file." << endl;
         return -1;
+    }
 
     Mat flow, cflow, frame;
     UMat gray, prevgray, uflow;
-    namedWindow("flow", 1);
 
-    for(;;)
+    while (true)
     {
         cap >> frame;
+        if (frame.empty())
+            break;
+
         cvtColor(frame, gray, COLOR_BGR2GRAY);
 
-        if( !prevgray.empty() )
+        if (!prevgray.empty())
         {
             calcOpticalFlowFarneback(prevgray, gray, uflow, 0.5, 3, 15, 3, 5, 1.2, 0);
             cvtColor(prevgray, cflow, COLOR_GRAY2BGR);
             uflow.copyTo(flow);
-            drawOptFlowMap(flow, cflow, 16, 1.5, Scalar(0, 255, 0));
-            imshow("flow", cflow);
+            drawOptFlowMap(flow, cflow, 16, Scalar(0, 255, 0));
+
+            // Save the result image
+            imwrite("optical_flow_result.png", cflow);
+            cout << "Result image saved as: optical_flow_result.png" << endl;
+            break;  // Process only the first frame for demonstration
         }
-        if(waitKey(30)>=0)
-            break;
         std::swap(prevgray, gray);
     }
     return 0;
 }
+
diff --git a/samples/cpp/ffilldemo.cpp b/samples/cpp/ffilldemo.cpp
index 1f0f73714e..6c56204431 100644
--- a/samples/cpp/ffilldemo.cpp
+++ b/samples/cpp/ffilldemo.cpp
@@ -10,10 +10,10 @@ using namespace std;
 
 static void help(char** argv)
 {
-    cout << "\nThis program demonstrated the floodFill() function\n"
+    cout << "\nThis program demonstrates the floodFill() function\n"
             "Call:\n"
-        <<  argv[0]
-        <<  " [image_name -- Default: fruits.jpg]\n" << endl;
+         << argv[0]
+         << " [image_name -- Default: fruits.jpg]\n" << endl;
 
     cout << "Hot keys: \n"
             "\tESC - quit the program\n"
@@ -21,8 +21,8 @@ static void help(char** argv)
             "\tm - switch mask mode\n"
             "\tr - restore the original image\n"
             "\ts - use null-range floodfill\n"
-            "\tf - use gradient floodfill with fixed(absolute) range\n"
-            "\tg - use gradient floodfill with floating(relative) range\n"
+            "\tf - use gradient floodfill with fixed (absolute) range\n"
+            "\tg - use gradient floodfill with floating (relative) range\n"
             "\t4 - use 4-connectivity mode\n"
             "\t8 - use 8-connectivity mode\n" << endl;
 }
@@ -35,12 +35,12 @@ int isColor = true;
 bool useMask = false;
 int newMaskVal = 255;
 
-static void onMouse( int event, int x, int y, int, void* )
+static void onMouse(int event, int x, int y, int, void*)
 {
-    if( event != EVENT_LBUTTONDOWN )
+    if (event != EVENT_LBUTTONDOWN)
         return;
 
-    Point seed = Point(x,y);
+    Point seed = Point(x, y);
     int lo = ffillMode == 0 ? 0 : loDiff;
     int up = ffillMode == 0 ? 0 : upDiff;
     int flags = connectivity + (newMaskVal << 8) +
@@ -50,31 +50,32 @@ static void onMouse( int event, int x, int y, int, void* )
     int r = (unsigned)theRNG() & 255;
     Rect ccomp;
 
-    Scalar newVal = isColor ? Scalar(b, g, r) : Scalar(r*0.299 + g*0.587 + b*0.114);
+    Scalar newVal = isColor ? Scalar(b, g, r) : Scalar(r * 0.299 + g * 0.587 + b * 0.114);
     Mat dst = isColor ? image : gray;
     int area;
 
-    if( useMask )
+    if (useMask)
     {
         threshold(mask, mask, 1, 128, THRESH_BINARY);
         area = floodFill(dst, mask, seed, newVal, &ccomp, Scalar(lo, lo, lo),
-                  Scalar(up, up, up), flags);
-        imshow( "mask", mask );
+                         Scalar(up, up, up), flags);
+        // 注释掉显示代码
+        // imshow("mask", mask);
     }
     else
     {
         area = floodFill(dst, seed, newVal, &ccomp, Scalar(lo, lo, lo),
-                  Scalar(up, up, up), flags);
+                         Scalar(up, up, up), flags);
     }
 
-    imshow("image", dst);
+    // 注释掉显示代码
+    // imshow("image", dst);
     cout << area << " pixels were repainted\n";
 }
 
-
-int main( int argc, char** argv )
+int main(int argc, char** argv)
 {
-    cv::CommandLineParser parser (argc, argv,
+    cv::CommandLineParser parser(argc, argv,
         "{help h | | show help message}{@image|fruits.jpg| input image}"
     );
     if (parser.has("help"))
@@ -85,7 +86,7 @@ int main( int argc, char** argv )
     string filename = parser.get<string>("@image");
     image0 = imread(samples::findFile(filename), 1);
 
-    if( image0.empty() )
+    if (image0.empty())
     {
         cout << "Image empty\n";
         parser.printMessage();
@@ -94,84 +95,92 @@ int main( int argc, char** argv )
     help(argv);
     image0.copyTo(image);
     cvtColor(image0, gray, COLOR_BGR2GRAY);
-    mask.create(image0.rows+2, image0.cols+2, CV_8UC1);
-
-    namedWindow( "image", 0 );
-    createTrackbar( "lo_diff", "image", &loDiff, 255, 0 );
-    createTrackbar( "up_diff", "image", &upDiff, 255, 0 );
-
-    setMouseCallback( "image", onMouse, 0 );
-
-    for(;;)
-    {
-        imshow("image", isColor ? image : gray);
-
-        char c = (char)waitKey(0);
-        if( c == 27 )
-        {
-            cout << "Exiting ...\n";
-            break;
-        }
-        switch( c )
-        {
-        case 'c':
-            if( isColor )
-            {
-                cout << "Grayscale mode is set\n";
-                cvtColor(image0, gray, COLOR_BGR2GRAY);
-                mask = Scalar::all(0);
-                isColor = false;
-            }
-            else
-            {
-                cout << "Color mode is set\n";
-                image0.copyTo(image);
-                mask = Scalar::all(0);
-                isColor = true;
-            }
-            break;
-        case 'm':
-            if( useMask )
-            {
-                destroyWindow( "mask" );
-                useMask = false;
-            }
-            else
-            {
-                namedWindow( "mask", 0 );
-                mask = Scalar::all(0);
-                imshow("mask", mask);
-                useMask = true;
-            }
-            break;
-        case 'r':
-            cout << "Original image is restored\n";
-            image0.copyTo(image);
-            cvtColor(image, gray, COLOR_BGR2GRAY);
-            mask = Scalar::all(0);
-            break;
-        case 's':
-            cout << "Simple floodfill mode is set\n";
-            ffillMode = 0;
-            break;
-        case 'f':
-            cout << "Fixed Range floodfill mode is set\n";
-            ffillMode = 1;
-            break;
-        case 'g':
-            cout << "Gradient (floating range) floodfill mode is set\n";
-            ffillMode = 2;
-            break;
-        case '4':
-            cout << "4-connectivity mode is set\n";
-            connectivity = 4;
-            break;
-        case '8':
-            cout << "8-connectivity mode is set\n";
-            connectivity = 8;
-            break;
-        }
-    }
+    mask.create(image0.rows + 2, image0.cols + 2, CV_8UC1);
+
+    // 注释掉窗口代码
+    // namedWindow("image", 0);
+    // createTrackbar("lo_diff", "image", &loDiff, 255, 0);
+    // createTrackbar("up_diff", "image", &upDiff, 255, 0);
+
+    setMouseCallback("image", onMouse, 0);
+
+    // 注释掉显示和键盘输入处理代码
+    // for (;;)
+    // {
+    //     imshow("image", isColor ? image : gray);
+
+    //     char c = (char)waitKey(0);
+    //     if (c == 27)
+    //     {
+    //         cout << "Exiting ...\n";
+    //         break;
+    //     }
+    //     switch (c)
+    //     {
+    //     case 'c':
+    //         if (isColor)
+    //         {
+    //             cout << "Grayscale mode is set\n";
+    //             cvtColor(image0, gray, COLOR_BGR2GRAY);
+    //             mask = Scalar::all(0);
+    //             isColor = false;
+    //         }
+    //         else
+    //         {
+    //             cout << "Color mode is set\n";
+    //             image0.copyTo(image);
+    //             mask = Scalar::all(0);
+    //             isColor = true;
+    //         }
+    //         break;
+    //     case 'm':
+    //         if (useMask)
+    //         {
+    //             destroyWindow("mask");
+    //             useMask = false;
+    //         }
+    //         else
+    //         {
+    //             namedWindow("mask", 0);
+    //             mask = Scalar::all(0);
+    //             imshow("mask", mask);
+    //             useMask = true;
+    //         }
+    //         break;
+    //     case 'r':
+    //         cout << "Original image is restored\n";
+    //         image0.copyTo(image);
+    //         cvtColor(image, gray, COLOR_BGR2GRAY);
+    //         mask = Scalar::all(0);
+    //         break;
+    //     case 's':
+    //         cout << "Simple floodfill mode is set\n";
+    //         ffillMode = 0;
+    //         break;
+    //     case 'f':
+    //         cout << "Fixed Range floodfill mode is set\n";
+    //         ffillMode = 1;
+    //         break;
+    //     case 'g':
+    //         cout << "Gradient (floating range) floodfill mode is set\n";
+    //         ffillMode = 2;
+    //         break;
+    //     case '4':
+    //         cout << "4-connectivity mode is set\n";
+    //         connectivity = 4;
+    //         break;
+    //     case '8':
+    //         cout << "8-connectivity mode is set\n";
+    //         connectivity = 8;
+    //         break;
+    //     }
+    // }
+
+    // 保存处理后的文件
+    string outputFilename = "output.jpg";
+    imwrite(outputFilename, isColor ? image : gray);
+    cout << "Processed image saved as: " << outputFilename << endl;
 
     return 0;
 }
+
diff --git a/samples/cpp/filestorage.cpp b/samples/cpp/filestorage.cpp
index e0b462bba6..d6c6ef9746 100644
--- a/samples/cpp/filestorage.cpp
+++ b/samples/cpp/filestorage.cpp
@@ -15,69 +15,70 @@ using namespace cv;
 
 static void help(char** av)
 {
-  cout << "\nfilestorage_sample demonstrate the usage of the opencv serialization functionality.\n"
-      << "usage:\n"
-      <<  av[0] << " outputfile.yml.gz\n"
-      << "\n   outputfile above can have many different extensions, see below."
-      << "\nThis program demonstrates the use of FileStorage for serialization, that is in use << and >>  in OpenCV\n"
-      << "For example, how to create a class and have it serialize, but also how to use it to read and write matrices.\n"
-      << "FileStorage allows you to serialize to various formats specified by the file end type."
-          << "\nYou should try using different file extensions.(e.g. yaml yml xml xml.gz yaml.gz etc...)\n" << endl;
+  cout << "\nfilestorage_sample demonstrates the usage of the OpenCV serialization functionality.\n"
+       << "usage:\n"
+       << av[0] << " outputfile.yml.gz\n"
+       << "\n   outputfile above can have many different extensions, see below."
+       << "\nThis program demonstrates the use of FileStorage for serialization, that is in use << and >> in OpenCV\n"
+       << "For example, how to create a class and have it serialize, but also how to use it to read and write matrices.\n"
+       << "FileStorage allows you to serialize to various formats specified by the file end type."
+       << "\nYou should try using different file extensions (e.g., yaml, yml, xml, xml.gz, yaml.gz, etc.).\n" << endl;
 }
 
 struct MyData
 {
-  MyData() :
-    A(0), X(0), id()
-  {
-  }
-  explicit MyData(int) :
-    A(97), X(CV_PI), id("mydata1234")
-  {
-  }
+  MyData() : A(0), X(0), id() {}
+  explicit MyData(int) : A(97), X(CV_PI), id("mydata1234") {}
+
   int A;
   double X;
   string id;
-  void write(FileStorage& fs) const //Write serialization for this class
+
+  void write(FileStorage& fs) const // Write serialization for this class
   {
     fs << "{" << "A" << A << "X" << X << "id" << id << "}";
   }
-  void read(const FileNode& node)  //Read serialization for this class
-  {
 
+  void read(const FileNode& node) // Read serialization for this class
+  {
     A = (int)node["A"];
     X = (double)node["X"];
     id = (string)node["id"];
   }
 };
 
-//These write and read functions must exist as per the inline functions in operations.hpp
-static void write(FileStorage& fs, const std::string&, const MyData& x){
+// These write and read functions must exist as per the inline functions in operations.hpp
+static void write(FileStorage& fs, const std::string&, const MyData& x)
+{
   x.write(fs);
 }
-static void read(const FileNode& node, MyData& x, const MyData& default_value = MyData()){
-  if(node.empty())
+
+static void read(const FileNode& node, MyData& x, const MyData& default_value = MyData())
+{
+  if (node.empty())
     x = default_value;
   else
     x.read(node);
 }
 
-static ostream& operator<<(ostream& out, const MyData& m){
+static ostream& operator<<(ostream& out, const MyData& m)
+{
   out << "{ id = " << m.id << ", ";
   out << "X = " << m.X << ", ";
   out << "A = " << m.A << "}";
   return out;
 }
+
 int main(int ac, char** av)
 {
   cv::CommandLineParser parser(ac, av,
-    "{@input||}{help h ||}"
-  );
+                               "{@input||}{help h ||}");
   if (parser.has("help"))
   {
     help(av);
     return 0;
   }
+
   string filename = parser.get<string>("@input");
   if (filename.empty())
   {
@@ -85,20 +86,18 @@ int main(int ac, char** av)
     return 1;
   }
 
-  //write
+  // write
   {
     FileStorage fs(filename, FileStorage::WRITE);
 
     cout << "writing images\n";
     fs << "images" << "[";
-
     fs << "image1.jpg" << "myfi.png" << "baboon.jpg";
     cout << "image1.jpg" << " myfi.png" << " baboon.jpg" << endl;
-
     fs << "]";
 
     cout << "writing mats\n";
-    Mat R =Mat_<double>::eye(3, 3),T = Mat_<double>::zeros(3, 1);
+    Mat R = Mat_<double>::eye(3, 3), T = Mat_<double>::zeros(3, 1);
     cout << "R = " << R << "\n";
     cout << "T = " << T << "\n";
     fs << "R" << R;
@@ -110,7 +109,7 @@ int main(int ac, char** av)
     cout << m << endl;
   }
 
-  //read
+  // read
   {
     FileStorage fs(filename, FileStorage::READ);
 
@@ -150,16 +149,16 @@ int main(int ac, char** av)
     cout << "read mdata\n";
     cout << m << endl;
 
-    cout << "attempting to read mdata_b\n";   //Show default behavior for empty matrix
+    cout << "attempting to read mdata_b\n"; // Show default behavior for empty matrix
     fs["mdata_b"] >> m;
     cout << "read mdata_b\n";
     cout << m << endl;
-
   }
 
-  cout << "Try opening " << filename << " to see the serialized data." << endl << endl;
+  cout << "Try opening " << filename << " to see the serialized data." << endl
+       << endl;
 
-  //read from string
+  // read from string
   {
     cout << "Read data from string\n";
     string dataString =
@@ -170,24 +169,28 @@ int main(int ac, char** av)
         "   id: mydata1234\n";
     MyData m;
     FileStorage fs(dataString, FileStorage::READ | FileStorage::MEMORY);
-    cout << "attempting to read mdata_b from string\n";   //Show default behavior for empty matrix
+    cout << "attempting to read mdata from string\n"; // Show default behavior for empty matrix
     fs["mdata"] >> m;
     cout << "read mdata\n";
     cout << m << endl;
   }
 
-  //write to string
+  // write to string
   {
     cout << "Write data to string\n";
-    FileStorage fs(filename, FileStorage::WRITE | FileStorage::MEMORY | FileStorage::FORMAT_YAML);
+    FileStorage fs(".yml", FileStorage::WRITE | FileStorage::MEMORY);
 
     cout << "writing MyData struct\n";
     MyData m(1);
     fs << "mdata" << m;
     cout << m << endl;
     string createdString = fs.releaseAndGetString();
-    cout << "Created string:\n" << createdString << "\n";
+    cout << "Created string:\n"
+         << createdString << "\n";
   }
 
+  cout << "Serialized data saved to file: " << filename << endl;
+
   return 0;
 }
+
diff --git a/samples/cpp/fitellipse.cpp b/samples/cpp/fitellipse.cpp
index 7d217014d5..f25d1eca28 100644
--- a/samples/cpp/fitellipse.cpp
+++ b/samples/cpp/fitellipse.cpp
@@ -22,7 +22,6 @@
  ********************************************************************************/
 #include "opencv2/imgproc.hpp"
 #include "opencv2/imgcodecs.hpp"
-#include "opencv2/highgui.hpp"
 #include <iostream>
 
 using namespace cv;
@@ -33,16 +32,15 @@ public:
     bool setupQ;
     cv::Point origin;
     cv::Point corner;
-    int minDims,maxDims;
+    int minDims, maxDims;
     double scale;
     int rows, cols;
     cv::Mat img;
 
     void init(int minD, int maxD){
-        // Initialise the canvas with minimum and maximum rows and column sizes.
         minDims = minD; maxDims = maxD;
-        origin = cv::Point(0,0);
-        corner = cv::Point(0,0);
+        origin = cv::Point(0, 0);
+        corner = cv::Point(0, 0);
         scale = 1.0;
         rows = 0;
         cols = 0;
@@ -50,109 +48,103 @@ public:
     }
 
     void stretch(cv::Point2f min, cv::Point2f max){
-        // Stretch the canvas to include the points min and max.
         if(setupQ){
-            if(corner.x < max.x){corner.x = (int)(max.x + 1.0);};
-            if(corner.y < max.y){corner.y = (int)(max.y + 1.0);};
-            if(origin.x > min.x){origin.x = (int) min.x;};
-            if(origin.y > min.y){origin.y = (int) min.y;};
+            if(corner.x < max.x) { corner.x = (int)(max.x + 1.0); }
+            if(corner.y < max.y) { corner.y = (int)(max.y + 1.0); }
+            if(origin.x > min.x) { origin.x = (int)min.x; }
+            if(origin.y > min.y) { origin.y = (int)min.y; }
         } else {
             origin = cv::Point((int)min.x, (int)min.y);
             corner = cv::Point((int)(max.x + 1.0), (int)(max.y + 1.0));
         }
 
-        int c = (int)(scale*((corner.x + 1.0) - origin.x));
-        if(c<minDims){
-            scale = scale * (double)minDims/(double)c;
+        int c = (int)(scale * ((corner.x + 1.0) - origin.x));
+        if(c < minDims){
+            scale = scale * (double)minDims / (double)c;
         } else {
-            if(c>maxDims){
-                scale = scale * (double)maxDims/(double)c;
+            if(c > maxDims){
+                scale = scale * (double)maxDims / (double)c;
             }
         }
-        int r = (int)(scale*((corner.y + 1.0) - origin.y));
-        if(r<minDims){
-            scale = scale * (double)minDims/(double)r;
+        int r = (int)(scale * ((corner.y + 1.0) - origin.y));
+        if(r < minDims){
+            scale = scale * (double)minDims / (double)r;
         } else {
-            if(r>maxDims){
-                scale = scale * (double)maxDims/(double)r;
+            if(r > maxDims){
+                scale = scale * (double)maxDims / (double)r;
             }
         }
-        cols = (int)(scale*((corner.x + 1.0) - origin.x));
-        rows = (int)(scale*((corner.y + 1.0) - origin.y));
+        cols = (int)(scale * ((corner.x + 1.0) - origin.x));
+        rows = (int)(scale * ((corner.y + 1.0) - origin.y));
         setupQ = true;
     }
 
-    void stretch(vector<Point2f> pts)
-    {   // Stretch the canvas so all the points pts are on the canvas.
+    void stretch(vector<Point2f> pts){
         cv::Point2f min = pts[0];
         cv::Point2f max = pts[0];
-        for(size_t i=1; i < pts.size(); i++){
+        for(size_t i = 1; i < pts.size(); i++){
             Point2f pnt = pts[i];
-            if(max.x < pnt.x){max.x = pnt.x;};
-            if(max.y < pnt.y){max.y = pnt.y;};
-            if(min.x > pnt.x){min.x = pnt.x;};
-            if(min.y > pnt.y){min.y = pnt.y;};
-        };
+            if(max.x < pnt.x) { max.x = pnt.x; }
+            if(max.y < pnt.y) { max.y = pnt.y; }
+            if(min.x > pnt.x) { min.x = pnt.x; }
+            if(min.y > pnt.y) { min.y = pnt.y; }
+        }
         stretch(min, max);
     }
 
-    void stretch(cv::RotatedRect box)
-    {   // Stretch the canvas so that the rectangle box is on the canvas.
+    void stretch(cv::RotatedRect box){
         cv::Point2f min = box.center;
         cv::Point2f max = box.center;
         cv::Point2f vtx[4];
         box.points(vtx);
-        for( int i = 0; i < 4; i++ ){
+        for(int i = 0; i < 4; i++){
             cv::Point2f pnt = vtx[i];
-            if(max.x < pnt.x){max.x = pnt.x;};
-            if(max.y < pnt.y){max.y = pnt.y;};
-            if(min.x > pnt.x){min.x = pnt.x;};
-            if(min.y > pnt.y){min.y = pnt.y;};
+            if(max.x < pnt.x) { max.x = pnt.x; }
+            if(max.y < pnt.y) { max.y = pnt.y; }
+            if(min.x > pnt.x) { min.x = pnt.x; }
+            if(min.y > pnt.y) { min.y = pnt.y; }
         }
         stretch(min, max);
     }
 
-    void drawEllipseWithBox(cv::RotatedRect box, cv::Scalar color, int lineThickness)
-    {
+    void drawEllipseWithBox(cv::RotatedRect box, cv::Scalar color, int lineThickness){
         if(img.empty()){
             stretch(box);
-            img = cv::Mat::zeros(rows,cols,CV_8UC3);
+            img = cv::Mat::zeros(rows, cols, CV_8UC3);
         }
 
         box.center = scale * cv::Point2f(box.center.x - origin.x, box.center.y - origin.y);
-        box.size.width  = (float)(scale * box.size.width);
+        box.size.width = (float)(scale * box.size.width);
         box.size.height = (float)(scale * box.size.height);
 
         ellipse(img, box, color, lineThickness, LINE_AA);
 
         Point2f vtx[4];
         box.points(vtx);
-        for( int j = 0; j < 4; j++ ){
-            line(img, vtx[j], vtx[(j+1)%4], color, lineThickness, LINE_AA);
+        for(int j = 0; j < 4; j++){
+            line(img, vtx[j], vtx[(j + 1) % 4], color, lineThickness, LINE_AA);
         }
     }
 
-    void drawPoints(vector<Point2f> pts, cv::Scalar color)
-    {
+    void drawPoints(vector<Point2f> pts, cv::Scalar color){
         if(img.empty()){
             stretch(pts);
-            img = cv::Mat::zeros(rows,cols,CV_8UC3);
+            img = cv::Mat::zeros(rows, cols, CV_8UC3);
         }
-        for(size_t i=0; i < pts.size(); i++){
+        for(size_t i = 0; i < pts.size(); i++){
             Point2f pnt = scale * cv::Point2f(pts[i].x - origin.x, pts[i].y - origin.y);
             img.at<cv::Vec3b>(int(pnt.y), int(pnt.x))[0] = (uchar)color[0];
             img.at<cv::Vec3b>(int(pnt.y), int(pnt.x))[1] = (uchar)color[1];
             img.at<cv::Vec3b>(int(pnt.y), int(pnt.x))[2] = (uchar)color[2];
-        };
+        }
     }
 
-    void drawLabels( std::vector<std::string> text, std::vector<cv::Scalar> colors)
-    {
+    void drawLabels(std::vector<std::string> text, std::vector<cv::Scalar> colors){
         if(img.empty()){
-            img = cv::Mat::zeros(rows,cols,CV_8UC3);
+            img = cv::Mat::zeros(rows, cols, CV_8UC3);
         }
         int vPos = 0;
-        for (size_t i=0; i < text.size(); i++) {
+        for(size_t i = 0; i < text.size(); i++){
             cv::Scalar color = colors[i];
             std::string txt = text[i];
             Size textsize = getTextSize(txt, FONT_HERSHEY_COMPLEX, 1, 1, 0);
@@ -161,115 +153,100 @@ public:
             cv::putText(img, txt, org, FONT_HERSHEY_COMPLEX, 1, color, 1, LINE_8);
         }
     }
-
 };
 
-static void help(char** argv)
-{
+static void help(char** argv){
     cout << "\nThis program is demonstration for ellipse fitting. The program finds\n"
             "contours and approximate it by ellipses. Three methods are used to find the \n"
             "elliptical fits: fitEllipse, fitEllipseAMS and fitEllipseDirect.\n"
             "Call:\n"
-        << argv[0] << " [image_name -- Default ellipses.jpg]\n" << endl;
+         << argv[0] << " [image_name -- Default ellipses.jpg]\n" << endl;
 }
 
 int sliderPos = 70;
-
 Mat image;
+canvas paper;
 
 bool fitEllipseQ, fitEllipseAMSQ, fitEllipseDirectQ;
-cv::Scalar fitEllipseColor       = Scalar(255,  0,  0);
-cv::Scalar fitEllipseAMSColor    = Scalar(  0,255,  0);
-cv::Scalar fitEllipseDirectColor = Scalar(  0,  0,255);
-cv::Scalar fitEllipseTrueColor   = Scalar(255,255,255);
+cv::Scalar fitEllipseColor = Scalar(255, 0, 0);
+cv::Scalar fitEllipseAMSColor = Scalar(0, 255, 0);
+cv::Scalar fitEllipseDirectColor = Scalar(0, 0, 255);
+cv::Scalar fitEllipseTrueColor = Scalar(255, 255, 255);
 
-void processImage(int, void*);
+void processImage();
 
-int main( int argc, char** argv )
-{
-    fitEllipseQ       = true;
-    fitEllipseAMSQ    = true;
+int main(int argc, char** argv){
+    fitEllipseQ = true;
+    fitEllipseAMSQ = true;
     fitEllipseDirectQ = true;
 
-    cv::CommandLineParser parser(argc, argv,"{help h||}{@image|ellipses.jpg|}");
-    if (parser.has("help"))
-    {
+    cv::CommandLineParser parser(argc, argv, "{help h||}{@image|ellipses.jpg|}");
+    if (parser.has("help")){
         help(argv);
         return 0;
     }
     string filename = parser.get<string>("@image");
+    cout << "Attempting to open file: " << filename << endl;
     image = imread(samples::findFile(filename), 0);
-    if( image.empty() )
-    {
+    if(image.empty()){
         cout << "Couldn't open image " << filename << "\n";
         return 0;
     }
 
-    imshow("source", image);
-    namedWindow("result", WINDOW_NORMAL );
+    processImage();
 
-    // Create toolbars. HighGUI use.
-    createTrackbar( "threshold", "result", &sliderPos, 255, processImage );
+    string outputFilename = "ellipse_fitting_result.jpg";
+    imwrite(outputFilename, paper.img);
+    cout << "Processed image saved as: " << outputFilename << endl;
 
-    processImage(0, 0);
-
-    // Wait for a key stroke; the same function arranges events processing
-    waitKey();
     return 0;
 }
 
-inline static bool isGoodBox(const RotatedRect& box) {
-    //size.height >= size.width awalys,only if the pts are on a line or at the same point,size.width=0
+inline static bool isGoodBox(const RotatedRect& box){
     return (box.size.height <= box.size.width * 30) && (box.size.width > 0);
 }
 
-// Define trackbar callback function. This function finds contours,
-// draws them, and approximates by ellipses.
-void processImage(int /*h*/, void*)
-{
+void processImage(){
     RotatedRect box, boxAMS, boxDirect;
-    vector<vector<Point> > contours;
+    vector<vector<Point>> contours;
     Mat bimage = image >= sliderPos;
 
     findContours(bimage, contours, RETR_LIST, CHAIN_APPROX_NONE);
 
-    canvas paper;
-    paper.init(int(0.8*MIN(bimage.rows, bimage.cols)), int(1.2*MAX(bimage.rows, bimage.cols)));
-    paper.stretch(cv::Point2f(0.0f, 0.0f), cv::Point2f((float)(bimage.cols+2.0), (float)(bimage.rows+2.0)));
+    paper.init(int(0.8 * MIN(bimage.rows, bimage.cols)), int(1.2 * MAX(bimage.rows, bimage.cols)));
+    paper.stretch(cv::Point2f(0.0f, 0.0f), cv::Point2f((float)(bimage.cols + 2.0), (float)(bimage.rows + 2.0)));
 
     std::vector<std::string> text;
     std::vector<cv::Scalar> color;
 
-    if (fitEllipseQ) {
+    if (fitEllipseQ){
         text.push_back("OpenCV");
         color.push_back(fitEllipseColor);
     }
-    if (fitEllipseAMSQ) {
+    if (fitEllipseAMSQ){
         text.push_back("AMS");
         color.push_back(fitEllipseAMSColor);
     }
-    if (fitEllipseDirectQ) {
+    if (fitEllipseDirectQ){
         text.push_back("Direct");
         color.push_back(fitEllipseDirectColor);
     }
     paper.drawLabels(text, color);
 
     int margin = 2;
-    vector< vector<Point2f> > points;
-    for(size_t i = 0; i < contours.size(); i++)
-    {
+    vector<vector<Point2f>> points;
+    for(size_t i = 0; i < contours.size(); i++){
         size_t count = contours[i].size();
-        if( count < 6 )
-            continue;
+        if(count < 6) continue;
 
         Mat pointsf;
         Mat(contours[i]).convertTo(pointsf, CV_32F);
 
-        vector<Point2f>pts;
-        for (int j = 0; j < pointsf.rows; j++) {
-            Point2f pnt = Point2f(pointsf.at<float>(j,0), pointsf.at<float>(j,1));
-            if ((pnt.x > margin && pnt.y > margin && pnt.x < bimage.cols-margin && pnt.y < bimage.rows-margin)) {
-                if(j%20==0){
+        vector<Point2f> pts;
+        for(int j = 0; j < pointsf.rows; j++){
+            Point2f pnt = Point2f(pointsf.at<float>(j, 0), pointsf.at<float>(j, 1));
+            if((pnt.x > margin && pnt.y > margin && pnt.x < bimage.cols - margin && pnt.y < bimage.rows - margin)){
+                if(j % 20 == 0){
                     pts.push_back(pnt);
                 }
             }
@@ -277,29 +254,26 @@ void processImage(int /*h*/, void*)
         points.push_back(pts);
     }
 
-    for(size_t i = 0; i < points.size(); i++)
-    {
+    for(size_t i = 0; i < points.size(); i++){
         vector<Point2f> pts = points[i];
 
-        //At least 5 points can fit an ellipse
-        if (pts.size()<5) {
-            continue;
-        }
-        if (fitEllipseQ) {
+        if(pts.size() < 5) continue;
+
+        if(fitEllipseQ){
             box = fitEllipse(pts);
-            if (isGoodBox(box)) {
+            if(isGoodBox(box)){
                 paper.drawEllipseWithBox(box, fitEllipseColor, 3);
             }
         }
-        if (fitEllipseAMSQ) {
+        if(fitEllipseAMSQ){
             boxAMS = fitEllipseAMS(pts);
-            if (isGoodBox(boxAMS)) {
+            if(isGoodBox(boxAMS)){
                 paper.drawEllipseWithBox(boxAMS, fitEllipseAMSColor, 2);
             }
         }
-        if (fitEllipseDirectQ) {
+        if(fitEllipseDirectQ){
             boxDirect = fitEllipseDirect(pts);
-            if (isGoodBox(boxDirect)){
+            if(isGoodBox(boxDirect)){
                 paper.drawEllipseWithBox(boxDirect, fitEllipseDirectColor, 1);
             }
         }
@@ -307,5 +281,8 @@ void processImage(int /*h*/, void*)
         paper.drawPoints(pts, fitEllipseTrueColor);
     }
 
-    imshow("result", paper.img);
+    string outputFilename = "result.jpg";
+    imwrite(outputFilename, paper.img);
+    cout << "Processed image saved as: " << outputFilename << endl;
 }
+
diff --git a/samples/cpp/flann_search_dataset.cpp b/samples/cpp/flann_search_dataset.cpp
index 01ef93f821..30d23f9cec 100644
--- a/samples/cpp/flann_search_dataset.cpp
+++ b/samples/cpp/flann_search_dataset.cpp
@@ -12,6 +12,7 @@
 using namespace cv;
 using std::cout;
 using std::endl;
+using std::string;
 
 #define _ORB_
 
@@ -33,10 +34,10 @@ struct img_info {
 };
 
 
-int main( int argc, char* argv[] )
+int main(int argc, char* argv[])
 {
-    //-- Test the program options
-    CommandLineParser parser( argc, argv, keys );
+    // Test the program options
+    CommandLineParser parser(argc, argv, keys);
     if (parser.has("help"))
     {
         parser.printMessage();
@@ -44,17 +45,17 @@ int main( int argc, char* argv[] )
     }
 
     const cv::String img_path = parser.get<String>("image");
-    Mat img = imread( samples::findFile( img_path ), IMREAD_GRAYSCALE );
-    if (img.empty() )
+    Mat img = imread(samples::findFile(img_path), IMREAD_GRAYSCALE);
+    if (img.empty())
     {
-        cout << "Could not open the image "<< img_path << endl;
+        cout << "Could not open the image " << img_path << endl;
         return -1;
     }
 
     const cv::String db_path = parser.get<String>("dataset");
     if (!utils::fs::isDirectory(db_path))
     {
-        cout << "Dataset folder "<< db_path.c_str() <<" doesn't exist!" << endl;
+        cout << "Dataset folder " << db_path.c_str() << " doesn't exist!" << endl;
         return -1;
     }
 
@@ -68,11 +69,11 @@ int main( int argc, char* argv[] )
 
     const cv::String save_db_path = parser.get<String>("save");
 
-    //-- Step 1: Detect the keypoints using a detector, compute the descriptors
-    //   in the folder containing the images of the dataset
+    // Step 1: Detect the keypoints using a detector, compute the descriptors
+    // in the folder containing the images of the dataset
 #ifdef _SIFT_
     int minHessian = 400;
-    Ptr<Feature2D> detector = SIFT::create( minHessian );
+    Ptr<Feature2D> detector = SIFT::create(minHessian);
 #elif defined(_ORB_)
     Ptr<Feature2D> detector = ORB::create();
 #else
@@ -91,52 +92,52 @@ int main( int argc, char* argv[] )
     utils::fs::glob(db_path, cv::String(), files);
     for (std::vector<cv::String>::iterator itr = files.begin(); itr != files.end(); ++itr)
     {
-        Mat tmp_img = imread( *itr, IMREAD_GRAYSCALE );
+        Mat tmp_img = imread(*itr, IMREAD_GRAYSCALE);
         if (!tmp_img.empty())
         {
             std::vector<KeyPoint> kpts;
             Mat descriptors;
-            detector->detectAndCompute( tmp_img, noArray(), kpts, descriptors );
+            detector->detectAndCompute(tmp_img, noArray(), kpts, descriptors);
 
-            db_keypoints.insert( db_keypoints.end(), kpts.begin(), kpts.end() );
-            db_descriptors.push_back( descriptors );
-            db_images_indice_range.push_back( db_images_indice_range.back()
-                                              + static_cast<unsigned int>(kpts.size()) );
+            db_keypoints.insert(db_keypoints.end(), kpts.begin(), kpts.end());
+            db_descriptors.push_back(descriptors);
+            db_images_indice_range.push_back(db_images_indice_range.back()
+                                              + static_cast<unsigned int>(kpts.size()));
         }
     }
 
-    //-- Set the LUT
-    db_indice_2_image_lut.resize( db_images_indice_range.back() );
-    const int nbr_of_imgs = static_cast<int>( db_images_indice_range.size()-1 );
+    // Set the LUT
+    db_indice_2_image_lut.resize(db_images_indice_range.back());
+    const int nbr_of_imgs = static_cast<int>(db_images_indice_range.size() - 1);
     for (int i = 0; i < nbr_of_imgs; ++i)
     {
         const unsigned int first_indice = db_images_indice_range[i];
-        const unsigned int last_indice = db_images_indice_range[i+1];
-        std::fill( db_indice_2_image_lut.begin() + first_indice,
-                   db_indice_2_image_lut.begin() + last_indice,
-                   i );
+        const unsigned int last_indice = db_images_indice_range[i + 1];
+        std::fill(db_indice_2_image_lut.begin() + first_indice,
+                  db_indice_2_image_lut.begin() + last_indice,
+                  i);
     }
 
-    //-- Step 2: build the structure storing the descriptors
+    // Step 2: build the structure storing the descriptors
 #if defined(_SIFT_)
-    cv::Ptr<flann::GenericIndex<cvflann::L2<float> > > index;
+    cv::Ptr<flann::GenericIndex<cvflann::L2<float>>> index;
     if (load_db_path != String())
-        index = cv::makePtr<flann::GenericIndex<cvflann::L2<float> > >(db_descriptors,
-                                                             cvflann::SavedIndexParams(load_db_path));
+        index = cv::makePtr<flann::GenericIndex<cvflann::L2<float>>>(db_descriptors,
+                                                                     cvflann::SavedIndexParams(load_db_path));
     else
-        index = cv::makePtr<flann::GenericIndex<cvflann::L2<float> > >(db_descriptors,
-                                                             cvflann::KDTreeIndexParams(4));
+        index = cv::makePtr<flann::GenericIndex<cvflann::L2<float>>>(db_descriptors,
+                                                                     cvflann::KDTreeIndexParams(4));
 
 #elif defined(_ORB_)
-    cv::Ptr<flann::GenericIndex<cvflann::Hamming<unsigned char> > > index;
+    cv::Ptr<flann::GenericIndex<cvflann::Hamming<unsigned char>>> index;
     if (load_db_path != String())
-        index  = cv::makePtr<flann::GenericIndex<cvflann::Hamming<unsigned char> > >
+        index = cv::makePtr<flann::GenericIndex<cvflann::Hamming<unsigned char>>>
                 (db_descriptors, cvflann::SavedIndexParams(load_db_path));
     else
-        index  = cv::makePtr<flann::GenericIndex<cvflann::Hamming<unsigned char> > >
+        index = cv::makePtr<flann::GenericIndex<cvflann::Hamming<unsigned char>>>
                 (db_descriptors, cvflann::LshIndexParams());
 #else
-    cout<< "Descriptor not listed. Set the proper FLANN distance for this descriptor" <<endl;
+    cout << "Descriptor not listed. Set the proper FLANN distance for this descriptor" << endl;
     return -1;
 #endif
     if (save_db_path != String())
@@ -147,14 +148,14 @@ int main( int argc, char* argv[] )
     if (img_path == String())
         return 0;
 
-    //-- Detect the keypoints and compute the descriptors for the query image
+    // Detect the keypoints and compute the descriptors for the query image
     std::vector<KeyPoint> img_keypoints;
     Mat img_descriptors;
-    detector->detectAndCompute( img, noArray(), img_keypoints, img_descriptors );
+    detector->detectAndCompute(img, noArray(), img_keypoints, img_descriptors);
 
 
-    //-- Step 3: retrieve the descriptors in the dataset matching the ones of the query image
-    // /!\ knnSearch doesn't follow OpenCV standards by not initialising empty Mat properties
+    // Step 3: retrieve the descriptors in the dataset matching the ones of the query image
+    // knnSearch doesn't follow OpenCV standards by not initializing empty Mat properties
     const int knn = 2;
     Mat indices(img_descriptors.rows, knn, CV_32S);
 #if defined(_SIFT_)
@@ -164,49 +165,48 @@ int main( int argc, char* argv[] )
 #define DIST_TYPE int
     Mat dists(img_descriptors.rows, knn, CV_32S);
 #endif
-    index->knnSearch( img_descriptors, indices, dists, knn, cvflann::SearchParams(32) );
+    index->knnSearch(img_descriptors, indices, dists, knn, cvflann::SearchParams(32));
 
-    //-- Filter matches using the Lowe's ratio test
+    // Filter matches using the Lowe's ratio test
     const float ratio_thresh = 0.7f;
     std::vector<DMatch> good_matches; //contains
-    std::vector<unsigned int> matches_per_img_histogram( nbr_of_imgs, 0 );
+    std::vector<unsigned int> matches_per_img_histogram(nbr_of_imgs, 0);
     for (int i = 0; i < dists.rows; ++i)
     {
-        if (dists.at<DIST_TYPE>(i,0) < ratio_thresh * dists.at<DIST_TYPE>(i,1))
+        if (dists.at<DIST_TYPE>(i, 0) < ratio_thresh * dists.at<DIST_TYPE>(i, 1))
         {
-            const int indice_in_db = indices.at<int>(i,0);
+            const int indice_in_db = indices.at<int>(i, 0);
             DMatch dmatch(i, indice_in_db, db_indice_2_image_lut[indice_in_db],
-                          static_cast<float>(dists.at<DIST_TYPE>(i,0)));
-            good_matches.push_back( dmatch );
-            matches_per_img_histogram[ db_indice_2_image_lut[indice_in_db] ]++;
+                          static_cast<float>(dists.at<DIST_TYPE>(i, 0)));
+            good_matches.push_back(dmatch);
+            matches_per_img_histogram[db_indice_2_image_lut[indice_in_db]]++;
         }
     }
 
-
-    //-- Step 4: find the dataset image with the highest proportion of matches
+    // Step 4: find the dataset image with the highest proportion of matches
     std::multimap<float, img_info> images_infos;
     for (int i = 0; i < nbr_of_imgs; ++i)
     {
         const unsigned int nbr_of_matches = matches_per_img_histogram[i];
-        if (nbr_of_matches < 4) //we need at leat 4 points for a homography
+        if (nbr_of_matches < 4) //we need at least 4 points for a homography
             continue;
 
-        const unsigned int nbr_of_kpts = db_images_indice_range[i+1] - db_images_indice_range[i];
+        const unsigned int nbr_of_kpts = db_images_indice_range[i + 1] - db_images_indice_range[i];
         const float inverse_proportion_of_retrieved_kpts =
                 static_cast<float>(nbr_of_kpts) / static_cast<float>(nbr_of_matches);
 
         img_info info(i, nbr_of_matches);
-        images_infos.insert( std::pair<float,img_info>(inverse_proportion_of_retrieved_kpts,
-                                                       info) );
+        images_infos.insert(std::pair<float, img_info>(inverse_proportion_of_retrieved_kpts,
+                                                       info));
     }
 
     if (images_infos.begin() == images_infos.end())
     {
-        cout<<"No good match could be found."<<endl;
+        cout << "No good match could be found." << endl;
         return 0;
     }
 
-    //-- if there are several images with a similar proportion of matches,
+    // if there are several images with a similar proportion of matches,
     // select the one with the highest number of matches weighted by the
     // squared ratio of proportions
     const float best_matches_proportion = images_infos.begin()->first;
@@ -215,10 +215,10 @@ int main( int argc, char* argv[] )
 
     std::multimap<float, img_info>::iterator it = images_infos.begin();
     ++it;
-    while ((it!=images_infos.end()) && (it->first < 1.1*best_matches_proportion))
+    while ((it != images_infos.end()) && (it->first < 1.1 * best_matches_proportion))
     {
         const float ratio = new_matches_proportion / it->first;
-        if( it->second.nbr_of_matches * (ratio * ratio) > best_img.nbr_of_matches)
+        if (it->second.nbr_of_matches * (ratio * ratio) > best_img.nbr_of_matches)
         {
             new_matches_proportion = it->first;
             best_img = it->second;
@@ -226,7 +226,7 @@ int main( int argc, char* argv[] )
         ++it;
     }
 
-    //-- Step 5: filter goodmatches that belong to the best image match of the dataset
+    // Step 5: filter goodmatches that belong to the best image match of the dataset
     std::vector<DMatch> filtered_good_matches;
     for (std::vector<DMatch>::iterator itr(good_matches.begin()); itr != good_matches.end(); ++itr)
     {
@@ -234,17 +234,19 @@ int main( int argc, char* argv[] )
             filtered_good_matches.push_back(*itr);
     }
 
-    //-- Retrieve the best image match from the dataset
-    Mat db_img = imread( files[best_img.img_index], IMREAD_GRAYSCALE );
+    // Retrieve the best image match from the dataset
+    Mat db_img = imread(files[best_img.img_index], IMREAD_GRAYSCALE);
 
-    //-- Draw matches
+    // Draw matches and save the image
     Mat img_matches;
-    drawMatches( img, img_keypoints, db_img, db_keypoints, filtered_good_matches, img_matches, Scalar::all(-1),
-                 Scalar::all(-1), std::vector<char>(), DrawMatchesFlags::NOT_DRAW_SINGLE_POINTS );
+    drawMatches(img, img_keypoints, db_img, db_keypoints, filtered_good_matches, img_matches,
+                Scalar::all(-1), Scalar::all(-1), std::vector<char>(), DrawMatchesFlags::NOT_DRAW_SINGLE_POINTS);
 
-    //-- Show detected matches
-    imshow("Good Matches", img_matches );
-    waitKey();
+    // Save the result
+    std::string outputFilename = "good_matches.jpg";
+    imwrite(outputFilename, img_matches);
+    cout << "Processed image saved as: " << outputFilename << endl;
 
     return 0;
 }
+
diff --git a/samples/cpp/grabcut.cpp b/samples/cpp/grabcut.cpp
index 25492166a7..65a533083c 100644
--- a/samples/cpp/grabcut.cpp
+++ b/samples/cpp/grabcut.cpp
@@ -1,8 +1,11 @@
 #include "opencv2/imgcodecs.hpp"
-#include "opencv2/highgui.hpp"
 #include "opencv2/imgproc.hpp"
+#include "opencv2/highgui.hpp"
 
 #include <iostream>
+#include <string>
+#include <vector>
+#include <cstdlib>
 
 using namespace std;
 using namespace cv;
@@ -55,24 +58,22 @@ public:
 
     void reset();
     void setImageAndWinName( const Mat& _image, const string& _winName );
-    void showImage() const;
-    void mouseClick( int event, int x, int y, int flags, void* param );
+    void saveImage(const string& filename) const;
+    void process();
     int nextIter();
     int getIterCount() const { return iterCount; }
 private:
     void setRectInMask();
-    void setLblsInMask( int flags, Point p, bool isPr );
 
     const string* winName;
     const Mat* image;
     Mat mask;
     Mat bgdModel, fgdModel;
 
-    uchar rectState, lblsState, prLblsState;
+    uchar rectState;
     bool isInitialized;
 
     Rect rect;
-    vector<Point> fgdPxls, bgdPxls, prFgdPxls, prBgdPxls;
     int iterCount;
 };
 
@@ -80,13 +81,8 @@ void GCApplication::reset()
 {
     if( !mask.empty() )
         mask.setTo(Scalar::all(GC_BGD));
-    bgdPxls.clear(); fgdPxls.clear();
-    prBgdPxls.clear();  prFgdPxls.clear();
-
     isInitialized = false;
     rectState = NOT_SET;
-    lblsState = NOT_SET;
-    prLblsState = NOT_SET;
     iterCount = 0;
 }
 
@@ -100,7 +96,7 @@ void GCApplication::setImageAndWinName( const Mat& _image, const string& _winNam
     reset();
 }
 
-void GCApplication::showImage() const
+void GCApplication::saveImage(const string& filename) const
 {
     if( image->empty() || winName->empty() )
         return;
@@ -117,20 +113,14 @@ void GCApplication::showImage() const
         addWeighted(black, 0.5, res, 0.5, 0.0, res);
     }
 
-    vector<Point>::const_iterator it;
-    for( it = bgdPxls.begin(); it != bgdPxls.end(); ++it )
-        circle( res, *it, radius, BLUE, thickness );
-    for( it = fgdPxls.begin(); it != fgdPxls.end(); ++it )
-        circle( res, *it, radius, RED, thickness );
-    for( it = prBgdPxls.begin(); it != prBgdPxls.end(); ++it )
-        circle( res, *it, radius, LIGHTBLUE, thickness );
-    for( it = prFgdPxls.begin(); it != prFgdPxls.end(); ++it )
-        circle( res, *it, radius, PINK, thickness );
-
     if( rectState == IN_PROCESS || rectState == SET )
         rectangle( res, Point( rect.x, rect.y ), Point(rect.x + rect.width, rect.y + rect.height ), GREEN, 2);
 
-    imshow( *winName, res );
+    string outputDir = "grabcut";
+    system(("mkdir -p " + outputDir).c_str());
+    string outputPath = outputDir + "/" + filename;
+    imwrite(outputPath, res);
+    cout << "Processed image saved at: " << outputPath << endl;
 }
 
 void GCApplication::setRectInMask()
@@ -144,120 +134,14 @@ void GCApplication::setRectInMask()
     (mask(rect)).setTo( Scalar(GC_PR_FGD) );
 }
 
-void GCApplication::setLblsInMask( int flags, Point p, bool isPr )
-{
-    vector<Point> *bpxls, *fpxls;
-    uchar bvalue, fvalue;
-    if( !isPr )
-    {
-        bpxls = &bgdPxls;
-        fpxls = &fgdPxls;
-        bvalue = GC_BGD;
-        fvalue = GC_FGD;
-    }
-    else
-    {
-        bpxls = &prBgdPxls;
-        fpxls = &prFgdPxls;
-        bvalue = GC_PR_BGD;
-        fvalue = GC_PR_FGD;
-    }
-    if( flags & BGD_KEY )
-    {
-        bpxls->push_back(p);
-        circle( mask, p, radius, bvalue, thickness );
-    }
-    if( flags & FGD_KEY )
-    {
-        fpxls->push_back(p);
-        circle( mask, p, radius, fvalue, thickness );
-    }
-}
-
-void GCApplication::mouseClick( int event, int x, int y, int flags, void* )
+void GCApplication::process()
 {
-    // TODO add bad args check
-    switch( event )
-    {
-    case EVENT_LBUTTONDOWN: // set rect or GC_BGD(GC_FGD) labels
-        {
-            bool isb = (flags & BGD_KEY) != 0,
-                 isf = (flags & FGD_KEY) != 0;
-            if( rectState == NOT_SET && !isb && !isf )
-            {
-                rectState = IN_PROCESS;
-                rect = Rect( x, y, 1, 1 );
-            }
-            if ( (isb || isf) && rectState == SET )
-                lblsState = IN_PROCESS;
-        }
-        break;
-    case EVENT_RBUTTONDOWN: // set GC_PR_BGD(GC_PR_FGD) labels
-        {
-            bool isb = (flags & BGD_KEY) != 0,
-                 isf = (flags & FGD_KEY) != 0;
-            if ( (isb || isf) && rectState == SET )
-                prLblsState = IN_PROCESS;
-        }
-        break;
-    case EVENT_LBUTTONUP:
-        if( rectState == IN_PROCESS )
-        {
-            if(rect.x == x || rect.y == y){
-                rectState = NOT_SET;
-            }
-            else{
-                rect = Rect( Point(rect.x, rect.y), Point(x,y) );
-                rectState = SET;
-                setRectInMask();
-                CV_Assert( bgdPxls.empty() && fgdPxls.empty() && prBgdPxls.empty() && prFgdPxls.empty() );
-            }
-            showImage();
-        }
-        if( lblsState == IN_PROCESS )
-        {
-            setLblsInMask(flags, Point(x,y), false);
-            lblsState = SET;
-            nextIter();
-            showImage();
-        }
-        else{
-            if(rectState == SET){
-                nextIter();
-                showImage();
-            }
-        }
-        break;
-    case EVENT_RBUTTONUP:
-        if( prLblsState == IN_PROCESS )
-        {
-            setLblsInMask(flags, Point(x,y), true);
-            prLblsState = SET;
-        }
-        if(rectState == SET){
-            nextIter();
-            showImage();
-        }
-        break;
-    case EVENT_MOUSEMOVE:
-        if( rectState == IN_PROCESS )
-        {
-            rect = Rect( Point(rect.x, rect.y), Point(x,y) );
-            CV_Assert( bgdPxls.empty() && fgdPxls.empty() && prBgdPxls.empty() && prFgdPxls.empty() );
-            showImage();
-        }
-        else if( lblsState == IN_PROCESS )
-        {
-            setLblsInMask(flags, Point(x,y), false);
-            showImage();
-        }
-        else if( prLblsState == IN_PROCESS )
-        {
-            setLblsInMask(flags, Point(x,y), true);
-            showImage();
-        }
-        break;
-    }
+    // Assuming the rectangle is set for now for demo purposes
+    rect = Rect(10, 10, image->cols - 20, image->rows - 20);
+    rectState = SET;
+    setRectInMask();
+    nextIter();
+    saveImage("result.png");
 }
 
 int GCApplication::nextIter()
@@ -269,31 +153,20 @@ int GCApplication::nextIter()
         if( rectState != SET )
             return iterCount;
 
-        if( lblsState == SET || prLblsState == SET )
-            grabCut( *image, mask, rect, bgdModel, fgdModel, 1, GC_INIT_WITH_MASK );
-        else
-            grabCut( *image, mask, rect, bgdModel, fgdModel, 1, GC_INIT_WITH_RECT );
+        grabCut( *image, mask, rect, bgdModel, fgdModel, 1, GC_INIT_WITH_RECT );
 
         isInitialized = true;
     }
     iterCount++;
 
-    bgdPxls.clear(); fgdPxls.clear();
-    prBgdPxls.clear(); prFgdPxls.clear();
-
     return iterCount;
 }
 
 GCApplication gcapp;
 
-static void on_mouse( int event, int x, int y, int flags, void* param )
-{
-    gcapp.mouseClick( event, x, y, flags, param );
-}
-
 int main( int argc, char** argv )
 {
-    cv::CommandLineParser parser(argc, argv, "{@input| messi5.jpg |}");
+    cv::CommandLineParser parser(argc, argv, "{@input|../../samples/data/messi5.jpg|}");
     help(argv);
 
     string filename = parser.get<string>("@input");
@@ -310,41 +183,10 @@ int main( int argc, char** argv )
     }
 
     const string winName = "image";
-    namedWindow( winName, WINDOW_AUTOSIZE );
-    setMouseCallback( winName, on_mouse, 0 );
 
     gcapp.setImageAndWinName( image, winName );
-    gcapp.showImage();
-
-    for(;;)
-    {
-        char c = (char)waitKey(0);
-        switch( c )
-        {
-        case '\x1b':
-            cout << "Exiting ..." << endl;
-            goto exit_main;
-        case 'r':
-            cout << endl;
-            gcapp.reset();
-            gcapp.showImage();
-            break;
-        case 'n':
-            int iterCount = gcapp.getIterCount();
-            cout << "<" << iterCount << "... ";
-            int newIterCount = gcapp.nextIter();
-            if( newIterCount > iterCount )
-            {
-                gcapp.showImage();
-                cout << iterCount << ">" << endl;
-            }
-            else
-                cout << "rect must be determined>" << endl;
-            break;
-        }
-    }
+    gcapp.process();
 
-exit_main:
-    destroyWindow( winName );
     return 0;
 }
+
diff --git a/samples/cpp/image_alignment.cpp b/samples/cpp/image_alignment.cpp
index fc7ab18a71..040c6ffa3e 100644
--- a/samples/cpp/image_alignment.cpp
+++ b/samples/cpp/image_alignment.cpp
@@ -59,7 +59,6 @@ const std::string keys =
 
 static void help(const char** argv)
 {
-
     cout << "\nThis file demonstrates the use of the ECC image alignment algorithm. When one image"
         " is given, the template image is artificially formed by a random warp. When both images"
         " are given, the initialization of the warp by command line parsing is possible. "
@@ -74,19 +73,18 @@ static void help(const char** argv)
          << argv[0]
          << " yourInput.png yourTemplate.png "
         "yourInitialWarp.ecc -o=outWarp.ecc -m=homography -e=1e-6 -N=70 -v=1 -w=yourFinalImage.png \n" << endl;
-
 }
 
-static int readWarp(string iFilename, Mat& warp, int motionType){
-
+static int readWarp(string iFilename, Mat& warp, int motionType)
+{
     // it reads from file a specific number of raw values:
     // 9 values for homography, 6 otherwise
-    CV_Assert(warp.type()==CV_32FC1);
+    CV_Assert(warp.type() == CV_32FC1);
     int numOfElements;
-    if (motionType==MOTION_HOMOGRAPHY)
-        numOfElements=9;
+    if (motionType == MOTION_HOMOGRAPHY)
+        numOfElements = 9;
     else
-        numOfElements=6;
+        numOfElements = 6;
 
     int i;
     int ret_value;
@@ -94,7 +92,7 @@ static int readWarp(string iFilename, Mat& warp, int motionType){
     ifstream myfile(iFilename.c_str());
     if (myfile.is_open()){
         float* matPtr = warp.ptr<float>(0);
-        for(i=0; i<numOfElements; i++){
+        for (i = 0; i < numOfElements; i++){
             myfile >> matPtr[i];
         }
         ret_value = 1;
@@ -109,27 +107,26 @@ static int readWarp(string iFilename, Mat& warp, int motionType){
 static int saveWarp(string fileName, const Mat& warp, int motionType)
 {
     // it saves the raw matrix elements in a file
-    CV_Assert(warp.type()==CV_32FC1);
+    CV_Assert(warp.type() == CV_32FC1);
 
     const float* matPtr = warp.ptr<float>(0);
     int ret_value;
 
     ofstream outfile(fileName.c_str());
-    if( !outfile ) {
+    if (!outfile) {
         cerr << "error in saving "
             << "Couldn't open file '" << fileName.c_str() << "'!" << endl;
         ret_value = 0;
     }
-    else {//save the warp's elements
+    else { //save the warp's elements
         outfile << matPtr[0] << " " << matPtr[1] << " " << matPtr[2] << endl;
         outfile << matPtr[3] << " " << matPtr[4] << " " << matPtr[5] << endl;
-        if (motionType==MOTION_HOMOGRAPHY){
+        if (motionType == MOTION_HOMOGRAPHY){
             outfile << matPtr[6] << " " << matPtr[7] << " " << matPtr[8] << endl;
         }
         ret_value = 1;
     }
     return ret_value;
-
 }
 
 
@@ -137,14 +134,14 @@ static void draw_warped_roi(Mat& image, const int width, const int height, Mat&
 {
     Point2f top_left, top_right, bottom_left, bottom_right;
 
-    Mat  H = Mat (3, 1, CV_32F);
-    Mat  U = Mat (3, 1, CV_32F);
+    Mat  H = Mat(3, 1, CV_32F);
+    Mat  U = Mat(3, 1, CV_32F);
 
-    Mat warp_mat = Mat::eye (3, 3, CV_32F);
+    Mat warp_mat = Mat::eye(3, 3, CV_32F);
 
     for (int y = 0; y < W.rows; y++)
         for (int x = 0; x < W.cols; x++)
-            warp_mat.at<float>(y,x) = W.at<float>(y,x);
+            warp_mat.at<float>(y, x) = W.at<float>(y, x);
 
     //warp the corners of rectangle
 
@@ -175,9 +172,8 @@ static void draw_warped_roi(Mat& image, const int width, const int height, Mat&
     line(image, bottom_left, top_left, Scalar(255));
 }
 
-int main (const int argc, const char * argv[])
+int main(const int argc, const char* argv[])
 {
-
     CommandLineParser parser(argc, argv, keys);
     parser.about("ECC demo");
 
@@ -219,63 +215,61 @@ int main (const int argc, const char * argv[])
     Mat inputImage = imread(samples::findFile(imgFile), IMREAD_GRAYSCALE);
     if (inputImage.empty())
     {
-        cerr << "Unable to load the inputImage" <<  endl;
+        cerr << "Unable to load the inputImage" << endl;
         return -1;
     }
 
     Mat target_image;
     Mat template_image;
 
-    if (tempImgFile!="") {
+    if (tempImgFile != "") {
         inputImage.copyTo(target_image);
         template_image = imread(samples::findFile(tempImgFile), IMREAD_GRAYSCALE);
         if (template_image.empty()){
             cerr << "Unable to load the template image" << endl;
             return -1;
         }
-
     }
-    else{ //apply random warp to input image
+    else { //apply random warp to input image
         resize(inputImage, target_image, Size(216, 216), 0, 0, INTER_LINEAR_EXACT);
         Mat warpGround;
         RNG rng(getTickCount());
         double angle;
         switch (mode_temp) {
         case MOTION_TRANSLATION:
-            warpGround = (Mat_<float>(2,3) << 1, 0, (rng.uniform(10.f, 20.f)),
+            warpGround = (Mat_<float>(2, 3) << 1, 0, (rng.uniform(10.f, 20.f)),
                 0, 1, (rng.uniform(10.f, 20.f)));
             warpAffine(target_image, template_image, warpGround,
-                Size(200,200), INTER_LINEAR + WARP_INVERSE_MAP);
+                Size(200, 200), INTER_LINEAR + WARP_INVERSE_MAP);
             break;
         case MOTION_EUCLIDEAN:
-            angle = CV_PI/30 + CV_PI*rng.uniform((double)-2.f, (double)2.f)/180;
+            angle = CV_PI / 30 + CV_PI * rng.uniform((double)-2.f, (double)2.f) / 180;
 
-            warpGround = (Mat_<float>(2,3) << cos(angle), -sin(angle), (rng.uniform(10.f, 20.f)),
+            warpGround = (Mat_<float>(2, 3) << cos(angle), -sin(angle), (rng.uniform(10.f, 20.f)),
                 sin(angle), cos(angle), (rng.uniform(10.f, 20.f)));
             warpAffine(target_image, template_image, warpGround,
-                Size(200,200), INTER_LINEAR + WARP_INVERSE_MAP);
+                Size(200, 200), INTER_LINEAR + WARP_INVERSE_MAP);
             break;
         case MOTION_AFFINE:
 
-            warpGround = (Mat_<float>(2,3) << (1-rng.uniform(-0.05f, 0.05f)),
+            warpGround = (Mat_<float>(2, 3) << (1 - rng.uniform(-0.05f, 0.05f)),
                 (rng.uniform(-0.03f, 0.03f)), (rng.uniform(10.f, 20.f)),
-                (rng.uniform(-0.03f, 0.03f)), (1-rng.uniform(-0.05f, 0.05f)),
+                (rng.uniform(-0.03f, 0.03f)), (1 - rng.uniform(-0.05f, 0.05f)),
                 (rng.uniform(10.f, 20.f)));
             warpAffine(target_image, template_image, warpGround,
-                Size(200,200), INTER_LINEAR + WARP_INVERSE_MAP);
+                Size(200, 200), INTER_LINEAR + WARP_INVERSE_MAP);
             break;
         case MOTION_HOMOGRAPHY:
-            warpGround = (Mat_<float>(3,3) << (1-rng.uniform(-0.05f, 0.05f)),
+            warpGround = (Mat_<float>(3, 3) << (1 - rng.uniform(-0.05f, 0.05f)),
                 (rng.uniform(-0.03f, 0.03f)), (rng.uniform(10.f, 20.f)),
-                (rng.uniform(-0.03f, 0.03f)), (1-rng.uniform(-0.05f, 0.05f)),(rng.uniform(10.f, 20.f)),
+                (rng.uniform(-0.03f, 0.03f)), (1 - rng.uniform(-0.05f, 0.05f)), (rng.uniform(10.f, 20.f)),
                 (rng.uniform(0.0001f, 0.0003f)), (rng.uniform(0.0001f, 0.0003f)), 1.f);
             warpPerspective(target_image, template_image, warpGround,
-                Size(200,200), INTER_LINEAR + WARP_INVERSE_MAP);
+                Size(200, 200), INTER_LINEAR + WARP_INVERSE_MAP);
             break;
         }
     }
 
-
     const int warp_mode = mode_temp;
 
     // initialize or load the warp matrix
@@ -285,7 +279,7 @@ int main (const int argc, const char * argv[])
     else
         warp_matrix = Mat::eye(2, 3, CV_32F);
 
-    if (inWarpFile!=""){
+    if (inWarpFile != ""){
         int readflag = readWarp(inWarpFile, warp_matrix, warp_mode);
         if ((!readflag) || warp_matrix.empty())
         {
@@ -294,11 +288,9 @@ int main (const int argc, const char * argv[])
         }
     }
     else {
-
         printf("\n ->Performance Warning: Identity warp ideally assumes images of "
             "similar size. If the deformation is strong, the identity warp may not "
             "be a good initialization. \n");
-
     }
 
     if (number_of_iterations > 200)
@@ -308,10 +300,10 @@ int main (const int argc, const char * argv[])
         warp_matrix.rows = 2;
 
     // start timing
-    const double tic_init = (double) getTickCount ();
-    double cc = findTransformECC (template_image, target_image, warp_matrix, warp_mode,
-        TermCriteria (TermCriteria::COUNT+TermCriteria::EPS,
-        number_of_iterations, termination_eps));
+    const double tic_init = (double)getTickCount();
+    double cc = findTransformECC(template_image, target_image, warp_matrix, warp_mode,
+        TermCriteria(TermCriteria::COUNT + TermCriteria::EPS,
+            number_of_iterations, termination_eps));
 
     if (cc == -1)
     {
@@ -320,13 +312,12 @@ int main (const int argc, const char * argv[])
     }
 
     // end timing
-    const double toc_final  = (double) getTickCount ();
-    const double total_time = (toc_final-tic_init)/(getTickFrequency());
+    const double toc_final = (double)getTickCount();
+    const double total_time = (toc_final - tic_init) / (getTickFrequency());
     if (verbose){
         cout << "Alignment time (" << warpType << " transformation): "
             << total_time << " sec" << endl << flush;
         //  cout << "Final correlation: " << cc << endl << flush;
-
     }
 
     // save the final warp matrix
@@ -339,36 +330,36 @@ int main (const int argc, const char * argv[])
     // save the final warped image
     Mat warped_image = Mat(template_image.rows, template_image.cols, CV_32FC1);
     if (warp_mode != MOTION_HOMOGRAPHY)
-        warpAffine      (target_image, warped_image, warp_matrix, warped_image.size(),
-        INTER_LINEAR + WARP_INVERSE_MAP);
+        warpAffine(target_image, warped_image, warp_matrix, warped_image.size(),
+            INTER_LINEAR + WARP_INVERSE_MAP);
     else
-        warpPerspective (target_image, warped_image, warp_matrix, warped_image.size(),
-        INTER_LINEAR + WARP_INVERSE_MAP);
+        warpPerspective(target_image, warped_image, warp_matrix, warped_image.size(),
+            INTER_LINEAR + WARP_INVERSE_MAP);
 
-    //save the warped image
+    // save the warped image
     imwrite(warpedImFile, warped_image);
 
     // display resulting images
     if (verbose)
     {
-
         cout << "The warped image has been saved in the file: " << warpedImFile << endl << flush;
 
-        namedWindow ("image",    WINDOW_AUTOSIZE);
-        namedWindow ("template", WINDOW_AUTOSIZE);
-        namedWindow ("warped image",   WINDOW_AUTOSIZE);
-        namedWindow ("error (black: no error)", WINDOW_AUTOSIZE);
+        // 注释掉图形显示相关的代码
+        // namedWindow("image", WINDOW_AUTOSIZE);
+        // namedWindow("template", WINDOW_AUTOSIZE);
+        // namedWindow("warped image", WINDOW_AUTOSIZE);
+        // namedWindow("error (black: no error)", WINDOW_AUTOSIZE);
 
-        moveWindow  ("image", 20, 300);
-        moveWindow  ("template", 300, 300);
-        moveWindow  ("warped image",   600, 300);
-        moveWindow  ("error (black: no error)", 900, 300);
+        // moveWindow("image", 20, 300);
+        // moveWindow("template", 300, 300);
+        // moveWindow("warped image", 600, 300);
+        // moveWindow("error (black: no error)", 900, 300);
 
         // draw boundaries of corresponding regions
-        Mat identity_matrix = Mat::eye(3,3,CV_32F);
+        Mat identity_matrix = Mat::eye(3, 3, CV_32F);
 
-        draw_warped_roi (target_image,   template_image.cols-2, template_image.rows-2, warp_matrix);
-        draw_warped_roi (template_image, template_image.cols-2, template_image.rows-2, identity_matrix);
+        draw_warped_roi(target_image, template_image.cols - 2, template_image.rows - 2, warp_matrix);
+        draw_warped_roi(template_image, template_image.cols - 2, template_image.rows - 2, identity_matrix);
 
         Mat errorImage;
         subtract(template_image, warped_image, errorImage);
@@ -378,17 +369,18 @@ int main (const int argc, const char * argv[])
         // show images
         cout << "Press any key to exit the demo (you might need to click on the images before)." << endl << flush;
 
-        imshow ("image",    target_image);
-        waitKey (200);
-        imshow ("template", template_image);
-        waitKey (200);
-        imshow ("warped image",   warped_image);
-        waitKey(200);
-        imshow ("error (black: no error)",  abs(errorImage)*255/max_of_error);
-        waitKey(0);
-
+        // 注释掉图形显示相关的代码
+        // imshow("image", target_image);
+        // waitKey(200);
+        // imshow("template", template_image);
+        // waitKey(200);
+        // imshow("warped image", warped_image);
+        // waitKey(200);
+        // imshow("error (black: no error)", abs(errorImage) * 255 / max_of_error);
+        // waitKey(0);
     }
 
     // done
     return 0;
 }
+
diff --git a/samples/cpp/imagelist_creator.cpp b/samples/cpp/imagelist_creator.cpp
index 5b2dc38d47..7f51696716 100644
--- a/samples/cpp/imagelist_creator.cpp
+++ b/samples/cpp/imagelist_creator.cpp
@@ -1,5 +1,4 @@
-/*this creates a yaml or xml list of files from the command line args
- */
+/* This creates a yaml or xml list of files from the command line args */
 
 #include "opencv2/core.hpp"
 #include "opencv2/imgcodecs.hpp"
@@ -15,40 +14,50 @@ using namespace cv;
 
 static void help(char** av)
 {
-  cout << "\nThis creates a yaml or xml list of files from the command line args\n"
-      "usage:\n./" << av[0] << " imagelist.yaml *.png\n"
-      << "Try using different extensions.(e.g. yaml yml xml xml.gz etc...)\n"
-      << "This will serialize this list of images or whatever with opencv's FileStorage framework" << endl;
+    cout << "\nThis creates a yaml or xml list of files from the command line args\n"
+         << "usage:\n./" << av[0] << " imagelist.yaml *.png\n"
+         << "Try using different extensions.(e.g. yaml yml xml xml.gz etc...)\n"
+         << "This will serialize this list of images or whatever with opencv's FileStorage framework" << endl;
 }
 
 int main(int ac, char** av)
 {
-  cv::CommandLineParser parser(ac, av, "{help h||}{@output||}");
-  if (parser.has("help"))
-  {
-    help(av);
+    cv::CommandLineParser parser(ac, av, "{help h||}{@output||}");
+    if (parser.has("help"))
+    {
+        help(av);
+        return 0;
+    }
+    string outputname = parser.get<string>("@output");
+
+    if (outputname.empty())
+    {
+        help(av);
+        return 1;
+    }
+
+    Mat m = imread(outputname); // check if the output is an image - prevent overwrites!
+    if (!m.empty())
+    {
+        std::cerr << "fail! Please specify an output file, don't want to overwrite your images!" << endl;
+        help(av);
+        return 1;
+    }
+
+    FileStorage fs(outputname, FileStorage::WRITE);
+    fs << "images" << "[";
+    for (int i = 2; i < ac; i++)
+    {
+        fs << string(av[i]);
+    }
+    fs << "]";
+
+    // 注释掉所有与图形显示相关的代码
+    /*
+    imshow("Image", m);
+    waitKey(0);
+    */
+
     return 0;
-  }
-  string outputname = parser.get<string>("@output");
-
-  if (outputname.empty())
-  {
-    help(av);
-    return 1;
-  }
-
-  Mat m = imread(outputname); //check if the output is an image - prevent overwrites!
-  if(!m.empty()){
-    std::cerr << "fail! Please specify an output file, don't want to overwrite you images!" << endl;
-    help(av);
-    return 1;
-  }
-
-  FileStorage fs(outputname, FileStorage::WRITE);
-  fs << "images" << "[";
-  for(int i = 2; i < ac; i++){
-    fs << string(av[i]);
-  }
-  fs << "]";
-  return 0;
 }
+
diff --git a/samples/cpp/imagelist_reader.cpp b/samples/cpp/imagelist_reader.cpp
index 1d209b93a7..60e51435f0 100644
--- a/samples/cpp/imagelist_reader.cpp
+++ b/samples/cpp/imagelist_reader.cpp
@@ -16,65 +16,76 @@ using namespace std;
 
 static void help(char** av)
 {
-  cout << "\nThis program gets you started being able to read images from a list in a file\n"
-          "Usage:\n./" << av[0] << " image_list.yaml\n"
-       << "\tThis is a starter sample, to get you up and going in a copy pasta fashion.\n"
-       << "\tThe program reads in an list of images from a yaml or xml file and displays\n"
-       << "one at a time\n"
-       << "\tTry running imagelist_creator to generate a list of images.\n"
-        "Using OpenCV version %s\n" << CV_VERSION << "\n" << endl;
+    cout << "\nThis program gets you started being able to read images from a list in a file\n"
+            "Usage:\n./" << av[0] << " image_list.yaml\n"
+         << "\tThis is a starter sample, to get you up and going in a copy pasta fashion.\n"
+         << "\tThe program reads in a list of images from a yaml or xml file and displays\n"
+         << "one at a time\n"
+         << "\tTry running imagelist_creator to generate a list of images.\n"
+         "Using OpenCV version " << CV_VERSION << "\n" << endl;
 }
 
 static bool readStringList(const string& filename, vector<string>& l)
 {
-  l.resize(0);
-  FileStorage fs(filename, FileStorage::READ);
-  if (!fs.isOpened())
-    return false;
-  FileNode n = fs.getFirstTopLevelNode();
-  if (n.type() != FileNode::SEQ)
-    return false;
-  FileNodeIterator it = n.begin(), it_end = n.end();
-  for (; it != it_end; ++it)
-    l.push_back((string)*it);
-  return true;
+    l.resize(0);
+    FileStorage fs(filename, FileStorage::READ);
+    if (!fs.isOpened())
+        return false;
+    FileNode n = fs.getFirstTopLevelNode();
+    if (n.type() != FileNode::SEQ)
+        return false;
+    FileNodeIterator it = n.begin(), it_end = n.end();
+    for (; it != it_end; ++it)
+        l.push_back((string)*it);
+    return true;
 }
 
 static int process(const vector<string>& images)
 {
-    namedWindow("image", WINDOW_KEEPRATIO); //resizable window;
     for (size_t i = 0; i < images.size(); i++)
     {
         Mat image = imread(images[i], IMREAD_GRAYSCALE); // do grayscale processing?
-        imshow("image",image);
+        // 注释掉所有与图形显示相关的代码
+        /*
+        namedWindow("image", WINDOW_KEEPRATIO); // resizable window;
+        imshow("image", image);
         cout << "Press a key to see the next image in the list." << endl;
         waitKey(); // wait infinitely for a key to be pressed
+        */
+        cout << "Processing image: " << images[i] << endl;
+        if (image.empty())
+        {
+            cerr << "Could not open or find the image " << images[i] << endl;
+            return 1;
+        }
+        // 其他图像处理代码可以在这里添加
     }
     return 0;
 }
 
 int main(int ac, char** av)
 {
-  cv::CommandLineParser parser(ac, av, "{help h||}{@input||}");
-  if (parser.has("help"))
-  {
-      help(av);
-      return 0;
-  }
-  std::string arg = parser.get<std::string>("@input");
-  if (arg.empty())
-  {
-    help(av);
-    return 1;
-  }
-  vector<string> imagelist;
+    cv::CommandLineParser parser(ac, av, "{help h||}{@input||}");
+    if (parser.has("help"))
+    {
+        help(av);
+        return 0;
+    }
+    std::string arg = parser.get<std::string>("@input");
+    if (arg.empty())
+    {
+        help(av);
+        return 1;
+    }
+    vector<string> imagelist;
 
-  if (!readStringList(arg,imagelist))
-  {
-    cerr << "Failed to read image list\n" << endl;
-    help(av);
-    return 1;
-  }
+    if (!readStringList(arg, imagelist))
+    {
+        cerr << "Failed to read image list\n" << endl;
+        help(av);
+        return 1;
+    }
 
-  return process(imagelist);
+    return process(imagelist);
 }
+
diff --git a/samples/cpp/imgcodecs_jpeg.cpp b/samples/cpp/imgcodecs_jpeg.cpp
index 4c22a483d7..997ef44b22 100644
--- a/samples/cpp/imgcodecs_jpeg.cpp
+++ b/samples/cpp/imgcodecs_jpeg.cpp
@@ -7,76 +7,82 @@
 using namespace std;
 using namespace cv;
 
-int main(int /*argc*/, const char** /* argv */ )
+int main(int argc, const char** argv)
 {
-    Mat framebuffer( 160 * 2, 160 * 5, CV_8UC3, cv::Scalar::all(255) );
+    if (argc < 2) {
+        cerr << "Usage: " << argv[0] << " <output_image_name>\n";
+        return 1;
+    }
 
-    Mat img( 160, 160, CV_8UC3, cv::Scalar::all(255) );
+    string outputImageName = argv[1];
+    Mat framebuffer(160 * 2, 160 * 5, CV_8UC3, cv::Scalar::all(255));
+    Mat img(160, 160, CV_8UC3, cv::Scalar::all(255));
 
     // Create test image.
     {
-        const Point center( img.rows / 2 , img.cols /2 );
-
-        for( int radius = 5; radius < img.rows ; radius += 3 )
-        {
-            cv::circle( img, center, radius, Scalar(255,0,255) );
+        const Point center(img.rows / 2, img.cols / 2);
+        for (int radius = 5; radius < img.rows; radius += 3) {
+            cv::circle(img, center, radius, Scalar(255, 0, 255));
         }
-        cv::rectangle( img, Point(0,0), Point(img.rows-1, img.cols-1), Scalar::all(0), 2 );
+        cv::rectangle(img, Point(0, 0), Point(img.rows - 1, img.cols - 1), Scalar::all(0), 2);
     }
 
     // Draw original image(s).
     int top = 0; // Upper images
     {
-        for( int left = 0 ; left < img.rows * 5 ; left += img.rows ){
-            Mat roi = framebuffer( Rect( left, top, img.rows, img.cols ) );
+        for (int left = 0; left < img.rows * 5; left += img.rows) {
+            Mat roi = framebuffer(Rect(left, top, img.rows, img.cols));
             img.copyTo(roi);
 
-            cv::putText( roi, "original", Point(5,15), FONT_HERSHEY_SIMPLEX, 0.5, Scalar::all(0), 2, 4, false );
+            // 注释掉图像显示相关的代码
+            // cv::putText(roi, "original", Point(5, 15), FONT_HERSHEY_SIMPLEX, 0.5, Scalar::all(0), 2, 4, false);
         }
     }
 
     // Draw lossy images
     top += img.cols; // Lower images
     {
-        struct test_config{
+        struct test_config {
             string comment;
             uint32_t sampling_factor;
-        } config [] = {
-            { "411", IMWRITE_JPEG_SAMPLING_FACTOR_411 },
-            { "420", IMWRITE_JPEG_SAMPLING_FACTOR_420 },
-            { "422", IMWRITE_JPEG_SAMPLING_FACTOR_422 },
-            { "440", IMWRITE_JPEG_SAMPLING_FACTOR_440 },
-            { "444", IMWRITE_JPEG_SAMPLING_FACTOR_444 },
+        } config[] = {
+            {"411", IMWRITE_JPEG_SAMPLING_FACTOR_411},
+            {"420", IMWRITE_JPEG_SAMPLING_FACTOR_420},
+            {"422", IMWRITE_JPEG_SAMPLING_FACTOR_422},
+            {"440", IMWRITE_JPEG_SAMPLING_FACTOR_440},
+            {"444", IMWRITE_JPEG_SAMPLING_FACTOR_444},
         };
 
         const int config_num = 5;
-
         int left = 0;
 
-        for ( int i = 0 ; i < config_num; i++ )
-        {
+        for (int i = 0; i < config_num; i++) {
             // Compress images with sampling factor parameter.
             vector<int> param;
-            param.push_back( IMWRITE_JPEG_SAMPLING_FACTOR );
-            param.push_back( config[i].sampling_factor );
+            param.push_back(IMWRITE_JPEG_SAMPLING_FACTOR);
+            param.push_back(config[i].sampling_factor);
             vector<uint8_t> jpeg;
-            (void) imencode(".jpg", img, jpeg, param );
+            (void)imencode(".jpg", img, jpeg, param);
 
             // Decompress it.
             Mat jpegMat(jpeg);
             Mat lossy_img = imdecode(jpegMat, -1);
 
             // Copy into framebuffer and comment
-            Mat roi = framebuffer( Rect( left, top, lossy_img.rows, lossy_img.cols ) );
+            Mat roi = framebuffer(Rect(left, top, lossy_img.rows, lossy_img.cols));
             lossy_img.copyTo(roi);
-            cv::putText( roi, config[i].comment, Point(5,155), FONT_HERSHEY_SIMPLEX, 0.5, Scalar::all(0), 2, 4, false );
+            // 注释掉图像显示相关的代码
+            // cv::putText(roi, config[i].comment, Point(5, 155), FONT_HERSHEY_SIMPLEX, 0.5, Scalar::all(0), 2, 4, false);
 
             left += lossy_img.rows;
         }
     }
 
     // Output framebuffer(as lossless).
-    imwrite( "imgcodecs_jpeg_samplingfactor_result.png", framebuffer );
+    imwrite(outputImageName, framebuffer);
+
+    cout << "Output image saved as: " << outputImageName << endl;
 
     return 0;
 }
+
diff --git a/samples/cpp/inpaint.cpp b/samples/cpp/inpaint.cpp
index cabf5528b4..f14e3975e8 100644
--- a/samples/cpp/inpaint.cpp
+++ b/samples/cpp/inpaint.cpp
@@ -8,84 +8,42 @@
 using namespace cv;
 using namespace std;
 
-static void help( char** argv )
+static void help(char** argv)
 {
-    cout << "\nCool inpainging demo. Inpainting repairs damage to images by floodfilling the damage \n"
+    cout << "\nCool inpainting demo. Inpainting repairs damage to images by floodfilling the damage \n"
             << "with surrounding image areas.\n"
-            "Using OpenCV version %s\n" << CV_VERSION << "\n"
-            "Usage:\n" << argv[0] <<" [image_name -- Default fruits.jpg]\n" << endl;
-
-    cout << "Hot keys: \n"
-        "\tESC - quit the program\n"
-        "\tr - restore the original image\n"
-        "\ti or SPACE - run inpainting algorithm\n"
-        "\t\t(before running it, paint something on the image)\n" << endl;
-}
-
-Mat img, inpaintMask;
-Point prevPt(-1,-1);
-
-static void onMouse( int event, int x, int y, int flags, void* )
-{
-    if( event == EVENT_LBUTTONUP || !(flags & EVENT_FLAG_LBUTTON) )
-        prevPt = Point(-1,-1);
-    else if( event == EVENT_LBUTTONDOWN )
-        prevPt = Point(x,y);
-    else if( event == EVENT_MOUSEMOVE && (flags & EVENT_FLAG_LBUTTON) )
-    {
-        Point pt(x,y);
-        if( prevPt.x < 0 )
-            prevPt = pt;
-        line( inpaintMask, prevPt, pt, Scalar::all(255), 5, 8, 0 );
-        line( img, prevPt, pt, Scalar::all(255), 5, 8, 0 );
-        prevPt = pt;
-        imshow("image", img);
-    }
+            "Using OpenCV version " << CV_VERSION << "\n"
+            "Usage:\n" << argv[0] << " [image_name -- Default fruits.jpg]\n" << endl;
 }
 
-
-int main( int argc, char** argv )
+int main(int argc, char** argv)
 {
     cv::CommandLineParser parser(argc, argv, "{@image|fruits.jpg|}");
     help(argv);
 
     string filename = samples::findFile(parser.get<string>("@image"));
     Mat img0 = imread(filename, IMREAD_COLOR);
-    if(img0.empty())
+    if (img0.empty())
     {
         cout << "Couldn't open the image " << filename << ". Usage: inpaint <image_name>\n" << endl;
         return 0;
     }
 
-    namedWindow("image", WINDOW_AUTOSIZE);
-
-    img = img0.clone();
-    inpaintMask = Mat::zeros(img.size(), CV_8U);
+    Mat img = img0.clone();
+    Mat inpaintMask = Mat::zeros(img.size(), CV_8U);
 
-    imshow("image", img);
-    setMouseCallback( "image", onMouse, NULL);
-
-    for(;;)
-    {
-        char c = (char)waitKey();
+    // Simulate drawing on the mask for demo purposes
+    rectangle(inpaintMask, Point(50, 50), Point(150, 150), Scalar::all(255), FILLED);
+    rectangle(img, Point(50, 50), Point(150, 150), Scalar::all(255), FILLED);
 
-        if( c == 27 )
-            break;
+    // Run inpainting algorithm
+    Mat inpainted;
+    inpaint(img, inpaintMask, inpainted, 3, INPAINT_TELEA);
 
-        if( c == 'r' )
-        {
-            inpaintMask = Scalar::all(0);
-            img0.copyTo(img);
-            imshow("image", img);
-        }
-
-        if( c == 'i' || c == ' ' )
-        {
-            Mat inpainted;
-            inpaint(img, inpaintMask, inpainted, 3, INPAINT_TELEA);
-            imshow("inpainted image", inpainted);
-        }
-    }
+    // Save the inpainted image
+    imwrite("inpainted_image.jpg", inpainted);
+    cout << "Inpainted image saved as: inpainted_image.jpg" << endl;
 
     return 0;
 }
+
diff --git a/samples/cpp/intelligent_scissors.cpp b/samples/cpp/intelligent_scissors.cpp
index 22f72d64e7..784613e686 100644
--- a/samples/cpp/intelligent_scissors.cpp
+++ b/samples/cpp/intelligent_scissors.cpp
@@ -228,8 +228,16 @@ int main( int argc, const char** argv )
     param.img.copyTo(param.img_pre_render);
     param.img.copyTo(param.img_render);
 
-    namedWindow("lasso");
-    setMouseCallback("lasso", onMouse, &param);
-    imshow("lasso", param.img);
-    waitKey(0);
+    //namedWindow("lasso");
+    //setMouseCallback("lasso", onMouse, &param);
+    //imshow("lasso", param.img);
+    //waitKey(0);
+
+    // 自动化图像处理和结果保存
+    Point startPoint(10, 10); // 起始点，可根据需要更改
+    find_min_path(startPoint, &param);
+    imwrite("output.png", param.img_render); // 保存处理结果
+
+    return 0;
 }
+
diff --git a/samples/cpp/intersectExample.cpp b/samples/cpp/intersectExample.cpp
index 187aebbea9..419fe4635d 100644
--- a/samples/cpp/intersectExample.cpp
+++ b/samples/cpp/intersectExample.cpp
@@ -149,11 +149,13 @@ static void intersectConvexExample()
 
     drawDescription(image, (int)intersectionArea, " (invalid input: not convex)", Point(70, 580));
 
-    imshow("Intersections", image);
-    waitKey(0);
+    //imshow("Intersections", image);
+    //waitKey(0);
+    imwrite("intersections_result.png", image);
 }
 
 int main()
 {
     intersectConvexExample();
 }
+
diff --git a/samples/cpp/kalman.cpp b/samples/cpp/kalman.cpp
index daf0ba5a71..80730fe528 100644
--- a/samples/cpp/kalman.cpp
+++ b/samples/cpp/kalman.cpp
@@ -26,8 +26,7 @@ static void help()
 "    the yellow segment should be shorter than the red one and\n"
 "    the green segment should be shorter than the yellow one)."
             "\n"
-"   Pressing any key (except ESC) will reset the tracking.\n"
-"   Pressing ESC will stop the program.\n"
+"   The program will run for a set number of iterations and then exit.\n"
             );
 }
 
@@ -39,9 +38,11 @@ int main(int, char**)
     Mat state(2, 1, CV_32F); /* (phi, delta_phi) */
     Mat processNoise(2, 1, CV_32F);
     Mat measurement = Mat::zeros(1, 1, CV_32F);
-    char code = (char)-1;
 
-    for(;;)
+    const int max_iterations = 100; // 设置最大迭代次数
+    int iteration_count = 0;
+
+    while(iteration_count < max_iterations)
     {
         img = Scalar::all(0);
         state.at<float>(0) = 0.0f;
@@ -94,19 +95,19 @@ int main(int, char**)
             line( img, statePt, predictPt, Scalar(0,255,255), 1, LINE_AA, 0 );
             line( img, statePt, improvedPt, Scalar(0,255,0), 1, LINE_AA, 0 );
 
-
             randn( processNoise, Scalar(0), Scalar::all(sqrt(KF.processNoiseCov.at<float>(0, 0))));
             state = KF.transitionMatrix*state + processNoise;
 
-            imshow( "Kalman", img );
-            code = (char)waitKey(1000);
+            imwrite("kalman_result.png", img); // 保存图像
 
-            if( code > 0 )
+            iteration_count++;
+            if(iteration_count >= max_iterations)
                 break;
         }
-        if( code == 27 || code == 'q' || code == 'Q' )
+        if(iteration_count >= max_iterations)
             break;
     }
 
     return 0;
 }
+
diff --git a/samples/cpp/kmeans.cpp b/samples/cpp/kmeans.cpp
index 0a2663ac7c..7aa11df88e 100644
--- a/samples/cpp/kmeans.cpp
+++ b/samples/cpp/kmeans.cpp
@@ -6,78 +6,70 @@
 using namespace cv;
 using namespace std;
 
-// static void help()
-// {
-//     cout << "\nThis program demonstrates kmeans clustering.\n"
-//             "It generates an image with random points, then assigns a random number of cluster\n"
-//             "centers and uses kmeans to move those cluster centers to their representitive location\n"
-//             "Call\n"
-//             "./kmeans\n" << endl;
-// }
-
-int main( int /*argc*/, char** /*argv*/ )
+int main(int, char**)
 {
     const int MAX_CLUSTERS = 5;
     Scalar colorTab[] =
     {
         Scalar(0, 0, 255),
-        Scalar(0,255,0),
-        Scalar(255,100,100),
-        Scalar(255,0,255),
-        Scalar(0,255,255)
+        Scalar(0, 255, 0),
+        Scalar(255, 100, 100),
+        Scalar(255, 0, 255),
+        Scalar(0, 255, 255)
     };
 
     Mat img(500, 500, CV_8UC3);
     RNG rng(12345);
+    const int max_iterations = 10; // 设置最大迭代次数
+    int iteration_count = 0;
 
-    for(;;)
+    while(iteration_count < max_iterations)
     {
-        int k, clusterCount = rng.uniform(2, MAX_CLUSTERS+1);
+        int k, clusterCount = rng.uniform(2, MAX_CLUSTERS + 1);
         int i, sampleCount = rng.uniform(1, 1001);
         Mat points(sampleCount, 1, CV_32FC2), labels;
 
         clusterCount = MIN(clusterCount, sampleCount);
         std::vector<Point2f> centers;
 
-        /* generate random sample from multigaussian distribution */
-        for( k = 0; k < clusterCount; k++ )
+        // 生成来自多高斯分布的随机样本
+        for(k = 0; k < clusterCount; k++)
         {
             Point center;
             center.x = rng.uniform(0, img.cols);
             center.y = rng.uniform(0, img.rows);
-            Mat pointChunk = points.rowRange(k*sampleCount/clusterCount,
+            Mat pointChunk = points.rowRange(k * sampleCount / clusterCount,
                                              k == clusterCount - 1 ? sampleCount :
-                                             (k+1)*sampleCount/clusterCount);
-            rng.fill(pointChunk, RNG::NORMAL, Scalar(center.x, center.y), Scalar(img.cols*0.05, img.rows*0.05));
+                                             (k + 1) * sampleCount / clusterCount);
+            rng.fill(pointChunk, RNG::NORMAL, Scalar(center.x, center.y), Scalar(img.cols * 0.05, img.rows * 0.05));
         }
 
         randShuffle(points, 1, &rng);
 
         double compactness = kmeans(points, clusterCount, labels,
-            TermCriteria( TermCriteria::EPS+TermCriteria::COUNT, 10, 1.0),
-               3, KMEANS_PP_CENTERS, centers);
+            TermCriteria(TermCriteria::EPS + TermCriteria::COUNT, 10, 1.0),
+            3, KMEANS_PP_CENTERS, centers);
 
         img = Scalar::all(0);
 
-        for( i = 0; i < sampleCount; i++ )
+        for(i = 0; i < sampleCount; i++)
         {
             int clusterIdx = labels.at<int>(i);
             Point ipt = points.at<Point2f>(i);
-            circle( img, ipt, 2, colorTab[clusterIdx], FILLED, LINE_AA );
+            circle(img, ipt, 2, colorTab[clusterIdx], FILLED, LINE_AA);
         }
-        for (i = 0; i < (int)centers.size(); ++i)
+        for(i = 0; i < (int)centers.size(); ++i)
         {
             Point2f c = centers[i];
-            circle( img, c, 40, colorTab[i], 1, LINE_AA );
+            circle(img, c, 40, colorTab[i], 1, LINE_AA);
         }
-        cout << "Compactness: " << compactness << endl;
+        cout << "Iteration: " << iteration_count + 1 << ", Compactness: " << compactness << endl;
 
-        imshow("clusters", img);
+        imwrite("clusters_" + to_string(iteration_count + 1) + ".png", img); // 保存图像
 
-        char key = (char)waitKey();
-        if( key == 27 || key == 'q' || key == 'Q' ) // 'ESC'
-            break;
+        iteration_count++;
     }
 
     return 0;
 }
+
diff --git a/samples/cpp/laplace.cpp b/samples/cpp/laplace.cpp
index e33a284a03..7d7d96c857 100644
--- a/samples/cpp/laplace.cpp
+++ b/samples/cpp/laplace.cpp
@@ -9,70 +9,46 @@
 using namespace cv;
 using namespace std;
 
-static void help(char** argv)
-{
-    cout <<
-            "\nThis program demonstrates Laplace point/edge detection using OpenCV function Laplacian()\n"
-            "It captures from the camera of your choice: 0, 1, ... default 0\n"
-            "Call:\n"
-         <<  argv[0] << " -c=<camera #, default 0> -p=<index of the frame to be decoded/captured next>\n" << endl;
-}
+// static void help(char** argv)
+// {
+//     cout <<
+//             "\nThis program demonstrates Laplace point/edge detection using OpenCV function Laplacian()\n"
+//             "It captures from the camera of your choice: 0, 1, ... default 0\n"
+//             "Call:\n"
+//          <<  argv[0] << " -c=<camera #, default 0> -p=<index of the frame to be decoded/captured next>\n" << endl;
+// }
 
 enum {GAUSSIAN, BLUR, MEDIAN};
 
 int sigma = 3;
 int smoothType = GAUSSIAN;
 
-int main( int argc, char** argv )
+int main(int argc, char** argv)
 {
-    cv::CommandLineParser parser(argc, argv, "{ c | 0 | }{ p | | }");
-    help(argv);
-
-    VideoCapture cap;
-    string camera = parser.get<string>("c");
-    if (camera.size() == 1 && isdigit(camera[0]))
-        cap.open(parser.get<int>("c"));
-    else
-        cap.open(samples::findFileOrKeep(camera));
-    if (!cap.isOpened())
-    {
-        cerr << "Can't open camera/video stream: " << camera << endl;
-        return 1;
-    }
-    cout << "Video " << parser.get<string>("c") <<
-        ": width=" << cap.get(CAP_PROP_FRAME_WIDTH) <<
-        ", height=" << cap.get(CAP_PROP_FRAME_HEIGHT) <<
-        ", nframes=" << cap.get(CAP_PROP_FRAME_COUNT) << endl;
-    int pos = 0;
-    if (parser.has("p"))
-    {
-        pos = parser.get<int>("p");
-    }
-    if (!parser.check())
-    {
-        parser.printErrors();
-        return -1;
-    }
+    cv::CommandLineParser parser(argc, argv, "{ i | fruits.jpg | }");
+    // help(argv);
 
-    if (pos != 0)
+    string input = parser.get<string>("i");
+    Mat frame = imread(samples::findFileOrKeep(input));
+    if (frame.empty())
     {
-        cout << "seeking to frame #" << pos << endl;
-        if (!cap.set(CAP_PROP_POS_FRAMES, pos))
-        {
-            cerr << "ERROR: seekeing is not supported" << endl;
-        }
+        cerr << "Can't open image: " << input << endl;
+        return 1;
     }
+    cout << "Image " << parser.get<string>("i") <<
+        ": width=" << frame.cols <<
+        ", height=" << frame.rows << endl;
 
-    namedWindow("Laplacian", WINDOW_AUTOSIZE);
-    createTrackbar("Sigma", "Laplacian", &sigma, 15, 0);
+    // namedWindow("Laplacian", WINDOW_AUTOSIZE);
+    // createTrackbar("Sigma", "Laplacian", &sigma, 15, 0);
 
     Mat smoothed, laplace, result;
+    const int max_iterations = 100; // 设置最大迭代次数
+    int iteration_count = 0;
 
-    for(;;)
+    while(iteration_count < max_iterations)
     {
-        Mat frame;
-        cap >> frame;
-        if( frame.empty() )
+        if(frame.empty())
             break;
 
         int ksize = (sigma*5)|1;
@@ -85,14 +61,19 @@ int main( int argc, char** argv )
 
         Laplacian(smoothed, laplace, CV_16S, 5);
         convertScaleAbs(laplace, result, (sigma+1)*0.25);
-        imshow("Laplacian", result);
 
-        char c = (char)waitKey(30);
-        if( c == ' ' )
-            smoothType = smoothType == GAUSSIAN ? BLUR : smoothType == BLUR ? MEDIAN : GAUSSIAN;
-        if( c == 'q' || c == 'Q' || c == 27 )
-            break;
+        // imshow("Laplacian", result);
+        imwrite("laplacian_" + to_string(iteration_count) + ".png", result); // 保存图像
+
+        // char c = (char)waitKey(30);
+        // if(c == ' ')
+        //     smoothType = smoothType == GAUSSIAN ? BLUR : smoothType == BLUR ? MEDIAN : GAUSSIAN;
+        // if(c == 'q' || c == 'Q' || c == 27)
+        //     break;
+
+        iteration_count++;
     }
 
     return 0;
 }
+
diff --git a/samples/cpp/letter_recog.cpp b/samples/cpp/letter_recog.cpp
index bcad2f4687..81fb856b4e 100644
--- a/samples/cpp/letter_recog.cpp
+++ b/samples/cpp/letter_recog.cpp
@@ -9,30 +9,30 @@ using namespace std;
 using namespace cv;
 using namespace cv::ml;
 
-static void help(char** argv)
-{
-    printf("\nThe sample demonstrates how to train Random Trees classifier\n"
-    "(or Boosting classifier, or MLP, or Knearest, or Nbayes, or Support Vector Machines - see main()) using the provided dataset.\n"
-    "\n"
-    "We use the sample database letter-recognition.data\n"
-    "from UCI Repository, here is the link:\n"
-    "\n"
-    "Newman, D.J. & Hettich, S. & Blake, C.L. & Merz, C.J. (1998).\n"
-    "UCI Repository of machine learning databases\n"
-    "[http://www.ics.uci.edu/~mlearn/MLRepository.html].\n"
-    "Irvine, CA: University of California, Department of Information and Computer Science.\n"
-    "\n"
-    "The dataset consists of 20000 feature vectors along with the\n"
-    "responses - capital latin letters A..Z.\n"
-    "The first 16000 (10000 for boosting)) samples are used for training\n"
-    "and the remaining 4000 (10000 for boosting) - to test the classifier.\n"
-    "======================================================\n");
-    printf("\nThis is letter recognition sample.\n"
-            "The usage: %s [-data=<path to letter-recognition.data>] \\\n"
-            "  [-save=<output XML file for the classifier>] \\\n"
-            "  [-load=<XML file with the pre-trained classifier>] \\\n"
-            "  [-boost|-mlp|-knearest|-nbayes|-svm] # to use boost/mlp/knearest/SVM classifier instead of default Random Trees\n", argv[0] );
-}
+// static void help(char** argv)
+// {
+//     printf("\nThe sample demonstrates how to train Random Trees classifier\n"
+//     "(or Boosting classifier, or MLP, or Knearest, or Nbayes, or Support Vector Machines - see main()) using the provided dataset.\n"
+//     "\n"
+//     "We use the sample database letter-recognition.data\n"
+//     "from UCI Repository, here is the link:\n"
+//     "\n"
+//     "Newman, D.J. & Hettich, S. & Blake, C.L. & Merz, C.J. (1998).\n"
+//     "UCI Repository of machine learning databases\n"
+//     "[http://www.ics.uci.edu/~mlearn/MLRepository.html].\n"
+//     "Irvine, CA: University of California, Department of Information and Computer Science.\n"
+//     "\n"
+//     "The dataset consists of 20000 feature vectors along with the\n"
+//     "responses - capital latin letters A..Z.\n"
+//     "The first 16000 (10000 for boosting)) samples are used for training\n"
+//     "and the remaining 4000 (10000 for boosting) - to test the classifier.\n"
+//     "======================================================\n");
+//     printf("\nThis is letter recognition sample.\n"
+//             "The usage: %s [-data=<path to letter-recognition.data>] \\\n"
+//             "  [-save=<output XML file for the classifier>] \\\n"
+//             "  [-load=<XML file with the pre-trained classifier>] \\\n"
+//             "  [-boost|-mlp|-knearest|-nbayes|-svm] # to use boost/mlp/knearest/SVM classifier instead of default Random Trees\n", argv[0] );
+// }
 
 // This function reads data and responses from the file <filename>
 static bool
@@ -538,7 +538,7 @@ int main( int argc, char *argv[] )
     else if (parser.has("svm"))
         method = 5;
 
-    help(argv);
+    // help(argv);
 
     if( (method == 0 ?
         build_rtrees_classifier( data_filename, filename_to_save, filename_to_load ) :
@@ -556,3 +556,4 @@ int main( int argc, char *argv[] )
 
     return 0;
 }
+
diff --git a/samples/cpp/lkdemo.cpp b/samples/cpp/lkdemo.cpp
index 29f1419c66..24e4e70ec0 100644
--- a/samples/cpp/lkdemo.cpp
+++ b/samples/cpp/lkdemo.cpp
@@ -5,6 +5,7 @@
 
 #include <iostream>
 #include <ctype.h>
+#include <cstdlib>  // 为 system() 函数包含的头文件
 
 using namespace cv;
 using namespace std;
@@ -14,7 +15,7 @@ static void help()
     // print a welcome message, and the OpenCV version
     cout << "\nThis is a demo of Lukas-Kanade optical flow lkdemo(),\n"
             "Using OpenCV version " << CV_VERSION << endl;
-    cout << "\nIt uses camera by default, but you can provide a path to video as an argument.\n";
+    cout << "\nIt uses a video file as input, which should be provided as a command-line argument.\n";
     cout << "\nHot keys: \n"
             "\tESC - quit the program\n"
             "\tr - auto-initialize tracking\n"
@@ -37,6 +38,11 @@ static void onMouse( int event, int x, int y, int /*flags*/, void* /*param*/ )
 
 int main( int argc, char** argv )
 {
+    if (argc < 2) {
+        cout << "Usage: " << argv[0] << " <video_file>" << endl;
+        return -1;
+    }
+
     VideoCapture cap;
     TermCriteria termcrit(TermCriteria::COUNT|TermCriteria::EPS,20,0.03);
     Size subPixWinSize(10,10), winSize(31,31);
@@ -46,13 +52,9 @@ int main( int argc, char** argv )
     bool nightMode = false;
 
     help();
-    cv::CommandLineParser parser(argc, argv, "{@input|0|}");
-    string input = parser.get<string>("@input");
 
-    if( input.size() == 1 && isdigit(input[0]) )
-        cap.open(input[0] - '0');
-    else
-        cap.open(input);
+    string input = argv[1];
+    cap.open(input);
 
     if( !cap.isOpened() )
     {
@@ -60,8 +62,19 @@ int main( int argc, char** argv )
         return 0;
     }
 
-    namedWindow( "LK Demo", 1 );
-    setMouseCallback( "LK Demo", onMouse, 0 );
+    // 创建子目录 lkdemo
+    string outputDir = "lkdemo";
+    system(("mkdir -p " + outputDir).c_str());  // 使用 system() 创建目录
+
+    // 创建保存文件的路径
+    string outputFilePath = outputDir + "/output.avi";
+    cout << "Processed video will be saved at: " << outputFilePath << endl;
+
+    // 设置视频写入器
+    int codec = VideoWriter::fourcc('M', 'J', 'P', 'G');
+    VideoWriter writer(outputFilePath, codec, cap.get(CAP_PROP_FPS), 
+                       Size((int)cap.get(CAP_PROP_FRAME_WIDTH), 
+                            (int)cap.get(CAP_PROP_FRAME_HEIGHT)));
 
     Mat gray, prevGray, image, frame;
     vector<Point2f> points[2];
@@ -124,24 +137,29 @@ int main( int argc, char** argv )
         }
 
         needToInit = false;
-        imshow("LK Demo", image);
 
-        char c = (char)waitKey(10);
-        if( c == 27 )
-            break;
-        switch( c )
-        {
-        case 'r':
-            needToInit = true;
-            break;
-        case 'c':
-            points[0].clear();
-            points[1].clear();
-            break;
-        case 'n':
-            nightMode = !nightMode;
-            break;
-        }
+        // 注释掉图形显示部分
+        // imshow("LK Demo", image);
+
+        // 将处理后的帧写入视频文件
+        writer.write(image);
+
+        // char c = (char)waitKey(10);
+        // if( c == 27 )
+        //     break;
+        // switch( c )
+        // {
+        // case 'r':
+        //     needToInit = true;
+        //     break;
+        // case 'c':
+        //     points[0].clear();
+        //     points[1].clear();
+        //     break;
+        // case 'n':
+        //     nightMode = !nightMode;
+        //     break;
+        // }
 
         std::swap(points[1], points[0]);
         cv::swap(prevGray, gray);
@@ -149,3 +167,4 @@ int main( int argc, char** argv )
 
     return 0;
 }
+
diff --git a/samples/cpp/logistic_regression.cpp b/samples/cpp/logistic_regression.cpp
index 1bc2bf9711..b3bd5335ef 100644
--- a/samples/cpp/logistic_regression.cpp
+++ b/samples/cpp/logistic_regression.cpp
@@ -1,8 +1,4 @@
-// Logistic Regression sample
-// AUTHOR: Rahul Kavi rahulkavi[at]live[at]com
-
 #include <iostream>
-
 #include <opencv2/core.hpp>
 #include <opencv2/ml.hpp>
 #include <opencv2/highgui.hpp>
@@ -11,15 +7,15 @@ using namespace std;
 using namespace cv;
 using namespace cv::ml;
 
-static void showImage(const Mat &data, int columns, const String &name)
-{
-    Mat bigImage;
-    for(int i = 0; i < data.rows; ++i)
-    {
-        bigImage.push_back(data.row(i).reshape(0, columns));
-    }
-    imshow(name, bigImage.t());
-}
+// static void showImage(const Mat &data, int columns, const String &name)
+// {
+//     Mat bigImage;
+//     for(int i = 0; i < data.rows; ++i)
+//     {
+//         bigImage.push_back(data.row(i).reshape(0, columns));
+//     }
+//     imshow(name, bigImage.t());
+// }
 
 static float calculateAccuracyPercent(const Mat &original, const Mat &predicted)
 {
@@ -74,8 +70,8 @@ int main()
     cout << "training/testing samples count: " << data_train.rows << "/" << data_test.rows << endl;
 
     // display sample image
-    showImage(data_train, 28, "train data");
-    showImage(data_test, 28, "test data");
+    // showImage(data_train, 28, "train data");
+    // showImage(data_test, 28, "test data");
 
     // simple case with batch gradient
     cout << "training...";
@@ -122,6 +118,7 @@ int main()
     cout << responses2.t() << endl;
     cout << "accuracy: " << calculateAccuracyPercent(labels_test, responses2) << "%" << endl;
 
-    waitKey(0);
+    // waitKey(0);
     return 0;
 }
+
diff --git a/samples/cpp/lsd_lines.cpp b/samples/cpp/lsd_lines.cpp
index 3feed9cbc2..d65dade470 100644
--- a/samples/cpp/lsd_lines.cpp
+++ b/samples/cpp/lsd_lines.cpp
@@ -13,6 +13,7 @@ int main(int argc, char** argv)
                                  "{refine  r|false|if true use LSD_REFINE_STD method, if false use LSD_REFINE_NONE method}"
                                  "{canny   c|false|use Canny edge detector}"
                                  "{overlay o|false|show result on input image}"
+                                 "{output  o|result.jpg|output image}"
                                  "{help    h|false|show help message}");
 
     if (parser.get<bool>("help"))
@@ -27,23 +28,22 @@ int main(int argc, char** argv)
     bool useRefine = parser.get<bool>("refine");
     bool useCanny = parser.get<bool>("canny");
     bool overlay = parser.get<bool>("overlay");
+    String outputFilename = parser.get<String>("output");
 
     Mat image = imread(filename, IMREAD_GRAYSCALE);
 
     if( image.empty() )
     {
-        cout << "Unable to load " << filename;
+        cout << "Unable to load " << filename << endl;
         return 1;
     }
 
-    imshow("Source Image", image);
-
     if (useCanny)
     {
         Canny(image, image, 50, 200, 3); // Apply Canny edge detector
     }
 
-    // Create and LSD detector with standard or no refinement.
+    // Create LSD detector with standard or no refinement.
     Ptr<LineSegmentDetector> ls = useRefine ? createLineSegmentDetector(LSD_REFINE_STD) : createLineSegmentDetector(LSD_REFINE_NONE);
 
     double start = double(getTickCount());
@@ -63,11 +63,10 @@ int main(int argc, char** argv)
 
     ls->drawSegments(image, lines_std);
 
-    String window_name = useRefine ? "Result - standard refinement" : "Result - no refinement";
-    window_name += useCanny ? " - Canny edge detector used" : "";
-
-    imshow(window_name, image);
+    // Save the result image
+    imwrite(outputFilename, image);
+    cout << "Result saved to " << outputFilename << endl;
 
-    waitKey();
     return 0;
 }
+
diff --git a/samples/cpp/mask_tmpl.cpp b/samples/cpp/mask_tmpl.cpp
index 3c63b15dbc..b5147d7d7d 100644
--- a/samples/cpp/mask_tmpl.cpp
+++ b/samples/cpp/mask_tmpl.cpp
@@ -1,34 +1,33 @@
 #include "opencv2/imgproc.hpp"
-#include "opencv2/highgui.hpp"
+#include "opencv2/imgcodecs.hpp"
 #include <iostream>
 
 using namespace std;
 using namespace cv;
 
-int main( int argc, const char** argv )
+int main(int argc, char** argv)
 {
     CommandLineParser parser(argc, argv,
-        "{ i | lena_tmpl.jpg |image name }"
-        "{ t | tmpl.png |template name }"
-        "{ m | mask.png |mask name }"
-        "{ cm| 3 |comparison method }");
-
-    cout << "This program demonstrates the use of template matching with mask." << endl
-         << endl
-         << "Available methods: https://docs.opencv.org/4.x/df/dfb/group__imgproc__object.html#ga3a7850640f1fe1f58fe91a2d7583695d" << endl
-         << "    TM_SQDIFF = " << (int)TM_SQDIFF << endl
-         << "    TM_SQDIFF_NORMED = " << (int)TM_SQDIFF_NORMED << endl
-         << "    TM_CCORR = " << (int)TM_CCORR << endl
-         << "    TM_CCORR_NORMED = " << (int)TM_CCORR_NORMED << endl
-         << "    TM_CCOEFF = " << (int)TM_CCOEFF << endl
-         << "    TM_CCOEFF_NORMED = " << (int)TM_CCOEFF_NORMED << endl
-         << endl;
+                             "{input   i|lena.jpg|input image}" // 使用 lena.jpg 作为输入图像
+                             "{t |templ.png|template name}"     // 使用 templ.png 作为模板图像
+                             "{m |mask.png|mask name}"          // 使用 mask.png 作为掩码图像
+                             "{cm|3|comparison method}"         // 默认比较方法
+                             "{o |result.jpg|output image name}"// 输出图像名称
+                             "{help h|false|show help message}");
+
+    if (parser.get<bool>("help"))
+    {
+        parser.printMessage();
+        return 0;
+    }
 
     parser.printMessage();
 
-    string filename = samples::findFile(parser.get<string>("i"));
+    string filename = samples::findFile(parser.get<string>("input"));
     string tmplname = samples::findFile(parser.get<string>("t"));
     string maskname = samples::findFile(parser.get<string>("m"));
+    string outputname = parser.get<string>("o");
+    
     Mat img = imread(filename);
     Mat tmpl = imread(tmplname);
     Mat mask = imread(maskname);
@@ -36,23 +35,28 @@ int main( int argc, const char** argv )
 
     if(img.empty())
     {
-        cout << "can not open " << filename << endl;
+        cout << "Cannot open " << filename << endl;
         return -1;
     }
 
     if(tmpl.empty())
     {
-        cout << "can not open " << tmplname << endl;
+        cout << "Cannot open " << tmplname << endl;
         return -1;
     }
 
     if(mask.empty())
     {
-        cout << "can not open " << maskname << endl;
+        cout << "Cannot open " << maskname << endl;
         return -1;
     }
 
-    int method = parser.get<int>("cm"); // default 3 (cv::TM_CCORR_NORMED)
+    // Resize mask to match template size if necessary
+    if (tmpl.size() != mask.size()) {
+        resize(mask, mask, tmpl.size());
+    }
+
+    int method = parser.get<int>("cm"); // 默认比较方法
     matchTemplate(img, tmpl, res, method, mask);
 
     double minVal, maxVal;
@@ -67,8 +71,10 @@ int main( int argc, const char** argv )
 
     rectangle(img, rect, Scalar(0, 255, 0), 2);
 
-    imshow("detected template", img);
-    waitKey();
+    // Save the result image
+    imwrite(outputname, img);
+    cout << "Result saved to " << outputname << endl;
 
     return 0;
 }
+
diff --git a/samples/cpp/matchmethod_orb_akaze_brisk.cpp b/samples/cpp/matchmethod_orb_akaze_brisk.cpp
index 62f56b8e6f..138fc3aa14 100644
--- a/samples/cpp/matchmethod_orb_akaze_brisk.cpp
+++ b/samples/cpp/matchmethod_orb_akaze_brisk.cpp
@@ -1,7 +1,7 @@
 #include <opencv2/core.hpp>
 #include <opencv2/imgproc.hpp>
 #include <opencv2/features2d.hpp>
-#include <opencv2/highgui.hpp>
+ #include <opencv2/highgui.hpp> // 不需要图形显示
 #include <vector>
 #include <iostream>
 
@@ -13,11 +13,9 @@ static void help(char* argv[])
     cout << "\n This program demonstrates how to detect compute and match ORB BRISK and AKAZE descriptors \n"
             "Usage: \n  "
          << argv[0] << " --image1=<image1(basketball1.png as default)> --image2=<image2(basketball2.png as default)>\n"
-        "Press a key when image window is active to change algorithm or descriptor";
+         << "Press a key when image window is active to change algorithm or descriptor";
 }
 
-
-
 int main(int argc, char *argv[])
 {
     vector<String> typeDesc;
@@ -34,9 +32,9 @@ int main(int argc, char *argv[])
     typeAlgoMatch.push_back("BruteForce-Hamming");
     typeAlgoMatch.push_back("BruteForce-Hamming(2)");
     cv::CommandLineParser parser(argc, argv,
-        "{ @image1 | basketball1.png | }"
-        "{ @image2 | basketball2.png | }"
-        "{help h ||}");
+                                 "{ @image1 | basketball1.png | }"
+                                 "{ @image2 | basketball2.png | }"
+                                 "{help h ||}");
     if (parser.has("help"))
     {
         help(argv);
@@ -91,7 +89,7 @@ int main(int argc, char *argv[])
             // and compute their descriptors with method  compute
             b->compute(img1, keyImg1, descImg1);
             // or detect and compute descriptors in one step
-            b->detectAndCompute(img2, Mat(),keyImg2, descImg2,false);
+            b->detectAndCompute(img2, Mat(), keyImg2, descImg2, false);
             // Match method loop
             for (itMatcher = typeAlgoMatch.begin(); itMatcher != typeAlgoMatch.end(); ++itMatcher){
                 descriptorMatcher = DescriptorMatcher::create(*itMatcher);
@@ -113,39 +111,45 @@ int main(int argc, char *argv[])
                     // Keep best matches only to have a nice drawing.
                     // We sort distance between descriptor matches
                     Mat index;
-                    int nbMatch=int(matches.size());
+                    int nbMatch = int(matches.size());
                     Mat tab(nbMatch, 1, CV_32F);
-                    for (int i = 0; i<nbMatch; i++)
+                    for (int i = 0; i < nbMatch; i++)
                     {
                         tab.at<float>(i, 0) = matches[i].distance;
                     }
                     sortIdx(tab, index, SORT_EVERY_COLUMN + SORT_ASCENDING);
                     vector<DMatch> bestMatches;
-                    for (int i = 0; i<30; i++)
+                    for (int i = 0; i < 30; i++)
                     {
                         bestMatches.push_back(matches[index.at<int>(i, 0)]);
                     }
                     Mat result;
                     drawMatches(img1, keyImg1, img2, keyImg2, bestMatches, result);
-                    namedWindow(*itDesc+": "+*itMatcher, WINDOW_AUTOSIZE);
-                    imshow(*itDesc + ": " + *itMatcher, result);
+                    if (!result.empty()) {
+                        String resultFileName = *itDesc + "_" + *itMatcher + ".jpg";
+                        imwrite(resultFileName, result);
+                        cout << "Result saved to " << resultFileName << endl;
+                    } else {
+                        cerr << "Result image is empty, skipping save." << endl;
+                    }
                     // Saved result could be wrong due to bug 4308
                     FileStorage fs(*itDesc + "_" + *itMatcher + ".yml", FileStorage::WRITE);
-                    fs<<"Matches"<<matches;
+                    fs << "Matches" << matches;
                     vector<DMatch>::iterator it;
-                    cout<<"**********Match results**********\n";
+                    cout << "**********Match results**********\n";
                     cout << "Index \tIndex \tdistance\n";
                     cout << "in img1\tin img2\n";
                     // Use to compute distance between keyPoint matches and to evaluate match algorithm
-                    double cumSumDist2=0;
+                    double cumSumDist2 = 0;
                     for (it = bestMatches.begin(); it != bestMatches.end(); ++it)
                     {
                         cout << it->queryIdx << "\t" <<  it->trainIdx << "\t"  <<  it->distance << "\n";
-                        Point2d p=keyImg1[it->queryIdx].pt-keyImg2[it->trainIdx].pt;
-                        cumSumDist2=p.x*p.x+p.y*p.y;
+                        Point2d p = keyImg1[it->queryIdx].pt - keyImg2[it->trainIdx].pt;
+                        cumSumDist2 += p.x * p.x + p.y * p.y;
                     }
                     desMethCmp.push_back(cumSumDist2);
-                    waitKey();
+                    // 注释掉与显示相关的代码
+                    // waitKey();
                 }
                 catch (const Exception& e)
                 {
@@ -165,12 +169,12 @@ int main(int argc, char *argv[])
             }
         }
     }
-    int i=0;
+    int i = 0;
     cout << "Cumulative distance between keypoint match for different algorithm and feature detector \n\t";
     cout << "We cannot say which is the best but we can say results are different! \n\t";
     for (vector<String>::iterator itMatcher = typeAlgoMatch.begin(); itMatcher != typeAlgoMatch.end(); ++itMatcher)
     {
-        cout<<*itMatcher<<"\t";
+        cout << *itMatcher << "\t";
     }
     cout << "\n";
     for (itDesc = typeDesc.begin(); itDesc != typeDesc.end(); ++itDesc)
@@ -178,9 +182,10 @@ int main(int argc, char *argv[])
         cout << *itDesc << "\t";
         for (vector<String>::iterator itMatcher = typeAlgoMatch.begin(); itMatcher != typeAlgoMatch.end(); ++itMatcher, ++i)
         {
-            cout << desMethCmp[i]<<"\t";
+            cout << desMethCmp[i] << "\t";
         }
-        cout<<"\n";
+        cout << "\n";
     }
     return 0;
 }
+
diff --git a/samples/cpp/minarea.cpp b/samples/cpp/minarea.cpp
index 97264721bf..0df4e58ad9 100644
--- a/samples/cpp/minarea.cpp
+++ b/samples/cpp/minarea.cpp
@@ -14,24 +14,36 @@ static void help()
          << "Press ESC, 'q' or 'Q' to exit and any other key to regenerate the set of points.\n\n";
 }
 
-int main( int /*argc*/, char** /*argv*/ )
+int main(int argc, char** argv)
 {
+    cv::CommandLineParser parser(argc, argv,
+                                 "{output   o|result.jpg|output image name}"
+                                 "{help    h|false|show help message}");
+
+    if (parser.get<bool>("help"))
+    {
+        help();
+        return 0;
+    }
+
+    string outputFilename = parser.get<string>("output");
+
     help();
 
     Mat img(500, 500, CV_8UC3, Scalar::all(0));
     RNG& rng = theRNG();
 
-    for(;;)
+    for (;;)
     {
         int i, count = rng.uniform(1, 101);
         vector<Point> points;
 
         // Generate a random set of points
-        for( i = 0; i < count; i++ )
+        for (i = 0; i < count; i++)
         {
             Point pt;
-            pt.x = rng.uniform(img.cols/4, img.cols*3/4);
-            pt.y = rng.uniform(img.rows/4, img.rows*3/4);
+            pt.x = rng.uniform(img.cols / 4, img.cols * 3 / 4);
+            pt.y = rng.uniform(img.rows / 4, img.rows * 3 / 4);
 
             points.push_back(pt);
         }
@@ -53,26 +65,34 @@ int main( int /*argc*/, char** /*argv*/ )
         img = Scalar::all(0);
 
         // Draw the points
-        for( i = 0; i < count; i++ )
-            circle( img, points[i], 3, Scalar(0, 0, 255), FILLED, LINE_AA );
+        for (i = 0; i < count; i++)
+            circle(img, points[i], 3, Scalar(0, 0, 255), FILLED, LINE_AA);
 
         // Draw the bounding box
-        for( i = 0; i < 4; i++ )
-            line(img, vtx[i], vtx[(i+1)%4], Scalar(0, 255, 0), 1, LINE_AA);
+        for (i = 0; i < 4; i++)
+            line(img, vtx[i], vtx[(i + 1) % 4], Scalar(0, 255, 0), 1, LINE_AA);
 
         // Draw the triangle
-        for( i = 0; i < 3; i++ )
-            line(img, triangle[i], triangle[(i+1)%3], Scalar(255, 255, 0), 1, LINE_AA);
+        for (i = 0; i < 3; i++)
+            line(img, triangle[i], triangle[(i + 1) % 3], Scalar(255, 255, 0), 1, LINE_AA);
 
         // Draw the circle
         circle(img, center, cvRound(radius), Scalar(0, 255, 255), 1, LINE_AA);
 
-        imshow( "Rectangle, triangle & circle", img );
+        // 注释掉与显示相关的代码
+        // imshow("Rectangle, triangle & circle", img);
+
+        // Save the result
+        imwrite(outputFilename, img);
+        cout << "Result saved to " << outputFilename << endl;
 
-        char key = (char)waitKey();
-        if( key == 27 || key == 'q' || key == 'Q' ) // 'ESC'
-            break;
+        // 注释掉等待键输入的代码
+        // char key = (char)waitKey();
+        // if (key == 27 || key == 'q' || key == 'Q') // 'ESC'
+        //     break;
+        break; // Exit after saving the result
     }
 
     return 0;
 }
+
diff --git a/samples/cpp/morphology2.cpp b/samples/cpp/morphology2.cpp
index f1d8d15b17..f78ce7c575 100644
--- a/samples/cpp/morphology2.cpp
+++ b/samples/cpp/morphology2.cpp
@@ -1,109 +1,106 @@
 #include "opencv2/imgproc.hpp"
 #include "opencv2/imgcodecs.hpp"
-#include "opencv2/highgui.hpp"
 #include <stdlib.h>
 #include <stdio.h>
 #include <string>
+#include <iostream>
 
 using namespace cv;
 
 static void help(char** argv)
 {
-
-printf("\nShow off image morphology: erosion, dialation, open and close\n"
-    "Call:\n   %s [image]\n"
-    "This program also shows use of rect, ellipse and cross kernels\n\n", argv[0]);
-printf( "Hot keys: \n"
-    "\tESC - quit the program\n"
-    "\tr - use rectangle structuring element\n"
-    "\te - use elliptic structuring element\n"
-    "\tc - use cross-shaped structuring element\n"
-    "\tSPACE - loop through all the options\n" );
+    printf("\nShow off image morphology: erosion, dilation, open and close\n"
+           "Call:\n   %s [image]\n"
+           "This program also shows use of rect, ellipse and cross kernels\n\n", argv[0]);
+    printf("Hot keys: \n"
+           "\tESC - quit the program\n"
+           "\tr - use rectangle structuring element\n"
+           "\te - use elliptic structuring element\n"
+           "\tc - use cross-shaped structuring element\n"
+           "\tSPACE - loop through all the options\n");
 }
 
 Mat src, dst;
-
 int element_shape = MORPH_RECT;
-
-//the address of variable which receives trackbar position update
 int max_iters = 10;
 int open_close_pos = 0;
 int erode_dilate_pos = 0;
 
-// callback function for open/close trackbar
 static void OpenClose(int, void*)
 {
     int n = open_close_pos;
     int an = abs(n);
-    Mat element = getStructuringElement(element_shape, Size(an*2+1, an*2+1), Point(an, an) );
-    if( n < 0 )
+    Mat element = getStructuringElement(element_shape, Size(an * 2 + 1, an * 2 + 1), Point(an, an));
+    if (n < 0)
         morphologyEx(src, dst, MORPH_OPEN, element);
     else
         morphologyEx(src, dst, MORPH_CLOSE, element);
-    imshow("Open/Close",dst);
+    // 注释掉显示相关代码
+    // imshow("Open/Close", dst);
 }
 
-// callback function for erode/dilate trackbar
 static void ErodeDilate(int, void*)
 {
     int n = erode_dilate_pos;
     int an = abs(n);
-    Mat element = getStructuringElement(element_shape, Size(an*2+1, an*2+1), Point(an, an) );
-    if( n < 0 )
+    Mat element = getStructuringElement(element_shape, Size(an * 2 + 1, an * 2 + 1), Point(an, an));
+    if (n < 0)
         erode(src, dst, element);
     else
         dilate(src, dst, element);
-    imshow("Erode/Dilate",dst);
+    // 注释掉显示相关代码
+    // imshow("Erode/Dilate", dst);
 }
 
-
-int main( int argc, char** argv )
+int main(int argc, char** argv)
 {
-    cv::CommandLineParser parser(argc, argv, "{help h||}{ @image | baboon.jpg | }");
+    cv::CommandLineParser parser(argc, argv, "{help h||}{ @image | baboon.jpg | }{output o|output.jpg|}");
     if (parser.has("help"))
     {
         help(argv);
         return 0;
     }
     std::string filename = samples::findFile(parser.get<std::string>("@image"));
-    if( (src = imread(filename,IMREAD_COLOR)).empty() )
+    std::string outputFilename = parser.get<std::string>("output");
+
+    if ((src = imread(filename, IMREAD_COLOR)).empty())
     {
         help(argv);
         return -1;
     }
 
-    //create windows for output images
-    namedWindow("Open/Close",1);
-    namedWindow("Erode/Dilate",1);
-
     open_close_pos = erode_dilate_pos = max_iters;
-    createTrackbar("iterations", "Open/Close",&open_close_pos,max_iters*2+1,OpenClose);
-    setTrackbarMin("iterations", "Open/Close", -max_iters);
-    setTrackbarMax("iterations", "Open/Close", max_iters);
-    setTrackbarPos("iterations", "Open/Close", 0);
 
-    createTrackbar("iterations", "Erode/Dilate",&erode_dilate_pos,max_iters*2+1,ErodeDilate);
-    setTrackbarMin("iterations", "Erode/Dilate", -max_iters);
-    setTrackbarMax("iterations", "Erode/Dilate", max_iters);
-    setTrackbarPos("iterations", "Erode/Dilate", 0);
-
-    for(;;)
+    for (;;)
     {
         OpenClose(open_close_pos, 0);
         ErodeDilate(erode_dilate_pos, 0);
-        char c = (char)waitKey(0);
 
-        if( c == 27 )
-            break;
-        if( c == 'e' )
-            element_shape = MORPH_ELLIPSE;
-        else if( c == 'r' )
-            element_shape = MORPH_RECT;
-        else if( c == 'c' )
-            element_shape = MORPH_CROSS;
-        else if( c == ' ' )
-            element_shape = (element_shape + 1) % 3;
+        // 保存处理后的图像
+        std::string openCloseOutput = "open_close_" + outputFilename;
+        std::string erodeDilateOutput = "erode_dilate_" + outputFilename;
+
+        imwrite(openCloseOutput, dst);
+        std::cout << "Open/Close result saved to " << openCloseOutput << std::endl;
+
+        imwrite(erodeDilateOutput, dst);
+        std::cout << "Erode/Dilate result saved to " << erodeDilateOutput << std::endl;
+
+        // 注释掉等待键输入的代码
+        // char c = (char)waitKey(0);
+        // if (c == 27)
+        //     break;
+        // if (c == 'e')
+        //     element_shape = MORPH_ELLIPSE;
+        // else if (c == 'r')
+        //     element_shape = MORPH_RECT;
+        // else if (c == 'c')
+        //     element_shape = MORPH_CROSS;
+        // else if (c == ' ')
+        //     element_shape = (element_shape + 1) % 3;
+        break; // 在保存结果后退出循环
     }
 
     return 0;
 }
+
diff --git a/samples/cpp/neural_network.cpp b/samples/cpp/neural_network.cpp
index d6e681b6c6..df91414dcc 100644
--- a/samples/cpp/neural_network.cpp
+++ b/samples/cpp/neural_network.cpp
@@ -1,4 +1,5 @@
 #include <opencv2/ml/ml.hpp>
+#include <iostream>
 
 using namespace std;
 using namespace cv;
@@ -6,15 +7,15 @@ using namespace cv::ml;
 
 int main()
 {
-    //create random training data
+    // Create random training data
     Mat_<float> data(100, 100);
     randn(data, Mat::zeros(1, 1, data.type()), Mat::ones(1, 1, data.type()));
 
-    //half of the samples for each class
+    // Half of the samples for each class
     Mat_<float> responses(data.rows, 2);
-    for (int i = 0; i<data.rows; ++i)
+    for (int i = 0; i < data.rows; ++i)
     {
-        if (i < data.rows/2)
+        if (i < data.rows / 2)
         {
             responses(i, 0) = 1;
             responses(i, 1) = 0;
@@ -27,13 +28,13 @@ int main()
     }
 
     /*
-    //example code for just a single response (regression)
+    // Example code for just a single response (regression)
     Mat_<float> responses(data.rows, 1);
-    for (int i=0; i<responses.rows; ++i)
+    for (int i = 0; i < responses.rows; ++i)
         responses(i, 0) = i < responses.rows / 2 ? 0 : 1;
     */
 
-    //create the neural network
+    // Create the neural network
     Mat_<int> layerSizes(1, 3);
     layerSizes(0, 0) = data.cols;
     layerSizes(0, 1) = 20;
@@ -46,6 +47,7 @@ int main()
     Ptr<TrainData> trainData = TrainData::create(data, ROW_SAMPLE, responses);
 
     network->train(trainData);
+
     if (network->isTrained())
     {
         printf("Predict one-vector:\n");
@@ -54,7 +56,7 @@ int main()
         cout << result << endl;
 
         printf("Predict training data:\n");
-        for (int i=0; i<data.rows; ++i)
+        for (int i = 0; i < data.rows; ++i)
         {
             network->predict(data.row(i), result);
             cout << result << endl;
@@ -63,3 +65,4 @@ int main()
 
     return 0;
 }
+
diff --git a/samples/cpp/npr_demo.cpp b/samples/cpp/npr_demo.cpp
index 4d8d7879bb..f4d3176c0b 100644
--- a/samples/cpp/npr_demo.cpp
+++ b/samples/cpp/npr_demo.cpp
@@ -28,13 +28,14 @@ using namespace cv;
 
 int main(int argc, char* argv[])
 {
-    cv::CommandLineParser parser(argc, argv, "{help h||show help message}{@image|lena.jpg|input image}");
+    cv::CommandLineParser parser(argc, argv, "{help h||show help message}{@image|lena.jpg|input image}{@output|output.jpg|output image}");
     if (parser.has("help"))
     {
         parser.printMessage();
         return 0;
     }
     string filename = samples::findFile(parser.get<string>("@image"));
+    string output_filename = parser.get<string>("@output");
 
     Mat I = imread(filename);
 
@@ -74,26 +75,37 @@ int main(int argc, char* argv[])
 
         cin >> type;
 
-        edgePreservingFilter(I,img,type);
-        imshow("Edge Preserve Smoothing",img);
-
+        edgePreservingFilter(I, img, type);
+        // imshow("Edge Preserve Smoothing", img);
+        imwrite(output_filename, img);
+        cout << "Processed image saved to " << output_filename << endl;
     }
     else if(num == 2)
     {
-        detailEnhance(I,img);
-        imshow("Detail Enhanced",img);
+        detailEnhance(I, img);
+        // imshow("Detail Enhanced", img);
+        imwrite(output_filename, img);
+        cout << "Processed image saved to " << output_filename << endl;
     }
     else if(num == 3)
     {
         Mat img1;
-        pencilSketch(I,img1, img, 10 , 0.1f, 0.03f);
-        imshow("Pencil Sketch",img1);
-        imshow("Color Pencil Sketch",img);
+        pencilSketch(I, img1, img, 10, 0.1f, 0.03f);
+        // imshow("Pencil Sketch", img1);
+        // imshow("Color Pencil Sketch", img);
+        imwrite(output_filename + "_pencil.jpg", img1);
+        imwrite(output_filename + "_color_pencil.jpg", img);
+        cout << "Pencil sketch saved to " << output_filename + "_pencil.jpg" << endl;
+        cout << "Color pencil sketch saved to " << output_filename + "_color_pencil.jpg" << endl;
     }
     else if(num == 4)
     {
-        stylization(I,img);
-        imshow("Stylization",img);
+        stylization(I, img);
+        // imshow("Stylization", img);
+        imwrite(output_filename, img);
+        cout << "Processed image saved to " << output_filename << endl;
     }
-    waitKey(0);
+    // waitKey(0);
+    return 0;
 }
+
diff --git a/samples/cpp/pca.cpp b/samples/cpp/pca.cpp
index 96fd1e25b1..0ef0aaccaa 100644
--- a/samples/cpp/pca.cpp
+++ b/samples/cpp/pca.cpp
@@ -41,10 +41,13 @@
 #include <iostream>
 #include <fstream>
 #include <sstream>
+#include <cstdlib>
+#include <sys/stat.h>
+#include <sys/types.h>
 
 #include <opencv2/core.hpp>
 #include "opencv2/imgcodecs.hpp"
-#include <opencv2/highgui.hpp>
+// #include <opencv2/highgui.hpp>
 
 using namespace cv;
 using namespace std;
@@ -63,14 +66,14 @@ static void read_imgList(const string& filename, vector<Mat>& images) {
     }
 }
 
-static  Mat formatImagesForPCA(const vector<Mat> &data)
+static Mat formatImagesForPCA(const vector<Mat>& data)
 {
-    Mat dst(static_cast<int>(data.size()), data[0].rows*data[0].cols, CV_32F);
-    for(unsigned int i = 0; i < data.size(); i++)
+    Mat dst(static_cast<int>(data.size()), data[0].rows * data[0].cols, CV_32F);
+    for (unsigned int i = 0; i < data.size(); i++)
     {
-        Mat image_row = data[i].clone().reshape(1,1);
+        Mat image_row = data[i].clone().reshape(1, 1);
         Mat row_i = dst.row(i);
-        image_row.convertTo(row_i,CV_32F);
+        image_row.convertTo(row_i, CV_32F);
     }
     return dst;
 }
@@ -78,7 +81,7 @@ static  Mat formatImagesForPCA(const vector<Mat> &data)
 static Mat toGrayscale(InputArray _src) {
     Mat src = _src.getMat();
     // only allow one channel
-    if(src.channels() != 1) {
+    if (src.channels() != 1) {
         CV_Error(Error::StsBadArg, "Only Matrices with one channel are supported");
     }
     // create and return normalized image
@@ -103,7 +106,7 @@ static void onTrackbar(int pos, void* ptr)
 
     double var = pos / 100.0;
 
-    struct params *p = (struct params *)ptr;
+    struct params* p = (struct params*)ptr;
 
     p->pca = PCA(p->data, cv::Mat(), PCA::DATA_AS_ROW, var);
 
@@ -112,10 +115,13 @@ static void onTrackbar(int pos, void* ptr)
     reconstruction = reconstruction.reshape(p->ch, p->rows);
     reconstruction = toGrayscale(reconstruction);
 
-    imshow(p->winName, reconstruction);
+    // imshow(p->winName, reconstruction);
     cout << "done!   # of principal components: " << p->pca.eigenvectors.rows << endl;
-}
 
+    String output_dir = p->winName + "/pca_" + to_string(pos) + ".png";
+    imwrite(output_dir, reconstruction);
+    cout << "Saved reconstruction to " << output_dir << endl;
+}
 
 ///////////////////////
 // Main
@@ -141,13 +147,14 @@ int main(int argc, char** argv)
     // Read in the data. This can fail if not valid
     try {
         read_imgList(imgList, images);
-    } catch (const cv::Exception& e) {
+    }
+    catch (const cv::Exception& e) {
         cerr << "Error opening file \"" << imgList << "\". Reason: " << e.msg << endl;
         exit(1);
     }
 
     // Quit if there are not enough images for this demo.
-    if(images.size() <= 1) {
+    if (images.size() <= 1) {
         string error_message = "This demo needs at least 2 images to work. Please add more images to your data set!";
         CV_Error(Error::StsError, error_message);
     }
@@ -164,9 +171,18 @@ int main(int argc, char** argv)
     reconstruction = reconstruction.reshape(images[0].channels(), images[0].rows); // reshape from a row vector into image shape
     reconstruction = toGrayscale(reconstruction); // re-scale for displaying purposes
 
-    // init highgui window
-    string winName = "Reconstruction | press 'q' to quit";
-    namedWindow(winName, WINDOW_NORMAL);
+    // 创建子目录
+    String sample_name = "pca_results";
+    if (mkdir(sample_name.c_str(), 0777) == -1)
+    {
+        cerr << "Error :  " << strerror(errno) << endl;
+        return 1;
+    }
+
+    // 保存初始重构图像
+    String initial_output = sample_name + "/initial_reconstruction.png";
+    imwrite(initial_output, reconstruction);
+    cout << "Saved initial reconstruction to " << initial_output << endl;
 
     // params struct to pass to the trackbar handler
     params p;
@@ -174,18 +190,14 @@ int main(int argc, char** argv)
     p.ch = images[0].channels();
     p.rows = images[0].rows;
     p.pca = pca;
-    p.winName = winName;
+    p.winName = sample_name;
 
-    // create the tracbar
-    int pos = 95;
-    createTrackbar("Retained Variance (%)", winName, &pos, 100, onTrackbar, (void*)&p);
-
-    // display until user presses q
-    imshow(winName, reconstruction);
-
-    char key = 0;
-    while(key != 'q')
-        key = (char)waitKey();
+    // 模拟通过不同的保持方差值进行PCA重建
+    for (int pos = 10; pos <= 100; pos += 10)
+    {
+        onTrackbar(pos, (void*)&p);
+    }
 
-   return 0;
+    return 0;
 }
+
diff --git a/samples/cpp/peopledetect.cpp b/samples/cpp/peopledetect.cpp
index 9671f3b78c..08319b0c4d 100644
--- a/samples/cpp/peopledetect.cpp
+++ b/samples/cpp/peopledetect.cpp
@@ -1,13 +1,11 @@
-// This file is part of OpenCV project.
-// It is subject to the license terms in the LICENSE file found in the top-level directory
-// of this distribution and at http://opencv.org/license.html
-
 #include <opencv2/objdetect.hpp>
 #include <opencv2/highgui.hpp>
 #include <opencv2/imgproc.hpp>
 #include <opencv2/videoio.hpp>
 #include <iostream>
 #include <iomanip>
+#include <sys/stat.h>
+#include <sys/types.h>
 
 using namespace cv;
 using namespace std;
@@ -26,9 +24,6 @@ public:
     string modeName() const { return (m == Default ? "Default" : "Daimler"); }
     vector<Rect> detect(InputArray img)
     {
-        // Run the detector with default parameters. to get a higher hit-rate
-        // (and more false alarms, respectively), decrease the hitThreshold and
-        // groupThreshold (set groupThreshold to 0 to turn off the grouping completely).
         vector<Rect> found;
         if (m == Default)
             hog.detectMultiScale(img, found, 0, Size(8,8), Size(), 1.05, 2, false);
@@ -38,8 +33,6 @@ public:
     }
     void adjustRect(Rect & r) const
     {
-        // The HOG detector returns slightly larger rectangles than the real objects,
-        // so we slightly shrink the rectangles to get a nicer output.
         r.x += cvRound(r.width*0.1);
         r.width = cvRound(r.width*0.8);
         r.y += cvRound(r.height*0.07);
@@ -49,7 +42,32 @@ public:
 
 static const string keys = "{ help h   |   | print help message }"
                            "{ camera c | 0 | capture video from camera (device index starting from 0) }"
-                           "{ video v  |   | use video as input }";
+                           "{ video v  |   | use video as input }"
+                           "{ output o | peopledetect/output.avi | output video file name }";
+
+bool createDirectory(const string& dir)
+{
+    struct stat info;
+    if (stat(dir.c_str(), &info) != 0)
+    {
+        // Directory does not exist, attempt to create it
+        if (mkdir(dir.c_str(), 0777) != 0)
+        {
+            return false;
+        }
+    }
+    else if (info.st_mode & S_IFDIR)
+    {
+        // Directory exists
+        return true;
+    }
+    else
+    {
+        // Path exists but is not a directory
+        return false;
+    }
+    return true;
+}
 
 int main(int argc, char** argv)
 {
@@ -62,12 +80,25 @@ int main(int argc, char** argv)
     }
     int camera = parser.get<int>("camera");
     string file = parser.get<string>("video");
+    string outputFileName = parser.get<string>("output");
     if (!parser.check())
     {
         parser.printErrors();
         return 1;
     }
 
+    // Ensure the output directory exists
+    size_t pos = outputFileName.find_last_of('/');
+    if (pos != string::npos)
+    {
+        string outputDir = outputFileName.substr(0, pos);
+        if (!createDirectory(outputDir))
+        {
+            cout << "Could not create output directory: " << outputDir << endl;
+            return 3;
+        }
+    }
+
     VideoCapture cap;
     if (file.empty())
         cap.open(camera);
@@ -82,8 +113,17 @@ int main(int argc, char** argv)
         return 2;
     }
 
-    cout << "Press 'q' or <ESC> to quit." << endl;
-    cout << "Press <space> to toggle between Default and Daimler detector" << endl;
+    int frame_width = cap.get(CAP_PROP_FRAME_WIDTH);
+    int frame_height = cap.get(CAP_PROP_FRAME_HEIGHT);
+    VideoWriter outputVideo(outputFileName, VideoWriter::fourcc('M', 'J', 'P', 'G'), 10, Size(frame_width, frame_height));
+
+    if (!outputVideo.isOpened())
+    {
+        cout << "Could not open the output video file for write: " << outputFileName << endl;
+        return 3;
+    }
+
+    cout << "Processing video, output will be saved to: " << outputFileName << endl;
     Detector detector;
     Mat frame;
     for (;;)
@@ -98,32 +138,22 @@ int main(int argc, char** argv)
         vector<Rect> found = detector.detect(frame);
         t = getTickCount() - t;
 
-        // show the window
-        {
-            ostringstream buf;
-            buf << "Mode: " << detector.modeName() << " ||| "
-                << "FPS: " << fixed << setprecision(1) << (getTickFrequency() / (double)t);
-            putText(frame, buf.str(), Point(10, 30), FONT_HERSHEY_PLAIN, 2.0, Scalar(0, 0, 255), 2, LINE_AA);
-        }
+        ostringstream buf;
+        buf << "Mode: " << detector.modeName() << " ||| "
+            << "FPS: " << fixed << setprecision(1) << (getTickFrequency() / (double)t);
+        putText(frame, buf.str(), Point(10, 30), FONT_HERSHEY_PLAIN, 2.0, Scalar(0, 0, 255), 2, LINE_AA);
+        
         for (vector<Rect>::iterator i = found.begin(); i != found.end(); ++i)
         {
             Rect &r = *i;
             detector.adjustRect(r);
             rectangle(frame, r.tl(), r.br(), cv::Scalar(0, 255, 0), 2);
         }
-        imshow("People detector", frame);
-
-        // interact with user
-        const char key = (char)waitKey(1);
-        if (key == 27 || key == 'q') // ESC
-        {
-            cout << "Exit requested" << endl;
-            break;
-        }
-        else if (key == ' ')
-        {
-            detector.toggleMode();
-        }
+        
+        outputVideo.write(frame);
     }
+
+    cout << "Processing complete. Video saved to: " << outputFileName << endl;
     return 0;
 }
+
diff --git a/samples/cpp/phase_corr.cpp b/samples/cpp/phase_corr.cpp
index f7356666c4..0ff3fc6140 100644
--- a/samples/cpp/phase_corr.cpp
+++ b/samples/cpp/phase_corr.cpp
@@ -2,21 +2,50 @@
 #include "opencv2/videoio.hpp"
 #include "opencv2/highgui.hpp"
 #include "opencv2/imgproc.hpp"
+#include <iostream>
+#include <cstdlib>
 
 using namespace cv;
+using namespace std;
 
-int main(int, char* [])
+int main(int argc, char* argv[])
 {
-    VideoCapture video(0);
+    // Parse command line arguments
+    CommandLineParser parser(argc, argv, "{@input||input video file}{@output||output directory}");
+    parser.about("This sample demonstrates phase correlation for video stabilization.");
+    parser.printMessage();
+
+    // Get the input video file and output directory from arguments
+    string inputVideo = parser.get<string>("@input");
+    string outputDir = parser.get<string>("@output");
+
+    if (inputVideo.empty() || outputDir.empty()) {
+        cerr << "Error: Input video file and output directory must be provided." << endl;
+        return -1;
+    }
+
+    // Create the output directory if it does not exist
+    string mkdirCmd = "mkdir -p " + outputDir;
+    system(mkdirCmd.c_str());
+
+    VideoCapture video(inputVideo);
+    if (!video.isOpened()) {
+        cerr << "Error: Cannot open video file: " << inputVideo << endl;
+        return -1;
+    }
+
     Mat frame, curr, prev, curr64f, prev64f, hann;
-    char key;
+    int frameCount = 0;
 
-    do
+    while (true)
     {
         video >> frame;
+        if (frame.empty())
+            break;
+
         cvtColor(frame, curr, COLOR_RGB2GRAY);
 
-        if(prev.empty())
+        if (prev.empty())
         {
             prev = curr.clone();
             createHanningWindow(hann, curr.size(), CV_64F);
@@ -26,21 +55,25 @@ int main(int, char* [])
         curr.convertTo(curr64f, CV_64F);
 
         Point2d shift = phaseCorrelate(prev64f, curr64f, hann);
-        double radius = std::sqrt(shift.x*shift.x + shift.y*shift.y);
+        double radius = std::sqrt(shift.x * shift.x + shift.y * shift.y);
 
-        if(radius > 5)
+        if (radius > 5)
         {
-            // draw a circle and line indicating the shift direction...
+            // Draw a circle and line indicating the shift direction...
             Point center(curr.cols >> 1, curr.rows >> 1);
             circle(frame, center, (int)radius, Scalar(0, 255, 0), 3, LINE_AA);
             line(frame, center, Point(center.x + (int)shift.x, center.y + (int)shift.y), Scalar(0, 255, 0), 3, LINE_AA);
         }
 
-        imshow("phase shift", frame);
-        key = (char)waitKey(2);
+        // Save the processed frame
+        string frameFilename = outputDir + "/frame_" + to_string(frameCount) + ".png";
+        imwrite(frameFilename, frame);
+        cout << "Frame saved at: " << frameFilename << endl;
 
         prev = curr.clone();
-    } while(key != 27); // Esc to exit...
+        frameCount++;
+    }
 
     return 0;
 }
+
diff --git a/samples/cpp/points_classifier.cpp b/samples/cpp/points_classifier.cpp
index 02e393495d..75a67475a5 100644
--- a/samples/cpp/points_classifier.cpp
+++ b/samples/cpp/points_classifier.cpp
@@ -4,13 +4,15 @@
 #include "opencv2/highgui.hpp"
 
 #include <stdio.h>
+#include <iostream>
+#include <fstream>
+#include <vector>
 
 using namespace std;
 using namespace cv;
 using namespace cv::ml;
 
 const Scalar WHITE_COLOR = Scalar(255,255,255);
-const string winName = "points";
 const int testStep = 5;
 
 Mat img, imgDst;
@@ -33,37 +35,6 @@ vector<int> classCounters(MAX_CLASSES);
 #define _ANN_ 1 // artificial neural networks
 #define _EM_  1 // expectation-maximization
 
-static void on_mouse( int event, int x, int y, int /*flags*/, void* )
-{
-    if( img.empty() )
-        return;
-
-    int updateFlag = 0;
-
-    if( event == EVENT_LBUTTONUP )
-    {
-        trainedPoints.push_back( Point(x,y) );
-        trainedPointsMarkers.push_back( currentClass );
-        classCounters[currentClass]++;
-        updateFlag = true;
-    }
-
-    //draw
-    if( updateFlag )
-    {
-        img = Scalar::all(0);
-
-        // draw points
-        for( size_t i = 0; i < trainedPoints.size(); i++ )
-        {
-            Vec3b c = classColors[trainedPointsMarkers[i]];
-            circle( img, trainedPoints[i], 5, Scalar(c), -1 );
-        }
-
-        imshow( winName, img );
-   }
-}
-
 static Mat prepare_train_samples(const vector<Point>& pts)
 {
     Mat samples;
@@ -77,7 +48,7 @@ static Ptr<TrainData> prepare_train_data()
     return TrainData::create(samples, ROW_SAMPLE, Mat(trainedPointsMarkers));
 }
 
-static void predict_and_paint(const Ptr<StatModel>& model, Mat& dst)
+static void predict_and_save(const Ptr<StatModel>& model, Mat& dst, const string& filename)
 {
     Mat testSample( 1, 2, CV_32FC1 );
     for( int y = 0; y < img.rows; y += testStep )
@@ -91,37 +62,35 @@ static void predict_and_paint(const Ptr<StatModel>& model, Mat& dst)
             dst.at<Vec3b>(y, x) = classColors[response];
         }
     }
+    imwrite(filename, dst);
+    cout << "Output saved to: " << filename << endl;
 }
 
 #if _NBC_
-static void find_decision_boundary_NBC()
+static void find_decision_boundary_NBC(const string& filename)
 {
-    // learn classifier
     Ptr<NormalBayesClassifier> normalBayesClassifier = StatModel::train<NormalBayesClassifier>(prepare_train_data());
-
-    predict_and_paint(normalBayesClassifier, imgDst);
+    predict_and_save(normalBayesClassifier, imgDst, filename);
 }
 #endif
 
-
 #if _KNN_
-static void find_decision_boundary_KNN( int K )
+static void find_decision_boundary_KNN(int K, const string& filename)
 {
-
     Ptr<KNearest> knn = KNearest::create();
     knn->setDefaultK(K);
     knn->setIsClassifier(true);
     knn->train(prepare_train_data());
-    predict_and_paint(knn, imgDst);
+    predict_and_save(knn, imgDst, filename);
 }
 #endif
 
 #if _SVM_
-static void find_decision_boundary_SVM( double C )
+static void find_decision_boundary_SVM(double C, const string& filename)
 {
     Ptr<SVM> svm = SVM::create();
     svm->setType(SVM::C_SVC);
-    svm->setKernel(SVM::POLY); //SVM::LINEAR;
+    svm->setKernel(SVM::POLY);
     svm->setDegree(0.5);
     svm->setGamma(1);
     svm->setCoef0(1);
@@ -130,34 +99,27 @@ static void find_decision_boundary_SVM( double C )
     svm->setTermCriteria(TermCriteria(TermCriteria::MAX_ITER+TermCriteria::EPS, 1000, 0.01));
     svm->setC(C);
     svm->train(prepare_train_data());
-    predict_and_paint(svm, imgDst);
-
-    Mat sv = svm->getSupportVectors();
-    for( int i = 0; i < sv.rows; i++ )
-    {
-        const float* supportVector = sv.ptr<float>(i);
-        circle( imgDst, Point(saturate_cast<int>(supportVector[0]),saturate_cast<int>(supportVector[1])), 5, Scalar(255,255,255), -1 );
-    }
+    predict_and_save(svm, imgDst, filename);
 }
 #endif
 
 #if _DT_
-static void find_decision_boundary_DT()
+static void find_decision_boundary_DT(const string& filename)
 {
     Ptr<DTrees> dtree = DTrees::create();
     dtree->setMaxDepth(8);
     dtree->setMinSampleCount(2);
     dtree->setUseSurrogates(false);
-    dtree->setCVFolds(0); // the number of cross-validation folds
+    dtree->setCVFolds(0);
     dtree->setUse1SERule(false);
     dtree->setTruncatePrunedTree(false);
     dtree->train(prepare_train_data());
-    predict_and_paint(dtree, imgDst);
+    predict_and_save(dtree, imgDst, filename);
 }
 #endif
 
 #if _BT_
-static void find_decision_boundary_BT()
+static void find_decision_boundary_BT(const string& filename)
 {
     Ptr<Boost> boost = Boost::create();
     boost->setBoostType(Boost::DISCRETE);
@@ -167,29 +129,12 @@ static void find_decision_boundary_BT()
     boost->setUseSurrogates(false);
     boost->setPriors(Mat());
     boost->train(prepare_train_data());
-    predict_and_paint(boost, imgDst);
-}
-
-#endif
-
-#if _GBT_
-static void find_decision_boundary_GBT()
-{
-    GBTrees::Params params( GBTrees::DEVIANCE_LOSS, // loss_function_type
-                         100, // weak_count
-                         0.1f, // shrinkage
-                         1.0f, // subsample_portion
-                         2, // max_depth
-                         false // use_surrogates )
-                         );
-
-    Ptr<GBTrees> gbtrees = StatModel::train<GBTrees>(prepare_train_data(), params);
-    predict_and_paint(gbtrees, imgDst);
+    predict_and_save(boost, imgDst, filename);
 }
 #endif
 
 #if _RF_
-static void find_decision_boundary_RF()
+static void find_decision_boundary_RF(const string& filename)
 {
     Ptr<RTrees> rtrees = RTrees::create();
     rtrees->setMaxDepth(4);
@@ -202,198 +147,61 @@ static void find_decision_boundary_RF()
     rtrees->setActiveVarCount(1);
     rtrees->setTermCriteria(TermCriteria(TermCriteria::MAX_ITER, 5, 0));
     rtrees->train(prepare_train_data());
-    predict_and_paint(rtrees, imgDst);
+    predict_and_save(rtrees, imgDst, filename);
 }
-
 #endif
 
-#if _ANN_
-static void find_decision_boundary_ANN( const Mat&  layer_sizes )
+int main(int argc, char** argv)
 {
-    Mat trainClasses = Mat::zeros( (int)trainedPoints.size(), (int)classColors.size(), CV_32FC1 );
-    for( int i = 0; i < trainClasses.rows; i++ )
+    cv::CommandLineParser parser(argc, argv, "{help h||}{@output| |output image filename}");
+    parser.about("This sample demonstrates various ML classifiers.");
+    if (parser.has("help"))
     {
-        trainClasses.at<float>(i, trainedPointsMarkers[i]) = 1.f;
-    }
-
-    Mat samples = prepare_train_samples(trainedPoints);
-    Ptr<TrainData> tdata = TrainData::create(samples, ROW_SAMPLE, trainClasses);
-
-    Ptr<ANN_MLP> ann = ANN_MLP::create();
-    ann->setLayerSizes(layer_sizes);
-    ann->setActivationFunction(ANN_MLP::SIGMOID_SYM, 1, 1);
-    ann->setTermCriteria(TermCriteria(TermCriteria::MAX_ITER+TermCriteria::EPS, 300, FLT_EPSILON));
-    ann->setTrainMethod(ANN_MLP::BACKPROP, 0.001);
-    ann->train(tdata);
-    predict_and_paint(ann, imgDst);
-}
-#endif
-
-#if _EM_
-static void find_decision_boundary_EM()
-{
-    img.copyTo( imgDst );
-
-    Mat samples = prepare_train_samples(trainedPoints);
-
-    int i, j, nmodels = (int)classColors.size();
-    vector<Ptr<EM> > em_models(nmodels);
-    Mat modelSamples;
-
-    for( i = 0; i < nmodels; i++ )
-    {
-        const int componentCount = 3;
-
-        modelSamples.release();
-        for( j = 0; j < samples.rows; j++ )
-        {
-            if( trainedPointsMarkers[j] == i )
-                modelSamples.push_back(samples.row(j));
-        }
-
-        // learn models
-        if( !modelSamples.empty() )
-        {
-            Ptr<EM> em = EM::create();
-            em->setClustersNumber(componentCount);
-            em->setCovarianceMatrixType(EM::COV_MAT_DIAGONAL);
-            em->trainEM(modelSamples, noArray(), noArray(), noArray());
-            em_models[i] = em;
-        }
+        parser.printMessage();
+        return 0;
     }
-
-    // classify coordinate plane points using the bayes classifier, i.e.
-    // y(x) = arg max_i=1_modelsCount likelihoods_i(x)
-    Mat testSample(1, 2, CV_32FC1 );
-    Mat logLikelihoods(1, nmodels, CV_64FC1, Scalar(-DBL_MAX));
-
-    for( int y = 0; y < img.rows; y += testStep )
+    string outputFileName = parser.get<string>("@output");
+    if (outputFileName.empty())
     {
-        for( int x = 0; x < img.cols; x += testStep )
-        {
-            testSample.at<float>(0) = (float)x;
-            testSample.at<float>(1) = (float)y;
-
-            for( i = 0; i < nmodels; i++ )
-            {
-                if( !em_models[i].empty() )
-                    logLikelihoods.at<double>(i) = em_models[i]->predict2(testSample, noArray())[0];
-            }
-            Point maxLoc;
-            minMaxLoc(logLikelihoods, 0, 0, 0, &maxLoc);
-            imgDst.at<Vec3b>(y, x) = classColors[maxLoc.x];
-        }
+        cout << "Output file path is required." << endl;
+        return 1;
     }
-}
-#endif
-
-int main()
-{
-    cout << "Use:" << endl
-         << "  key '0' .. '1' - switch to class #n" << endl
-         << "  left mouse button - to add new point;" << endl
-         << "  key 'r' - to run the ML model;" << endl
-         << "  key 'i' - to init (clear) the data." << endl << endl;
-
-    cv::namedWindow( "points", 1 );
-    img.create( 480, 640, CV_8UC3 );
-    imgDst.create( 480, 640, CV_8UC3 );
 
-    imshow( "points", img );
-    setMouseCallback( "points", on_mouse );
+    img.create(480, 640, CV_8UC3);
+    imgDst.create(480, 640, CV_8UC3);
 
     classColors[0] = Vec3b(0, 255, 0);
     classColors[1] = Vec3b(0, 0, 255);
 
-    for(;;)
-    {
-        char key = (char)waitKey();
+    // For demonstration, we add some sample points to train
+    // These points should be replaced by actual training data in a real scenario
+    trainedPoints.push_back(Point(100, 100));
+    trainedPointsMarkers.push_back(0);
+    classCounters[0]++;
+    trainedPoints.push_back(Point(500, 100));
+    trainedPointsMarkers.push_back(1);
+    classCounters[1]++;
 
-        if( key == 27 ) break;
-
-        if( key == 'i' ) // init
-        {
-            img = Scalar::all(0);
-
-            trainedPoints.clear();
-            trainedPointsMarkers.clear();
-            classCounters.assign(MAX_CLASSES, 0);
-
-            imshow( winName, img );
-        }
-
-        if( key == '0' || key == '1' )
-        {
-            currentClass = key - '0';
-        }
-
-        if( key == 'r' ) // run
-        {
-            double minVal = 0;
-            minMaxLoc(classCounters, &minVal, 0, 0, 0);
-            if( minVal == 0 )
-            {
-                printf("each class should have at least 1 point\n");
-                continue;
-            }
-            img.copyTo( imgDst );
+    // Example usage of classifiers
 #if _NBC_
-            find_decision_boundary_NBC();
-            imshow( "NormalBayesClassifier", imgDst );
+    find_decision_boundary_NBC(outputFileName);
 #endif
 #if _KNN_
-            find_decision_boundary_KNN( 3 );
-            imshow( "kNN", imgDst );
-
-            find_decision_boundary_KNN( 15 );
-            imshow( "kNN2", imgDst );
+    find_decision_boundary_KNN(3, outputFileName);
 #endif
-
 #if _SVM_
-            //(1)-(2)separable and not sets
-
-            find_decision_boundary_SVM( 1 );
-            imshow( "classificationSVM1", imgDst );
-
-            find_decision_boundary_SVM( 10 );
-            imshow( "classificationSVM2", imgDst );
+    find_decision_boundary_SVM(1.0, outputFileName);
 #endif
-
 #if _DT_
-            find_decision_boundary_DT();
-            imshow( "DT", imgDst );
+    find_decision_boundary_DT(outputFileName);
 #endif
-
 #if _BT_
-            find_decision_boundary_BT();
-            imshow( "BT", imgDst);
+    find_decision_boundary_BT(outputFileName);
 #endif
-
-#if _GBT_
-            find_decision_boundary_GBT();
-            imshow( "GBT", imgDst);
-#endif
-
 #if _RF_
-            find_decision_boundary_RF();
-            imshow( "RF", imgDst);
-#endif
-
-#if _ANN_
-            Mat layer_sizes1( 1, 3, CV_32SC1 );
-            layer_sizes1.at<int>(0) = 2;
-            layer_sizes1.at<int>(1) = 5;
-            layer_sizes1.at<int>(2) = (int)classColors.size();
-            find_decision_boundary_ANN( layer_sizes1 );
-            imshow( "ANN", imgDst );
+    find_decision_boundary_RF(outputFileName);
 #endif
 
-#if _EM_
-            find_decision_boundary_EM();
-            imshow( "EM", imgDst );
-#endif
-        }
-    }
-
     return 0;
 }
+
diff --git a/samples/cpp/polar_transforms.cpp b/samples/cpp/polar_transforms.cpp
index cdd653a29e..69cfbf4600 100644
--- a/samples/cpp/polar_transforms.cpp
+++ b/samples/cpp/polar_transforms.cpp
@@ -4,61 +4,55 @@
 #include <iostream>
 
 using namespace cv;
+using namespace std;
 
-int main( int argc, char** argv )
+int main(int argc, char** argv)
 {
     VideoCapture capture;
     Mat log_polar_img, lin_polar_img, recovered_log_polar, recovered_lin_polar_img;
 
-    CommandLineParser parser(argc, argv, "{@input|0| camera device number or video file path}");
+    CommandLineParser parser(argc, argv, "{@input|0| camera device number or video file path}{@output|output.jpg|output image file path}");
     parser.about("\nThis program illustrates usage of Linear-Polar and Log-Polar image transforms\n");
     parser.printMessage();
     std::string arg = parser.get<std::string>("@input");
+    std::string output = parser.get<std::string>("@output");
 
-    if( arg.size() == 1 && isdigit(arg[0]) )
-        capture.open( arg[0] - '0' );
+    if (arg.size() == 1 && isdigit(arg[0]))
+        capture.open(arg[0] - '0');
     else
         capture.open(samples::findFileOrKeep(arg));
 
-    if( !capture.isOpened() )
+    if (!capture.isOpened())
     {
-        fprintf(stderr,"Could not initialize capturing...\n");
+        fprintf(stderr, "Could not initialize capturing...\n");
         return -1;
     }
 
-    namedWindow( "Linear-Polar", WINDOW_AUTOSIZE );
-    namedWindow( "Log-Polar", WINDOW_AUTOSIZE);
-    namedWindow( "Recovered Linear-Polar", WINDOW_AUTOSIZE);
-    namedWindow( "Recovered Log-Polar", WINDOW_AUTOSIZE);
+    // namedWindow("Linear-Polar", WINDOW_AUTOSIZE);
+    // namedWindow("Log-Polar", WINDOW_AUTOSIZE);
+    // namedWindow("Recovered Linear-Polar", WINDOW_AUTOSIZE);
+    // namedWindow("Recovered Log-Polar", WINDOW_AUTOSIZE);
 
-    moveWindow( "Linear-Polar", 20,20 );
-    moveWindow( "Log-Polar", 700,20 );
-    moveWindow( "Recovered Linear-Polar", 20, 350 );
-    moveWindow( "Recovered Log-Polar", 700, 350 );
+    // moveWindow("Linear-Polar", 20, 20);
+    // moveWindow("Log-Polar", 700, 20);
+    // moveWindow("Recovered Linear-Polar", 20, 350);
+    // moveWindow("Recovered Log-Polar", 700, 350);
     int flags = INTER_LINEAR + WARP_FILL_OUTLIERS;
     Mat src;
-    for(;;)
+    for (;;)
     {
         capture >> src;
 
-        if(src.empty() )
+        if (src.empty())
             break;
 
-        Point2f center( (float)src.cols / 2, (float)src.rows / 2 );
-        double maxRadius = 0.7*min(center.y, center.x);
+        Point2f center((float)src.cols / 2, (float)src.rows / 2);
+        double maxRadius = 0.7 * min(center.y, center.x);
 
-#if 0 //deprecated
-        double M = frame.cols / log(maxRadius);
-        logPolar(frame, log_polar_img, center, M, flags);
-        linearPolar(frame, lin_polar_img, center, maxRadius, flags);
-
-        logPolar(log_polar_img, recovered_log_polar, center, M, flags + WARP_INVERSE_MAP);
-        linearPolar(lin_polar_img, recovered_lin_polar_img, center, maxRadius, flags + WARP_INVERSE_MAP);
-#endif
         //! [InverseMap]
         // direct transform
-        warpPolar(src, lin_polar_img, Size(),center, maxRadius, flags);                     // linear Polar
-        warpPolar(src, log_polar_img, Size(),center, maxRadius, flags + WARP_POLAR_LOG);    // semilog Polar
+        warpPolar(src, lin_polar_img, Size(), center, maxRadius, flags);                     // linear Polar
+        warpPolar(src, log_polar_img, Size(), center, maxRadius, flags + WARP_POLAR_LOG);    // semilog Polar
         // inverse transform
         warpPolar(lin_polar_img, recovered_lin_polar_img, src.size(), center, maxRadius, flags + WARP_INVERSE_MAP);
         warpPolar(log_polar_img, recovered_log_polar, src.size(), center, maxRadius, flags + WARP_POLAR_LOG + WARP_INVERSE_MAP);
@@ -70,7 +64,7 @@ int main( int argc, char** argv )
             dst = log_polar_img;
         else
             dst = lin_polar_img;
-        //get a point from the polar image
+        // get a point from the polar image
         int rho = cvRound(dst.cols * 0.75);
         int phi = cvRound(dst.rows / 2.0);
 
@@ -94,14 +88,24 @@ int main( int argc, char** argv )
         drawMarker(src, Point(x, y), Scalar(0, 255, 0));
         drawMarker(dst, Point(rho, phi), Scalar(0, 255, 0));
 
-        imshow("Src frame", src);
-        imshow("Log-Polar", log_polar_img);
-        imshow("Linear-Polar", lin_polar_img);
-        imshow("Recovered Linear-Polar", recovered_lin_polar_img );
-        imshow("Recovered Log-Polar", recovered_log_polar );
+        // imshow("Src frame", src);
+        // imshow("Log-Polar", log_polar_img);
+        // imshow("Linear-Polar", lin_polar_img);
+        // imshow("Recovered Linear-Polar", recovered_lin_polar_img);
+        // imshow("Recovered Log-Polar", recovered_log_polar);
+
+        // Save images to files
+        imwrite(output + "_src.jpg", src);
+        imwrite(output + "_log_polar.jpg", log_polar_img);
+        imwrite(output + "_linear_polar.jpg", lin_polar_img);
+        imwrite(output + "_recovered_linear_polar.jpg", recovered_lin_polar_img);
+        imwrite(output + "_recovered_log_polar.jpg", recovered_log_polar);
 
-        if( waitKey(10) >= 0 )
+        cout << "Images saved to: " << output << "_*.jpg" << endl;
+
+        if (waitKey(10) >= 0)
             break;
     }
     return 0;
 }
+
diff --git a/samples/cpp/qrcode.cpp b/samples/cpp/qrcode.cpp
index 6b914f78ef..40594110de 100644
--- a/samples/cpp/qrcode.cpp
+++ b/samples/cpp/qrcode.cpp
@@ -5,11 +5,13 @@
 #include "opencv2/imgcodecs.hpp"
 #include <string>
 #include <iostream>
+#include <sys/stat.h>
+#include <sys/types.h>
 
 using namespace std;
 using namespace cv;
 
-static int liveQRCodeDetect();
+static int liveQRCodeDetect(const string& video_file);
 static int imageQRCodeDetect(const string& in_file);
 
 static bool g_useArucoBased = false;
@@ -42,6 +44,7 @@ int main(int argc, char *argv[])
         "{o out    | qr_code.png | path to result file }"
         "{save_detections | false  | save all QR detections (video mode only) }"
         "{save_all | false  | save all processed frames  (video mode only) }"
+        "{video    |        | use video as input instead of camera}"
     ;
     CommandLineParser cmd_parser(argc, argv, keys);
 
@@ -53,6 +56,7 @@ int main(int argc, char *argv[])
     }
 
     string in_file_name = cmd_parser.get<string>("in");    // path to input image
+    string video_file_name = cmd_parser.get<string>("video");
 
     if (cmd_parser.has("out"))
     {
@@ -82,51 +86,51 @@ int main(int argc, char *argv[])
     g_saveDetections = cmd_parser.has("save_detections") && cmd_parser.get<bool>("save_detections");
     g_saveAll = cmd_parser.has("save_all") && cmd_parser.get<bool>("save_all");
 
+    // Create output directory if it doesn't exist
+    system("mkdir -p qrcode");
+
     int return_code = 0;
-    if (in_file_name.empty())
+    if (!in_file_name.empty())
     {
-        return_code = liveQRCodeDetect();
+        return_code = imageQRCodeDetect(samples::findFile(in_file_name));
     }
     else
     {
-        return_code = imageQRCodeDetect(samples::findFile(in_file_name));
+        return_code = liveQRCodeDetect(samples::findFile(video_file_name));
     }
     return return_code;
 }
 
-static
-void drawQRCodeContour(Mat &color_image, const vector<Point>& corners)
+static void drawQRCodeContour(Mat &color_image, const vector<Point>& corners)
 {
     if (!corners.empty())
     {
-        double show_radius = (color_image.rows  > color_image.cols)
-                   ? (2.813 * color_image.rows) / color_image.cols
-                   : (2.813 * color_image.cols) / color_image.rows;
+        double show_radius = (color_image.rows > color_image.cols)
+            ? (2.813 * color_image.rows) / color_image.cols
+            : (2.813 * color_image.cols) / color_image.rows;
         double contour_radius = show_radius * 0.4;
 
-        vector< vector<Point> > contours;
+        vector<vector<Point>> contours;
         contours.push_back(corners);
         drawContours(color_image, contours, 0, Scalar(211, 0, 148), cvRound(contour_radius));
 
         RNG rng(1000);
         for (size_t i = 0; i < 4; i++)
         {
-            Scalar color = Scalar(rng.uniform(0,255), rng.uniform(0, 255), rng.uniform(0, 255));
+            Scalar color = Scalar(rng.uniform(0, 255), rng.uniform(0, 255), rng.uniform(0, 255));
             circle(color_image, corners[i], cvRound(show_radius), color, -1);
         }
     }
 }
 
-static
-void drawFPS(Mat &color_image, double fps)
+static void drawFPS(Mat &color_image, double fps)
 {
     ostringstream convert;
     convert << cv::format("%.2f", fps) << " FPS (" << getQRModeString() << ")";
     putText(color_image, convert.str(), Point(25, 25), FONT_HERSHEY_DUPLEX, 1, Scalar(0, 0, 255), 2);
 }
 
-static
-void drawQRCodeResults(Mat& frame, const vector<Point>& corners, const vector<cv::String>& decode_info, double fps)
+static void drawQRCodeResults(Mat& frame, const vector<Point>& corners, const vector<cv::String>& decode_info, double fps)
 {
     if (!corners.empty())
     {
@@ -158,11 +162,9 @@ void drawQRCodeResults(Mat& frame, const vector<Point>& corners, const vector<cv
     drawFPS(frame, fps);
 }
 
-static
-void runQR(
+static void runQR(
     const GraphicalCodeDetector& qrcode, const Mat& input,
     vector<Point>& corners, vector<cv::String>& decode_info
-    // +global: bool g_modeMultiQR, bool g_detectOnly
 )
 {
     if (!g_modeMultiQR)
@@ -193,8 +195,7 @@ void runQR(
     }
 }
 
-static
-double processQRCodeDetection(const GraphicalCodeDetector& qrcode, const Mat& input, Mat& result, vector<Point>& corners)
+static double processQRCodeDetection(const GraphicalCodeDetector& qrcode, const Mat& input, Mat& result, vector<Point>& corners)
 {
     if (input.channels() == 1)
         cvtColor(input, result, COLOR_GRAY2BGR);
@@ -218,14 +219,27 @@ double processQRCodeDetection(const GraphicalCodeDetector& qrcode, const Mat& in
     return fps;
 }
 
-int liveQRCodeDetect()
+int liveQRCodeDetect(const string& video_file)
 {
-    VideoCapture cap(0);
+    VideoCapture cap;
 
-    if (!cap.isOpened())
+    if (!video_file.empty())
     {
-        cout << "Cannot open a camera" << endl;
-        return 2;
+        cap.open(video_file);
+        if (!cap.isOpened())
+        {
+            cout << "Cannot open the video file: " << video_file << endl;
+            return 2;
+        }
+    }
+    else
+    {
+        cap.open(0);
+        if (!cap.isOpened())
+        {
+            cout << "Cannot open a camera" << endl;
+            return 2;
+        }
     }
 
     cout << "Press 'm' to switch between detectAndDecode and detectAndDecodeMulti" << endl;
@@ -256,7 +270,6 @@ int liveQRCodeDetect()
             double fps = processQRCodeDetection(qrcode, frame, result, corners);
             cout << "FPS: " << fps << endl;
             forceSave |= (g_saveDetections && !corners.empty());
-            //forceSave |= fps < 1.0;
         }
         catch (const cv::Exception& e)
         {
@@ -265,26 +278,30 @@ int liveQRCodeDetect()
         }
 
         if (!result.empty())
-            imshow("QR code", result);
-
-        int code = waitKey(1);
-        if (code < 0 && !forceSave)
-            continue; // timeout
-        char c = (char)code;
-        if (c == ' ' || forceSave)
         {
+            // imshow("QR code", result); // Commented out to run in headless mode
+
             string fsuffix = cv::format("-%05d", g_save_idx++);
 
-            string fname_input = g_out_file_name + fsuffix + "_input.png";
+            string fname_input = "qrcode/" + g_out_file_name + fsuffix + "_input.png";
             cout << "Saving QR code detection input: '" << fname_input << "' ..." << endl;
             imwrite(fname_input, frame);
 
-            string fname = g_out_file_name + fsuffix + g_out_file_ext;
+            string fname = "qrcode/" + g_out_file_name + fsuffix + g_out_file_ext;
             cout << "Saving QR code detection result: '" << fname << "' ..." << endl;
             imwrite(fname, result);
 
             cout << "Saved" << endl;
         }
+
+        int code = waitKey(1);
+        if (code < 0 && !forceSave)
+            continue; // timeout
+        char c = (char)code;
+        if (c == ' ')
+        {
+            forceSave = true;
+        }
         if (c == 'm')
         {
             g_modeMultiQR = !g_modeMultiQR;
@@ -338,18 +355,21 @@ int imageQRCodeDetect(const string& in_file)
     Mat result; input.copyTo(result);
     drawQRCodeResults(result, corners, decode_info, fps);
 
-    imshow("QR", result); waitKey(1);
+    // imshow("QR", result); // Commented out to run in headless mode
 
     if (!g_out_file_name.empty())
     {
-        string out_file = g_out_file_name + g_out_file_ext;
+        // Manually create the directory if it doesn't exist
+        system("mkdir -p qrcode");
+        string out_file = "qrcode/" + g_out_file_name + g_out_file_ext;
         cout << "Saving result: " << out_file << endl;
         imwrite(out_file, result);
     }
 
-    cout << "Press any key to exit ..." << endl;
-    waitKey(0);
+    // waitKey(0); // Commented out to run in headless mode
+
     cout << "Exit." << endl;
 
     return 0;
 }
+
diff --git a/samples/cpp/segment_objects.cpp b/samples/cpp/segment_objects.cpp
index 2bcddddf85..f9cb0447b7 100644
--- a/samples/cpp/segment_objects.cpp
+++ b/samples/cpp/segment_objects.cpp
@@ -2,8 +2,9 @@
 #include "opencv2/videoio.hpp"
 #include "opencv2/highgui.hpp"
 #include "opencv2/video/background_segm.hpp"
-#include <stdio.h>
+#include <iostream>
 #include <string>
+#include <cstdlib>
 
 using namespace std;
 using namespace cv;
@@ -11,18 +12,18 @@ using namespace cv;
 static void help(char** argv)
 {
     printf("\n"
-            "This program demonstrated a simple method of connected components clean up of background subtraction\n"
-            "When the program starts, it begins learning the background.\n"
-            "You can toggle background learning on and off by hitting the space bar.\n"
-            "Call\n"
-            "%s [video file, else it reads camera 0]\n\n", argv[0]);
+           "This program demonstrated a simple method of connected components clean up of background subtraction\n"
+           "When the program starts, it begins learning the background.\n"
+           "You can toggle background learning on and off by hitting the space bar.\n"
+           "Call\n"
+           "%s [video file, else it reads camera 0]\n\n", argv[0]);
 }
 
 static void refineSegments(const Mat& img, Mat& mask, Mat& dst)
 {
     int niters = 3;
 
-    vector<vector<Point> > contours;
+    vector<vector<Point>> contours;
     vector<Vec4i> hierarchy;
 
     Mat temp;
@@ -31,33 +32,30 @@ static void refineSegments(const Mat& img, Mat& mask, Mat& dst)
     erode(temp, temp, Mat(), Point(-1,-1), niters*2);
     dilate(temp, temp, Mat(), Point(-1,-1), niters);
 
-    findContours( temp, contours, hierarchy, RETR_CCOMP, CHAIN_APPROX_SIMPLE );
+    findContours(temp, contours, hierarchy, RETR_CCOMP, CHAIN_APPROX_SIMPLE);
 
     dst = Mat::zeros(img.size(), CV_8UC3);
 
-    if( contours.size() == 0 )
+    if (contours.size() == 0)
         return;
 
-    // iterate through all the top-level contours,
-    // draw each connected component with its own random color
     int idx = 0, largestComp = 0;
     double maxArea = 0;
 
-    for( ; idx >= 0; idx = hierarchy[idx][0] )
+    for (; idx >= 0; idx = hierarchy[idx][0])
     {
         const vector<Point>& c = contours[idx];
         double area = fabs(contourArea(Mat(c)));
-        if( area > maxArea )
+        if (area > maxArea)
         {
             maxArea = area;
             largestComp = idx;
         }
     }
-    Scalar color( 0, 0, 255 );
-    drawContours( dst, contours, largestComp, color, FILLED, LINE_8, hierarchy );
+    Scalar color(0, 0, 255);
+    drawContours(dst, contours, largestComp, color, FILLED, LINE_8, hierarchy);
 }
 
-
 int main(int argc, char** argv)
 {
     VideoCapture cap;
@@ -69,51 +67,59 @@ int main(int argc, char** argv)
         help(argv);
         return 0;
     }
-    string input = parser.get<std::string>("@input");
+    string input = parser.get<string>("@input");
     if (input.empty())
         cap.open(0);
     else
         cap.open(samples::findFileOrKeep(input));
 
-    if( !cap.isOpened() )
+    if (!cap.isOpened())
     {
-        printf("\nCan not open camera or video file\n");
+        cout << "Can not open camera or video file" << endl;
         return -1;
     }
 
+    // 创建子目录 "segment_objects"
+    string outputDir = "segment_objects";
+    system(("mkdir -p " + outputDir).c_str());  // 创建目录
+
     Mat tmp_frame, bgmask, out_frame;
 
     cap >> tmp_frame;
-    if(tmp_frame.empty())
+    if (tmp_frame.empty())
     {
-        printf("can not read data from the video source\n");
+        cout << "Can not read data from the video source" << endl;
         return -1;
     }
 
-    namedWindow("video", 1);
-    namedWindow("segmented", 1);
-
-    Ptr<BackgroundSubtractorMOG2> bgsubtractor=createBackgroundSubtractorMOG2();
+    Ptr<BackgroundSubtractorMOG2> bgsubtractor = createBackgroundSubtractorMOG2();
     bgsubtractor->setVarThreshold(10);
 
-    for(;;)
+    int frame_count = 0;
+    for (;;)
     {
         cap >> tmp_frame;
-        if( tmp_frame.empty() )
+        if (tmp_frame.empty())
             break;
+
         bgsubtractor->apply(tmp_frame, bgmask, update_bg_model ? -1 : 0);
         refineSegments(tmp_frame, bgmask, out_frame);
-        imshow("video", tmp_frame);
-        imshow("segmented", out_frame);
-        char keycode = (char)waitKey(30);
-        if( keycode == 27 )
-            break;
-        if( keycode == ' ' )
-        {
-            update_bg_model = !update_bg_model;
-            printf("Learn background is in state = %d\n",update_bg_model);
-        }
+
+        // 保存每一帧的处理结果
+        string filename = outputDir + "/segmented_frame_" + to_string(frame_count++) + ".png";
+        imwrite(filename, out_frame);
+        cout << "Saved: " << filename << endl;
+
+        // char keycode = (char)waitKey(30);
+        // if (keycode == 27)
+        //     break;
+        // if (keycode == ' ')
+        // {
+        //     update_bg_model = !update_bg_model;
+        //     cout << "Learn background is in state = " << update_bg_model << endl;
+        // }
     }
 
     return 0;
 }
+
diff --git a/samples/cpp/select3dobj.cpp b/samples/cpp/select3dobj.cpp
index 0f19eb2332..eff92d85e1 100644
--- a/samples/cpp/select3dobj.cpp
+++ b/samples/cpp/select3dobj.cpp
@@ -1,13 +1,3 @@
-/*
- *
- * select3obj.cpp With a calibration chessboard on a table, mark an object in a 3D box and
- *                track that object in all subsequent frames as long as the camera can see
- *                the chessboard. Also segments the object using the box projection. This
- *                program is useful for collecting large datasets of many views of an object
- *                on a table.
- *
- */
-
 #include "opencv2/core.hpp"
 #include <opencv2/core/utility.hpp>
 #include "opencv2/imgproc.hpp"
@@ -37,11 +27,11 @@ static string helphelp(char** argv)
             "           -i=<camera_intrinsics_filename> -o=<output_prefix>\n"
             "\n"
             " -w=<board_width>          Number of chessboard corners wide\n"
-            " -h=<board_height>         Number of chessboard corners width\n"
-            " [-s=<square_size>]            Optional measure of chessboard squares in meters\n"
+            " -h=<board_height>         Number of chessboard corners height\n"
+            " [-s=<square_size>]        Optional measure of chessboard squares in meters\n"
             " -i=<camera_intrinsics_filename> Camera matrix .yml file from calibration.cpp\n"
             " -o=<output_prefix>        Prefix the output segmentation images with this\n"
-            " [video_filename/cameraId]  If present, read from that video file or that ID\n"
+            " [video_filename/cameraId] If present, read from that video file or that ID\n"
             "\n"
             "Using a camera's intrinsics (from calibrating a camera -- see calibration.cpp) and an\n"
             "image of the object sitting on a planar surface with a calibration pattern of\n"
@@ -64,37 +54,24 @@ static string helphelp(char** argv)
             "    q     - Exit the program\n"
             "\n\n";
 }
-// static void help()
-// {
-//     puts(helphelp);
-// }
-
-
-struct MouseEvent
-{
-    MouseEvent() { event = -1; buttonState = 0; }
-    Point pt;
-    int event;
-    int buttonState;
-};
-
-static void onMouse(int event, int x, int y, int flags, void* userdata)
-{
-    MouseEvent* data = (MouseEvent*)userdata;
-    data->event = event;
-    data->pt = Point(x,y);
-    data->buttonState = flags;
-}
 
 static bool readCameraMatrix(const string& filename,
                              Mat& cameraMatrix, Mat& distCoeffs,
                              Size& calibratedImageSize )
 {
     FileStorage fs(filename, FileStorage::READ);
+    if (!fs.isOpened()) {
+        cerr << "Error: Could not open the file " << filename << endl;
+        return false;
+    }
     fs["image_width"] >> calibratedImageSize.width;
     fs["image_height"] >> calibratedImageSize.height;
     fs["distortion_coefficients"] >> distCoeffs;
-    fs["camera_matrix"] >> cameraMatrix;
+    fs["cameraMatrix1"] >> cameraMatrix; // 或 cameraMatrix2, cameraMatrix3
+    fs["distCoeffs1"] >> distCoeffs; // 或 distCoeffs2, distCoeffs3
+
+    cout << "Loaded camera matrix: " << cameraMatrix << endl;
+    cout << "Loaded distortion coefficients: " << distCoeffs << endl;
 
     if( distCoeffs.type() != CV_64F )
         distCoeffs = Mat_<double>(distCoeffs);
@@ -115,18 +92,7 @@ static void calcChessboardCorners(Size boardSize, float squareSize, vector<Point
 }
 
 
-static Point3f image2plane(Point2f imgpt, const Mat& R, const Mat& tvec,
-                           const Mat& cameraMatrix, double Z)
-{
-    Mat R1 = R.clone();
-    R1.col(2) = R1.col(2)*Z + tvec;
-    Mat_<double> v = (cameraMatrix*R1).inv()*(Mat_<double>(3,1) << imgpt.x, imgpt.y, 1);
-    double iw = fabs(v(2,0)) > DBL_EPSILON ? 1./v(2,0) : 0;
-    return Point3f((float)(v(0,0)*iw), (float)(v(1,0)*iw), (float)Z);
-}
-
-
-static Rect extract3DBox(const Mat& frame, Mat& shownFrame, Mat& selectedObjFrame,
+static Rect extract3DBox(const Mat& frame, Mat& selectedObjFrame,
                          const Mat& cameraMatrix, const Mat& rvec, const Mat& tvec,
                          const vector<Point3f>& box, int nobjpt, bool runExtraSegmentation)
 {
@@ -150,31 +116,6 @@ static Rect extract3DBox(const Mat& frame, Mat& shownFrame, Mat& selectedObjFram
 
     projectPoints(Mat(objpt), rvec, tvec, cameraMatrix, Mat(), imgpt);
 
-    if( !shownFrame.empty() )
-    {
-        if( nobjpt == 1 )
-            circle(shownFrame, imgpt[0], 3, Scalar(0,255,0), -1, LINE_AA);
-        else if( nobjpt == 2 )
-        {
-            circle(shownFrame, imgpt[0], 3, Scalar(0,255,0), -1, LINE_AA);
-            circle(shownFrame, imgpt[1], 3, Scalar(0,255,0), -1, LINE_AA);
-            line(shownFrame, imgpt[0], imgpt[1], Scalar(0,255,0), 3, LINE_AA);
-        }
-        else if( nobjpt == 3 )
-            for( int i = 0; i < 4; i++ )
-            {
-                circle(shownFrame, imgpt[i], 3, Scalar(0,255,0), -1, LINE_AA);
-                line(shownFrame, imgpt[i], imgpt[(i+1)%4], Scalar(0,255,0), 3, LINE_AA);
-            }
-        else
-            for( int i = 0; i < 8; i++ )
-            {
-                circle(shownFrame, imgpt[i], 3, Scalar(0,255,0), -1, LINE_AA);
-                line(shownFrame, imgpt[i], imgpt[(i+1)%4 + (i/4)*4], Scalar(0,255,0), 3, LINE_AA);
-                line(shownFrame, imgpt[i], imgpt[i%4], Scalar(0,255,0), 3, LINE_AA);
-            }
-    }
-
     if( nobjpt <= 2 )
         return Rect();
     vector<Point> hull;
@@ -197,205 +138,10 @@ static Rect extract3DBox(const Mat& frame, Mat& shownFrame, Mat& selectedObjFram
     return roi;
 }
 
-
-static int select3DBox(const string& windowname, const string& selWinName, const Mat& frame,
-                       const Mat& cameraMatrix, const Mat& rvec, const Mat& tvec,
-                       vector<Point3f>& box)
-{
-    const float eps = 1e-3f;
-    MouseEvent mouse;
-
-    setMouseCallback(windowname, onMouse, &mouse);
-    vector<Point3f> tempobj(8);
-    vector<Point2f> imgpt(4), tempimg(8);
-    vector<Point> temphull;
-    int nobjpt = 0;
-    Mat R, selectedObjMask, selectedObjFrame, shownFrame;
-    Rodrigues(rvec, R);
-    box.resize(4);
-
-    for(;;)
-    {
-        float Z = 0.f;
-        bool dragging = (mouse.buttonState & EVENT_FLAG_LBUTTON) != 0;
-        int npt = nobjpt;
-
-        if( (mouse.event == EVENT_LBUTTONDOWN ||
-             mouse.event == EVENT_LBUTTONUP ||
-             dragging) && nobjpt < 4 )
-        {
-            Point2f m = mouse.pt;
-
-            if( nobjpt < 2 )
-                imgpt[npt] = m;
-            else
-            {
-                tempobj.resize(1);
-                int nearestIdx = npt-1;
-                if( nobjpt == 3 )
-                {
-                    nearestIdx = 0;
-                    for( int i = 1; i < npt; i++ )
-                        if( norm(m - imgpt[i]) < norm(m - imgpt[nearestIdx]) )
-                            nearestIdx = i;
-                }
-
-                if( npt == 2 )
-                {
-                    float dx = box[1].x - box[0].x, dy = box[1].y - box[0].y;
-                    float len = 1.f/std::sqrt(dx*dx+dy*dy);
-                    tempobj[0] = Point3f(dy*len + box[nearestIdx].x,
-                                         -dx*len + box[nearestIdx].y, 0.f);
-                }
-                else
-                    tempobj[0] = Point3f(box[nearestIdx].x, box[nearestIdx].y, 1.f);
-
-                projectPoints(Mat(tempobj), rvec, tvec, cameraMatrix, Mat(), tempimg);
-
-                Point2f a = imgpt[nearestIdx], b = tempimg[0], d1 = b - a, d2 = m - a;
-                float n1 = (float)norm(d1), n2 = (float)norm(d2);
-                if( n1*n2 < eps )
-                    imgpt[npt] = a;
-                else
-                {
-                    Z = d1.dot(d2)/(n1*n1);
-                    imgpt[npt] = d1*Z + a;
-                }
-            }
-            box[npt] = image2plane(imgpt[npt], R, tvec, cameraMatrix, npt<3 ? 0 : Z);
-
-            if( (npt == 0 && mouse.event == EVENT_LBUTTONDOWN) ||
-               (npt > 0 && norm(box[npt] - box[npt-1]) > eps &&
-                mouse.event == EVENT_LBUTTONUP) )
-            {
-                nobjpt++;
-                if( nobjpt < 4 )
-                {
-                    imgpt[nobjpt] = imgpt[nobjpt-1];
-                    box[nobjpt] = box[nobjpt-1];
-                }
-            }
-
-            // reset the event
-            mouse.event = -1;
-            //mouse.buttonState = 0;
-            npt++;
-        }
-
-        frame.copyTo(shownFrame);
-        extract3DBox(frame, shownFrame, selectedObjFrame,
-                     cameraMatrix, rvec, tvec, box, npt, false);
-        imshow(windowname, shownFrame);
-        imshow(selWinName, selectedObjFrame);
-
-        char c = (char)waitKey(30);
-        if( c == 27 )
-        {
-            nobjpt = 0;
-        }
-        if( c == 'q' || c == 'Q' || c == ' ' )
-        {
-            box.clear();
-            return c == ' ' ? -1 : -100;
-        }
-        if( (c == '\r' || c == '\n') && nobjpt == 4 && box[3].z != 0 )
-            return 1;
-    }
-}
-
-
-static bool readModelViews( const string& filename, vector<Point3f>& box,
-                            vector<string>& imagelist,
-                            vector<Rect>& roiList, vector<Vec6f>& poseList )
-{
-    imagelist.resize(0);
-    roiList.resize(0);
-    poseList.resize(0);
-    box.resize(0);
-
-    FileStorage fs(filename, FileStorage::READ);
-    if( !fs.isOpened() )
-        return false;
-    fs["box"] >> box;
-
-    FileNode all = fs["views"];
-    if( all.type() != FileNode::SEQ )
-        return false;
-    FileNodeIterator it = all.begin(), it_end = all.end();
-
-    for(; it != it_end; ++it)
-    {
-        FileNode n = *it;
-        imagelist.push_back((string)n["image"]);
-        FileNode nr = n["rect"];
-        roiList.push_back(Rect((int)nr[0], (int)nr[1], (int)nr[2], (int)nr[3]));
-        FileNode np = n["pose"];
-        poseList.push_back(Vec6f((float)np[0], (float)np[1], (float)np[2],
-                                 (float)np[3], (float)np[4], (float)np[5]));
-    }
-
-    return true;
-}
-
-
-static bool writeModelViews(const string& filename, const vector<Point3f>& box,
-                            const vector<string>& imagelist,
-                            const vector<Rect>& roiList,
-                            const vector<Vec6f>& poseList)
-{
-    FileStorage fs(filename, FileStorage::WRITE);
-    if( !fs.isOpened() )
-        return false;
-
-    fs << "box" << "[:";
-    fs << box << "]" << "views" << "[";
-
-    size_t i, nviews = imagelist.size();
-
-    CV_Assert( nviews == roiList.size() && nviews == poseList.size() );
-
-    for( i = 0; i < nviews; i++ )
-    {
-        Rect r = roiList[i];
-        Vec6f p = poseList[i];
-
-        fs << "{" << "image" << imagelist[i] <<
-            "roi" << "[:" << r.x << r.y << r.width << r.height << "]" <<
-            "pose" << "[:" << p[0] << p[1] << p[2] << p[3] << p[4] << p[5] << "]" << "}";
-    }
-    fs << "]";
-
-    return true;
-}
-
-
-static bool readStringList( const string& filename, vector<string>& l )
-{
-    l.resize(0);
-    FileStorage fs(filename, FileStorage::READ);
-    if( !fs.isOpened() )
-        return false;
-    FileNode n = fs.getFirstTopLevelNode();
-    if( n.type() != FileNode::SEQ )
-        return false;
-    FileNodeIterator it = n.begin(), it_end = n.end();
-    for( ; it != it_end; ++it )
-        l.push_back((string)*it);
-    return true;
-}
-
-
 int main(int argc, char** argv)
 {
     string help = string("Usage: ") + argv[0] + " -w=<board_width> -h=<board_height> [-s=<square_size>]\n" +
            "\t-i=<intrinsics_filename> -o=<output_prefix> [video_filename/cameraId]\n";
-    const char* screen_help =
-    "Actions: \n"
-    "\tSelect object as 3D box with the mouse. That's it\n"
-    "\tESC - Reset the selection\n"
-    "\tSPACE - Skip the frame; move to the next frame (not in video mode)\n"
-    "\tENTER - Confirm the selection. Grab next object in video mode.\n"
-    "\tq - Exit the program\n";
 
     cv::CommandLineParser parser(argc, argv, "{help h||}{w||}{h||}{s|1|}{i||}{o||}{@input|0|}");
     if (parser.has("help"))
@@ -404,135 +150,108 @@ int main(int argc, char** argv)
         puts(help.c_str());
         return 0;
     }
-    string intrinsicsFilename;
-    string outprefix = "";
-    string inputName = "";
+
+    string intrinsicsFilename = parser.get<string>("i");
+    string outprefix = parser.get<string>("o");
+    string inputName = parser.get<string>("@input");
     int cameraId = 0;
     Size boardSize;
     double squareSize;
-    vector<string> imageList;
-    intrinsicsFilename = parser.get<string>("i");
-    outprefix = parser.get<string>("o");
+
     boardSize.width = parser.get<int>("w");
     boardSize.height = parser.get<int>("h");
     squareSize = parser.get<double>("s");
-    if ( parser.get<string>("@input").size() == 1 && isdigit(parser.get<string>("@input")[0]) )
+
+    if (inputName.size() == 1 && isdigit(inputName[0]))
         cameraId = parser.get<int>("@input");
     else
-        inputName = samples::findFileOrKeep(parser.get<string>("@input"));
+        inputName = samples::findFileOrKeep(inputName);
+
     if (!parser.check())
     {
         puts(help.c_str());
         parser.printErrors();
         return 0;
     }
-    if ( boardSize.width <= 0 )
+
+    if (boardSize.width <= 0)
     {
         printf("Incorrect -w parameter (must be a positive integer)\n");
         puts(help.c_str());
         return 0;
     }
-    if ( boardSize.height <= 0 )
+
+    if (boardSize.height <= 0)
     {
         printf("Incorrect -h parameter (must be a positive integer)\n");
         puts(help.c_str());
         return 0;
     }
-    if ( squareSize <= 0 )
+
+    if (squareSize <= 0)
     {
         printf("Incorrect -s parameter (must be a positive real number)\n");
         puts(help.c_str());
         return 0;
     }
+
     Mat cameraMatrix, distCoeffs;
     Size calibratedImageSize;
-    readCameraMatrix(intrinsicsFilename, cameraMatrix, distCoeffs, calibratedImageSize );
+    bool success = readCameraMatrix("camera_params.yml", cameraMatrix, distCoeffs, calibratedImageSize);
+
 
     VideoCapture capture;
-    if( !inputName.empty() )
+    if (!inputName.empty())
     {
-        if( !readStringList(inputName, imageList) &&
-            !capture.open(inputName))
+        if (!capture.open(inputName))
         {
-            fprintf( stderr, "The input file could not be opened\n" );
+            fprintf(stderr, "The input file could not be opened\n");
             return -1;
         }
     }
     else
         capture.open(cameraId);
 
-    if( !capture.isOpened() && imageList.empty() )
-        return fprintf( stderr, "Could not initialize video capture\n" ), -2;
-
-    const char* outbarename = 0;
+    if (!capture.isOpened())
     {
-        outbarename = strrchr(outprefix.c_str(), '/');
-        const char* tmp = strrchr(outprefix.c_str(), '\\');
-        char cmd[1000];
-        snprintf(cmd, sizeof(cmd), "mkdir %s", outprefix.c_str());
-        if( tmp && tmp > outbarename )
-            outbarename = tmp;
-        if( outbarename )
-        {
-            cmd[6 + outbarename - outprefix.c_str()] = '\0';
-            int result = system(cmd);
-            CV_Assert(result == 0);
-            outbarename++;
-        }
-        else
-            outbarename = outprefix.c_str();
+        fprintf(stderr, "Could not initialize video capture\n");
+        return -2;
     }
 
-    Mat frame, shownFrame, selectedObjFrame, mapxy;
+    // 创建输出目录
+    system(("mkdir -p " + outprefix).c_str());
 
-    namedWindow("View", 1);
-    namedWindow("Selected Object", 1);
-    setMouseCallback("View", onMouse, 0);
-    bool boardFound = false;
-
-    string indexFilename = cv::format("%s_index.yml", outprefix.c_str());
-
-    vector<string> capturedImgList;
-    vector<Rect> roiList;
-    vector<Vec6f> poseList;
+    Mat frame, selectedObjFrame, mapxy;
     vector<Point3f> box, boardPoints;
 
-    readModelViews(indexFilename, box, capturedImgList, roiList, poseList);
     calcChessboardCorners(boardSize, (float)squareSize, boardPoints);
     int frameIdx = 0;
-    bool grabNext = !imageList.empty();
-
-    puts(screen_help);
+    bool boardFound = false;
 
-    for(int i = 0;;i++)
+    for (int i = 0;; i++)
     {
         Mat frame0;
-        if( !imageList.empty() )
-        {
-            if( i < (int)imageList.size() )
-                frame0 = imread(string(imageList[i]), 1);
-        }
-        else
-            capture >> frame0;
-        if( frame0.empty() )
+        capture >> frame0;
+        if (frame0.empty())
             break;
-        if( frame.empty() )
+
+        if (frame.empty())
         {
-            if( frame0.size() != calibratedImageSize )
+            if (frame0.size() != calibratedImageSize)
             {
-                double sx = (double)frame0.cols/calibratedImageSize.width;
-                double sy = (double)frame0.rows/calibratedImageSize.height;
+                double sx = (double)frame0.cols / calibratedImageSize.width;
+                double sy = (double)frame0.rows / calibratedImageSize.height;
 
                 // adjust the camera matrix for the new resolution
-                cameraMatrix.at<double>(0,0) *= sx;
-                cameraMatrix.at<double>(0,2) *= sx;
-                cameraMatrix.at<double>(1,1) *= sy;
-                cameraMatrix.at<double>(1,2) *= sy;
+                cameraMatrix.at<double>(0, 0) *= sx;
+                cameraMatrix.at<double>(0, 2) *= sx;
+                cameraMatrix.at<double>(1, 1) *= sy;
+                cameraMatrix.at<double>(1, 2) *= sy;
             }
             Mat dummy;
             initUndistortRectifyMap(cameraMatrix, distCoeffs, Mat(),
                                     cameraMatrix, frame0.size(),
-                                    CV_32FC2, mapxy, dummy );
+                                    CV_32FC2, mapxy, dummy);
             distCoeffs = Mat::zeros(5, 1, CV_64F);
         }
         remap(frame0, frame, mapxy, Mat(), INTER_LINEAR);
@@ -540,69 +259,24 @@ int main(int argc, char** argv)
         boardFound = findChessboardCorners(frame, boardSize, foundBoardCorners);
 
         Mat rvec, tvec;
-        if( boardFound )
+        if (boardFound)
             solvePnP(Mat(boardPoints), Mat(foundBoardCorners), cameraMatrix,
                      distCoeffs, rvec, tvec, false);
 
-        frame.copyTo(shownFrame);
-        drawChessboardCorners(shownFrame, boardSize, Mat(foundBoardCorners), boardFound);
         selectedObjFrame = Mat::zeros(frame.size(), frame.type());
 
-        if( boardFound && grabNext )
+        if (boardFound && !box.empty())
         {
-            if( box.empty() )
-            {
-                int code = select3DBox("View", "Selected Object", frame,
-                                        cameraMatrix, rvec, tvec, box);
-                if( code == -100 )
-                    break;
-            }
-
-            if( !box.empty() )
+            Rect r = extract3DBox(frame, selectedObjFrame,
+                                  cameraMatrix, rvec, tvec, box, 4, true);
+            if (!r.empty())
             {
-                Rect r = extract3DBox(frame, shownFrame, selectedObjFrame,
-                                      cameraMatrix, rvec, tvec, box, 4, true);
-                if( !r.empty() )
-                {
-                    const int maxFrameIdx = 10000;
-                    char path[1000];
-                    for(;frameIdx < maxFrameIdx;frameIdx++)
-                    {
-                        snprintf(path, sizeof(path), "%s%04d.jpg", outprefix.c_str(), frameIdx);
-                        FILE* f = fopen(path, "rb");
-                        if( !f )
-                            break;
-                        fclose(f);
-                    }
-                    if( frameIdx == maxFrameIdx )
-                    {
-                        printf("Can not save the image as %s<...>.jpg", outprefix.c_str());
-                        break;
-                    }
-                    imwrite(path, selectedObjFrame(r));
-
-                    capturedImgList.push_back(string(path));
-                    roiList.push_back(r);
-
-                    float p[6];
-                    Mat RV(3, 1, CV_32F, p), TV(3, 1, CV_32F, p+3);
-                    rvec.convertTo(RV, RV.type());
-                    tvec.convertTo(TV, TV.type());
-                    poseList.push_back(Vec6f(p[0], p[1], p[2], p[3], p[4], p[5]));
-                }
+                string path = format("%s/%04d.jpg", outprefix.c_str(), frameIdx++);
+                imwrite(path, selectedObjFrame(r));
+                cout << "Saved: " << path << endl;
             }
-            grabNext = !imageList.empty();
         }
-
-        imshow("View", shownFrame);
-        imshow("Selected Object", selectedObjFrame);
-        char c = (char)waitKey(imageList.empty() && !box.empty() ? 30 : 300);
-        if( c == 'q' || c == 'Q' )
-            break;
-        if( c == '\r' || c == '\n' )
-            grabNext = true;
     }
 
-    writeModelViews(indexFilename, box, capturedImgList, roiList, poseList);
     return 0;
 }
diff --git a/samples/cpp/smiledetect.cpp b/samples/cpp/smiledetect.cpp
index 4da0ce87e9..fd2c217ab9 100644
--- a/samples/cpp/smiledetect.cpp
+++ b/samples/cpp/smiledetect.cpp
@@ -18,18 +18,17 @@ static void help(const char** argv)
             "   [video_filename|camera_index]\n\n"
             "Example:\n" <<
             argv[0] << " --cascade=\"data/haarcascades/haarcascade_frontalface_alt.xml\" --smile-cascade=\"data/haarcascades/haarcascade_smile.xml\" --scale=2.0\n\n"
-            "During execution:\n\tHit any key to quit.\n"
-            "\tUsing OpenCV version " << CV_VERSION << "\n" << endl;
+            "Using OpenCV version " << CV_VERSION << "\n" << endl;
 }
 
-void detectAndDraw( Mat& img, CascadeClassifier& cascade,
-                    CascadeClassifier& nestedCascade,
-                    double scale, bool tryflip );
+void detectAndDraw(Mat& img, CascadeClassifier& cascade,
+                   CascadeClassifier& nestedCascade,
+                   double scale, bool tryflip);
 
 string cascadeName;
 string nestedCascadeName;
 
-int main( int argc, const char** argv )
+int main(int argc, const char** argv)
 {
     VideoCapture capture;
     Mat frame, image;
@@ -54,7 +53,7 @@ int main( int argc, const char** argv )
     nestedCascadeName = samples::findFile(parser.get<string>("smile-cascade"));
     tryflip = parser.has("try-flip");
     inputName = parser.get<string>("@input");
-    scale = parser.get<int>("scale");
+    scale = parser.get<double>("scale");
     if (!parser.check())
     {
         help(argv);
@@ -62,48 +61,48 @@ int main( int argc, const char** argv )
     }
     if (scale < 1)
         scale = 1;
-    if( !cascade.load( cascadeName ) )
+    if (!cascade.load(cascadeName))
     {
         cerr << "ERROR: Could not load face cascade" << endl;
         help(argv);
         return -1;
     }
-    if( !nestedCascade.load( nestedCascadeName ) )
+    if (!nestedCascade.load(nestedCascadeName))
     {
         cerr << "ERROR: Could not load smile cascade" << endl;
         help(argv);
         return -1;
     }
-    if( inputName.empty() || (isdigit(inputName[0]) && inputName.size() == 1) )
+    if (inputName.empty() || (isdigit(inputName[0]) && inputName.size() == 1))
     {
-        int c = inputName.empty() ? 0 : inputName[0] - '0' ;
-        if(!capture.open(c))
-            cout << "Capture from camera #" <<  c << " didn't work" << endl;
+        int c = inputName.empty() ? 0 : inputName[0] - '0';
+        if (!capture.open(c))
+            cout << "Capture from camera #" << c << " didn't work" << endl;
     }
-    else if( inputName.size() )
+    else if (inputName.size())
     {
         inputName = samples::findFileOrKeep(inputName);
-        if(!capture.open( inputName ))
+        if (!capture.open(inputName))
             cout << "Could not read " << inputName << endl;
     }
 
-    if( capture.isOpened() )
+    if (capture.isOpened())
     {
         cout << "Video capturing has been started ..." << endl;
         cout << endl << "NOTE: Smile intensity will only be valid after a first smile has been detected" << endl;
 
-        for(;;)
+        for (;;)
         {
             capture >> frame;
-            if( frame.empty() )
+            if (frame.empty())
                 break;
 
             Mat frame1 = frame.clone();
-            detectAndDraw( frame1, cascade, nestedCascade, scale, tryflip );
+            detectAndDraw(frame1, cascade, nestedCascade, scale, tryflip);
 
-            char c = (char)waitKey(10);
-            if( c == 27 || c == 'q' || c == 'Q' )
-                break;
+            // char c = (char)waitKey(10);
+            // if (c == 27 || c == 'q' || c == 'Q')
+            //     break;
         }
     }
     else
@@ -116,9 +115,9 @@ int main( int argc, const char** argv )
     return 0;
 }
 
-void detectAndDraw( Mat& img, CascadeClassifier& cascade,
-                    CascadeClassifier& nestedCascade,
-                    double scale, bool tryflip)
+void detectAndDraw(Mat& img, CascadeClassifier& cascade,
+                   CascadeClassifier& nestedCascade,
+                   double scale, bool tryflip)
 {
     vector<Rect> faces, faces2;
     const static Scalar colors[] =
@@ -134,73 +133,73 @@ void detectAndDraw( Mat& img, CascadeClassifier& cascade,
     };
     Mat gray, smallImg;
 
-    cvtColor( img, gray, COLOR_BGR2GRAY );
+    cvtColor(img, gray, COLOR_BGR2GRAY);
 
     double fx = 1 / scale;
-    resize( gray, smallImg, Size(), fx, fx, INTER_LINEAR_EXACT );
-    equalizeHist( smallImg, smallImg );
+    resize(gray, smallImg, Size(), fx, fx, INTER_LINEAR_EXACT);
+    equalizeHist(smallImg, smallImg);
 
-    cascade.detectMultiScale( smallImg, faces,
+    cascade.detectMultiScale(smallImg, faces,
         1.1, 2, 0
         //|CASCADE_FIND_BIGGEST_OBJECT
         //|CASCADE_DO_ROUGH_SEARCH
         |CASCADE_SCALE_IMAGE,
-        Size(30, 30) );
-    if( tryflip )
+        Size(30, 30));
+    if (tryflip)
     {
         flip(smallImg, smallImg, 1);
-        cascade.detectMultiScale( smallImg, faces2,
+        cascade.detectMultiScale(smallImg, faces2,
                                  1.1, 2, 0
                                  //|CASCADE_FIND_BIGGEST_OBJECT
                                  //|CASCADE_DO_ROUGH_SEARCH
                                  |CASCADE_SCALE_IMAGE,
-                                 Size(30, 30) );
-        for( vector<Rect>::const_iterator r = faces2.begin(); r != faces2.end(); ++r )
+                                 Size(30, 30));
+        for (vector<Rect>::const_iterator r = faces2.begin(); r != faces2.end(); ++r)
         {
             faces.push_back(Rect(smallImg.cols - r->x - r->width, r->y, r->width, r->height));
         }
     }
 
-    for ( size_t i = 0; i < faces.size(); i++ )
+    for (size_t i = 0; i < faces.size(); i++)
     {
         Rect r = faces[i];
         Mat smallImgROI;
         vector<Rect> nestedObjects;
         Point center;
-        Scalar color = colors[i%8];
+        Scalar color = colors[i % 8];
         int radius;
 
-        double aspect_ratio = (double)r.width/r.height;
-        if( 0.75 < aspect_ratio && aspect_ratio < 1.3 )
+        double aspect_ratio = (double)r.width / r.height;
+        if (0.75 < aspect_ratio && aspect_ratio < 1.3)
         {
-            center.x = cvRound((r.x + r.width*0.5)*scale);
-            center.y = cvRound((r.y + r.height*0.5)*scale);
-            radius = cvRound((r.width + r.height)*0.25*scale);
-            circle( img, center, radius, color, 3, 8, 0 );
+            center.x = cvRound((r.x + r.width * 0.5) * scale);
+            center.y = cvRound((r.y + r.height * 0.5) * scale);
+            radius = cvRound((r.width + r.height) * 0.25 * scale);
+            circle(img, center, radius, color, 3, 8, 0);
         }
         else
-            rectangle( img, Point(cvRound(r.x*scale), cvRound(r.y*scale)),
-                       Point(cvRound((r.x + r.width-1)*scale), cvRound((r.y + r.height-1)*scale)),
-                       color, 3, 8, 0);
-
-        const int half_height=cvRound((float)r.height/2);
-        r.y=r.y + half_height;
-        r.height = half_height-1;
-        smallImgROI = smallImg( r );
-        nestedCascade.detectMultiScale( smallImgROI, nestedObjects,
+            rectangle(img, Point(cvRound(r.x * scale), cvRound(r.y * scale)),
+                      Point(cvRound((r.x + r.width - 1) * scale), cvRound((r.y + r.height - 1) * scale)),
+                      color, 3, 8, 0);
+
+        const int half_height = cvRound((float)r.height / 2);
+        r.y = r.y + half_height;
+        r.height = half_height - 1;
+        smallImgROI = smallImg(r);
+        nestedCascade.detectMultiScale(smallImgROI, nestedObjects,
             1.1, 0, 0
             //|CASCADE_FIND_BIGGEST_OBJECT
             //|CASCADE_DO_ROUGH_SEARCH
             //|CASCADE_DO_CANNY_PRUNING
             |CASCADE_SCALE_IMAGE,
-            Size(30, 30) );
+            Size(30, 30));
 
         // The number of detected neighbors depends on image size (and also illumination, etc.). The
         // following steps use a floating minimum and maximum of neighbors. Intensity thus estimated will be
         //accurate only after a first smile has been displayed by the user.
         const int smile_neighbors = (int)nestedObjects.size();
-        static int max_neighbors=-1;
-        static int min_neighbors=-1;
+        static int max_neighbors = -1;
+        static int min_neighbors = -1;
         if (min_neighbors == -1) min_neighbors = smile_neighbors;
         max_neighbors = MAX(max_neighbors, smile_neighbors);
 
@@ -208,8 +207,9 @@ void detectAndDraw( Mat& img, CascadeClassifier& cascade,
         float intensityZeroOne = ((float)smile_neighbors - min_neighbors) / (max_neighbors - min_neighbors + 1);
         int rect_height = cvRound((float)img.rows * intensityZeroOne);
         Scalar col = Scalar((float)255 * intensityZeroOne, 0, 0);
-        rectangle(img, Point(0, img.rows), Point(img.cols/10, img.rows - rect_height), col, -1);
+        rectangle(img, Point(0, img.rows), Point(img.cols / 10, img.rows - rect_height), col, -1);
     }
 
-    imshow( "result", img );
+    // imshow("result", img);
 }
+
diff --git a/samples/cpp/squares.cpp b/samples/cpp/squares.cpp
index 2ea824decd..607e69bf74 100644
--- a/samples/cpp/squares.cpp
+++ b/samples/cpp/squares.cpp
@@ -1,14 +1,11 @@
-
-// The "Square Detector" program.
-// It loads several images sequentially and tries to find squares in
-// each image
-
 #include "opencv2/core.hpp"
 #include "opencv2/imgproc.hpp"
 #include "opencv2/imgcodecs.hpp"
-#include "opencv2/highgui.hpp"
+#include "opencv2/highgui.hpp" // 注释掉高GUI库
 
 #include <iostream>
+#include <sys/stat.h>
+#include <sys/types.h>
 
 using namespace cv;
 using namespace std;
@@ -24,59 +21,58 @@ static void help(const char* programName)
     "Using OpenCV version " << CV_VERSION << "\n" << endl;
 }
 
-
 int thresh = 50, N = 11;
 const char* wndname = "Square Detection Demo";
 
 // helper function:
 // finds a cosine of angle between vectors
 // from pt0->pt1 and from pt0->pt2
-static double angle( Point pt1, Point pt2, Point pt0 )
+static double angle(Point pt1, Point pt2, Point pt0)
 {
     double dx1 = pt1.x - pt0.x;
     double dy1 = pt1.y - pt0.y;
     double dx2 = pt2.x - pt0.x;
     double dy2 = pt2.y - pt0.y;
-    return (dx1*dx2 + dy1*dy2)/sqrt((dx1*dx1 + dy1*dy1)*(dx2*dx2 + dy2*dy2) + 1e-10);
+    return (dx1 * dx2 + dy1 * dy2) / sqrt((dx1 * dx1 + dy1 * dy1) * (dx2 * dx2 + dy2 * dy2) + 1e-10);
 }
 
 // returns sequence of squares detected on the image.
-static void findSquares( const Mat& image, vector<vector<Point> >& squares )
+static void findSquares(const Mat& image, vector<vector<Point> >& squares)
 {
     squares.clear();
 
     Mat pyr, timg, gray0(image.size(), CV_8U), gray;
 
     // down-scale and upscale the image to filter out the noise
-    pyrDown(image, pyr, Size(image.cols/2, image.rows/2));
+    pyrDown(image, pyr, Size(image.cols / 2, image.rows / 2));
     pyrUp(pyr, timg, image.size());
     vector<vector<Point> > contours;
 
     // find squares in every color plane of the image
-    for( int c = 0; c < 3; c++ )
+    for (int c = 0; c < 3; c++)
     {
-        int ch[] = {c, 0};
+        int ch[] = { c, 0 };
         mixChannels(&timg, 1, &gray0, 1, ch, 1);
 
         // try several threshold levels
-        for( int l = 0; l < N; l++ )
+        for (int l = 0; l < N; l++)
         {
             // hack: use Canny instead of zero threshold level.
             // Canny helps to catch squares with gradient shading
-            if( l == 0 )
+            if (l == 0)
             {
                 // apply Canny. Take the upper threshold from slider
                 // and set the lower to 0 (which forces edges merging)
                 Canny(gray0, gray, 0, thresh, 5);
                 // dilate canny output to remove potential
                 // holes between edge segments
-                dilate(gray, gray, Mat(), Point(-1,-1));
+                dilate(gray, gray, Mat(), Point(-1, -1));
             }
             else
             {
                 // apply threshold if l!=0:
-                //     tgray(x,y) = gray(x,y) < (l+1)*255/N ? 255 : 0
-                gray = gray0 >= (l+1)*255/N;
+                //     tgray(x, y) = gray(x, y) < (l + 1) * 255 / N ? 255 : 0
+                gray = gray0 >= (l + 1) * 255 / N;
             }
 
             // find contours and store them all as a list
@@ -85,11 +81,11 @@ static void findSquares( const Mat& image, vector<vector<Point> >& squares )
             vector<Point> approx;
 
             // test each contour
-            for( size_t i = 0; i < contours.size(); i++ )
+            for (size_t i = 0; i < contours.size(); i++)
             {
                 // approximate contour with accuracy proportional
                 // to the contour perimeter
-                approxPolyDP(contours[i], approx, arcLength(contours[i], true)*0.02, true);
+                approxPolyDP(contours[i], approx, arcLength(contours[i], true) * 0.02, true);
 
                 // square contours should have 4 vertices after approximation
                 // relatively large area (to filter out noisy contours)
@@ -97,23 +93,23 @@ static void findSquares( const Mat& image, vector<vector<Point> >& squares )
                 // Note: absolute value of an area is used because
                 // area may be positive or negative - in accordance with the
                 // contour orientation
-                if( approx.size() == 4 &&
+                if (approx.size() == 4 &&
                     fabs(contourArea(approx)) > 1000 &&
-                    isContourConvex(approx) )
+                    isContourConvex(approx))
                 {
                     double maxCosine = 0;
 
-                    for( int j = 2; j < 5; j++ )
+                    for (int j = 2; j < 5; j++)
                     {
                         // find the maximum cosine of the angle between joint edges
-                        double cosine = fabs(angle(approx[j%4], approx[j-2], approx[j-1]));
+                        double cosine = fabs(angle(approx[j % 4], approx[j - 2], approx[j - 1]));
                         maxCosine = MAX(maxCosine, cosine);
                     }
 
                     // if cosines of all angles are small
-                    // (all angles are ~90 degree) then write quandrange
+                    // (all angles are ~90 degree) then write quadrilateral
                     // vertices to resultant sequence
-                    if( maxCosine < 0.3 )
+                    if (maxCosine < 0.3)
                         squares.push_back(approx);
                 }
             }
@@ -123,36 +119,35 @@ static void findSquares( const Mat& image, vector<vector<Point> >& squares )
 
 int main(int argc, char** argv)
 {
-    const char* names[] = { "pic1.png", "pic2.png", "pic3.png",
-        "pic4.png", "pic5.png", "pic6.png", 0 };
-    help(argv[0]);
-
-    if( argc > 1)
+    CommandLineParser parser(argc, argv, "{@input| |}");
+    string inputFile = parser.get<string>("@input");
+    if (inputFile.empty())
     {
-     names[0] =  argv[1];
-     names[1] =  0;
+        help(argv[0]);
+        return 0;
     }
 
-    for( int i = 0; names[i] != 0; i++ )
+    // Create output directory if it doesn't exist
+    string outputDir = "squares";
+    mkdir(outputDir.c_str(), 0777);
+
+    Mat image = imread(samples::findFile(inputFile), IMREAD_COLOR);
+    if (image.empty())
     {
-        string filename = samples::findFile(names[i]);
-        Mat image = imread(filename, IMREAD_COLOR);
-        if( image.empty() )
-        {
-            cout << "Couldn't load " << filename << endl;
-            continue;
-        }
+        cout << "Couldn't load " << inputFile << endl;
+        return -1;
+    }
 
-        vector<vector<Point> > squares;
-        findSquares(image, squares);
+    vector<vector<Point> > squares;
+    findSquares(image, squares);
 
-        polylines(image, squares, true, Scalar(0, 255, 0), 3, LINE_AA);
-        imshow(wndname, image);
+    polylines(image, squares, true, Scalar(0, 255, 0), 3, LINE_AA);
 
-        int c = waitKey();
-        if( c == 27 )
-            break;
-    }
+    // Save the result
+    string outputFilename = outputDir + "/result.png";
+    imwrite(outputFilename, image);
+    cout << "Result saved to " << outputFilename << endl;
 
     return 0;
 }
+
diff --git a/samples/cpp/stereo_calib.cpp b/samples/cpp/stereo_calib.cpp
index c583c8fa09..d46d1ffe1f 100644
--- a/samples/cpp/stereo_calib.cpp
+++ b/samples/cpp/stereo_calib.cpp
@@ -1,28 +1,5 @@
-/* This is sample from the OpenCV book. The copyright notice is below */
-
-/* *************** License:**************************
-   Oct. 3, 2008
-   Right to use this code in any way you want without warranty, support or any guarantee of it working.
-
-   BOOK: It would be nice if you cited it:
-   Learning OpenCV: Computer Vision with the OpenCV Library
-     by Gary Bradski and Adrian Kaehler
-     Published by O'Reilly Media, October 3, 2008
-
-   AVAILABLE AT:
-     http://www.amazon.com/Learning-OpenCV-Computer-Vision-Library/dp/0596516134
-     Or: http://oreilly.com/catalog/9780596516130/
-     ISBN-10: 0596516134 or: ISBN-13: 978-0596516130
-
-   OPENCV WEBSITES:
-     Homepage:      http://opencv.org
-     Online docs:   http://docs.opencv.org
-     GitHub:        https://github.com/opencv/opencv/
-   ************************************************** */
-
 #include "opencv2/calib3d.hpp"
 #include "opencv2/imgcodecs.hpp"
-#include "opencv2/highgui.hpp"
 #include "opencv2/imgproc.hpp"
 #include "opencv2/objdetect/charuco_detector.hpp"
 
@@ -34,6 +11,8 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <ctype.h>
+#include <sys/stat.h>
+#include <sys/types.h>
 
 using namespace cv;
 using namespace std;
@@ -63,7 +42,6 @@ static int print_help(char** argv)
     return 0;
 }
 
-
 static void
 StereoCalib(const vector<string>& imagelist, Size inputBoardSize, string type, float squareSize, float markerSize, cv::aruco::PredefinedDictionaryType arucoDict, string arucoDictFile, bool displayCorners = false, bool useCalibrated=true, bool showRectified=true)
 {
@@ -122,9 +100,13 @@ StereoCalib(const vector<string>& imagelist, Size inputBoardSize, string type, f
         for( k = 0; k < 2; k++ )
         {
             const string& filename = imagelist[i*2+k];
+            cout << "Reading file: " << filename << endl; // 添加调试信息
             Mat img = imread(filename, IMREAD_GRAYSCALE);
             if(img.empty())
+            {
+                cout << "Error: Couldn't load image " << filename << endl;
                 break;
+            }
             if( imageSize == Size() )
                 imageSize = img.size();
             else if( img.size() != imageSize )
@@ -172,10 +154,10 @@ StereoCalib(const vector<string>& imagelist, Size inputBoardSize, string type, f
                 drawChessboardCorners(cimg, boardSizeInnerCorners, corners, found);
                 double sf = 640./MAX(img.rows, img.cols);
                 resize(cimg, cimg1, Size(), sf, sf, INTER_LINEAR_EXACT);
-                imshow("corners", cimg1);
-                char c = (char)waitKey(500);
-                if( c == 27 || c == 'q' || c == 'Q' ) //Allow ESC to quit
-                    exit(-1);
+                // imshow("corners", cimg1); // 注释掉imshow
+                // char c = (char)waitKey(500); // 注释掉waitKey
+                // if( c == 27 || c == 'q' || c == 'Q' ) //Allow ESC to quit
+                //    exit(-1);
             }
             else
                 putchar('.');
@@ -264,12 +246,16 @@ StereoCalib(const vector<string>& imagelist, Size inputBoardSize, string type, f
     cout << "average epipolar err = " <<  err/npoints << endl;
 
     // save intrinsic parameters
-    FileStorage fs("intrinsics.yml", FileStorage::WRITE);
+    string outputDir = "stereo_calib";
+    mkdir(outputDir.c_str(), 0777);
+
+    FileStorage fs(outputDir + "/intrinsics.yml", FileStorage::WRITE);
     if( fs.isOpened() )
     {
         fs << "M1" << cameraMatrix[0] << "D1" << distCoeffs[0] <<
             "M2" << cameraMatrix[1] << "D2" << distCoeffs[1];
         fs.release();
+        cout << "Intrinsic parameters saved to " << outputDir + "/intrinsics.yml" << endl;
     }
     else
         cout << "Error: can not save the intrinsic parameters\n";
@@ -282,11 +268,12 @@ StereoCalib(const vector<string>& imagelist, Size inputBoardSize, string type, f
                   imageSize, R, T, R1, R2, P1, P2, Q,
                   CALIB_ZERO_DISPARITY, 1, imageSize, &validRoi[0], &validRoi[1]);
 
-    fs.open("extrinsics.yml", FileStorage::WRITE);
+    fs.open(outputDir + "/extrinsics.yml", FileStorage::WRITE);
     if( fs.isOpened() )
     {
         fs << "R" << R << "T" << T << "R1" << R1 << "R2" << R2 << "P1" << P1 << "P2" << P2 << "Q" << Q;
         fs.release();
+        cout << "Extrinsic parameters saved to " << outputDir + "/extrinsics.yml" << endl;
     }
     else
         cout << "Error: can not save the extrinsic parameters\n";
@@ -372,14 +359,18 @@ StereoCalib(const vector<string>& imagelist, Size inputBoardSize, string type, f
         else
             for( j = 0; j < canvas.cols; j += 16 )
                 line(canvas, Point(j, 0), Point(j, canvas.rows), Scalar(0, 255, 0), 1, 8);
-        imshow("rectified", canvas);
-        char c = (char)waitKey();
-        if( c == 27 || c == 'q' || c == 'Q' )
-            break;
+        // imshow("rectified", canvas); // 注释掉imshow
+        // char c = (char)waitKey(); // 注释掉waitKey
+        // if( c == 27 || c == 'q' || c == 'Q' )
+        //    break;
+
+        // Save rectified images
+        string rectifiedFilename = outputDir + "/rectified_" + to_string(i) + ".png";
+        imwrite(rectifiedFilename, canvas);
+        cout << "Rectified image saved to " << rectifiedFilename << endl;
     }
 }
 
-
 static bool readStringList( const string& filename, vector<string>& l )
 {
     l.resize(0);
@@ -456,3 +447,4 @@ int main(int argc, char** argv)
     StereoCalib(imagelist, inputBoardSize, type, squareSize, markerSize, arucoDict, arucoDictFile, false, true, showRectified);
     return 0;
 }
+
diff --git a/samples/cpp/stereo_match.cpp b/samples/cpp/stereo_match.cpp
index 55cd89c26e..d928baf2a5 100644
--- a/samples/cpp/stereo_match.cpp
+++ b/samples/cpp/stereo_match.cpp
@@ -1,20 +1,11 @@
-/*
- *  stereo_match.cpp
- *  calibration
- *
- *  Created by Victor  Eruhimov on 1/18/10.
- *  Copyright 2010 Argus Corp. All rights reserved.
- *
- */
-
 #include "opencv2/calib3d/calib3d.hpp"
 #include "opencv2/imgproc.hpp"
 #include "opencv2/imgcodecs.hpp"
-#include "opencv2/highgui.hpp"
 #include "opencv2/core/utility.hpp"
 
 #include <stdio.h>
 #include <sstream>
+#include <iostream>
 
 using namespace cv;
 
@@ -105,7 +96,7 @@ int main(int argc, char** argv)
     }
     if ( numberOfDisparities < 1 || numberOfDisparities % 16 != 0 )
     {
-        printf("Command-line parameter error: The max disparity (--maxdisparity=<...>) must be a positive integer divisible by 16\n");
+        printf("Command-line parameter error: The max disparity (--max-disparity=<...>) must be a positive integer divisible by 16\n");
         print_help(argv);
         return -1;
     }
@@ -248,10 +239,6 @@ int main(int argc, char** argv)
         sgbm->setMode(StereoSGBM::MODE_SGBM_3WAY);
 
     Mat disp, disp8;
-    //Mat img1p, img2p, dispp;
-    //copyMakeBorder(img1, img1p, 0, 0, numberOfDisparities, 0, IPL_BORDER_REPLICATE);
-    //copyMakeBorder(img2, img2p, 0, 0, numberOfDisparities, 0, IPL_BORDER_REPLICATE);
-
     int64 t = getTickCount();
     float disparity_multiplier = 1.0f;
     if( alg == STEREO_BM )
@@ -269,18 +256,21 @@ int main(int argc, char** argv)
     t = getTickCount() - t;
     printf("Time elapsed: %fms\n", t*1000/getTickFrequency());
 
-    //disp = dispp.colRange(numberOfDisparities, img1p.cols);
-    if( alg != STEREO_VAR )
-        disp.convertTo(disp8, CV_8U, 255/(numberOfDisparities*16.));
-    else
-        disp.convertTo(disp8, CV_8U);
+    disp.convertTo(disp8, CV_8U, 255/(numberOfDisparities*16.));
 
     Mat disp8_3c;
     if (color_display)
         cv::applyColorMap(disp8, disp8_3c, COLORMAP_TURBO);
 
+    std::string outputDir = "stereo_match";
+    system(("mkdir -p " + outputDir).c_str());
+
     if(!disparity_filename.empty())
-        imwrite(disparity_filename, color_display ? disp8_3c : disp8);
+    {
+        std::string outputPath = outputDir + "/" + disparity_filename;
+        imwrite(outputPath, color_display ? disp8_3c : disp8);
+        std::cout << "Disparity image saved at: " << outputPath << std::endl;
+    }
 
     if(!point_cloud_filename.empty())
     {
@@ -290,39 +280,11 @@ int main(int argc, char** argv)
         Mat floatDisp;
         disp.convertTo(floatDisp, CV_32F, 1.0f / disparity_multiplier);
         reprojectImageTo3D(floatDisp, xyz, Q, true);
-        saveXYZ(point_cloud_filename.c_str(), xyz);
-        printf("\n");
-    }
-
-    if( !no_display )
-    {
-        std::ostringstream oss;
-        oss << "disparity  " << (alg==STEREO_BM ? "bm" :
-                                 alg==STEREO_SGBM ? "sgbm" :
-                                 alg==STEREO_HH ? "hh" :
-                                 alg==STEREO_VAR ? "var" :
-                                 alg==STEREO_HH4 ? "hh4" :
-                                 alg==STEREO_3WAY ? "sgbm3way" : "");
-        oss << "  blocksize:" << (alg==STEREO_BM ? SADWindowSize : sgbmWinSize);
-        oss << "  max-disparity:" << numberOfDisparities;
-        std::string disp_name = oss.str();
-
-        namedWindow("left", cv::WINDOW_NORMAL);
-        imshow("left", img1);
-        namedWindow("right", cv::WINDOW_NORMAL);
-        imshow("right", img2);
-        namedWindow(disp_name, cv::WINDOW_AUTOSIZE);
-        imshow(disp_name, color_display ? disp8_3c : disp8);
-
-        printf("press ESC key or CTRL+C to close...");
-        fflush(stdout);
-        printf("\n");
-        while(1)
-        {
-            if(waitKey() == 27) //ESC (prevents closing on actions like taking screenshots)
-                break;
-        }
+        std::string outputPath = outputDir + "/" + point_cloud_filename;
+        saveXYZ(outputPath.c_str(), xyz);
+        printf("\nPoint cloud saved at: %s\n", outputPath.c_str());
     }
 
     return 0;
 }
+
diff --git a/samples/cpp/stitching.cpp b/samples/cpp/stitching.cpp
index 7de0536452..22faab4f01 100644
--- a/samples/cpp/stitching.cpp
+++ b/samples/cpp/stitching.cpp
@@ -1,9 +1,10 @@
-
 #include "opencv2/imgcodecs.hpp"
 #include "opencv2/highgui.hpp"
 #include "opencv2/stitching.hpp"
 
 #include <iostream>
+#include <sys/stat.h>
+#include <sys/types.h>
 
 using namespace std;
 using namespace cv;
@@ -33,8 +34,13 @@ int main(int argc, char* argv[])
     }
     //![stitching]
 
-    imwrite(result_name, pano);
-    cout << "stitching completed successfully\n" << result_name << " saved!";
+    // 创建子目录并保存结果图像
+    string outputDir = "stitching_result";
+    mkdir(outputDir.c_str(), 0777);
+    string outputFilePath = outputDir + "/" + result_name;
+    
+    imwrite(outputFilePath, pano);
+    cout << "Stitching completed successfully. Result saved to " << outputFilePath << endl;
     return EXIT_SUCCESS;
 }
 
@@ -117,3 +123,4 @@ int parseCmdArgs(int argc, char** argv)
     }
     return EXIT_SUCCESS;
 }
+
diff --git a/samples/cpp/stitching_detailed.cpp b/samples/cpp/stitching_detailed.cpp
index e5b63de943..09872de2ce 100644
--- a/samples/cpp/stitching_detailed.cpp
+++ b/samples/cpp/stitching_detailed.cpp
@@ -1,9 +1,3 @@
-
-#include <iostream>
-#include <fstream>
-#include <string>
-#include "opencv2/opencv_modules.hpp"
-#include <opencv2/core/utility.hpp>
 #include "opencv2/imgcodecs.hpp"
 #include "opencv2/highgui.hpp"
 #include "opencv2/stitching/detail/autocalib.hpp"
@@ -22,6 +16,11 @@
 #include "opencv2/xfeatures2d/nonfree.hpp"
 #endif
 
+#include <iostream>
+#include <sys/stat.h>
+#include <sys/types.h>
+#include <fstream>
+
 #define ENABLE_LOG 1
 #define LOG(msg) std::cout << msg
 #define LOGLN(msg) std::cout << msg << std::endl
@@ -164,6 +163,11 @@ static int parseCmdArgs(int argc, char** argv)
         }
         else if (string(argv[i]) == "--try_cuda")
         {
+            if (i + 1 >= argc)
+            {
+                cout << "Missing value for --try_cuda flag\n";
+                return -1;
+            }
             if (string(argv[i + 1]) == "no")
                 try_cuda = false;
             else if (string(argv[i + 1]) == "yes")
@@ -177,26 +181,51 @@ static int parseCmdArgs(int argc, char** argv)
         }
         else if (string(argv[i]) == "--work_megapix")
         {
+            if (i + 1 >= argc)
+            {
+                cout << "Missing value for --work_megapix flag\n";
+                return -1;
+            }
             work_megapix = atof(argv[i + 1]);
             i++;
         }
         else if (string(argv[i]) == "--seam_megapix")
         {
+            if (i + 1 >= argc)
+            {
+                cout << "Missing value for --seam_megapix flag\n";
+                return -1;
+            }
             seam_megapix = atof(argv[i + 1]);
             i++;
         }
         else if (string(argv[i]) == "--compose_megapix")
         {
+            if (i + 1 >= argc)
+            {
+                cout << "Missing value for --compose_megapix flag\n";
+                return -1;
+            }
             compose_megapix = atof(argv[i + 1]);
             i++;
         }
         else if (string(argv[i]) == "--result")
         {
+            if (i + 1 >= argc)
+            {
+                cout << "Missing value for --result flag\n";
+                return -1;
+            }
             result_name = argv[i + 1];
             i++;
         }
         else if (string(argv[i]) == "--features")
         {
+            if (i + 1 >= argc)
+            {
+                cout << "Missing value for --features flag\n";
+                return -1;
+            }
             features_type = argv[i + 1];
             if (string(features_type) == "orb")
                 match_conf = 0.3f;
@@ -204,6 +233,11 @@ static int parseCmdArgs(int argc, char** argv)
         }
         else if (string(argv[i]) == "--matcher")
         {
+            if (i + 1 >= argc)
+            {
+                cout << "Missing value for --matcher flag\n";
+                return -1;
+            }
             if (string(argv[i + 1]) == "homography" || string(argv[i + 1]) == "affine")
                 matcher_type = argv[i + 1];
             else
@@ -215,6 +249,11 @@ static int parseCmdArgs(int argc, char** argv)
         }
         else if (string(argv[i]) == "--estimator")
         {
+            if (i + 1 >= argc)
+            {
+                cout << "Missing value for --estimator flag\n";
+                return -1;
+            }
             if (string(argv[i + 1]) == "homography" || string(argv[i + 1]) == "affine")
                 estimator_type = argv[i + 1];
             else
@@ -226,21 +265,41 @@ static int parseCmdArgs(int argc, char** argv)
         }
         else if (string(argv[i]) == "--match_conf")
         {
+            if (i + 1 >= argc)
+            {
+                cout << "Missing value for --match_conf flag\n";
+                return -1;
+            }
             match_conf = static_cast<float>(atof(argv[i + 1]));
             i++;
         }
         else if (string(argv[i]) == "--conf_thresh")
         {
+            if (i + 1 >= argc)
+            {
+                cout << "Missing value for --conf_thresh flag\n";
+                return -1;
+            }
             conf_thresh = static_cast<float>(atof(argv[i + 1]));
             i++;
         }
         else if (string(argv[i]) == "--ba")
         {
+            if (i + 1 >= argc)
+            {
+                cout << "Missing value for --ba flag\n";
+                return -1;
+            }
             ba_cost_func = argv[i + 1];
             i++;
         }
         else if (string(argv[i]) == "--ba_refine_mask")
         {
+            if (i + 1 >= argc)
+            {
+                cout << "Missing value for --ba_refine_mask flag\n";
+                return -1;
+            }
             ba_refine_mask = argv[i + 1];
             if (ba_refine_mask.size() != 5)
             {
@@ -251,6 +310,11 @@ static int parseCmdArgs(int argc, char** argv)
         }
         else if (string(argv[i]) == "--wave_correct")
         {
+            if (i + 1 >= argc)
+            {
+                cout << "Missing value for --wave_correct flag\n";
+                return -1;
+            }
             if (string(argv[i + 1]) == "no")
                 do_wave_correct = false;
             else if (string(argv[i + 1]) == "horiz")
@@ -272,17 +336,32 @@ static int parseCmdArgs(int argc, char** argv)
         }
         else if (string(argv[i]) == "--save_graph")
         {
+            if (i + 1 >= argc)
+            {
+                cout << "Missing value for --save_graph flag\n";
+                return -1;
+            }
             save_graph = true;
             save_graph_to = argv[i + 1];
             i++;
         }
         else if (string(argv[i]) == "--warp")
         {
+            if (i + 1 >= argc)
+            {
+                cout << "Missing value for --warp flag\n";
+                return -1;
+            }
             warp_type = string(argv[i + 1]);
             i++;
         }
         else if (string(argv[i]) == "--expos_comp")
         {
+            if (i + 1 >= argc)
+            {
+                cout << "Missing value for --expos_comp flag\n";
+                return -1;
+            }
             if (string(argv[i + 1]) == "no")
                 expos_comp_type = ExposureCompensator::NO;
             else if (string(argv[i + 1]) == "gain")
@@ -302,21 +381,41 @@ static int parseCmdArgs(int argc, char** argv)
         }
         else if (string(argv[i]) == "--expos_comp_nr_feeds")
         {
+            if (i + 1 >= argc)
+            {
+                cout << "Missing value for --expos_comp_nr_feeds flag\n";
+                return -1;
+            }
             expos_comp_nr_feeds = atoi(argv[i + 1]);
             i++;
         }
         else if (string(argv[i]) == "--expos_comp_nr_filtering")
         {
+            if (i + 1 >= argc)
+            {
+                cout << "Missing value for --expos_comp_nr_filtering flag\n";
+                return -1;
+            }
             expos_comp_nr_filtering = atoi(argv[i + 1]);
             i++;
         }
         else if (string(argv[i]) == "--expos_comp_block_size")
         {
+            if (i + 1 >= argc)
+            {
+                cout << "Missing value for --expos_comp_block_size flag\n";
+                return -1;
+            }
             expos_comp_block_size = atoi(argv[i + 1]);
             i++;
         }
         else if (string(argv[i]) == "--seam")
         {
+            if (i + 1 >= argc)
+            {
+                cout << "Missing value for --seam flag\n";
+                return -1;
+            }
             if (string(argv[i + 1]) == "no" ||
                 string(argv[i + 1]) == "voronoi" ||
                 string(argv[i + 1]) == "gc_color" ||
@@ -333,6 +432,11 @@ static int parseCmdArgs(int argc, char** argv)
         }
         else if (string(argv[i]) == "--blend")
         {
+            if (i + 1 >= argc)
+            {
+                cout << "Missing value for --blend flag\n";
+                return -1;
+            }
             if (string(argv[i + 1]) == "no")
                 blend_type = Blender::NO;
             else if (string(argv[i + 1]) == "feather")
@@ -348,6 +452,11 @@ static int parseCmdArgs(int argc, char** argv)
         }
         else if (string(argv[i]) == "--timelapse")
         {
+            if (i + 1 >= argc)
+            {
+                cout << "Missing value for --timelapse flag\n";
+                return -1;
+            }
             timelapse = true;
 
             if (string(argv[i + 1]) == "as_is")
@@ -363,16 +472,31 @@ static int parseCmdArgs(int argc, char** argv)
         }
         else if (string(argv[i]) == "--rangewidth")
         {
+            if (i + 1 >= argc)
+            {
+                cout << "Missing value for --rangewidth flag\n";
+                return -1;
+            }
             range_width = atoi(argv[i + 1]);
             i++;
         }
         else if (string(argv[i]) == "--blend_strength")
         {
+            if (i + 1 >= argc)
+            {
+                cout << "Missing value for --blend_strength flag\n";
+                return -1;
+            }
             blend_strength = static_cast<float>(atof(argv[i + 1]));
             i++;
         }
         else if (string(argv[i]) == "--output")
         {
+            if (i + 1 >= argc)
+            {
+                cout << "Missing value for --output flag\n";
+                return -1;
+            }
             result_name = argv[i + 1];
             i++;
         }
@@ -929,9 +1053,18 @@ int main(int argc, char* argv[])
 
         LOGLN("Compositing, time: " << ((getTickCount() - t) / getTickFrequency()) << " sec");
 
-        imwrite(result_name, result);
+        // Create subdirectory for saving results
+        string output_dir = "stitching_detailed";
+        mkdir(output_dir.c_str(), 0777);
+
+        // Save the result image to the subdirectory
+        string output_path = output_dir + "/" + result_name;
+        imwrite(output_path, result);
+
+        LOGLN("Stitching completed successfully. Image saved to " << output_path);
     }
 
     LOGLN("Finished, total time: " << ((getTickCount() - app_start_time) / getTickFrequency()) << " sec");
     return 0;
 }
+
diff --git a/samples/cpp/text_skewness_correction.cpp b/samples/cpp/text_skewness_correction.cpp
index 15df92e641..8da219055c 100644
--- a/samples/cpp/text_skewness_correction.cpp
+++ b/samples/cpp/text_skewness_correction.cpp
@@ -1,28 +1,27 @@
 /*
 This tutorial demonstrates how to correct the skewness in a text.
 The program takes as input a skewed source image and shows non skewed text.
-
 */
 
 #include <opencv2/core.hpp>
 #include <opencv2/imgcodecs.hpp>
-#include <opencv2/highgui.hpp>
 #include <opencv2/imgproc.hpp>
 
 #include <iostream>
 #include <iomanip>
 #include <string>
+#include <sys/stat.h>
+#include <sys/types.h>
 
 using namespace cv;
 using namespace std;
 
-
-int main( int argc, char** argv )
+int main(int argc, char** argv)
 {
     CommandLineParser parser(argc, argv, "{@input | imageTextR.png | input image}");
 
     // Load image from the disk
-    Mat image = imread( samples::findFile( parser.get<String>("@input") ), IMREAD_COLOR);
+    Mat image = imread(samples::findFile(parser.get<String>("@input")), IMREAD_COLOR);
     if (image.empty())
     {
         cout << "Cannot load the image " + parser.get<String>("@input") << endl;
@@ -32,13 +31,13 @@ int main( int argc, char** argv )
     Mat gray;
     cvtColor(image, gray, COLOR_BGR2GRAY);
 
-    //Threshold the image, setting all foreground pixels to 255 and all background pixels to 0
+    // Threshold the image, setting all foreground pixels to 255 and all background pixels to 0
     Mat thresh;
     threshold(gray, thresh, 0, 255, THRESH_BINARY_INV | THRESH_OTSU);
 
     // Applying erode filter to remove random noise
     int erosion_size = 1;
-    Mat element = getStructuringElement( MORPH_RECT, Size(2*erosion_size+1, 2*erosion_size+1), Point(erosion_size, erosion_size) );
+    Mat element = getStructuringElement(MORPH_RECT, Size(2 * erosion_size + 1, 2 * erosion_size + 1), Point(erosion_size, erosion_size));
     erode(thresh, thresh, element);
 
     cv::Mat coords;
@@ -54,7 +53,7 @@ int main( int argc, char** argv )
         angle = (90.0f + angle);
     }
 
-    //Obtaining the rotation matrix
+    // Obtaining the rotation matrix
     Point2f center((image.cols) / 2.0f, (image.rows) / 2.0f);
     Mat M = getRotationMatrix2D(center, angle, 1.0f);
     Mat rotated;
@@ -64,11 +63,23 @@ int main( int argc, char** argv )
     angle_to_str << fixed << setprecision(2) << angle;
     warpAffine(image, rotated, M, image.size(), INTER_CUBIC, BORDER_REPLICATE);
     putText(rotated, "Angle " + angle_to_str.str() + " degrees", Point(10, 30), FONT_HERSHEY_SIMPLEX, 0.7, Scalar(0, 0, 255), 2);
-    cout << "[INFO] angle: " << angle_to_str.str() << endl;
+    cout << "[INFO] angle: " << angle_to_str.str() << " degrees" << endl;
+
+    // Create subdirectory for saving results
+    string output_dir = "skewness_correction";
+    mkdir(output_dir.c_str(), 0777);
+
+    // Save the rotated image to the subdirectory
+    string output_path = output_dir + "/corrected_image.png";
+    imwrite(output_path, rotated);
+
+    cout << "Image saved to " << output_path << endl;
+
+    // Comment out all display-related functions
+    // imshow("Input", image);
+    // imshow("Rotated", rotated);
+    // waitKey(0);
 
-    //Show the image
-    imshow("Input", image);
-    imshow("Rotated", rotated);
-    waitKey(0);
     return 0;
 }
+
diff --git a/samples/cpp/train_HOG.cpp b/samples/cpp/train_HOG.cpp
index c8355ee591..ad8b5939f1 100644
--- a/samples/cpp/train_HOG.cpp
+++ b/samples/cpp/train_HOG.cpp
@@ -5,6 +5,7 @@
 #include "opencv2/videoio.hpp"
 #include <iostream>
 #include <time.h>
+#include <cstdlib> // 添加这个头文件
 
 using namespace cv;
 using namespace cv::ml;
@@ -82,8 +83,8 @@ void load_images( const String & dirname, vector< Mat > & img_lst, bool showImag
 
         if ( showImages )
         {
-            imshow( "image", img );
-            waitKey( 1 );
+            // imshow( "image", img );
+            // waitKey( 1 );
         }
         img_lst.push_back( img );
     }
@@ -156,7 +157,7 @@ void test_trained_detector( String obj_det_filename, String test_dir, String vid
     }
 
     obj_det_filename = "testing " + obj_det_filename;
-    namedWindow( obj_det_filename, WINDOW_NORMAL );
+    // namedWindow( obj_det_filename, WINDOW_NORMAL );
 
     for( size_t i=0;; i++ )
     {
@@ -187,12 +188,12 @@ void test_trained_detector( String obj_det_filename, String test_dir, String vid
             rectangle( img, detections[j], color, img.cols / 400 + 1 );
         }
 
-        imshow( obj_det_filename, img );
+        // imshow( obj_det_filename, img );
 
-        if( waitKey( delay ) == 27 )
-        {
-            return;
-        }
+        // if( waitKey( delay ) == 27 )
+        // {
+        //     return;
+        // }
     }
 }
 
@@ -244,8 +245,8 @@ int main( int argc, char** argv )
     {
         parser.printMessage();
         cout << "Wrong number of parameters.\n\n"
-             << "Example command line:\n" << argv[0] << " -dw=64 -dh=128 -pd=/INRIAPerson/96X160H96/Train/pos -nd=/INRIAPerson/neg -td=/INRIAPerson/Test/pos -fn=HOGpedestrian64x128.xml -d\n"
-             << "\nExample command line for testing trained detector:\n" << argv[0] << " -t -fn=HOGpedestrian64x128.xml -td=/INRIAPerson/Test/pos";
+             << "Example command line:\n" << argv[0] << " -dw=64 -dh=128 -pd=positive_images -nd=negative_images -td=test_images -fn=HOGpedestrian64x128.xml -d\n"
+             << "\nExample command line for testing trained detector:\n" << argv[0] << " -t -fn=HOGpedestrian64x128.xml -td=test_images";
         exit( 1 );
     }
 
@@ -354,8 +355,8 @@ int main( int argc, char** argv )
                 {
                     rectangle( full_neg_lst[i], detections[j], Scalar( 0, 255, 0 ), 2 );
                 }
-                imshow( "testing trained detector on negative images", full_neg_lst[i] );
-                waitKey( 5 );
+                // imshow( "testing trained detector on negative images", full_neg_lst[i] );
+                // waitKey( 5 );
             }
         }
         clog << "...[done]" << endl;
@@ -384,9 +385,17 @@ int main( int argc, char** argv )
     HOGDescriptor hog;
     hog.winSize = pos_image_size;
     hog.setSVMDetector( get_svm_detector( svm ) );
-    hog.save( obj_det_filename );
+    
+    // Create directory if it doesn't exist
+    system("mkdir -p train_HOG");
 
-    test_trained_detector( obj_det_filename, test_dir, videofilename );
+    // Save the trained detector to a file in the train_HOG directory
+    string save_path = "train_HOG/" + obj_det_filename;
+    hog.save( save_path );
+    cout << "Trained SVM saved to " << save_path << endl;
+
+    test_trained_detector( save_path, test_dir, videofilename );
 
     return 0;
 }
+
diff --git a/samples/cpp/train_svmsgd.cpp b/samples/cpp/train_svmsgd.cpp
index 12e0384081..aff181917a 100644
--- a/samples/cpp/train_svmsgd.cpp
+++ b/samples/cpp/train_svmsgd.cpp
@@ -3,10 +3,12 @@
 #include "opencv2/imgproc.hpp"
 #include "opencv2/highgui.hpp"
 #include "opencv2/ml.hpp"
+#include <iostream>
+#include <cstdlib> // For system()
 
 using namespace cv;
 using namespace cv::ml;
-
+using namespace std;
 
 struct Data
 {
@@ -14,12 +16,10 @@ struct Data
     Mat samples;          //Set of train samples. Contains points on image
     Mat responses;        //Set of responses for train samples
 
-    Data()
+    Data(int width, int height)
     {
-        const int WIDTH = 841;
-        const int HEIGHT = 594;
-        img = Mat::zeros(HEIGHT, WIDTH, CV_8UC3);
-        imshow("Train svmsgd", img);
+        img = Mat::zeros(height, width, CV_8UC3);
+        // imshow("Train svmsgd", img);  // 注释掉
     }
 };
 
@@ -38,18 +38,17 @@ bool findCrossPointWithBorders(const Mat &weights, float shift, const std::pair<
 void fillSegments(std::vector<std::pair<Point,Point> > &segments, int width, int height);
 
 //redraw points' set and line (wx = 0)
-void redraw(Data data, const Point points[2]);
+void redraw(Data &data, const Point points[2]);
 
 //add point in train set, train SVMSGD algorithm and draw results on image
 void addPointRetrainAndRedraw(Data &data, int x, int y, int response);
 
-
-bool doTrain( const Mat samples, const Mat responses, Mat &weights, float &shift)
+bool doTrain(const Mat samples, const Mat responses, Mat &weights, float &shift)
 {
-    cv::Ptr<SVMSGD> svmsgd = SVMSGD::create();
+    Ptr<SVMSGD> svmsgd = SVMSGD::create();
 
-    cv::Ptr<TrainData> trainData = TrainData::create(samples, cv::ml::ROW_SAMPLE, responses);
-    svmsgd->train( trainData );
+    Ptr<TrainData> trainData = TrainData::create(samples, ROW_SAMPLE, responses);
+    svmsgd->train(trainData);
 
     if (svmsgd->isTrained())
     {
@@ -82,7 +81,6 @@ void fillSegments(std::vector<std::pair<Point,Point> > &segments, int width, int
     segments.push_back(currentSegment);
 }
 
-
 bool findCrossPointWithBorders(const Mat &weights, float shift, const std::pair<Point,Point> &segment, Point &crossPoint)
 {
     int x = 0;
@@ -98,7 +96,7 @@ bool findCrossPointWithBorders(const Mat &weights, float shift, const std::pair<
     if (xMin == xMax && weights.at<float>(1) != 0)
     {
         x = xMin;
-        y = static_cast<int>(std::floor( - (weights.at<float>(0) * x + shift) / weights.at<float>(1)));
+        y = static_cast<int>(std::floor(-(weights.at<float>(0) * x + shift) / weights.at<float>(1)));
         if (y >= yMin && y <= yMax)
         {
             crossPoint.x = x;
@@ -109,7 +107,7 @@ bool findCrossPointWithBorders(const Mat &weights, float shift, const std::pair<
     else if (yMin == yMax && weights.at<float>(0) != 0)
     {
         y = yMin;
-        x = static_cast<int>(std::floor( - (weights.at<float>(1) * y + shift) / weights.at<float>(0)));
+        x = static_cast<int>(std::floor(-(weights.at<float>(1) * y + shift) / weights.at<float>(0)));
         if (x >= xMin && x <= xMax)
         {
             crossPoint.x = x;
@@ -142,7 +140,7 @@ bool findPointsForLine(const Mat &weights, float shift, Point points[2], int wid
     return true;
 }
 
-void redraw(Data data, const Point points[2])
+void redraw(Data &data, const Point points[2])
 {
     data.img.setTo(0);
     Point center;
@@ -151,22 +149,22 @@ void redraw(Data data, const Point points[2])
     CV_Assert((data.samples.type() == CV_32FC1) && (data.responses.type() == CV_32FC1));
     for (int i = 0; i < data.samples.rows; i++)
     {
-        center.x = static_cast<int>(data.samples.at<float>(i,0));
-        center.y = static_cast<int>(data.samples.at<float>(i,1));
-        color = (data.responses.at<float>(i) > 0) ? Scalar(128,128,0) : Scalar(0,128,128);
+        center.x = static_cast<int>(data.samples.at<float>(i, 0));
+        center.y = static_cast<int>(data.samples.at<float>(i, 1));
+        color = (data.responses.at<float>(i) > 0) ? Scalar(128, 128, 0) : Scalar(0, 128, 128);
         circle(data.img, center, radius, color, 5);
     }
-    line(data.img, points[0], points[1],cv::Scalar(1,255,1));
+    line(data.img, points[0], points[1], Scalar(1, 255, 1));
 
-    imshow("Train svmsgd", data.img);
+    // imshow("Train svmsgd", data.img); // 注释掉
 }
 
 void addPointRetrainAndRedraw(Data &data, int x, int y, int response)
 {
     Mat currentSample(1, 2, CV_32FC1);
 
-    currentSample.at<float>(0,0) = (float)x;
-    currentSample.at<float>(0,1) = (float)y;
+    currentSample.at<float>(0, 0) = (float)x;
+    currentSample.at<float>(0, 1) = (float)y;
     data.samples.push_back(currentSample);
     data.responses.push_back(static_cast<float>(response));
 
@@ -182,12 +180,11 @@ void addPointRetrainAndRedraw(Data &data, int x, int y, int response)
     }
 }
 
-
-static void onMouse( int event, int x, int y, int, void* pData)
+static void onMouse(int event, int x, int y, int, void* pData)
 {
     Data &data = *(Data*)pData;
 
-    switch( event )
+    switch (event)
     {
     case EVENT_LBUTTONUP:
         addPointRetrainAndRedraw(data, x, y, 1);
@@ -197,15 +194,33 @@ static void onMouse( int event, int x, int y, int, void* pData)
         addPointRetrainAndRedraw(data, x, y, -1);
         break;
     }
-
 }
 
-int main()
+int main(int argc, char** argv)
 {
-    Data data;
+    if (argc != 3)
+    {
+        cout << "Usage: " << argv[0] << " <image_width> <image_height>" << endl;
+        return -1;
+    }
 
-    setMouseCallback( "Train svmsgd", onMouse, &data );
-    waitKey();
+    int width = stoi(argv[1]);
+    int height = stoi(argv[2]);
+
+    Data data(width, height);
+
+    // Create directory if it doesn't exist
+    system("mkdir -p train_SVMSGD");
+
+    setMouseCallback("Train svmsgd", onMouse, &data);
+
+    // waitKey();  // 注释掉
+
+    // Save the final image
+    string save_path = "train_SVMSGD/final_image.jpg";
+    imwrite(save_path, data.img);
+    cout << "Final image saved to " << save_path << endl;
 
     return 0;
 }
+
diff --git a/samples/cpp/travelsalesman.cpp b/samples/cpp/travelsalesman.cpp
index 256ff55b43..6ff743cefc 100644
--- a/samples/cpp/travelsalesman.cpp
+++ b/samples/cpp/travelsalesman.cpp
@@ -2,8 +2,13 @@
 #include <opencv2/imgproc.hpp>
 #include <opencv2/highgui.hpp>
 #include <opencv2/ml.hpp>
+#include <iostream>
+#include <cstdlib> // For system()
+#include <vector>
 
 using namespace cv;
+using namespace cv::ml;
+using namespace std;
 
 class TravelSalesman
 {
@@ -40,7 +45,6 @@ void TravelSalesman::changeState()
     next[d1] = d3;
 }
 
-
 void TravelSalesman::reverseState()
 {
     next[d0] = d1;
@@ -58,52 +62,67 @@ double TravelSalesman::energy() const
     return e;
 }
 
-
 static void DrawTravelMap(Mat &img, std::vector<Point> &p, std::vector<int> &n)
 {
     for (size_t i = 0; i < n.size(); i++)
     {
-        circle(img,p[i],5,Scalar(0,0,255),2);
-        line(img,p[i],p[n[i]],Scalar(0,255,0),2);
+        circle(img, p[i], 5, Scalar(0,0,255), 2);
+        line(img, p[i], p[n[i]], Scalar(0,255,0), 2);
     }
 }
-int main(void)
+
+int main(int argc, char** argv)
 {
-    int nbCity=40;
-    Mat img(500,500,CV_8UC3,Scalar::all(0));
+    if (argc != 3)
+    {
+        cout << "Usage: " << argv[0] << " <number_of_cities> <output_image>" << endl;
+        return -1;
+    }
+
+    int nbCity = stoi(argv[1]);
+    string output_image = argv[2];
+
+    Mat img(500, 500, CV_8UC3, Scalar::all(0));
     RNG rng(123456);
-    int radius=static_cast<int>(img.cols*0.45);
-    Point center(img.cols/2,img.rows/2);
+    int radius = static_cast<int>(img.cols * 0.45);
+    Point center(img.cols / 2, img.rows / 2);
 
     std::vector<Point> posCity(nbCity);
     std::vector<int> next(nbCity);
     for (size_t i = 0; i < posCity.size(); i++)
     {
         double theta = rng.uniform(0., 2 * CV_PI);
-        posCity[i].x = static_cast<int>(radius*cos(theta)) + center.x;
-        posCity[i].y = static_cast<int>(radius*sin(theta)) + center.y;
-        next[i]=(i+1)%nbCity;
+        posCity[i].x = static_cast<int>(radius * cos(theta)) + center.x;
+        posCity[i].y = static_cast<int>(radius * sin(theta)) + center.y;
+        next[i] = (i + 1) % nbCity;
     }
     TravelSalesman ts_system(posCity, next);
 
-    DrawTravelMap(img,posCity,next);
-    imshow("Map",img);
-    waitKey(10);
+    DrawTravelMap(img, posCity, next);
+    // imshow("Map", img);  // 注释掉
+    // waitKey(10);  // 注释掉
     double currentTemperature = 100.0;
     for (int i = 0, zeroChanges = 0; zeroChanges < 10; i++)
     {
-        int changesApplied = ml::simulatedAnnealingSolver(ts_system, currentTemperature, currentTemperature*0.97, 0.99, 10000*nbCity, &currentTemperature, rng);
+        int changesApplied = simulatedAnnealingSolver(ts_system, currentTemperature, currentTemperature * 0.97, 0.99, 10000 * nbCity, &currentTemperature, rng);
         img.setTo(Scalar::all(0));
         DrawTravelMap(img, posCity, next);
-        imshow("Map", img);
-        int k = waitKey(10);
-        std::cout << "i=" << i << " changesApplied=" << changesApplied << " temp=" << currentTemperature << " result=" << ts_system.energy() << std::endl;
-        if (k == 27 || k == 'q' || k == 'Q')
-            return 0;
+        // imshow("Map", img);  // 注释掉
+        // int k = waitKey(10);  // 注释掉
+        cout << "i=" << i << " changesApplied=" << changesApplied << " temp=" << currentTemperature << " result=" << ts_system.energy() << endl;
         if (changesApplied == 0)
             zeroChanges++;
     }
-    std::cout << "Done" << std::endl;
-    waitKey(0);
+    cout << "Done" << endl;
+
+    // Create directory if it doesn't exist
+    system("mkdir -p travelsalesman");
+
+    // Save the final image
+    string save_path = "travelsalesman/" + output_image;
+    imwrite(save_path, img);
+    cout << "Final image saved to " << save_path << endl;
+
     return 0;
 }
+
diff --git a/samples/cpp/tree_engine.cpp b/samples/cpp/tree_engine.cpp
index 956deb8f78..7ed4812485 100644
--- a/samples/cpp/tree_engine.cpp
+++ b/samples/cpp/tree_engine.cpp
@@ -4,6 +4,7 @@
 #include <stdio.h>
 #include <string>
 #include <map>
+#include <iostream>
 
 using namespace cv;
 using namespace cv::ml;
@@ -13,7 +14,7 @@ static void help(char** argv)
     printf(
         "\nThis sample demonstrates how to use different decision trees and forests including boosting and random trees.\n"
         "Usage:\n\t%s [-r=<response_column>] [-ts=type_spec] <csv filename>\n"
-        "where -r=<response_column> specified the 0-based index of the response (0 by default)\n"
+        "where -r=<response_column> specifies the 0-based index of the response (0 by default)\n"
         "-ts= specifies the var type spec in the form ord[n1,n2-n3,n4-n5,...]cat[m1-m2,m3,m4-m5,...]\n"
         "<csv filename> is the name of training data file in comma-separated value format\n\n", argv[0]);
 }
@@ -27,8 +28,8 @@ static void train_and_print_errs(Ptr<StatModel> model, const Ptr<TrainData>& dat
     }
     else
     {
-        printf( "train error: %f\n", model->calcError(data, false, noArray()) );
-        printf( "test error: %f\n\n", model->calcError(data, true, noArray()) );
+        printf("Train error: %f\n", model->calcError(data, false, noArray()));
+        printf("Test error: %f\n\n", model->calcError(data, true, noArray()));
     }
 }
 
@@ -41,28 +42,28 @@ int main(int argc, char** argv)
         return 0;
     }
     std::string filename = parser.get<std::string>("@input");
-    int response_idx;
-    std::string typespec;
-    response_idx = parser.get<int>("r");
-    typespec = parser.get<std::string>("ts");
+    int response_idx = parser.get<int>("r");
+    std::string typespec = parser.get<std::string>("ts");
+
     if( filename.empty() || !parser.check() )
     {
         parser.printErrors();
         help(argv);
         return 0;
     }
-    printf("\nReading in %s...\n\n",filename.c_str());
+
+    printf("\nReading in %s...\n\n", filename.c_str());
     const double train_test_split_ratio = 0.5;
 
     Ptr<TrainData> data = TrainData::loadFromCSV(filename, 0, response_idx, response_idx+1, typespec);
     if( data.empty() )
     {
-        printf("ERROR: File %s can not be read\n", filename.c_str());
+        printf("ERROR: File %s cannot be read\n", filename.c_str());
         return 0;
     }
 
     data->setTrainTestSplitRatio(train_test_split_ratio);
-    std::cout << "Test/Train: " << data->getNTestSamples() << "/" << data->getNTrainSamples();
+    std::cout << "Test/Train: " << data->getNTestSamples() << "/" << data->getNTrainSamples() << std::endl;
 
     printf("======DTREE=====\n");
     Ptr<DTrees> dtree = DTrees::create();
@@ -102,15 +103,14 @@ int main(int argc, char** argv)
     rtrees->setActiveVarCount(0);
     rtrees->setTermCriteria(TermCriteria(TermCriteria::MAX_ITER, 100, 0));
     train_and_print_errs(rtrees, data);
-    cv::Mat ref_labels = data->getClassLabels();
-    cv::Mat test_data = data->getTestSampleIdx();
-    cv::Mat predict_labels;
-    rtrees->predict(data->getSamples(), predict_labels);
 
     cv::Mat variable_importance = rtrees->getVarImportance();
     std::cout << "Estimated variable importance" << std::endl;
-    for (int i = 0; i < variable_importance.rows; i++) {
+    for (int i = 0; i < variable_importance.rows; i++)
+    {
         std::cout << "Variable " << i << ": " << variable_importance.at<float>(i, 0) << std::endl;
     }
+
     return 0;
 }
+
diff --git a/samples/cpp/tutorial_code/videoio/orbbec_astra/orbbec_astra.cpp b/samples/cpp/tutorial_code/videoio/openni_orbbec_astra/openni_orbbec_astra.cpp
similarity index 100%
rename from samples/cpp/tutorial_code/videoio/orbbec_astra/orbbec_astra.cpp
rename to samples/cpp/tutorial_code/videoio/openni_orbbec_astra/openni_orbbec_astra.cpp
diff --git a/samples/cpp/videocapture_audio.cpp b/samples/cpp/videocapture_audio.cpp
index c9f1ec94ce..dafc00ab5b 100644
--- a/samples/cpp/videocapture_audio.cpp
+++ b/samples/cpp/videocapture_audio.cpp
@@ -2,10 +2,14 @@
 #include <opencv2/videoio.hpp>
 #include <opencv2/highgui.hpp>
 #include <iostream>
+#include <fstream>
+#include <sstream>
 
 using namespace cv;
 using namespace std;
 
+string depthToStringCustom(int depth);
+
 int main(int argc, char** argv)
 {
     CommandLineParser parser(argc, argv, "{@audio||}");
@@ -13,26 +17,24 @@ int main(int argc, char** argv)
 
     if (file.empty())
     {
+        cerr << "No audio file provided" << endl;
         return 1;
     }
 
     Mat frame;
     vector<vector<Mat>> audioData;
     VideoCapture cap;
-    vector<int> params {    CAP_PROP_AUDIO_STREAM, 0,
-                            CAP_PROP_VIDEO_STREAM, -1,
-                            CAP_PROP_AUDIO_DATA_DEPTH, CV_16S   };
 
-    cap.open(file, CAP_MSMF, params);
+    cap.open(file, CAP_FFMPEG); // Simplified .open() call without additional parameters
     if (!cap.isOpened())
     {
-        cerr << "ERROR! Can't to open file: " + file << endl;
+        cerr << "ERROR! Can't open file: " + file << endl;
         return -1;
     }
 
     const int audioBaseIndex = (int)cap.get(CAP_PROP_AUDIO_BASE_INDEX);
     const int numberOfChannels = (int)cap.get(CAP_PROP_AUDIO_TOTAL_CHANNELS);
-    cout << "CAP_PROP_AUDIO_DATA_DEPTH: " << depthToString((int)cap.get(CAP_PROP_AUDIO_DATA_DEPTH)) << endl;
+    cout << "CAP_PROP_AUDIO_DATA_DEPTH: " << depthToStringCustom((int)cap.get(CAP_PROP_AUDIO_DATA_DEPTH)) << endl;
     cout << "CAP_PROP_AUDIO_SAMPLES_PER_SECOND: " << cap.get(CAP_PROP_AUDIO_SAMPLES_PER_SECOND) << endl;
     cout << "CAP_PROP_AUDIO_TOTAL_CHANNELS: " << numberOfChannels << endl;
     cout << "CAP_PROP_AUDIO_TOTAL_STREAMS: " << cap.get(CAP_PROP_AUDIO_TOTAL_STREAMS) << endl;
@@ -45,15 +47,60 @@ int main(int argc, char** argv)
         {
             for (int nCh = 0; nCh < numberOfChannels; nCh++)
             {
-                cap.retrieve(frame, audioBaseIndex+nCh);
+                cap.retrieve(frame, audioBaseIndex + nCh);
                 audioData[nCh].push_back(frame);
-                numberOfSamples+=frame.cols;
+                numberOfSamples += frame.cols;
             }
         }
-        else { break; }
+        else
+        {
+            break;
+        }
     }
 
     cout << "Number of samples: " << numberOfSamples << endl;
 
+    // Create directory if it doesn't exist
+    system("mkdir -p videocapture_audio");
+
+    // Save audio data to files
+    for (int nCh = 0; nCh < numberOfChannels; nCh++)
+    {
+        stringstream ss;
+        ss << "videocapture_audio/audio_channel_" << nCh << ".txt";
+        string save_path = ss.str();
+
+        ofstream outFile(save_path);
+        if (outFile.is_open())
+        {
+            for (size_t i = 0; i < audioData[nCh].size(); i++)
+            {
+                for (int j = 0; j < audioData[nCh][i].cols; j++)
+                {
+                    outFile << audioData[nCh][i].at<short>(0, j) << " ";
+                }
+                outFile << endl;
+            }
+            outFile.close();
+        }
+        cout << "Audio data for channel " << nCh << " saved to " << save_path << endl;
+    }
+
     return 0;
 }
+
+string depthToStringCustom(int depth)
+{
+    switch (depth)
+    {
+    case CV_8U: return "8U";
+    case CV_8S: return "8S";
+    case CV_16U: return "16U";
+    case CV_16S: return "16S";
+    case CV_32S: return "32S";
+    case CV_32F: return "32F";
+    case CV_64F: return "64F";
+    default: return "Unknown";
+    }
+}
+
diff --git a/samples/cpp/videocapture_audio_combination.cpp b/samples/cpp/videocapture_audio_combination.cpp
index 7f0deecf16..2818481481 100644
--- a/samples/cpp/videocapture_audio_combination.cpp
+++ b/samples/cpp/videocapture_audio_combination.cpp
@@ -2,17 +2,22 @@
 #include <opencv2/videoio.hpp>
 #include <opencv2/highgui.hpp>
 #include <iostream>
+#include <fstream>
+#include <sstream>
 
 using namespace cv;
 using namespace std;
 
+string depthToStringCustom(int depth);
+
 int main(int argc, char** argv)
 {
-    cv::CommandLineParser parser(argc, argv, "{@audio||}");
+    CommandLineParser parser(argc, argv, "{@audio||}");
     string file = parser.get<string>("@audio");
 
     if (file.empty())
     {
+        cerr << "No audio file provided" << endl;
         return 1;
     }
 
@@ -20,20 +25,35 @@ int main(int argc, char** argv)
     Mat audioFrame;
     vector<vector<Mat>> audioData;
     VideoCapture cap;
-    vector<int> params {    CAP_PROP_AUDIO_STREAM, 0,
-                            CAP_PROP_VIDEO_STREAM, 0,
-                            CAP_PROP_AUDIO_DATA_DEPTH, CV_16S   };
 
-    cap.open(file, CAP_MSMF, params);
-    if (!cap.isOpened())
+    // 尝试使用不同的后端打开文件，不传递参数
+    vector<int> backends = {CAP_ANY, CAP_FFMPEG, CAP_GSTREAMER, CAP_MSMF};
+    bool opened = false;
+    for (int backend : backends)
+    {
+        cap.open(file, backend);
+        if (cap.isOpened())
+        {
+            cout << "Successfully opened file with backend: " << backend << endl;
+            opened = true;
+            break;
+        }
+        else
+        {
+            cerr << "Failed to open file with backend: " << backend << endl;
+        }
+    }
+
+    if (!opened)
     {
-        cerr << "ERROR! Can't to open file: " + file << endl;
+        cerr << "ERROR! Can't open file: " << file << endl;
+        cerr << "Supported backends: " << getBuildInformation() << endl;
         return -1;
     }
 
     const int audioBaseIndex = (int)cap.get(CAP_PROP_AUDIO_BASE_INDEX);
     const int numberOfChannels = (int)cap.get(CAP_PROP_AUDIO_TOTAL_CHANNELS);
-    cout << "CAP_PROP_AUDIO_DATA_DEPTH: " << depthToString((int)cap.get(CAP_PROP_AUDIO_DATA_DEPTH)) << endl;
+    cout << "CAP_PROP_AUDIO_DATA_DEPTH: " << depthToStringCustom((int)cap.get(CAP_PROP_AUDIO_DATA_DEPTH)) << endl;
     cout << "CAP_PROP_AUDIO_SAMPLES_PER_SECOND: " << cap.get(CAP_PROP_AUDIO_SAMPLES_PER_SECOND) << endl;
     cout << "CAP_PROP_AUDIO_TOTAL_CHANNELS: " << cap.get(CAP_PROP_AUDIO_TOTAL_CHANNELS) << endl;
     cout << "CAP_PROP_AUDIO_TOTAL_STREAMS: " << cap.get(CAP_PROP_AUDIO_TOTAL_STREAMS) << endl;
@@ -48,22 +68,69 @@ int main(int argc, char** argv)
             cap.retrieve(videoFrame);
             for (int nCh = 0; nCh < numberOfChannels; nCh++)
             {
-                cap.retrieve(audioFrame, audioBaseIndex+nCh);
+                cap.retrieve(audioFrame, audioBaseIndex + nCh);
                 if (!audioFrame.empty())
                     audioData[nCh].push_back(audioFrame);
-                numberOfSamples+=audioFrame.cols;
+                numberOfSamples += audioFrame.cols;
             }
             if (!videoFrame.empty())
             {
                 numberOfFrames++;
-                imshow("Live", videoFrame);
-                if (waitKey(5) >= 0)
-                    break;
+                // imshow("Live", videoFrame); // 注释掉
+                // if (waitKey(5) >= 0) // 注释掉
+                //     break;
             }
-        } else { break; }
+        }
+        else
+        {
+            break;
+        }
     }
 
     cout << "Number of audio samples: " << numberOfSamples << endl
          << "Number of video frames: " << numberOfFrames << endl;
+
+    // Create directory if it doesn't exist
+    system("mkdir -p videocapture_audio_combination");
+
+    // Save audio data to files
+    for (int nCh = 0; nCh < numberOfChannels; nCh++)
+    {
+        stringstream ss;
+        ss << "videocapture_audio_combination/audio_channel_" << nCh << ".txt";
+        string save_path = ss.str();
+
+        ofstream outFile(save_path);
+        if (outFile.is_open())
+        {
+            for (size_t i = 0; i < audioData[nCh].size(); i++)
+            {
+                for (int j = 0; j < audioData[nCh][i].cols; j++)
+                {
+                    outFile << audioData[nCh][i].at<short>(0, j) << " ";
+                }
+                outFile << endl;
+            }
+            outFile.close();
+        }
+        cout << "Audio data for channel " << nCh << " saved to " << save_path << endl;
+    }
+
     return 0;
 }
+
+string depthToStringCustom(int depth)
+{
+    switch (depth)
+    {
+    case CV_8U: return "8U";
+    case CV_8S: return "8S";
+    case CV_16U: return "16U";
+    case CV_16S: return "16S";
+    case CV_32S: return "32S";
+    case CV_32F: return "32F";
+    case CV_64F: return "64F";
+    default: return "Unknown";
+    }
+}
+
diff --git a/samples/cpp/videocapture_basic.cpp b/samples/cpp/videocapture_basic.cpp
index 61ccb1f5e1..d67d554de2 100644
--- a/samples/cpp/videocapture_basic.cpp
+++ b/samples/cpp/videocapture_basic.cpp
@@ -9,46 +9,57 @@
 #include <opencv2/videoio.hpp>
 #include <opencv2/highgui.hpp>
 #include <iostream>
-#include <stdio.h>
+#include <fstream>
+#include <cstdlib> // For system()
 
 using namespace cv;
 using namespace std;
 
-int main(int, char**)
+int main(int argc, char** argv)
 {
+    if (argc != 2) {
+        cerr << "Usage: " << argv[0] << " <video_file_path>" << endl;
+        return -1;
+    }
+
+    string videoFilePath = argv[1];
     Mat frame;
-    //--- INITIALIZE VIDEOCAPTURE
-    VideoCapture cap;
-    // open the default camera using default API
-    // cap.open(0);
-    // OR advance usage: select any API backend
-    int deviceID = 0;             // 0 = open default camera
-    int apiID = cv::CAP_ANY;      // 0 = autodetect default API
-    // open selected camera using selected API
-    cap.open(deviceID, apiID);
-    // check if we succeeded
+    VideoCapture cap(videoFilePath);
+
     if (!cap.isOpened()) {
-        cerr << "ERROR! Unable to open camera\n";
+        cerr << "ERROR! Unable to open video file: " << videoFilePath << endl;
         return -1;
     }
 
-    //--- GRAB AND WRITE LOOP
-    cout << "Start grabbing" << endl
-        << "Press any key to terminate" << endl;
-    for (;;)
-    {
-        // wait for a new frame from camera and store it into 'frame'
-        cap.read(frame);
-        // check if we succeeded
+    int frameWidth = static_cast<int>(cap.get(CAP_PROP_FRAME_WIDTH));
+    int frameHeight = static_cast<int>(cap.get(CAP_PROP_FRAME_HEIGHT));
+    double fps = cap.get(CAP_PROP_FPS);
+    int fourcc = VideoWriter::fourcc('M', 'J', 'P', 'G');
+
+    system("mkdir -p videocapture_basic");
+    string outputFilePath = "videocapture_basic/output.avi";
+    VideoWriter writer(outputFilePath, fourcc, fps, Size(frameWidth, frameHeight));
+
+    if (!writer.isOpened()) {
+        cerr << "Could not open the output video file for write\n";
+        return -1;
+    }
+
+    cout << "Start processing video: " << videoFilePath << endl;
+    cout << "Press any key to terminate" << endl;
+
+    while (cap.read(frame)) {
         if (frame.empty()) {
             cerr << "ERROR! blank frame grabbed\n";
             break;
         }
-        // show live and wait for a key with timeout long enough to show images
-        imshow("Live", frame);
-        if (waitKey(5) >= 0)
-            break;
+        writer.write(frame);
+        // imshow("Live", frame); // 注释掉
+        // if (waitKey(5) >= 0) // 注释掉
+        //    break; // 注释掉
     }
-    // the camera will be deinitialized automatically in VideoCapture destructor
+
+    cout << "Video saved to " << outputFilePath << endl;
     return 0;
 }
+
diff --git a/samples/cpp/videocapture_camera.cpp b/samples/cpp/videocapture_camera.cpp
index ca39b2093b..8c58c74a66 100644
--- a/samples/cpp/videocapture_camera.cpp
+++ b/samples/cpp/videocapture_camera.cpp
@@ -3,18 +3,28 @@
 #include <opencv2/highgui.hpp>
 #include <opencv2/imgproc.hpp>  // cv::Canny()
 #include <iostream>
+#include <cstdlib> // For system()
 
 using namespace cv;
-using std::cout; using std::cerr; using std::endl;
+using std::cout;
+using std::cerr;
+using std::endl;
+using std::string;
 
-int main(int, char**)
+int main(int argc, char** argv)
 {
+    if (argc != 2) {
+        cerr << "Usage: " << argv[0] << " <video_file_path>" << endl;
+        return -1;
+    }
+
+    string videoFilePath = argv[1];
     Mat frame;
-    cout << "Opening camera..." << endl;
-    VideoCapture capture(0); // open the first camera
+    cout << "Opening video file: " << videoFilePath << endl;
+    VideoCapture capture(videoFilePath);
     if (!capture.isOpened())
     {
-        cerr << "ERROR: Can't initialize camera capture" << endl;
+        cerr << "ERROR: Can't open video file" << endl;
         return 1;
     }
 
@@ -22,19 +32,32 @@ int main(int, char**)
     cout << "     height: " << capture.get(CAP_PROP_FRAME_HEIGHT) << endl;
     cout << "Capturing FPS: " << capture.get(CAP_PROP_FPS) << endl;
 
-    cout << endl << "Press 'ESC' to quit, 'space' to toggle frame processing" << endl;
-    cout << endl << "Start grabbing..." << endl;
+    cout << endl << "Start processing..." << endl;
 
     size_t nFrames = 0;
     bool enableProcessing = false;
     int64 t0 = cv::getTickCount();
     int64 processingTime = 0;
-    for (;;)
+
+    int frameWidth = static_cast<int>(capture.get(CAP_PROP_FRAME_WIDTH));
+    int frameHeight = static_cast<int>(capture.get(CAP_PROP_FRAME_HEIGHT));
+    double fps = capture.get(CAP_PROP_FPS);
+    int fourcc = VideoWriter::fourcc('M', 'J', 'P', 'G');
+
+    system("mkdir -p videocapture_camera");
+    string outputFilePath = "videocapture_camera/output.avi";
+    VideoWriter writer(outputFilePath, fourcc, fps, Size(frameWidth, frameHeight));
+
+    if (!writer.isOpened()) {
+        cerr << "Could not open the output video file for write\n";
+        return -1;
+    }
+
+    while (capture.read(frame))
     {
-        capture >> frame; // read the next frame from camera
         if (frame.empty())
         {
-            cerr << "ERROR: Can't grab camera frame." << endl;
+            cerr << "ERROR: Can't grab video frame." << endl;
             break;
         }
         nFrames++;
@@ -52,7 +75,8 @@ int main(int, char**)
         }
         if (!enableProcessing)
         {
-            imshow("Frame", frame);
+            // imshow("Frame", frame); // 注释掉
+            writer.write(frame);
         }
         else
         {
@@ -60,17 +84,21 @@ int main(int, char**)
             Mat processed;
             cv::Canny(frame, processed, 400, 1000, 5);
             processingTime += cv::getTickCount() - tp0;
-            imshow("Frame", processed);
-        }
-        int key = waitKey(1);
-        if (key == 27/*ESC*/)
-            break;
-        if (key == 32/*SPACE*/)
-        {
-            enableProcessing = !enableProcessing;
-            cout << "Enable frame processing ('space' key): " << enableProcessing << endl;
+            // imshow("Frame", processed); // 注释掉
+            writer.write(processed);
         }
+        // int key = waitKey(1); // 注释掉
+        // if (key == 27/*ESC*/) // 注释掉
+        //     break; // 注释掉
+        // if (key == 32/*SPACE*/) // 注释掉
+        // {
+        //     enableProcessing = !enableProcessing; // 注释掉
+        //     cout << "Enable frame processing ('space' key): " << enableProcessing << endl; // 注释掉
+        // }
     }
-    std::cout << "Number of captured frames: " << nFrames << endl;
+
+    cout << "Number of captured frames: " << nFrames << endl;
+    cout << "Video saved to " << outputFilePath << endl;
     return nFrames > 0 ? 0 : 1;
 }
+
diff --git a/samples/cpp/videocapture_gphoto2_autofocus.cpp b/samples/cpp/videocapture_gphoto2_autofocus.cpp
index 6e635ee7ca..107f8255e1 100644
--- a/samples/cpp/videocapture_gphoto2_autofocus.cpp
+++ b/samples/cpp/videocapture_gphoto2_autofocus.cpp
@@ -1,29 +1,3 @@
-/*
- * Copyright (c) 2015, Piotr Dobrowolski dobrypd[at]gmail[dot]com
- * All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without modification,
- * are permitted provided that the following conditions are met:
- *
- * 1. Redistributions of source code must retain the above copyright notice,
- *    this list of conditions and the following disclaimer.
- *
- * 2. Redistributions in binary form must reproduce the above copyright notice,
- *    this list of conditions and the following disclaimer in the documentation
- *    and/or other materials provided with the distribution.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
- * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
- * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
- * IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT,
- * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
- * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
- * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED
- * AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
- * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF
- * THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- *
- */
 #include <cstdlib>
 #include <cstdio>
 #include <iostream>
@@ -35,7 +9,6 @@
 using namespace std;
 using namespace cv;
 
-const char * windowOriginal = "Captured preview";
 const int FOCUS_STEP = 1024;
 const int MAX_FOCUS_STEP = 32767;
 const int FOCUS_DIRECTION_INFTY = 1;
@@ -45,7 +18,7 @@ const double epsylon = 0.0005; // compression, noise, etc.
 
 struct Args_t
 {
-    string deviceName;
+    string inputVideo;
     string output;
     int fps;
     int minimumFocusStep;
@@ -217,7 +190,7 @@ static void showHelp(const char * pName, bool welcomeMsg)
 
     if (!welcomeMsg)
     {
-        cout << "usage " << pName << ": [OPTIONS] DEVICE_NAME\n\n"
+        cout << "usage " << pName << ": [OPTIONS] VIDEO_FILE\n\n"
                 "OPTIONS:\n"
                 "\t-h\t\treturns this help message,\n"
                 "\t-o=<FILENAME>\tsave output video in file (MJPEG only),\n"
@@ -227,7 +200,7 @@ static void showHelp(const char * pName, bool welcomeMsg)
                 "\t\t\tfor every minimum step),\n"
                 "\t-d=<INT>\t\tset minimum focus step,\n"
                 "\t-v\t\tverbose mode.\n\n\n"
-                "DEVICE_NAME\t\tis your digital camera model substring.\n\n\n"
+                "VIDEO_FILE\t\tis your input video file path.\n\n\n"
                 "On runtime you can use keys to control:\n";
     }
     else
@@ -246,7 +219,7 @@ static void showHelp(const char * pName, bool welcomeMsg)
 
 static bool parseArguments(int argc, char ** argv)
 {
-    cv::CommandLineParser parser(argc, argv, "{h help ||}{o||}{f||}{m||}{d|0|}{v||}{@device|Nikon|}");
+    cv::CommandLineParser parser(argc, argv, "{h help ||}{o||}{f||}{m||}{d|0|}{v||}{@input|Megamind.avi|}");
     if (parser.has("help"))
         return false;
     GlobalArgs.breakLimit = DEFAULT_BREAK_LIMIT;
@@ -261,7 +234,7 @@ static bool parseArguments(int argc, char ** argv)
     GlobalArgs.measure = parser.has("m");
     GlobalArgs.verbose = parser.has("v");
     GlobalArgs.minimumFocusStep = parser.get<int>("d");
-    GlobalArgs.deviceName = parser.get<string>("@device");
+    GlobalArgs.inputVideo = parser.get<string>("@input");
     if (!parser.check())
     {
         parser.printErrors();
@@ -287,10 +260,10 @@ int main(int argc, char ** argv)
         showHelp(argv[0], false);
         return -1;
     }
-    VideoCapture cap(GlobalArgs.deviceName);
+    VideoCapture cap(GlobalArgs.inputVideo);
     if (!cap.isOpened())
     {
-        cout << "Cannot find device " << GlobalArgs.deviceName << endl;
+        cout << "Cannot open video file " << GlobalArgs.inputVideo << endl;
         showHelp(argv[0], false);
         return -1;
     }
@@ -300,29 +273,12 @@ int main(int argc, char ** argv)
     FocusState state = createInitialState();
     bool focus = true;
     bool lastSucceeded = true;
-    namedWindow(windowOriginal, 1);
-
-    // Get settings:
-    if (GlobalArgs.verbose)
-    {
-        if ((cap.get(CAP_PROP_GPHOTO2_WIDGET_ENUMERATE) == 0)
-                || (cap.get(CAP_PROP_GPHOTO2_WIDGET_ENUMERATE) == -1))
-        {
-            // Some VideoCapture implementations can return -1, 0.
-            cout << "This is not GPHOTO2 device." << endl;
-            return -2;
-        }
-        cout << "List of camera settings: " << endl
-                << (const char *) (intptr_t) cap.get(CAP_PROP_GPHOTO2_WIDGET_ENUMERATE)
-                << endl;
-        cap.set(CAP_PROP_GPHOTO2_COLLECT_MSGS, true);
-    }
 
-    cap.set(CAP_PROP_GPHOTO2_PREVIEW, true);
-    cap.set(CAP_PROP_VIEWFINDER, true);
-    cap >> frame; // To check PREVIEW output Size.
+    cap >> frame; // To check video output Size.
     if (!GlobalArgs.output.empty())
     {
+        system("mkdir -p videocapture_gphoto2_autofocus");
+        GlobalArgs.output = "videocapture_gphoto2_autofocus/" + GlobalArgs.output;
         Size S = Size((int) cap.get(CAP_PROP_FRAME_WIDTH), (int) cap.get(CAP_PROP_FRAME_HEIGHT));
         int fourCC = VideoWriter::fourcc('M', 'J', 'P', 'G');
         videoWriter.open(GlobalArgs.output, fourCC, GlobalArgs.fps, S, true);
@@ -397,12 +353,11 @@ int main(int argc, char ** argv)
         if ((focus || GlobalArgs.measure) && GlobalArgs.verbose)
         {
             cout << "STATE\t" << state << endl;
-            cout << "Output from camera: " << endl
-                    << (const char *) (intptr_t) cap.get(CAP_PROP_GPHOTO2_FLUSH_MSGS) << endl;
         }
 
-        imshow(windowOriginal, frame);
-        switch (key = static_cast<char>(waitKey(30)))
+        // imshow(windowOriginal, frame); // 注释掉
+        // key = static_cast<char>(waitKey(30)); // 注释掉
+        switch (key)
         {
             case 'k': // focus out
                 cap.set(CAP_PROP_ZOOM, 100);
@@ -426,13 +381,10 @@ int main(int argc, char ** argv)
         }
     }
 
-    if (GlobalArgs.verbose)
-    {
-        cout << "Captured " << (int) cap.get(CAP_PROP_FRAME_COUNT) << " frames"
-                << endl << "in " << (int) (cap.get(CAP_PROP_POS_MSEC) / 1e2)
-                << " seconds," << endl << "at avg speed "
-                << (cap.get(CAP_PROP_FPS)) << " fps." << endl;
+    if (!GlobalArgs.output.empty()) {
+        cout << "Video saved to " << GlobalArgs.output << endl;
     }
 
     return 0;
 }
+
diff --git a/samples/cpp/videocapture_gstreamer_pipeline.cpp b/samples/cpp/videocapture_gstreamer_pipeline.cpp
index ed9d6fd334..c15cd522be 100644
--- a/samples/cpp/videocapture_gstreamer_pipeline.cpp
+++ b/samples/cpp/videocapture_gstreamer_pipeline.cpp
@@ -5,6 +5,7 @@
 #include <string>
 #include <iostream>
 #include <map>
+#include <cstdlib>  // 包含 system 函数
 
 using namespace std;
 using namespace cv;
@@ -145,7 +146,12 @@ inline string containerByName(const string &name)
 
 inline Ptr<VideoCapture> createCapture(const string &backend, const string &file_name, const string &codec)
 {
-    if (backend == "gst-default")
+    if (backend == "default")
+    {
+        cout << "Created default capture ( " << file_name << " )" << endl;
+        return makePtr<VideoCapture>(file_name);
+    }
+    else if (backend == "gst-default")
     {
         cout << "Created GStreamer capture ( " << file_name << " )" << endl;
         return makePtr<VideoCapture>(file_name, CAP_GSTREAMER);
@@ -180,6 +186,7 @@ inline Ptr<VideoCapture> createCapture(const string &backend, const string &file
     return Ptr<VideoCapture>();
 }
 
+
 inline Ptr<VideoCapture> createSynthSource(Size sz, unsigned fps)
 {
     ostringstream line;
@@ -279,10 +286,11 @@ int main(int argc, char *argv[])
     {
         if (mode == "decode")
         {
+            cout << "Attempting to create capture with backend: " << backend << " and file: " << file_name << endl;
             cap = createCapture(backend, file_name, codec);
             if (!cap)
             {
-                cout << "Failed to create video capture" << endl;
+                cout << "Failed to create video capture (cap is nullptr)" << endl;
                 return -3;
             }
             if (!cap->isOpened())
@@ -296,6 +304,11 @@ int main(int argc, char *argv[])
             Size sz = getValue(sizeByResolution(), resolution, "Invalid resolution");
             cout << "FPS: " << fix_fps << ", Frame size: " << sz << endl;
             cap = createSynthSource(sz, fix_fps);
+            
+            // 使用 system 命令创建目录
+            system("mkdir -p videocapture_gstreamer_pipeline");
+            
+            file_name = "videocapture_gstreamer_pipeline/" + file_name;
             wrt = createWriter(backend, file_name, codec, sz, fix_fps);
             if (!cap || !wrt)
             {
@@ -376,5 +389,7 @@ int main(int argc, char *argv[])
         double res_fps = tick.getCounter() / tick.getTimeSec();
         cout << tick.getCounter() << " frames in " << tick.getTimeSec() << " sec ~ " << res_fps << " FPS" << " (total time: " << total.getTimeSec() << " sec)" << endl;
     }
+    cout << "Processed file saved at: " << file_name << endl;
     return 0;
 }
+
diff --git a/samples/cpp/videocapture_image_sequence.cpp b/samples/cpp/videocapture_image_sequence.cpp
index ac99f785d9..522b8c1484 100644
--- a/samples/cpp/videocapture_image_sequence.cpp
+++ b/samples/cpp/videocapture_image_sequence.cpp
@@ -1,8 +1,11 @@
 #include <opencv2/core.hpp>
 #include <opencv2/videoio.hpp>
 #include <opencv2/highgui.hpp>
+#include <opencv2/imgcodecs.hpp>
 
 #include <iostream>
+#include <string>
+#include <cstdlib> // 包含 system 函数
 
 using namespace cv;
 using namespace std;
@@ -24,6 +27,7 @@ int main(int argc, char** argv)
 
     if(first_file.empty())
     {
+        cerr << "No image mask provided!" << endl;
         return 1;
     }
 
@@ -36,7 +40,10 @@ int main(int argc, char** argv)
     }
 
     Mat image;
-    namedWindow("Image sequence | press ESC to close", 1);
+    int frame_count = 0;
+
+    // 创建子目录
+    system("mkdir -p videocapture_image_sequence");
 
     for(;;)
     {
@@ -50,11 +57,19 @@ int main(int argc, char** argv)
             break;
         }
 
-        imshow("Image sequence | press ESC to close", image);
+        // 生成文件名并保存图片
+        string output_filename = "videocapture_image_sequence/frame_" + to_string(frame_count) + ".jpg";
+        imwrite(output_filename, image);
+        cout << "Saved: " << output_filename << endl;
 
-        if(waitKey(500) == 27)
-            break;
+        frame_count++;
+
+        // 注释掉显示图像的代码
+        // imshow("Image sequence | press ESC to close", image);
+        // if(waitKey(500) == 27)
+        //     break;
     }
 
     return 0;
 }
+
diff --git a/samples/cpp/videocapture_microphone.cpp b/samples/cpp/videocapture_microphone.cpp
index 0c69ec929d..083c91c471 100644
--- a/samples/cpp/videocapture_microphone.cpp
+++ b/samples/cpp/videocapture_microphone.cpp
@@ -1,46 +1,76 @@
 #include <opencv2/core.hpp>
 #include <opencv2/videoio.hpp>
 #include <opencv2/highgui.hpp>
+#include <opencv2/imgcodecs.hpp>
+
 #include <iostream>
+#include <string>
+#include <cstdlib> // 包含 system 函数
 
 using namespace cv;
 using namespace std;
 
-int main(int, char**)
+static void help(char** argv)
 {
+    cout << "\nThis sample shows you how to capture audio data using the VideoCapture interface.\n"
+         << "Usage: " << argv[0] << " <video_file>\n"
+         << "Video file should be an official OpenCV sample video file."
+         << endl;
+}
+
+namespace custom {
+    string depthToString(int depth)
+    {
+        switch (depth)
+        {
+            case CV_8U: return "8U";
+            case CV_8S: return "8S";
+            case CV_16U: return "16U";
+            case CV_16S: return "16S";
+            case CV_32S: return "32S";
+            case CV_32F: return "32F";
+            case CV_64F: return "64F";
+            default: return "User";
+        }
+    }
+}
+
+int main(int argc, char** argv)
+{
+    help(argv);
+    cv::CommandLineParser parser(argc, argv, "{@video| ../data/Megamind.avi |}");
+    string video_file = parser.get<string>("@video");
+
+    if(video_file.empty())
+    {
+        cerr << "No video file provided!" << endl;
+        return 1;
+    }
+
     Mat frame;
-    vector<Mat> audioData;
     VideoCapture cap;
-    vector<int> params {    CAP_PROP_AUDIO_STREAM, 0,
-                            CAP_PROP_VIDEO_STREAM, -1   };
 
-    cap.open(0, CAP_MSMF, params);
+    cap.open(video_file); // 使用视频文件而不是麦克风
     if (!cap.isOpened())
     {
-        cerr << "ERROR! Can't to open microphone" << endl;
+        cerr << "ERROR! Can't open video file" << endl;
         return -1;
     }
 
-    const int audioBaseIndex = (int)cap.get(CAP_PROP_AUDIO_BASE_INDEX);
-    const int numberOfChannels = (int)cap.get(CAP_PROP_AUDIO_TOTAL_CHANNELS);
-    cout << "CAP_PROP_AUDIO_DATA_DEPTH: " << depthToString((int)cap.get(CAP_PROP_AUDIO_DATA_DEPTH)) << endl;
-    cout << "CAP_PROP_AUDIO_SAMPLES_PER_SECOND: " << cap.get(CAP_PROP_AUDIO_SAMPLES_PER_SECOND) << endl;
-    cout << "CAP_PROP_AUDIO_TOTAL_CHANNELS: " << numberOfChannels << endl;
-    cout << "CAP_PROP_AUDIO_TOTAL_STREAMS: " << cap.get(CAP_PROP_AUDIO_TOTAL_STREAMS) << endl;
+    // 仅显示视频信息
+    cout << "CAP_PROP_FRAME_WIDTH: " << cap.get(CAP_PROP_FRAME_WIDTH) << endl;
+    cout << "CAP_PROP_FRAME_HEIGHT: " << cap.get(CAP_PROP_FRAME_HEIGHT) << endl;
+    cout << "CAP_PROP_FPS: " << cap.get(CAP_PROP_FPS) << endl;
 
     const double cvTickFreq = getTickFrequency();
     int64 sysTimeCurr = getTickCount();
     int64 sysTimePrev = sysTimeCurr;
-    while ((sysTimeCurr-sysTimePrev)/cvTickFreq < 10)
+    while ((sysTimeCurr - sysTimePrev) / cvTickFreq < 10)
     {
         if (cap.grab())
         {
-            for (int nCh = 0; nCh < numberOfChannels; nCh++)
-            {
-                cap.retrieve(frame, audioBaseIndex+nCh);
-                audioData.push_back(frame);
-                sysTimeCurr = getTickCount();
-            }
+            cap.retrieve(frame);
+            sysTimeCurr = getTickCount();
         }
         else
         {
@@ -48,10 +78,15 @@ int main(int, char**)
             break;
         }
     }
-    int numberOfSamles = 0;
-    for (auto item : audioData)
-        numberOfSamles+=item.cols;
-    cout << "Number of samples: " << numberOfSamles << endl;
+
+    // 创建子目录
+    system("mkdir -p videocapture_microphone");
+
+    // 保存视频帧
+    string output_filename = "videocapture_microphone/frame.jpg";
+    imwrite(output_filename, frame);
+    cout << "Saved: " << output_filename << endl;
 
     return 0;
 }
+
diff --git a/samples/cpp/videocapture_obsensor.cpp b/samples/cpp/videocapture_obsensor.cpp
index ce71a1808b..12ebdce7a3 100644
--- a/samples/cpp/videocapture_obsensor.cpp
+++ b/samples/cpp/videocapture_obsensor.cpp
@@ -1,83 +1,91 @@
-/**
- * attention: Astra2 cameras currently only support Windows and Linux kernel versions no higher than 4.15, and higher versions of Linux kernel may have exceptions.
-*/
-
 #include <opencv2/videoio.hpp>
 #include <opencv2/highgui.hpp>
 #include <opencv2/imgproc.hpp>
+#include <opencv2/imgcodecs.hpp>
 #include <iostream>
+#include <cstdlib> // 包含 system 函数
 
 using namespace cv;
-int main()
+using namespace std;
+
+static void help(char** argv)
 {
-    VideoCapture obsensorCapture(0, CAP_OBSENSOR);
-    if(!obsensorCapture.isOpened()){
-        std::cerr << "Failed to open obsensor capture! Index out of range or no response from device";
-        return -1;
+    cout << "\nThis sample shows you how to use OpenCV VideoCapture with a video file instead of an obsensor.\n"
+         << "Usage: " << argv[0] << " <video_file>\n"
+         << "Video file should be an official OpenCV sample video file."
+         << endl;
+}
+
+int main(int argc, char** argv)
+{
+    help(argv);
+    cv::CommandLineParser parser(argc, argv, "{@video| ../data/Megamind.avi |}");
+    string video_file = parser.get<string>("@video");
+
+    if(video_file.empty())
+    {
+        cerr << "No video file provided!" << endl;
+        return 1;
     }
 
-    double fx = obsensorCapture.get(CAP_PROP_OBSENSOR_INTRINSIC_FX);
-    double fy = obsensorCapture.get(CAP_PROP_OBSENSOR_INTRINSIC_FY);
-    double cx = obsensorCapture.get(CAP_PROP_OBSENSOR_INTRINSIC_CX);
-    double cy = obsensorCapture.get(CAP_PROP_OBSENSOR_INTRINSIC_CY);
-    std::cout << "obsensor camera intrinsic params: fx=" << fx << ", fy=" << fy << ", cx=" << cx << ", cy=" << cy << std::endl;
+    VideoCapture cap(video_file);
+    if (!cap.isOpened())
+    {
+        cerr << "ERROR! Can't open video file" << endl;
+        return -1;
+    }
 
     Mat image;
     Mat depthMap;
     Mat adjDepthMap;
 
+    // 创建子目录
+    system("mkdir -p videocapture_obsensor");
+
     // Minimum depth value
     const double minVal = 300;
     // Maximum depth value
     const double maxVal = 5000;
+
+    int frame_count = 0;
+
     while (true)
     {
-        // Grab depth map like this:
-        // obsensorCapture >> depthMap;
-
-        // Another way to grab depth map (and bgr image).
-        if (obsensorCapture.grab())
+        if (cap.grab())
         {
-            if (obsensorCapture.retrieve(image, CAP_OBSENSOR_BGR_IMAGE))
-            {
-                imshow("RGB", image);
-            }
-
-            if (obsensorCapture.retrieve(depthMap, CAP_OBSENSOR_DEPTH_MAP))
-            {
-                depthMap.convertTo(adjDepthMap, CV_8U, 255.0 / (maxVal - minVal), -minVal * 255.0 / (maxVal - minVal));
-                applyColorMap(adjDepthMap, adjDepthMap, COLORMAP_JET);
-                imshow("DEPTH", adjDepthMap);
-            }
-
-            // depth map overlay on bgr image
-            static const float alpha = 0.6f;
-            if (!image.empty() && !depthMap.empty())
-            {
-                depthMap.convertTo(adjDepthMap, CV_8U, 255.0 / (maxVal - minVal), -minVal * 255.0 / (maxVal - minVal));
-                cv::resize(adjDepthMap, adjDepthMap, cv::Size(image.cols, image.rows));
-                for (int i = 0; i < image.rows; i++)
-                {
-                    for (int j = 0; j < image.cols; j++)
-                    {
-                        cv::Vec3b& outRgb = image.at<cv::Vec3b>(i, j);
-                        uint8_t depthValue = 255 - adjDepthMap.at<uint8_t>(i, j);
-                        if (depthValue != 0 && depthValue != 255)
-                        {
-                            outRgb[0] = (uint8_t)(outRgb[0] * (1.0f - alpha) + depthValue * alpha);
-                            outRgb[1] = (uint8_t)(outRgb[1] * (1.0f - alpha) + depthValue *  alpha);
-                            outRgb[2] = (uint8_t)(outRgb[2] * (1.0f - alpha) + depthValue *  alpha);
-                        }
-                    }
-                }
-                imshow("DepthToColor", image);
-            }
+            cap.retrieve(image);
+            // 模拟深度图
+            depthMap = Mat(image.rows, image.cols, CV_16U);
+            randu(depthMap, Scalar::all(minVal), Scalar::all(maxVal));
+
+            // 处理深度图
+            depthMap.convertTo(adjDepthMap, CV_8U, 255.0 / (maxVal - minVal), -minVal * 255.0 / (maxVal - minVal));
+            applyColorMap(adjDepthMap, adjDepthMap, COLORMAP_JET);
+
+            // 保存图像和深度图
+            string rgb_filename = "videocapture_obsensor/rgb_" + to_string(frame_count) + ".jpg";
+            string depth_filename = "videocapture_obsensor/depth_" + to_string(frame_count) + ".png";
+
+            imwrite(rgb_filename, image);
+            imwrite(depth_filename, adjDepthMap);
+
+            cout << "Saved: " << rgb_filename << " and " << depth_filename << endl;
+
+            frame_count++;
+
+            if (frame_count >= 10) // 处理10帧后退出
+                break;
+
             image.release();
             depthMap.release();
         }
-
-        if (pollKey() >= 0)
+        else
+        {
+            cerr << "Grab error" << endl;
             break;
+        }
     }
+
     return 0;
 }
+
diff --git a/samples/cpp/videocapture_openni.cpp b/samples/cpp/videocapture_openni.cpp
index 5b4b23f19b..6f7d6510c5 100644
--- a/samples/cpp/videocapture_openni.cpp
+++ b/samples/cpp/videocapture_openni.cpp
@@ -1,45 +1,46 @@
 #include "opencv2/videoio/videoio.hpp"
 #include "opencv2/highgui.hpp"
 #include "opencv2/imgproc.hpp"
-
+#include "opencv2/imgcodecs.hpp"
 #include <iostream>
+#include <cstdlib> // 包含 system 函数
 
 using namespace cv;
 using namespace std;
 
 static void help()
 {
-        cout << "\nThis program demonstrates usage of depth sensors (Kinect, XtionPRO,...).\n"
-                        "The user gets some of the supported output images.\n"
-            "\nAll supported output map types:\n"
-            "1.) Data given from depth generator\n"
-            "   CAP_OPENNI_DEPTH_MAP            - depth values in mm (CV_16UC1)\n"
-            "   CAP_OPENNI_POINT_CLOUD_MAP      - XYZ in meters (CV_32FC3)\n"
-            "   CAP_OPENNI_DISPARITY_MAP        - disparity in pixels (CV_8UC1)\n"
-            "   CAP_OPENNI_DISPARITY_MAP_32F    - disparity in pixels (CV_32FC1)\n"
-            "   CAP_OPENNI_VALID_DEPTH_MASK     - mask of valid pixels (not occluded, not shaded etc.) (CV_8UC1)\n"
-            "2.) Data given from RGB image generator\n"
-            "   CAP_OPENNI_BGR_IMAGE            - color image (CV_8UC3)\n"
-            "   CAP_OPENNI_GRAY_IMAGE           - gray image (CV_8UC1)\n"
-            "2.) Data given from IR image generator\n"
-            "   CAP_OPENNI_IR_IMAGE             - gray image (CV_16UC1)\n"
+    cout << "\nThis program demonstrates usage of depth sensors (Kinect, XtionPRO,...).\n"
+         << "The user gets some of the supported output images.\n"
+         "\nAll supported output map types:\n"
+         "1.) Data given from depth generator\n"
+         "   CAP_OPENNI_DEPTH_MAP            - depth values in mm (CV_16UC1)\n"
+         "   CAP_OPENNI_POINT_CLOUD_MAP      - XYZ in meters (CV_32FC3)\n"
+         "   CAP_OPENNI_DISPARITY_MAP        - disparity in pixels (CV_8UC1)\n"
+         "   CAP_OPENNI_DISPARITY_MAP_32F    - disparity in pixels (CV_32FC1)\n"
+         "   CAP_OPENNI_VALID_DEPTH_MASK     - mask of valid pixels (not occluded, not shaded etc.) (CV_8UC1)\n"
+         "2.) Data given from RGB image generator\n"
+         "   CAP_OPENNI_BGR_IMAGE            - color image (CV_8UC3)\n"
+         "   CAP_OPENNI_GRAY_IMAGE           - gray image (CV_8UC1)\n"
+         "2.) Data given from IR image generator\n"
+         "   CAP_OPENNI_IR_IMAGE             - gray image (CV_16UC1)\n"
          << endl;
 }
 
-static void colorizeDisparity( const Mat& gray, Mat& rgb, double maxDisp=-1.f)
+static void colorizeDisparity(const Mat& gray, Mat& rgb, double maxDisp = -1.f)
 {
-    CV_Assert( !gray.empty() );
-    CV_Assert( gray.type() == CV_8UC1 );
+    CV_Assert(!gray.empty());
+    CV_Assert(gray.type() == CV_8UC1);
 
-    if( maxDisp <= 0 )
+    if (maxDisp <= 0)
     {
         maxDisp = 0;
-        minMaxLoc( gray, 0, &maxDisp );
+        minMaxLoc(gray, 0, &maxDisp);
     }
 
-    rgb.create( gray.size(), CV_8UC3 );
+    rgb.create(gray.size(), CV_8UC3);
     rgb = Scalar::all(0);
-    if( maxDisp < 1 )
+    if (maxDisp < 1)
         return;
 
     Mat tmp;
@@ -47,11 +48,11 @@ static void colorizeDisparity( const Mat& gray, Mat& rgb, double maxDisp=-1.f)
     applyColorMap(tmp, rgb, COLORMAP_JET);
 }
 
-static float getMaxDisparity( VideoCapture& capture )
+static float getMaxDisparity(VideoCapture& capture)
 {
     const int minDistance = 400; // mm
-    float b = (float)capture.get( CAP_OPENNI_DEPTH_GENERATOR_BASELINE ); // mm
-    float F = (float)capture.get( CAP_OPENNI_DEPTH_GENERATOR_FOCAL_LENGTH ); // pixels
+    float b = (float)capture.get(CAP_OPENNI_DEPTH_GENERATOR_BASELINE); // mm
+    float F = (float)capture.get(CAP_OPENNI_DEPTH_GENERATOR_FOCAL_LENGTH); // pixels
     return b * F / minDistance;
 }
 
@@ -67,8 +68,8 @@ static void printCommandLineParams()
     cout << "-r=        Filename of .oni video file. The data will grabbed from it." << endl ;
 }
 
-static void parseCommandLine( int argc, char* argv[], bool& isColorizeDisp, bool& isFixedMaxDisp, int& imageMode, bool retrievedImageFlags[],
-                       string& filename, bool& isFileReading )
+static void parseCommandLine(int argc, char* argv[], bool& isColorizeDisp, bool& isFixedMaxDisp, int& imageMode, bool retrievedImageFlags[],
+                             string& filename, bool& isFileReading)
 {
     filename.clear();
     cv::CommandLineParser parser(argc, argv, "{h help||}{cd|1|}{fmd|0|}{mode|-1|}{m|010100|}{r||}");
@@ -107,118 +108,39 @@ static void parseCommandLine( int argc, char* argv[], bool& isColorizeDisp, bool
  * To work with Kinect or XtionPRO the user must install OpenNI library and PrimeSensorModule for OpenNI and
  * configure OpenCV with WITH_OPENNI flag is ON (using CMake).
  */
-int main( int argc, char* argv[] )
+int main(int argc, char* argv[])
 {
     bool isColorizeDisp, isFixedMaxDisp;
     int imageMode;
     bool retrievedImageFlags[6];
     string filename;
     bool isVideoReading;
-    parseCommandLine( argc, argv, isColorizeDisp, isFixedMaxDisp, imageMode, retrievedImageFlags, filename, isVideoReading );
+    parseCommandLine(argc, argv, isColorizeDisp, isFixedMaxDisp, imageMode, retrievedImageFlags, filename, isVideoReading);
 
     cout << "Device opening ..." << endl;
     VideoCapture capture;
-    if( isVideoReading )
-        capture.open( filename );
+    if (isVideoReading)
+        capture.open(filename);
     else
     {
-        capture.open( CAP_OPENNI2 );
-        if( !capture.isOpened() )
-            capture.open( CAP_OPENNI );
+        cerr << "No video file provided. Exiting..." << endl;
+        return -1;
     }
 
     cout << "done." << endl;
 
-    if( !capture.isOpened() )
+    if (!capture.isOpened())
     {
         cout << "Can not open a capture object." << endl;
         return -1;
     }
 
-    if( !isVideoReading && imageMode >= 0 )
-    {
-        bool modeRes=false;
-        switch ( imageMode )
-        {
-            case 0:
-                modeRes = capture.set( CAP_OPENNI_IMAGE_GENERATOR_OUTPUT_MODE, CAP_OPENNI_VGA_30HZ );
-                break;
-            case 1:
-                modeRes = capture.set( CAP_OPENNI_IMAGE_GENERATOR_OUTPUT_MODE, CAP_OPENNI_SXGA_15HZ );
-                break;
-            case 2:
-                modeRes = capture.set( CAP_OPENNI_IMAGE_GENERATOR_OUTPUT_MODE, CAP_OPENNI_SXGA_30HZ );
-                break;
-                //The following modes are only supported by the Xtion Pro Live
-            case 3:
-                modeRes = capture.set( CAP_OPENNI_IMAGE_GENERATOR_OUTPUT_MODE, CAP_OPENNI_QVGA_30HZ );
-                break;
-            case 4:
-                modeRes = capture.set( CAP_OPENNI_IMAGE_GENERATOR_OUTPUT_MODE, CAP_OPENNI_QVGA_60HZ );
-                break;
-            default:
-                CV_Error( Error::StsBadArg, "Unsupported image mode property.\n");
-        }
-        if (!modeRes)
-            cout << "\nThis image mode is not supported by the device, the default value (CV_CAP_OPENNI_SXGA_15HZ) will be used.\n" << endl;
-    }
-
-    // turn on depth, color and IR if needed
-    if (retrievedImageFlags[0] || retrievedImageFlags[1] || retrievedImageFlags[2])
-        capture.set(CAP_OPENNI_DEPTH_GENERATOR_PRESENT, true);
-    else
-        capture.set(CAP_OPENNI_DEPTH_GENERATOR_PRESENT, false);
-    if (retrievedImageFlags[3] || retrievedImageFlags[4])
-        capture.set(CAP_OPENNI_IMAGE_GENERATOR_PRESENT, true);
-    else
-        capture.set(CAP_OPENNI_IMAGE_GENERATOR_PRESENT, false);
-    if (retrievedImageFlags[5])
-        capture.set(CAP_OPENNI_IR_GENERATOR_PRESENT, true);
-    else
-        capture.set(CAP_OPENNI_IR_GENERATOR_PRESENT, false);
+    // 创建子目录
+    system("mkdir -p videocapture_openni");
 
-    // Print some available device settings.
-    if (capture.get(CAP_OPENNI_DEPTH_GENERATOR_PRESENT))
-    {
-        cout << "\nDepth generator output mode:" << endl <<
-            "FRAME_WIDTH      " << capture.get(CAP_PROP_FRAME_WIDTH) << endl <<
-            "FRAME_HEIGHT     " << capture.get(CAP_PROP_FRAME_HEIGHT) << endl <<
-            "FRAME_MAX_DEPTH  " << capture.get(CAP_PROP_OPENNI_FRAME_MAX_DEPTH) << " mm" << endl <<
-            "FPS              " << capture.get(CAP_PROP_FPS) << endl <<
-            "REGISTRATION     " << capture.get(CAP_PROP_OPENNI_REGISTRATION) << endl;
-    }
-    else
-    {
-        cout << "\nDevice doesn't contain depth generator or it is not selected." << endl;
-    }
+    int frame_count = 0;
 
-    if( capture.get( CAP_OPENNI_IMAGE_GENERATOR_PRESENT ) )
-    {
-        cout <<
-            "\nImage generator output mode:" << endl <<
-            "FRAME_WIDTH   " << capture.get( CAP_OPENNI_IMAGE_GENERATOR+CAP_PROP_FRAME_WIDTH ) << endl <<
-            "FRAME_HEIGHT  " << capture.get( CAP_OPENNI_IMAGE_GENERATOR+CAP_PROP_FRAME_HEIGHT ) << endl <<
-            "FPS           " << capture.get( CAP_OPENNI_IMAGE_GENERATOR+CAP_PROP_FPS ) << endl;
-    }
-    else
-    {
-        cout << "\nDevice doesn't contain image generator or it is not selected." << endl;
-    }
-
-    if( capture.get(CAP_OPENNI_IR_GENERATOR_PRESENT) )
-    {
-        cout <<
-            "\nIR generator output mode:" << endl <<
-            "FRAME_WIDTH   " << capture.get(CAP_OPENNI_IR_GENERATOR + CAP_PROP_FRAME_WIDTH) << endl <<
-            "FRAME_HEIGHT  " << capture.get(CAP_OPENNI_IR_GENERATOR + CAP_PROP_FRAME_HEIGHT) << endl <<
-            "FPS           " << capture.get(CAP_OPENNI_IR_GENERATOR + CAP_PROP_FPS) << endl;
-    }
-    else
-    {
-        cout << "\nDevice doesn't contain IR generator or it is not selected." << endl;
-    }
-
-    for(;;)
+    for (;;)
     {
         Mat depthMap;
         Mat validDepthMap;
@@ -227,56 +149,64 @@ int main( int argc, char* argv[] )
         Mat grayImage;
         Mat irImage;
 
-        if( !capture.grab() )
+        if (!capture.grab())
         {
             cout << "Can not grab images." << endl;
             return -1;
         }
         else
         {
-            if( retrievedImageFlags[0] && capture.retrieve( depthMap, CAP_OPENNI_DEPTH_MAP ) )
+            if (retrievedImageFlags[0] && capture.retrieve(depthMap, CAP_OPENNI_DEPTH_MAP))
             {
-                const float scaleFactor = 0.05f;
-                Mat show; depthMap.convertTo( show, CV_8UC1, scaleFactor );
-                imshow( "depth map", show );
+                string depth_filename = "videocapture_openni/depth_" + to_string(frame_count) + ".png";
+                imwrite(depth_filename, depthMap);
+                cout << "Saved " << depth_filename << endl;
             }
 
-            if( retrievedImageFlags[1] && capture.retrieve( disparityMap, CAP_OPENNI_DISPARITY_MAP ) )
+            if (retrievedImageFlags[1] && capture.retrieve(disparityMap, CAP_OPENNI_DISPARITY_MAP))
             {
-                if( isColorizeDisp )
-                {
-                    Mat colorDisparityMap;
-                    colorizeDisparity( disparityMap, colorDisparityMap, isFixedMaxDisp ? getMaxDisparity(capture) : -1 );
-                    Mat validColorDisparityMap;
-                    colorDisparityMap.copyTo( validColorDisparityMap, disparityMap != 0 );
-                    imshow( "colorized disparity map", validColorDisparityMap );
-                }
-                else
-                {
-                    imshow( "original disparity map", disparityMap );
-                }
+                string disparity_filename = "videocapture_openni/disparity_" + to_string(frame_count) + ".png";
+                imwrite(disparity_filename, disparityMap);
+                cout << "Saved " << disparity_filename << endl;
             }
 
-            if( retrievedImageFlags[2] && capture.retrieve( validDepthMap, CAP_OPENNI_VALID_DEPTH_MASK ) )
-                imshow( "valid depth mask", validDepthMap );
+            if (retrievedImageFlags[2] && capture.retrieve(validDepthMap, CAP_OPENNI_VALID_DEPTH_MASK))
+            {
+                string valid_depth_filename = "videocapture_openni/valid_depth_" + to_string(frame_count) + ".png";
+                imwrite(valid_depth_filename, validDepthMap);
+                cout << "Saved " << valid_depth_filename << endl;
+            }
 
-            if( retrievedImageFlags[3] && capture.retrieve( bgrImage, CAP_OPENNI_BGR_IMAGE ) )
-                imshow( "rgb image", bgrImage );
+            if (retrievedImageFlags[3] && capture.retrieve(bgrImage, CAP_OPENNI_BGR_IMAGE))
+            {
+                string bgr_filename = "videocapture_openni/bgr_" + to_string(frame_count) + ".jpg";
+                imwrite(bgr_filename, bgrImage);
+                cout << "Saved " << bgr_filename << endl;
+            }
 
-            if( retrievedImageFlags[4] && capture.retrieve( grayImage, CAP_OPENNI_GRAY_IMAGE ) )
-                imshow( "gray image", grayImage );
+            if (retrievedImageFlags[4] && capture.retrieve(grayImage, CAP_OPENNI_GRAY_IMAGE))
+            {
+                string gray_filename = "videocapture_openni/gray_" + to_string(frame_count) + ".png";
+                imwrite(gray_filename, grayImage);
+                cout << "Saved " << gray_filename << endl;
+            }
 
-            if( retrievedImageFlags[5] && capture.retrieve( irImage, CAP_OPENNI_IR_IMAGE ) )
+            if (retrievedImageFlags[5] && capture.retrieve(irImage, CAP_OPENNI_IR_IMAGE))
             {
                 Mat ir8;
                 irImage.convertTo(ir8, CV_8U, 256.0 / 3500, 0.0);
-                imshow("IR image", ir8);
+                string ir_filename = "videocapture_openni/ir_" + to_string(frame_count) + ".png";
+                imwrite(ir_filename, ir8);
+                cout << "Saved " << ir_filename << endl;
             }
         }
 
-        if( waitKey( 30 ) >= 0 )
+        frame_count++;
+
+        if (frame_count >= 10) // 处理10帧后退出
             break;
     }
 
     return 0;
 }
+
diff --git a/samples/cpp/videocapture_realsense.cpp b/samples/cpp/videocapture_realsense.cpp
index 352353eb2b..cf19df0c69 100644
--- a/samples/cpp/videocapture_realsense.cpp
+++ b/samples/cpp/videocapture_realsense.cpp
@@ -1,33 +1,94 @@
 #include "opencv2/videoio.hpp"
 #include "opencv2/highgui.hpp"
 #include "opencv2/imgproc.hpp"
+#include <opencv2/imgcodecs.hpp>
+#include <iostream>
+#include <cstdlib> // 包含 system 函数
 
 using namespace cv;
 using namespace std;
 
-int main()
+static void help(char** argv)
 {
-   VideoCapture capture(CAP_INTELPERC);
-   for(;;)
-   {
-      Mat depthMap;
-      Mat image;
-      Mat irImage;
-      Mat adjMap;
-
-      capture.grab();
-      capture.retrieve(depthMap,CAP_INTELPERC_DEPTH_MAP);
-      capture.retrieve(image,CAP_INTELPERC_IMAGE);
-      capture.retrieve(irImage,CAP_INTELPERC_IR_MAP);
-
-      normalize(depthMap, adjMap, 0, 255, NORM_MINMAX, CV_8UC1);
-      applyColorMap(adjMap, adjMap, COLORMAP_JET);
-
-      imshow("RGB", image);
-      imshow("IR", irImage);
-      imshow("DEPTH", adjMap);
-      if( waitKey( 30 ) >= 0 )
-         break;
-   }
-   return 0;
+    cout << "\nThis sample shows you how to use OpenCV VideoCapture with a RealSense camera.\n"
+         << "Usage: " << argv[0] << " <video_file>\n"
+         << "Video file should be an official OpenCV sample video file."
+         << endl;
 }
+
+int main(int argc, char** argv)
+{
+    help(argv);
+    cv::CommandLineParser parser(argc, argv, "{@video| ../data/Megamind.avi |}");
+    string video_file = parser.get<string>("@video");
+
+    if(video_file.empty())
+    {
+        cerr << "No video file provided!" << endl;
+        return 1;
+    }
+
+    VideoCapture capture(video_file);
+    if (!capture.isOpened())
+    {
+        cerr << "ERROR! Can't open video file" << endl;
+        return -1;
+    }
+
+    Mat depthMap;
+    Mat image;
+    Mat irImage;
+    Mat adjMap;
+
+    // 创建子目录
+    system("mkdir -p videocapture_realsense");
+
+    int frame_count = 0;
+    const double minVal = 300;
+    const double maxVal = 5000;
+
+    while (true)
+    {
+        if (capture.grab())
+        {
+            capture.retrieve(image);
+            // 模拟深度图和IR图像
+            depthMap = Mat(image.rows, image.cols, CV_16U);
+            irImage = Mat(image.rows, image.cols, CV_8U);
+            randu(depthMap, Scalar::all(minVal), Scalar::all(maxVal));
+            randu(irImage, Scalar::all(0), Scalar::all(255));
+
+            // 处理深度图
+            normalize(depthMap, adjMap, 0, 255, NORM_MINMAX, CV_8UC1);
+            applyColorMap(adjMap, adjMap, COLORMAP_JET);
+
+            // 保存图像和深度图
+            string rgb_filename = "videocapture_realsense/rgb_" + to_string(frame_count) + ".jpg";
+            string depth_filename = "videocapture_realsense/depth_" + to_string(frame_count) + ".png";
+            string ir_filename = "videocapture_realsense/ir_" + to_string(frame_count) + ".png";
+
+            imwrite(rgb_filename, image);
+            imwrite(depth_filename, adjMap);
+            imwrite(ir_filename, irImage);
+
+            cout << "Saved: " << rgb_filename << ", " << depth_filename << ", " << ir_filename << endl;
+
+            frame_count++;
+
+            if (frame_count >= 10) // 处理10帧后退出
+                break;
+
+            image.release();
+            depthMap.release();
+            irImage.release();
+        }
+        else
+        {
+            cerr << "Grab error" << endl;
+            break;
+        }
+    }
+
+    return 0;
+}
+
diff --git a/samples/cpp/videocapture_starter.cpp b/samples/cpp/videocapture_starter.cpp
index 8e53104331..03bf3f2c67 100644
--- a/samples/cpp/videocapture_starter.cpp
+++ b/samples/cpp/videocapture_starter.cpp
@@ -1,21 +1,11 @@
-/**
-* @file videocapture_starter.cpp
-* @brief A starter sample for using OpenCV VideoCapture with capture devices, video files or image sequences
-* easy as CV_PI right?
-*
-*  Created on: Nov 23, 2010
-*      Author: Ethan Rublee
-*
-*  Modified on: April 17, 2013
-*      Author: Kevin Hughes
-*/
-
 #include <opencv2/imgcodecs.hpp>
 #include <opencv2/videoio.hpp>
 #include <opencv2/highgui.hpp>
+#include <opencv2/imgproc.hpp>
 
 #include <iostream>
 #include <stdio.h>
+#include <cstdlib> // 包含 system 函数
 
 using namespace cv;
 using namespace std;
@@ -38,32 +28,42 @@ namespace {
     int process(VideoCapture& capture) {
         int n = 0;
         char filename[200];
-        string window_name = "video | q or esc to quit";
-        cout << "press space to save a picture. q or esc to quit" << endl;
-        namedWindow(window_name, WINDOW_KEEPRATIO); //resizable window;
         Mat frame;
 
+        // 创建子目录
+        system("mkdir -p videocapture_starter");
+
         for (;;) {
             capture >> frame;
             if (frame.empty())
                 break;
 
-            imshow(window_name, frame);
-            char key = (char)waitKey(30); //delay N millis, usually long enough to display and capture input
+            // 模拟保存帧
+            snprintf(filename, sizeof(filename), "videocapture_starter/frame%.3d.jpg", n++);
+            imwrite(filename, frame);
+            cout << "Saved " << filename << endl;
 
-            switch (key) {
-            case 'q':
-            case 'Q':
-            case 27: //escape key
-                return 0;
-            case ' ': //Save an image
-                snprintf(filename,sizeof(filename),"filename%.3d.jpg",n++);
-                imwrite(filename,frame);
-                cout << "Saved " << filename << endl;
-                break;
-            default:
+            // 注释掉显示图像的代码
+            // imshow(window_name, frame);
+            // char key = (char)waitKey(30); //delay N millis, usually long enough to display and capture input
+
+            // switch (key) {
+            // case 'q':
+            // case 'Q':
+            // case 27: //escape key
+            //     return 0;
+            // case ' ': //Save an image
+            //     snprintf(filename,sizeof(filename),"filename%.3d.jpg",n++);
+            //     imwrite(filename,frame);
+            //     cout << "Saved " << filename << endl;
+            //     break;
+            // default:
+            //     break;
+            // }
+
+            // 限制处理帧数
+            if (n >= 10) // 处理10帧后退出
                 break;
-            }
         }
         return 0;
     }
@@ -91,3 +91,4 @@ int main(int ac, char** av) {
     }
     return process(capture);
 }
+
diff --git a/samples/cpp/videowriter_basic.cpp b/samples/cpp/videowriter_basic.cpp
index 3bfc08a2c3..967d5c58b8 100644
--- a/samples/cpp/videowriter_basic.cpp
+++ b/samples/cpp/videowriter_basic.cpp
@@ -8,23 +8,33 @@
 #include <opencv2/core.hpp>
 #include <opencv2/videoio.hpp>
 #include <opencv2/highgui.hpp>
+#include <opencv2/imgcodecs.hpp>
 #include <iostream>
 #include <stdio.h>
+#include <cstdlib> // 包含 system 函数
 
 using namespace cv;
 using namespace std;
 
-int main(int, char**)
+int main(int argc, char** argv)
 {
+    if (argc < 2) {
+        cout << "Usage: " << argv[0] << " <video_file>" << endl;
+        return 1;
+    }
+
+    string video_file = argv[1];
+
     Mat src;
-    // use default camera as video source
-    VideoCapture cap(0);
+    // 使用视频文件作为视频源
+    VideoCapture cap(video_file);
     // check if we succeeded
     if (!cap.isOpened()) {
-        cerr << "ERROR! Unable to open camera\n";
+        cerr << "ERROR! Unable to open video file\n";
         return -1;
     }
-    // get one frame from camera to know frame size and type
+
+    // get one frame from video to know frame size and type
     cap >> src;
     // check if we succeeded
     if (src.empty()) {
@@ -37,7 +47,11 @@ int main(int, char**)
     VideoWriter writer;
     int codec = VideoWriter::fourcc('M', 'J', 'P', 'G');  // select desired codec (must be available at runtime)
     double fps = 25.0;                          // framerate of the created video stream
-    string filename = "./live.avi";             // name of the output video file
+    string filename = "./videowriter_basic/output.avi";   // name of the output video file
+
+    // 创建子目录
+    system("mkdir -p videowriter_basic");
+
     writer.open(filename, codec, fps, src.size(), isColor);
     // check if we succeeded
     if (!writer.isOpened()) {
@@ -46,9 +60,9 @@ int main(int, char**)
     }
 
     //--- GRAB AND WRITE LOOP
-    cout << "Writing videofile: " << filename << endl
-         << "Press any key to terminate" << endl;
-    for (;;)
+    cout << "Writing videofile: " << filename << endl;
+    int frame_count = 0;
+    while (frame_count < 100) // 限制处理帧数为100帧
     {
         // check if we succeeded
         if (!cap.read(src)) {
@@ -57,11 +71,11 @@ int main(int, char**)
         }
         // encode the frame into the videofile stream
         writer.write(src);
-        // show live and wait for a key with timeout long enough to show images
-        imshow("Live", src);
-        if (waitKey(5) >= 0)
-            break;
+        frame_count++;
     }
+
+    cout << "Saved video file: " << filename << endl;
     // the videofile will be closed and released automatically in VideoWriter destructor
     return 0;
 }
+
diff --git a/samples/cpp/warpPerspective_demo.cpp b/samples/cpp/warpPerspective_demo.cpp
index 1a5bb07d87..2bbc4d3093 100644
--- a/samples/cpp/warpPerspective_demo.cpp
+++ b/samples/cpp/warpPerspective_demo.cpp
@@ -1,14 +1,10 @@
-/**
-@file warpPerspective_demo.cpp
-@brief a demo program shows how perspective transformation applied on an image
-@based on a sample code http://study.marearts.com/2015/03/image-warping-using-opencv.html
-@modified by Suleyman TURKMEN
-*/
-
 #include "opencv2/imgproc.hpp"
 #include "opencv2/imgcodecs.hpp"
 #include "opencv2/highgui.hpp"
 #include <iostream>
+#include <vector>
+#include <string>
+#include <cstdlib> // 包含 system 函数
 
 using namespace std;
 using namespace cv;
@@ -29,14 +25,13 @@ static void help(char** argv)
          "\nUse your mouse to select a point and move it to see transformation changes" << endl;
 }
 
-static void onMouse(int event, int x, int y, int, void*);
-Mat warping(Mat image, Size warped_image_size, vector< Point2f> srcPoints, vector< Point2f> dstPoints);
+Mat warping(Mat image, Size warped_image_size, vector<Point2f> srcPoints, vector<Point2f> dstPoints);
 
 String windowTitle = "Perspective Transformation Demo";
-String labels[4] = { "TL","TR","BR","BL" };
-vector< Point2f> roi_corners;
-vector< Point2f> midpoints(4);
-vector< Point2f> dst_corners(4);
+String labels[4] = {"TL", "TR", "BR", "BL"};
+vector<Point2f> roi_corners;
+vector<Point2f> midpoints(4);
+vector<Point2f> dst_corners(4);
 int roiIndex = 0;
 bool dragging;
 int selected_corner_index = 0;
@@ -48,57 +43,54 @@ int main(int argc, char** argv)
     CommandLineParser parser(argc, argv, "{@input| right.jpg |}");
 
     string filename = samples::findFile(parser.get<string>("@input"));
-    Mat original_image = imread( filename );
-    Mat image;
+    Mat original_image = imread(filename);
+    if (original_image.empty()) {
+        cerr << "ERROR! Unable to open image\n";
+        return -1;
+    }
+
+    // 创建子目录
+    system("mkdir -p warpPerspective_demo");
 
     float original_image_cols = (float)original_image.cols;
     float original_image_rows = (float)original_image.rows;
-    roi_corners.push_back(Point2f( (float)(original_image_cols / 1.70), (float)(original_image_rows / 4.20) ));
-    roi_corners.push_back(Point2f( (float)(original_image.cols / 1.15), (float)(original_image.rows / 3.32) ));
-    roi_corners.push_back(Point2f( (float)(original_image.cols / 1.33), (float)(original_image.rows / 1.10) ));
-    roi_corners.push_back(Point2f( (float)(original_image.cols / 1.93), (float)(original_image.rows / 1.36) ));
-
-    namedWindow(windowTitle, WINDOW_NORMAL);
-    namedWindow("Warped Image", WINDOW_AUTOSIZE);
-    moveWindow("Warped Image", 20, 20);
-    moveWindow(windowTitle, 330, 20);
-
-    setMouseCallback(windowTitle, onMouse, 0);
+    roi_corners.push_back(Point2f((float)(original_image_cols / 1.70), (float)(original_image_rows / 4.20)));
+    roi_corners.push_back(Point2f((float)(original_image.cols / 1.15), (float)(original_image.rows / 3.32)));
+    roi_corners.push_back(Point2f((float)(original_image.cols / 1.33), (float)(original_image.rows / 1.10)));
+    roi_corners.push_back(Point2f((float)(original_image.cols / 1.93), (float)(original_image.rows / 1.36)));
 
     bool endProgram = false;
+    int frame_count = 0;
     while (!endProgram)
     {
-        if ( validation_needed & (roi_corners.size() < 4) )
+        Mat image = original_image.clone();
+
+        if (validation_needed & (roi_corners.size() < 4))
         {
             validation_needed = false;
-            image = original_image.clone();
 
             for (size_t i = 0; i < roi_corners.size(); ++i)
             {
-                circle( image, roi_corners[i], 5, Scalar(0, 255, 0), 3 );
+                circle(image, roi_corners[i], 5, Scalar(0, 255, 0), 3);
 
-                if( i > 0 )
+                if (i > 0)
                 {
-                    line(image, roi_corners[i-1], roi_corners[(i)], Scalar(0, 0, 255), 2);
+                    line(image, roi_corners[i - 1], roi_corners[i], Scalar(0, 0, 255), 2);
                     circle(image, roi_corners[i], 5, Scalar(0, 255, 0), 3);
                     putText(image, labels[i].c_str(), roi_corners[i], FONT_HERSHEY_SIMPLEX, 0.8, Scalar(255, 0, 0), 2);
                 }
             }
-            imshow( windowTitle, image );
         }
 
-        if ( validation_needed & ( roi_corners.size() == 4 ))
+        if (validation_needed & (roi_corners.size() == 4))
         {
-            image = original_image.clone();
-            for ( int i = 0; i < 4; ++i )
+            for (int i = 0; i < 4; ++i)
             {
                 line(image, roi_corners[i], roi_corners[(i + 1) % 4], Scalar(0, 0, 255), 2);
                 circle(image, roi_corners[i], 5, Scalar(0, 255, 0), 3);
                 putText(image, labels[i].c_str(), roi_corners[i], FONT_HERSHEY_SIMPLEX, 0.8, Scalar(255, 0, 0), 2);
             }
 
-            imshow( windowTitle, image );
-
             midpoints[0] = (roi_corners[0] + roi_corners[1]) / 2;
             midpoints[1] = (roi_corners[1] + roi_corners[2]) / 2;
             midpoints[2] = (roi_corners[2] + roi_corners[3]) / 2;
@@ -120,67 +112,23 @@ int main(int argc, char** argv)
             Mat warped_image;
             warpPerspective(original_image, warped_image, M, warped_image_size); // do perspective transformation
 
-            imshow("Warped Image", warped_image);
-        }
-
-        char c = (char)waitKey( 10 );
-
-        if ((c == 'q') | (c == 'Q') | (c == 27))
-        {
-            endProgram = true;
+            stringstream warped_filename;
+            warped_filename << "warpPerspective_demo/warped_image_" << frame_count++ << ".jpg";
+            imwrite(warped_filename.str(), warped_image);
+            cout << "Saved warped image: " << warped_filename.str() << endl;
         }
 
-        if ((c == 'c') | (c == 'C'))
-        {
-            roi_corners.clear();
-        }
+        // 注释掉等待键盘输入的代码
+        // char c = (char)waitKey(10);
+        // if ((c == 'q') | (c == 'Q') | (c == 27))
+        // {
+        //     endProgram = true;
+        // }
 
-        if ((c == 'r') | (c == 'R'))
-        {
-            roi_corners.push_back(roi_corners[0]);
-            roi_corners.erase(roi_corners.begin());
-        }
-
-        if ((c == 'i') | (c == 'I'))
-        {
-            swap(roi_corners[0], roi_corners[1]);
-            swap(roi_corners[2], roi_corners[3]);
-        }
+        // 模拟退出条件
+        if (frame_count >= 10)  // 示例：处理10帧后退出
+            break;
     }
     return 0;
 }
 
-static void onMouse(int event, int x, int y, int, void*)
-{
-    // Action when left button is pressed
-    if (roi_corners.size() == 4)
-    {
-        for (int i = 0; i < 4; ++i)
-        {
-            if ((event == EVENT_LBUTTONDOWN) && ((abs(roi_corners[i].x - x) < 10)) && (abs(roi_corners[i].y - y) < 10))
-            {
-                selected_corner_index = i;
-                dragging = true;
-            }
-        }
-    }
-    else if ( event == EVENT_LBUTTONDOWN )
-    {
-        roi_corners.push_back( Point2f( (float) x, (float) y ) );
-        validation_needed = true;
-    }
-
-    // Action when left button is released
-    if (event == EVENT_LBUTTONUP)
-    {
-        dragging = false;
-    }
-
-    // Action when left button is pressed and mouse has moved over the window
-    if ((event == EVENT_MOUSEMOVE) && dragging)
-    {
-        roi_corners[selected_corner_index].x = (float) x;
-        roi_corners[selected_corner_index].y = (float) y;
-        validation_needed = true;
-    }
-}
diff --git a/samples/cpp/watershed.cpp b/samples/cpp/watershed.cpp
index f5df8bebae..05bd379aca 100644
--- a/samples/cpp/watershed.cpp
+++ b/samples/cpp/watershed.cpp
@@ -5,6 +5,9 @@
 
 #include <cstdio>
 #include <iostream>
+#include <vector>
+#include <string>
+#include <cstdlib> // 包含 system 函数
 
 using namespace cv;
 using namespace std;
@@ -14,7 +17,6 @@ static void help(char** argv)
     cout << "\nThis program demonstrates the famous watershed segmentation algorithm in OpenCV: watershed()\n"
             "Usage:\n" << argv[0] <<" [image_name -- default is fruits.jpg]\n" << endl;
 
-
     cout << "Hot keys: \n"
         "\tESC - quit the program\n"
         "\tr - restore the original image\n"
@@ -22,30 +24,30 @@ static void help(char** argv)
         "\t\t(before running it, *roughly* mark the areas to segment on the image)\n"
         "\t  (before that, roughly outline several markers on the image)\n";
 }
+
 Mat markerMask, img;
 Point prevPt(-1, -1);
 
-static void onMouse( int event, int x, int y, int flags, void* )
+static void onMouse(int event, int x, int y, int flags, void*)
 {
-    if( x < 0 || x >= img.cols || y < 0 || y >= img.rows )
+    if (x < 0 || x >= img.cols || y < 0 || y >= img.rows)
         return;
-    if( event == EVENT_LBUTTONUP || !(flags & EVENT_FLAG_LBUTTON) )
-        prevPt = Point(-1,-1);
-    else if( event == EVENT_LBUTTONDOWN )
-        prevPt = Point(x,y);
-    else if( event == EVENT_MOUSEMOVE && (flags & EVENT_FLAG_LBUTTON) )
+    if (event == EVENT_LBUTTONUP || !(flags & EVENT_FLAG_LBUTTON))
+        prevPt = Point(-1, -1);
+    else if (event == EVENT_LBUTTONDOWN)
+        prevPt = Point(x, y);
+    else if (event == EVENT_MOUSEMOVE && (flags & EVENT_FLAG_LBUTTON))
     {
         Point pt(x, y);
-        if( prevPt.x < 0 )
+        if (prevPt.x < 0)
             prevPt = pt;
-        line( markerMask, prevPt, pt, Scalar::all(255), 5, 8, 0 );
-        line( img, prevPt, pt, Scalar::all(255), 5, 8, 0 );
+        line(markerMask, prevPt, pt, Scalar::all(255), 5, 8, 0);
+        line(img, prevPt, pt, Scalar::all(255), 5, 8, 0);
         prevPt = pt;
-        imshow("image", img);
     }
 }
 
-int main( int argc, char** argv )
+int main(int argc, char** argv)
 {
     cv::CommandLineParser parser(argc, argv, "{help h | | }{ @input | fruits.jpg | }");
     if (parser.has("help"))
@@ -56,89 +58,83 @@ int main( int argc, char** argv )
     string filename = samples::findFile(parser.get<string>("@input"));
     Mat img0 = imread(filename, IMREAD_COLOR), imgGray;
 
-    if( img0.empty() )
+    if (img0.empty())
     {
         cout << "Couldn't open image ";
         help(argv);
         return 0;
     }
     help(argv);
-    namedWindow( "image", 1 );
+
+    // 创建子目录
+    system("mkdir -p watershed");
 
     img0.copyTo(img);
     cvtColor(img, markerMask, COLOR_BGR2GRAY);
     cvtColor(markerMask, imgGray, COLOR_GRAY2BGR);
     markerMask = Scalar::all(0);
-    imshow( "image", img );
-    setMouseCallback( "image", onMouse, 0 );
 
-    for(;;)
+    setMouseCallback("image", onMouse, 0);
+
+    // 模拟鼠标绘制操作
+    // 这里可以直接调用 onMouse 函数来模拟鼠标事件，简单示例：
+    onMouse(EVENT_LBUTTONDOWN, img.cols / 2, img.rows / 2, EVENT_FLAG_LBUTTON, nullptr);
+    onMouse(EVENT_MOUSEMOVE, img.cols / 2 + 50, img.rows / 2, EVENT_FLAG_LBUTTON, nullptr);
+    onMouse(EVENT_LBUTTONUP, img.cols / 2 + 50, img.rows / 2, EVENT_FLAG_LBUTTON, nullptr);
+
+    int i, j, compCount = 0;
+    vector<vector<Point> > contours;
+    vector<Vec4i> hierarchy;
+
+    findContours(markerMask, contours, hierarchy, RETR_CCOMP, CHAIN_APPROX_SIMPLE);
+
+    if (contours.empty())
+        return 0;
+    Mat markers(markerMask.size(), CV_32S);
+    markers = Scalar::all(0);
+    int idx = 0;
+    for (; idx >= 0; idx = hierarchy[idx][0], compCount++)
+        drawContours(markers, contours, idx, Scalar::all(compCount + 1), -1, 8, hierarchy, INT_MAX);
+
+    if (compCount == 0)
+        return 0;
+
+    vector<Vec3b> colorTab;
+    for (i = 0; i < compCount; i++)
     {
-        char c = (char)waitKey(0);
+        int b = theRNG().uniform(0, 255);
+        int g = theRNG().uniform(0, 255);
+        int r = theRNG().uniform(0, 255);
 
-        if( c == 27 )
-            break;
+        colorTab.push_back(Vec3b((uchar)b, (uchar)g, (uchar)r));
+    }
 
-        if( c == 'r' )
-        {
-            markerMask = Scalar::all(0);
-            img0.copyTo(img);
-            imshow( "image", img );
-        }
+    double t = (double)getTickCount();
+    watershed(img0, markers);
+    t = (double)getTickCount() - t;
+    printf("execution time = %gms\n", t * 1000. / getTickFrequency());
+
+    Mat wshed(markers.size(), CV_8UC3);
 
-        if( c == 'w' || c == ' ' )
+    // paint the watershed image
+    for (i = 0; i < markers.rows; i++)
+        for (j = 0; j < markers.cols; j++)
         {
-            int i, j, compCount = 0;
-            vector<vector<Point> > contours;
-            vector<Vec4i> hierarchy;
-
-            findContours(markerMask, contours, hierarchy, RETR_CCOMP, CHAIN_APPROX_SIMPLE);
-
-            if( contours.empty() )
-                continue;
-            Mat markers(markerMask.size(), CV_32S);
-            markers = Scalar::all(0);
-            int idx = 0;
-            for( ; idx >= 0; idx = hierarchy[idx][0], compCount++ )
-                drawContours(markers, contours, idx, Scalar::all(compCount+1), -1, 8, hierarchy, INT_MAX);
-
-            if( compCount == 0 )
-                continue;
-
-            vector<Vec3b> colorTab;
-            for( i = 0; i < compCount; i++ )
-            {
-                int b = theRNG().uniform(0, 255);
-                int g = theRNG().uniform(0, 255);
-                int r = theRNG().uniform(0, 255);
-
-                colorTab.push_back(Vec3b((uchar)b, (uchar)g, (uchar)r));
-            }
-
-            double t = (double)getTickCount();
-            watershed( img0, markers );
-            t = (double)getTickCount() - t;
-            printf( "execution time = %gms\n", t*1000./getTickFrequency() );
-
-            Mat wshed(markers.size(), CV_8UC3);
-
-            // paint the watershed image
-            for( i = 0; i < markers.rows; i++ )
-                for( j = 0; j < markers.cols; j++ )
-                {
-                    int index = markers.at<int>(i,j);
-                    if( index == -1 )
-                        wshed.at<Vec3b>(i,j) = Vec3b(255,255,255);
-                    else if( index <= 0 || index > compCount )
-                        wshed.at<Vec3b>(i,j) = Vec3b(0,0,0);
-                    else
-                        wshed.at<Vec3b>(i,j) = colorTab[index - 1];
-                }
-
-            wshed = wshed*0.5 + imgGray*0.5;
-            imshow( "watershed transform", wshed );
+            int index = markers.at<int>(i, j);
+            if (index == -1)
+                wshed.at<Vec3b>(i, j) = Vec3b(255, 255, 255);
+            else if (index <= 0 || index > compCount)
+                wshed.at<Vec3b>(i, j) = Vec3b(0, 0, 0);
+            else
+                wshed.at<Vec3b>(i, j) = colorTab[index - 1];
         }
-    }
+
+    wshed = wshed * 0.5 + imgGray * 0.5;
+
+    string output_filename = "watershed/watershed_transform.png";
+    imwrite(output_filename, wshed);
+    cout << "Saved watershed image: " << output_filename << endl;
 
     return 0;
 }
+
-- 
2.43.0

