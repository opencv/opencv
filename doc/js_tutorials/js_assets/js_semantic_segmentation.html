<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <title>Semantic segmentation example</title>
    <link href="js_example_style.css" rel="stylesheet" type="text/css" />
</head>

<body>
<h2>Semantic segmentation Example</h2>
<p>
    This tutorial show you how to write an semantic segmentation example with OpenCV.js.<br>
    Click <b>Try it</b> button to see the result. You can choose any other images.<br>
    You can also change the parameters in the first code snippet to investigate more models.
</p>    

<div class="control"><button id="tryIt">Try it</button></div>
<div>
    <table cellpadding="0" cellspacing="0" width="0" border="0">
        <tr>
            <td>
                <canvas id="canvasInput" width="400" height="400"></canvas>
            </td>
            <td>
                <canvas id="canvasOutput" style="visibility: hidden;" width="400" height="400"></canvas>
            </td>
        </tr>
        <tr>
            <td>
                <div class="caption">
                    canvasInput <input type="file" id="fileInput" name="file" accept="image/*">
                </div>
            </td>
            <td>
                <p id='status' align="left"></p>
            </td>
        </tr>
    </table>
</div>

<div>
    <h3>Help function</h3>
    <p>1.The parameters for model inference which you can modify to investigate more models.</p>
    <textarea class="code" rows="10" cols="100" id="codeEditor" spellcheck="false"></textarea>
    <p>2.Main loop in which will read the image from canvas and do inference once.</p>
    <textarea class="code" rows="26" cols="100" id="codeEditor1" spellcheck="false"></textarea>
    <p>3.Get blob from image as input for net, and standardize it with <b>mean</b> and <b>std</b>.</p>
    <textarea class="code" rows="11" cols="100" id="codeEditor2" spellcheck="false"></textarea>
    <p>4.Fetch model from network and save to emscripten file system.</p>
    <textarea class="code" rows="35" cols="100" id="codeEditor3" spellcheck="false"></textarea>
    <p>5.The post-processing, including gengerate colors for different classes and argmax to get the classes for each pixel.</p>
    <textarea class="code" rows="35" cols="100" id="codeEditor4" spellcheck="false"></textarea>
    <p class="err" id="errorMessage"></p>
</div>

<script src="utils.js" type="text/javascript"></script>

<script id="codeSnippet" type="text/code-snippet">
inputSize = [513, 513];
mean = [127.5, 127.5, 127.5];
std = 0.007843;
rgb = true;

// url for model, config and label files, can from native or Internet
// for model type like onnx which doesn't need config file, just let configUrl = ""
modelUrl = "deeplabV3.pb";
configUrl = "";
</script>

<script id="codeSnippet1" type="text/code-snippet">
main = async function() {
    const url = {
        modelUrl: modelUrl,
        configUrl: configUrl
    }; 
    const path = await loadModel(url);
    const input = getBlodFromImage(inputSize, mean, std, rgb);
    let net;
    if(path.configPath == "") {
        net = cv.readNet(path.modelPath);
    } else {
        net = cv.readNet(path.configPath, path.modelPath);
    }
    net.setInput(input);
    const start = performance.now();
    const result = net.forward();
    const time  = performance.now()-start;
    const colors = generateColors(result);
    const output = argmax(result, colors);

    updateResult(output, time);
    input.delete();
    net.delete();
    result.delete();
}
</script>

<script id="codeSnippet2" type="text/code-snippet">
getBlodFromImage = function() {
    let mat = cv.imread("canvasInput");
    let matC3 = new cv.Mat(mat.matSize[0],mat.matSize[1],cv.CV_8UC3);
    cv.cvtColor(mat, matC3, cv.COLOR_RGBA2RGB);
    let input = cv.blobFromImage(matC3, std, new cv.Size(inputSize[0], inputSize[1]), 
                                 new cv.Scalar(mean[0], mean[1], mean[2]), rgb);
    mat.delete();
    matC3.delete();
    return input;
}
</script>

<script id="codeSnippet3" type="text/code-snippet">
// get name of model and config file from url
function getNameFromUrl(url) {
    const modelParts = url.modelUrl.split('/');
    const modelPath = modelParts[modelParts.length-1];
    const configParts = url.configUrl.split('/');
    const configPath = configParts[configParts.length-1];
    return {
        modelPath: modelPath,
        configPath: configPath
    }
}

loadModel = async function(url) {
    path = getNameFromUrl(url);
    return new Promise((resolve) => {
        // check if the model has been loaded before
        if(modelLoaded.indexOf(path.modelPath) == -1){
            document.getElementById('status').innerHTML = 'Loading model...';
            utils.createFileFromUrl(path.modelPath, url.modelUrl, () => {
                modelLoaded.push(path.modelPath);
                // check if need to load config file
                if(url.configUrl !== "") {
                    utils.createFileFromUrl(path.configPath, url.configUrl, () => {
                        resolve(path);
                    });
                } else {
                    resolve(path);
                }
            });
        } else {
            resolve(path);
        }
    });
}
</script>

<script id="codeSnippet4" type="text/code-snippet">
generateColors = function(result) {
    const numClasses = result.matSize[1];
    let colors = [0,0,0];
    while(colors.length < numClasses*3){
        colors.push(Math.round((Math.random()*255 + colors[colors.length-3]) / 2));
    }
    return colors;
}

argmax = function(result, colors) {
    const C = result.matSize[1];
    const H = result.matSize[2];
    const W = result.matSize[3];
    const resultData = result.data32F;
    const imgSize = H*W;

    let classId = [];
    for (i = 0; i<imgSize; ++i){
        id = 0;
        for (j = 0; j < C; ++j){
            if(resultData[j*imgSize+i] > resultData[id*imgSize+i]){
                id = j;
            }
        }
        classId.push(colors[id*3]);
        classId.push(colors[id*3+1]);
        classId.push(colors[id*3+2]);
        classId.push(255);
    }

    output = cv.matFromArray(H,W,cv.CV_8UC4,classId);
    return output;
}
</script>

<script type="text/javascript">
    let utils = new Utils('errorMessage');

    utils.loadCode('codeSnippet', 'codeEditor');
    utils.loadCode('codeSnippet1', 'codeEditor1');
    utils.loadCode('codeSnippet2', 'codeEditor2');
    utils.loadCode('codeSnippet3', 'codeEditor3');
    utils.loadCode('codeSnippet4', 'codeEditor4');
    
    let canvas = document.getElementById('canvasInput');
    let ctx = canvas.getContext('2d');
    let img = new Image();
    img.crossOrigin = 'anonymous';
    img.src = 'space_shuttle.jpg';
    img.onload = function() {
        ctx.drawImage(img, 0, 0, canvas.width, canvas.height);
    };

    let tryIt = document.getElementById('tryIt');
    tryIt.addEventListener('click', () => {
        initStatus();
        utils.executeCode('codeEditor');
        utils.executeCode('codeEditor1');
        main();
    });

    let imgInput = document.getElementById('fileInput');
    imgInput.addEventListener('change', (e) => {
        initStatus();
        loadImageToCanvas(e);
    });

    utils.loadOpenCv(() => {
        tryIt.removeAttribute('disabled');
    });

    let modelLoaded = [];
    var main = async function() {};
    var getBlodFromImage = function() {};
    var loadModel = async function(url) {};
    var generateColors = function(result) {};
    var argmax = function(result, colors) {};
    var getNameFromUrl = function(url) {};
    
    utils.executeCode('codeEditor1');
    utils.executeCode('codeEditor2');
    utils.executeCode('codeEditor3');
    utils.executeCode('codeEditor4');

    function updateResult(output, time) {
        try{
            let canvasOutput = document.getElementById('canvasOutput');
            canvasOutput.style.visibility = "visible";
            let resized = new cv.Mat(canvasOutput.width, canvasOutput.height, cv.CV_8UC4);
            cv.resize(output, resized, new cv.Size(canvasOutput.width, canvasOutput.height));
            cv.imshow('canvasOutput', resized);
            let parts = path.modelPath.split('.');
            let format = parts[parts.length-1];
            parts.pop();
            let modelType;
            switch(format) {
                case "caffemodel": {
                    modelType = "Caffe";
                } break;
                case "onnx": {
                    modelType = "ONNX";
                } break;
                case "pb": {
                    modelType = "Tensorflow";
                } break;
                case "net": {
                    modelType = "Torch"
                } break;
                default: break;
            }
            document.getElementById('status').innerHTML = `<b>Model:</b> ${parts.join('.')} ${'(' + modelType + ')'} <br>
                                                         <b>Inference time:</b> ${time.toFixed(2)} ms`;
        } catch(e) {
            console.log(e);
        }
    }

    function initStatus() {
        document.getElementById('status').innerHTML = '';
        document.getElementById('canvasOutput').style.visibility = "hidden";
    }

    function loadImageToCanvas(e) {
        let files = e.target.files;
        let imgUrl = URL.createObjectURL(files[0]);
        let canvas = document.getElementById("canvasInput");
        let ctx = canvas.getContext('2d');
        let img = new Image();
        img.crossOrigin = 'anonymous';
        img.src = imgUrl;
        img.onload = function() {
            ctx.drawImage(img, 0, 0, canvas.width, canvas.height);
        };
    }

</script>
    
</body>

</html>